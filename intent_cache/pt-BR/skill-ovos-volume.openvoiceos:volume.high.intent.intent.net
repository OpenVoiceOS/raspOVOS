FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.30090453782713577624e-01) (1, -8.68275673092035460421e-02) (2, -1.48783421605887700157e-01) (3, -1.42186774402919102744e-01) (4, -8.23774696291116881319e-02) (5, -1.25351638878390736487e+00) (6, -3.62262924303199174147e-01) (7, -4.99068763210166799205e-01) (8, 9.90367829102547858611e+00) (9, -1.12772678870028553177e+00) (10, 4.12865190936417391504e-03) (0, 9.13558449739152145241e+00) (1, 9.16613545512184102471e-01) (2, 1.08390656510494620690e+00) (3, 1.05493493775032431969e+00) (4, 1.08535868326328688305e+00) (5, 5.95962446020021108239e+00) (6, 1.93421309800323487638e-01) (7, 1.28604100597108157444e+02) (8, 1.28172913039643443511e+01) (9, 5.21064825326970915143e+00) (10, 3.84565714676866343691e-01) (0, 1.97970359397889339448e+01) (1, 4.20957502702260177863e-01) (2, 4.00979560593152206671e-01) (3, 5.21494862416768234503e-01) (4, 4.88768663981938467078e-01) (5, -2.37593003360949728275e+00) (6, 2.39054371793481712505e-01) (7, -5.01302966054222487458e+00) (8, 6.30481251077045001807e-01) (9, -9.32858130307547495086e-01) (10, 1.04624655674531230609e+00) (0, 8.06081877480419883852e+00) (1, 7.45627887664466859619e-01) (2, 8.49969357369571687499e-01) (3, 9.15539063630729677001e-01) (4, 8.07461589692264558593e-01) (5, -1.39061728069893630888e+00) (6, -5.84544357967792915787e-01) (7, -5.99256805476186027448e+00) (8, -6.21164461245343613172e+00) (9, -1.22815467405744713214e-01) (10, 1.44893997607365276892e+00) (0, 9.05901084983283055863e+00) (1, 1.87748304871595550480e+00) (2, 1.98139781621969390812e+00) (3, 1.95506102708852935734e+00) (4, 1.94416304794824768010e+00) (5, 2.33564861306367106408e+01) (6, 2.04010303439137646864e-01) (7, 1.28686805938387664128e+02) (8, 1.27400519321281588958e+01) (9, 2.51467421409182723124e+00) (10, 1.11759997293872803681e+00) (0, 4.86618767985668654319e+01) (1, 3.10777130519432343014e-01) (2, 3.12007817422432220944e-01) (3, 2.54370617662949161097e-01) (4, 4.21250919794124878415e-01) (5, -1.20176964669654728901e+00) (6, 1.91444348368690842044e+00) (7, -1.10781373538633101106e+01) (8, 3.66119510064551256789e+00) (9, -3.17105728033711398162e-01) (10, 6.89707272365372214828e-01) (0, 2.14663439312784004587e-01) (1, 5.91927959895210548114e-02) (2, -1.74902260923309182949e-02) (3, 2.46681168055610695877e-02) (4, -1.61755860471648992005e-02) (5, 2.26561896979190979806e+00) (6, -2.08758841375223491710e-01) (7, 1.71358647562347443660e+00) (8, -9.80680941492083135813e+00) (9, -5.23988353444099996814e-01) (10, 5.58424204276333699393e-02) (0, 6.95310895604709156004e+00) (1, 4.59441834370762691719e-01) (2, 5.61500833611160876657e-01) (3, 4.18729053120285854561e-01) (4, 5.00235744993359321420e-01) (5, -3.37522848849571710517e+00) (6, 2.56742465664041796813e-01) (7, -4.07650228946504267213e+00) (8, -1.19982258502475090667e-02) (9, -5.24464944236850305614e-01) (10, 8.99860162189541346045e-01) (0, 2.02536361573348955289e+01) (1, 7.50332408738063838527e-01) (2, 8.00537248295473125026e-01) (3, 8.09142490070985820338e-01) (4, 7.83877757531332042262e-01) (5, -2.54752290655857382973e+00) (6, 4.95186303268464605987e-02) (7, -9.07897655262224034800e+00) (8, -6.93174692250592028309e-01) (9, -9.45914013350927285195e-01) (10, 2.99274587547381321073e+00) (0, -4.52044541892728246602e-01) (1, 2.75794043633985352937e-01) (2, 2.57004484031247981690e-01) (3, 3.19859519097852595948e-01) (4, 2.62116431686925721589e-01) (5, 8.29634803647060437015e-01) (6, -1.89306461891782129570e-01) (7, 2.23291877907397129377e+00) (8, -2.34569781802516930114e+00) (9, 8.27891063126761195257e-01) (10, 5.76279965059908541591e-02) (11, 6.06743233297049489039e-01) (12, 4.09804865216339742062e-01) (13, -1.28141863178250381416e-01) (14, -1.49967493775235966025e-01) (15, 4.30574960505093251584e-01) (16, -4.35540997541799423942e-01) (17, -1.85799350037667426738e-01) (18, -1.16224495721000242732e-01) (19, -1.96289026901818153270e-01) (20, 5.05056525529170463606e-01) (21, 2.37283951764960282516e-01) 
