FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.22224564044136396745e+00) (1, 7.04939378313294696454e+02) (2, -7.47095030321610953372e-01) (3, 4.72563554330829571626e+00) (4, -2.11255682415111278871e+00) (5, 2.04679965532562097019e-01) (6, -7.10672941366900401405e-01) (7, 3.46517277916818366990e+00) (8, 1.83127917536734741155e+00) (9, -1.13095028292309396356e+00) (10, -3.70020704324381055628e-01) (11, 2.61044726026954254650e+00) (12, -2.85796819350248654246e+00) (13, -4.06257672516567236443e+00) (14, 2.19413505142436315865e+00) (15, 7.82159844728713249395e-01) (16, -1.97847213682213390884e-01) (17, 1.52945644556835680383e+00) (18, 3.09587454584303944927e+00) (19, 5.95642601078417821547e-01) (20, 4.13376052918782033174e+00) (21, 6.82872434488765112093e-01) (22, 2.51499421854165383650e+00) (23, -1.62590446304834634894e+00) (0, -2.25810674629491625609e+00) (1, 9.53883707648110572563e+01) (2, -3.74587658582988813905e-01) (3, 5.92789838408117297774e+00) (4, -8.80027802330802522146e-02) (5, 5.73374415631447420516e-01) (6, 3.21642980227822894435e-01) (7, -6.10361770581026918947e-01) (8, 1.37421575387247951738e+00) (9, 2.54564954817565539114e-02) (10, 7.83126612760586038320e-01) (11, 1.33642772278226873439e+00) (12, 5.28421498467546574274e-02) (13, 5.50546664096879245776e-01) (14, 1.10851625972665934761e+00) (15, 2.27449854077939550567e-01) (16, 3.39380563410167257477e-01) (17, 4.44190727019832587441e-01) (18, 2.43063535854064038944e+00) (19, 2.71201832175508895928e-02) (20, 5.79857080489298071235e-01) (21, 3.96107641517510655760e-01) (22, 1.01678970795315359865e+00) (23, -6.88407990796784108323e-02) (0, 5.68509327069574421643e+00) (1, 1.93448198032598206453e+01) (2, 5.13780582782864758684e-01) (3, 2.03891668809478199265e+00) (4, 1.36394475256269354091e+00) (5, -3.91063220240832620789e-01) (6, 1.37912964643806090770e-01) (7, 2.11908230836310024214e-01) (8, -2.17763820592459200753e+00) (9, 5.06381001194253221875e-01) (10, -3.89054653312746667737e+00) (11, -3.43269520304910136232e+00) (12, -7.67921675586847651829e-01) (13, -3.30033249554329044528e+00) (14, -1.73089870718926475135e+00) (15, 7.09812909883917875220e-02) (16, -1.09265475946007193514e-02) (17, -1.10860471921914172100e+00) (18, -4.01046313239831597741e+00) (19, 4.00216174538700841801e-01) (20, -1.11809858544449292062e+00) (21, -3.29522672779807235255e-01) (22, -1.72220794685322253770e+00) (23, 7.26583885317675148841e-01) (24, 1.55587828937730616730e+01) (25, 7.15948306640310838667e-01) (26, -7.20868615989533445543e+00) (27, -3.17405458969916054457e+00) 
