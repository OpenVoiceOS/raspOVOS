FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=27 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (27, 6, 5.00000000000000000000e-01) (27, 6, 5.00000000000000000000e-01) (27, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.28718023546703541626e+00) (1, -3.15649238793250752622e+00) (2, 2.27634056451934962961e-01) (3, 5.95416429851397532858e-01) (4, 1.12703769806805431664e+00) (5, -5.23720352406594133465e-02) (6, -1.48361692204130757311e+00) (7, -1.99515558831567374476e+00) (8, -5.47510842141944897854e-01) (9, -1.41205210588858975918e+00) (10, -2.41707058565617627366e+00) (11, -2.59492106251548548812e+00) (12, -3.02352308848823003729e+00) (13, 1.78878205678811008639e+00) (14, -7.30334114174697179855e-01) (15, -2.87151811072268348113e+00) (16, 1.00077327136158522602e-02) (17, -2.17578785469225310933e+00) (18, -3.49186767493303973353e+00) (19, -3.20442233983121926855e+00) (20, 2.05798961844681915778e+00) (21, -5.07294305171804449373e+00) (22, 5.16747853375408983112e+00) (23, -1.25987157570778518512e+00) (24, -1.30369183021246581866e+00) (25, -1.31566362428127914264e+00) (26, 2.07576535343276225021e+00) (0, 6.50230946393873021627e-01) (1, -1.81509744695618230326e-01) (2, 4.54557080702148383344e-02) (3, -3.88860787316002223801e-02) (4, 1.03205971641900248748e-01) (5, 3.03825345788897971389e-01) (6, -3.30717168063449862281e-01) (7, -7.45563322719082210988e-01) (8, -2.62982188241571379628e-01) (9, -3.24489654080458989061e-01) (10, -5.19369249415092659738e-01) (11, -4.41977681252958443103e-01) (12, 3.58307067576760895911e-01) (13, 5.17355867772836708340e-01) (14, -2.46027494100020088785e-01) (15, -5.45171844891490842144e-01) (16, -1.00748080581434973357e-01) (17, -3.95615597944764196825e-01) (18, -8.57608215880943269838e-01) (19, -2.89517003920625293212e-01) (20, 7.42355242800988635032e-01) (21, -9.97188767519130547790e-01) (22, 1.17942655757018255436e+00) (23, -1.70495388803277386769e-01) (24, -2.82328789827618886754e-01) (25, -1.18373406824860832876e-01) (26, 2.88036323865522359000e-01) (0, 5.76885762067701146627e-01) (1, -3.33752375415756752375e-01) (2, -4.02914835650102984288e-03) (3, -4.45448891703057402690e-04) (4, 2.01114401443364509969e-01) (5, 1.41073447619380509810e-01) (6, -2.95067987651157381812e-01) (7, -8.29789595719322425893e-01) (8, -1.59756882565111141270e-01) (9, -2.88813562171050475236e-01) (10, -5.01823862266235543039e-01) (11, -9.01339038694067423707e-02) (12, 1.91649235386716410012e-01) (13, 5.18618763535757087979e-01) (14, -1.39672862616465276453e-01) (15, -5.33442332527818696697e-01) (16, -1.23462009996184118865e-01) (17, -4.67002993207482508531e-01) (18, -9.11882491779876791504e-01) (19, -1.80874510773039454126e-01) (20, 7.62942035201653157017e-01) (21, -1.01032012161253925697e+00) (22, 1.32537707611867117130e+00) (23, -1.22341943678651116079e-01) (24, -2.34781963524613862537e-01) (25, -1.25964713988099358266e-01) (26, 2.53609054536167277671e-01) (27, -5.26818093859658276301e+01) (28, -2.03110990752323083974e-01) (29, -4.87957181549734775317e-01) (30, -1.19540940918517968328e+00) 
