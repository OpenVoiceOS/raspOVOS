FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.51983525034907795970e+00) (1, 5.44772224467033538531e+02) (2, 9.66357617311213307199e-02) (3, 4.22327616266197480854e+00) (4, -1.61939140158796579527e+00) (5, 2.93701931478503874828e-01) (6, 1.23027244671747179594e-01) (7, 2.92556063944367794605e+00) (8, 1.51943833212436896218e+00) (9, 4.37954529807288370225e-02) (10, 1.46183059800179315779e+00) (11, 2.07536765237257903038e+00) (12, -4.14552608208630102293e-01) (13, -1.75423272108178540662e+00) (14, 2.58533379306033461731e+00) (15, 1.81096709834474289824e-01) (16, 2.78969551791130344898e-02) (17, 1.74440055228562584944e+00) (18, 4.80189410368310731769e+00) (19, 4.94936542113692257150e-01) (20, 4.27154191688692552731e+00) (21, 9.48303152705601615224e-01) (22, 5.44785293068522605608e+02) (23, -2.24467822352347434745e+00) (0, 2.64897549552088662494e+00) (1, -3.36753870941201540745e+01) (2, 6.47735720914492052458e-01) (3, -8.55426671623866097249e-01) (4, 3.20090379844871586457e+00) (5, -7.10981558301799765331e-01) (6, 9.86257501463643992956e-01) (7, -1.92489043430139195046e+00) (8, -1.69197672490725947725e+00) (9, 1.20557481963701218497e+00) (10, -7.72416925044584146143e-01) (11, -3.90868198581772174904e+00) (12, -4.50485369741589092296e-01) (13, 2.57790039333704834590e+00) (14, -3.36178748178139397140e+00) (15, -2.99712606116259050459e-01) (16, 9.64107693801686371771e-01) (17, -1.22727742930532857102e+00) (18, -2.50872877011309736162e+00) (19, -1.83147868196985502687e-01) (20, -2.03268646047448076075e+00) (21, -3.42388535718374298344e-01) (22, -3.19825222583628523410e+01) (23, 2.39808045925058621606e+00) (0, 1.60252692275791086551e+00) (1, -1.31814201972052202905e+01) (2, -2.40100980002580705053e-01) (3, -1.01827995628308998199e+00) (4, 3.86690966814965619847e-01) (5, 7.80839846499340739516e-02) (6, 3.62226030824932820895e-01) (7, -7.31249808011033564092e-02) (8, -7.09455478939172046182e-01) (9, 1.83489667264468442331e-01) (10, -5.35378942617184994113e-01) (11, -7.63612297476894186232e-01) (12, 2.60949216556179974802e-01) (13, 6.83995071120387376773e-02) (14, -2.45422585758056355232e+00) (15, -1.29634032001969511094e-02) (16, 3.76096100042494219107e-01) (17, 7.70147790174836310850e-02) (18, -1.92002850276915715266e-01) (19, 1.79841627973801654328e-01) (20, 2.65031244315504455056e-01) (21, 4.49001876145017020381e-01) (22, -1.27547626348165881183e+01) (23, 6.48383581842739142864e-01) (24, 1.40603378526689244410e+01) (25, -4.94867137269927237497e+00) (26, -1.50346579436604055324e+00) (27, -1.49890093209120989215e+00) 
