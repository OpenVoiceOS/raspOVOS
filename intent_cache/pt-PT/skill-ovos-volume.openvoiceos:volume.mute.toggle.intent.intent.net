FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.37166111815242541816e-01) (1, -2.51712773559632889409e-02) (2, -1.85504322182947739561e-01) (3, -1.06956851911360367735e-01) (4, -1.58449330609852417906e-01) (5, 2.61689453388633097575e+00) (6, 5.28889769564320877393e-01) (7, 2.18221662415243766731e+00) (8, 5.55468360849843856286e-01) (9, -2.42807042882628276725e-01) (0, 4.27775744541189162362e+00) (1, -1.16319722647500373158e-01) (2, -9.96865473340276253555e-02) (3, -7.97724641512158882950e-02) (4, 5.87056510497804898141e-02) (5, -1.08015710707718648464e+00) (6, -5.68852813719392114145e-03) (7, -1.97014257266199477314e-01) (8, -1.45341440553644118960e-01) (9, 1.07456798222982735647e-01) (0, -4.41412352669506014013e-01) (1, -7.92163435934129522842e-02) (2, -1.98648710977846726378e-01) (3, -1.56655666661078080137e-01) (4, -1.27515186798388108214e-01) (5, 2.58056374455870951579e+00) (6, 4.91851026068379659772e-01) (7, 2.32110652176715515083e+00) (8, 6.05083997317777400049e-01) (9, -8.72232104696701593394e-02) (0, 1.74028288215410886774e-01) (1, 2.02221774858259234486e-01) (2, 3.53878387612127309758e-01) (3, 2.01039255958818469106e-01) (4, 3.06023874682210927922e-01) (5, 1.08730718564971762241e+00) (6, 1.81574843977800853834e-01) (7, 7.71739266524269718062e-01) (8, 2.94889125052506750890e-01) (9, 2.25066913726788414563e-01) (0, 3.27805929270557239175e-01) (1, 7.04025492182469014857e-01) (2, 7.31091190239882116053e-01) (3, 8.22531599661802892420e-01) (4, 7.59383160731291306789e-01) (5, 6.68400414812260645903e-01) (6, 6.22300567774310531277e-01) (7, 4.56622574886181298304e-01) (8, 2.70896773692964554225e-01) (9, 2.85462087489199323187e-01) (0, -4.40841131556301057959e-01) (1, -3.62696920154634144806e-02) (2, -1.89666700792128190001e-01) (3, -3.82653449295106556916e-02) (4, -1.82166402470881089171e-01) (5, 2.59334264512242640421e+00) (6, 4.19389070819070119978e-01) (7, 2.28819483367778442329e+00) (8, 5.43336893388257857751e-01) (9, -2.53299818471855953117e-01) (0, -4.41891946542530000830e-01) (1, -1.06684779059702500303e-01) (2, -1.54449829143101319273e-01) (3, -7.16114018676820562881e-02) (4, -7.97089014766755865615e-02) (5, 2.67727625931681956217e+00) (6, 5.26610532651593521436e-01) (7, 2.20900346187926910346e+00) (8, 5.34765499600396987390e-01) (9, -2.18926758603043419837e-01) (0, 1.22034133059503435703e+00) (1, 1.29781082075075632210e-01) (2, 2.15460832964615378593e-01) (3, 1.35264742922024255867e-01) (4, 1.09380062472061639900e-01) (5, -1.53104890348577638015e+00) (6, 3.22745939922464419869e-02) (7, -8.00559995881422903352e-01) (8, -2.47762947792985965823e-01) (9, 9.10678603920577478537e-02) (0, 3.85785126507922071504e-01) (1, -1.09634780561850692093e-01) (2, 5.93623840882170905608e-04) (3, -4.26513415335875861745e-02) (4, 6.28588187933701580956e-02) (5, -4.18350499103137529744e+00) (6, 1.28865932267421623436e+00) (7, -4.28578163290688074483e+00) (8, 1.28032960812784396554e-01) (9, 7.59829364996043477021e-01) (0, 3.24126937124581182559e-01) (1, -4.39812607070483030380e-01) (2, -3.25324772795714145524e-01) (3, -3.82067157825506986679e-01) (4, -5.00665060183085097734e-01) (5, -6.37616306015238887284e+00) (6, 1.22661365162843605248e+00) (7, -5.09155792203146617680e+00) (8, 7.90632723545298232715e-01) (9, 1.37450417518649281590e+00) (10, 3.31120198246008190512e-01) (11, -4.15186047877860384125e-02) (12, 3.46890868737096957908e-01) (13, 2.61307166838006310616e-01) (14, 5.57736518044688114881e-02) (15, 3.53446108873850139975e-01) (16, 2.94804071661001476645e-01) (17, -7.06514373545436558111e-02) (18, -2.73753870164745727322e-01) (19, -3.79435405570839545675e-01) (20, 6.38116343873763924854e-01) 
