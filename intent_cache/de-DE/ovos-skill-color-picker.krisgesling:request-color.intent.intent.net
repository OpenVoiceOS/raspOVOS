FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.53638297368705128987e-01) (1, -1.43569103059028646552e-01) (2, -9.96185528008690923674e-02) (3, -1.48762411054824850165e-01) (4, -8.63006101815453618986e-02) (5, -1.54542052357071330038e-01) (6, 2.99774516574804021640e-02) (7, -1.48976882477205252453e-01) (8, 6.48744223787469209697e-01) (9, -5.35913817579601325924e-01) (10, -9.17598224276808038802e-01) (11, -1.29519105544987911394e-01) (0, -1.30842082695362734585e-02) (1, -1.33585071739410476965e-01) (2, -2.00890681323265096747e-01) (3, -8.62972872225991338713e-02) (4, -1.17118692573761062903e-01) (5, -1.28583689390295463628e-01) (6, -1.84303989492026511210e-02) (7, -4.14209943020986265383e-02) (8, 5.97507607608312563130e-01) (9, -4.36011314387176607266e-01) (10, -8.65172042543199792952e-01) (11, -1.29885048330893954072e-01) (0, 1.73594273065505705356e-01) (1, -3.08864021542621547400e-01) (2, -2.82866882029128963172e-01) (3, -3.08811956885410243689e-01) (4, -2.05977367106033343314e-01) (5, -1.00875550425325088977e-01) (6, 3.21295495583589219013e-01) (7, 2.72849180121731531290e-02) (8, -2.20419307160024280368e-01) (9, 1.43729205908505408562e-01) (10, 9.43303089071857336911e-01) (11, -7.30736339866007833521e-01) (0, 8.28626913128890363325e-01) (1, 3.59114348936187377515e-01) (2, 2.70829498815642832898e-01) (3, 3.83114263463126769604e-01) (4, 4.46435742128001800122e-01) (5, 2.96159495716540654975e-01) (6, 1.21529791970996359218e+00) (7, 2.96688526389484064083e-01) (8, -5.36133740969471972448e+00) (9, -1.26336186803997878314e-02) (10, 1.46782190559147096565e+01) (11, 5.99400038491261555329e-01) (0, -3.08107735714924668713e-01) (1, 9.25697701402032548275e-04) (2, -7.97932442851587847565e-02) (3, 1.98333341054395123626e-02) (4, -1.18503939934298183068e-02) (5, -1.05767263304576933369e-01) (6, -9.50657305435905486402e-02) (7, -1.21768175237485773432e-01) (8, 6.07460683700223214032e+01) (9, -2.42225136088837056381e-01) (10, -2.83175045934907521072e+00) (11, -4.66355428364909396777e-01) (0, 8.42558466939725247968e-01) (1, 3.91478480413131935123e-01) (2, 3.82158489539795143131e-01) (3, 3.07067760839634162906e-01) (4, 3.77737896158867103580e-01) (5, 5.69117599871053064797e-02) (6, -3.18370995995582384275e-01) (7, 4.23253172633476948405e-01) (8, -5.15097527231275176263e+00) (9, -2.08908660047109201452e-01) (10, 7.22063238038705037525e+01) (11, 2.87962486166125741782e-01) (0, -2.17374206026247074330e-01) (1, -2.09563883542309842278e-01) (2, -1.18189937024603869409e-01) (3, -2.19879879205714307000e-01) (4, -2.40260599701891980340e-01) (5, -1.38620058280567809428e-01) (6, 3.21609124749401509291e-01) (7, -9.75531767889456641329e-02) (8, -3.04059074425142905618e-01) (9, -7.87316142875830876635e-02) (10, -8.04696083366031711392e-01) (11, 4.98053470575558002165e-02) (0, -1.18666990794866422654e-01) (1, -1.98250446471285091121e-01) (2, -2.28832658382963405330e-01) (3, -1.80354479703020320613e-01) (4, -9.35747884240858418536e-02) (5, -1.32063834299694399244e-01) (6, 2.19838319052688635491e-01) (7, 2.29907727967171501837e-02) (8, -4.80852543817174293839e-01) (9, -3.82346793679363139429e-02) (10, -5.04873344424098036143e-01) (11, -6.40498054428559615570e-02) (0, 5.69995049665052100352e-01) (1, 7.17858991037100158117e-01) (2, 6.16842029998987628758e-01) (3, 5.75754320631712390721e-01) (4, 5.95583012710302783788e-01) (5, 6.53166861641875540201e-01) (6, 7.65501516940805926126e-01) (7, 6.86301456925959785238e-01) (8, 2.36130442114869998349e+00) (9, 3.73401958899194252872e-01) (10, 2.24807429950388881768e-01) (11, -2.40452382965234828793e-01) (0, -4.08398376224404224821e-01) (1, -3.13785006469654681460e-01) (2, -2.82802661127018573062e-01) (3, -1.75622691577839273869e-01) (4, -2.50693206852840688725e-01) (5, 7.55536761918882748823e-01) (6, 1.07285150538392115571e+00) (7, 3.32937996614899589520e-01) (8, 1.99472401980608315952e+00) (9, 6.20935577978549813061e-01) (10, 5.87980109044026977294e-01) (11, -8.77557022206204462300e-01) (12, -1.34733503239060109502e-01) (13, -1.65890817604332052593e-01) (14, 6.38759573267640101690e-01) (15, 5.38133386368898070096e-01) (16, 9.92930951319726196047e-01) (17, 5.20771641130593820890e-01) (18, -1.81379559977280946370e-01) (19, -1.93935412198731421674e-01) (20, -2.54395197186731203409e-01) (21, 6.39157837546599050249e-01) (22, 3.66444650219302725525e-01) 
