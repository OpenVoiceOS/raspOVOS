FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.01242473519344966526e+00) (1, -2.36781216466063787474e-01) (2, -3.75004298293227456007e-01) (3, -2.26331941091651250852e-01) (4, -3.36263357901210091505e-01) (5, 1.54199547797605029942e+00) (6, 2.02225084493957568688e-01) (7, 2.92468194922868351959e-01) (8, -1.30964263235661210194e-01) (0, 4.10913995228925410519e-01) (1, 4.66822208339432553892e-01) (2, 3.14661854380825833921e-01) (3, 3.69116635495880918150e-01) (4, 4.08497744673947171812e-01) (5, 4.03504849896559569800e+00) (6, 4.78707425566178512710e-01) (7, 7.46926211292834763000e-01) (8, -1.62773281021310195493e-01) (0, -1.00654023683567683811e+00) (1, -3.19510466658705971632e-01) (2, -2.25116363966101934446e-01) (3, -3.07591825031871102247e-01) (4, -2.87194631301993630323e-01) (5, 1.41871659934684313242e+00) (6, -7.51209667737945951949e-02) (7, 2.98392844459478001617e-01) (8, 5.97938132383648013324e-02) (0, -1.18773784286280337241e+00) (1, -2.47785470687979930693e-01) (2, -2.41381532752150823606e-01) (3, -2.96431600355738900099e-01) (4, -2.69173226558799050245e-01) (5, 1.51805883377953998448e+00) (6, 3.39506502340637339454e-01) (7, 4.89143951933060816550e-01) (8, -6.48191617090895566555e-01) (0, 1.03268038799922479143e+00) (1, 7.98762701619353671090e-03) (2, -2.56613332761457119124e-02) (3, -2.22174514068296663494e-02) (4, -5.63804645074536953109e-02) (5, -1.42324437934655434468e-01) (6, 1.07060781869955518042e-01) (7, 3.60803776747058213559e-01) (8, 5.38785387882396382686e-01) (0, -4.04677440039511726599e-02) (1, -1.45248346018868934593e-01) (2, -1.68477941292602073631e-01) (3, -1.02243654418069304657e-01) (4, -1.60751596081334602317e-01) (5, -2.12945050473045638384e+00) (6, 5.47689417290880053990e-01) (7, 3.40595962825816722663e-01) (8, 1.36957851158473670194e-01) (0, -1.05530848896999995823e+00) (1, -2.15156773992625061087e-01) (2, -2.49652887650576360556e-01) (3, -2.67528633543101079795e-01) (4, -2.11857642003146051657e-01) (5, 1.49088874191209308506e+00) (6, 2.94137756417595042091e-01) (7, 1.58113172728309991921e-01) (8, -2.80393368457886427159e-01) (0, -1.17671960561519989286e-01) (1, -1.65373973513708860672e-01) (2, -4.23284694205386669008e-02) (3, -1.70836470986471922195e-01) (4, -6.92874416361911327211e-02) (5, -2.19648086006473830523e+00) (6, 5.57873727667524188512e-01) (7, 1.96756596091788860114e-01) (8, 2.04842970626447379301e-01) (0, 4.33862200699964228878e-01) (1, 4.19519276792267636900e-01) (2, 3.50133025521496610288e-01) (3, 4.13114422435025052671e-01) (4, 4.79054139429787473325e-01) (5, 3.99733780995735976660e+00) (6, 4.81541402907830429214e-01) (7, 7.37423517282100204895e-01) (8, -3.72422930433286766827e-02) (0, -9.62756990071711116208e-01) (1, -1.98753590651598810446e-01) (2, -2.48132283755388954871e-01) (3, -2.31582666703310791068e-01) (4, -2.63025100298968084189e-01) (5, 1.51714358955785266758e+00) (6, 3.13917900513015879493e-01) (7, 5.99131688396563472088e-02) (8, -2.04717411552998246327e-01) (9, 4.20817952199097122801e-01) (10, 5.61992198707365830934e-01) (11, 4.13598615272160019529e-01) (12, 5.13385033352783737293e-01) (13, -1.07800415573083605003e-01) (14, -2.57673559458626688645e-01) (15, 4.19797714395637955320e-01) (16, -3.17542269808491262051e-01) (17, 5.79907253863120031312e-01) (18, 4.94498189134712551329e-01) (19, 7.41457434833104001015e-01) 
