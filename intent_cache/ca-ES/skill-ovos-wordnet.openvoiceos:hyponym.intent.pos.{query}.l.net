FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=31 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (31, 6, 5.00000000000000000000e-01) (31, 6, 5.00000000000000000000e-01) (31, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.91013726527240601527e+00) (1, 1.36477286332909208966e+00) (2, 3.49965781529762320901e+00) (3, -1.64945813947965547186e+00) (4, -7.73511715229903695779e-01) (5, -1.52248839595963403326e+00) (6, -6.41524503640164667218e-01) (7, 1.98189678866836826998e+00) (8, 5.34611218483974082183e-01) (9, 2.85494426325498984465e-01) (10, 2.04295033295128192208e+00) (11, -1.45286613191172264692e+00) (12, -2.06708073432626626698e+00) (13, -2.08104207891300951871e+00) (14, 3.98643929048261846937e-02) (15, -1.73681895816533510279e-01) (16, -6.85526564954587747103e-02) (17, -1.04983197921402121588e-01) (18, -1.59461374834238556186e-01) (19, -1.10131482248275824887e+00) (20, -2.10230732153239152638e+00) (21, -9.50470941329245172513e-02) (22, -7.42224958256998412764e-02) (23, 2.46978763752346264226e+00) (24, -8.43432564983810917347e-01) (25, 2.14218157618263305153e+00) (26, 3.67812965913110356819e-01) (27, 1.60797802887460150600e+00) (28, -1.71110885752527863701e+00) (29, -1.27634343727043453320e+00) (30, -1.08693006380033141411e+00) (0, 3.08006476557457542498e+00) (1, -3.57448107833383232901e+00) (2, -4.08454443124385679909e+00) (3, 5.38227504196111317114e-01) (4, 1.17097689008940641919e+00) (5, 1.58316772767622432339e-01) (6, -6.87022441044009113398e-01) (7, -1.54881851836161166247e+00) (8, -1.48629074265864447035e+00) (9, -2.02079116528984137346e+00) (10, -1.55816723122314959582e+00) (11, 1.08224684008501892407e+00) (12, 1.04284527305326268909e+00) (13, 9.67212015102789646193e-01) (14, 1.17823500686428239703e+00) (15, 1.14067743483629668866e+00) (16, 1.53920146086015541265e+00) (17, 1.51085346200265724370e+00) (18, 2.71443719453223708538e-01) (19, -1.64295821021140292517e-01) (20, -1.85703938372059895734e-01) (21, 1.16906107538539183466e+00) (22, 6.87471258456562206440e-01) (23, -4.13485486113702727096e+00) (24, 1.13862874866816787822e+00) (25, -1.66454554191523351747e+00) (26, -2.12350672066838219720e+00) (27, -2.23212629353332303594e+00) (28, -4.37201126349993016151e-02) (29, 6.76114716895732659196e-01) (30, 3.91655372775123211682e+00) (0, -5.44137518632980543565e-01) (1, 1.45978105971046101530e+00) (2, 1.91465793313557819388e+00) (3, -2.07653279945978974652e+00) (4, -6.29937710418350532704e-02) (5, -1.00333915326457812078e+00) (6, -6.32182098205611109343e-01) (7, 8.35768678617053506485e-01) (8, 9.11198008124582847778e-01) (9, 8.28813114688336183278e-01) (10, 7.30316316592907632810e-01) (11, -2.47351834648301682762e+00) (12, -1.52491226475975194532e+00) (13, -1.80484429427426928960e+00) (14, 7.02825021230143315298e-02) (15, -4.72666445531479739728e-01) (16, 1.96613622946111732404e-01) (17, 2.05199005199043327252e-01) (18, -4.25427353628092030924e-01) (19, -5.71398685681044793405e-01) (20, -2.01497759020437161581e+00) (21, -6.45998973874167409237e-02) (22, 1.06317178802104159163e-01) (23, 2.95718499615144647663e+00) (24, -2.10076416623575967790e+00) (25, 9.28368493538593519965e-01) (26, 1.01451327499533250354e+00) (27, 7.66372147616739218812e-01) (28, -2.26360664715338266717e+00) (29, -5.42405863623190320766e-01) (30, -7.17847291160198408555e-01) (31, 5.56440798535802105818e+00) (32, -1.25831539558718503713e+01) (33, 4.93126945561659990602e+00) (34, -1.54940081104177496130e+00) 
