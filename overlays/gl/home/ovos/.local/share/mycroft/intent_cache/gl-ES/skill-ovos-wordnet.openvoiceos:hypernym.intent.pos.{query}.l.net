FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.81291196493619333197e+00) (1, -3.18384754396130587040e+00) (2, -2.99872109424801358557e+00) (3, 1.96394278262978039251e+00) (4, -1.49003994131185768524e+00) (5, -4.68020345190678310754e-01) (6, -2.47038175047571195719e+00) (7, 1.79184704600381938810e+00) (8, -1.13384472798741775534e+00) (9, 1.16242936871306579150e+00) (10, -1.54162433810977661519e-01) (11, 2.98735597887547710272e+00) (12, 3.51506671549411642275e+00) (0, 8.75434775885535421125e-01) (1, -5.64054044903048334980e-01) (2, -3.18781178606473991621e+00) (3, -7.58582197740211849890e-01) (4, -1.07264055462453100631e+00) (5, 2.12022076993315489180e-01) (6, -1.02196216940543465057e+01) (7, 7.85993559742573788540e-01) (8, 9.96840310481181712809e-01) (9, 1.48431853904037591718e+00) (10, -1.07388676903134827612e+00) (11, 8.63037457508160743558e-01) (12, 1.78645314598585858157e+00) (0, 3.64066882375295675089e+00) (1, -3.93038120469240892518e+00) (2, -3.12302030246862027951e+00) (3, 2.03227268652854275999e+00) (4, 6.18787056651169842247e-01) (5, -1.72522117200245683755e-01) (6, -1.55243118006090008443e+00) (7, 1.67762448220062387882e+00) (8, -9.55330202693114305390e-01) (9, 1.18055585644499938525e+00) (10, 1.76361672541195141362e-01) (11, 3.92504396040842840065e+00) (12, 2.81208003312285992337e+00) (13, -5.02709970397163896649e+00) (14, -5.84898318557696494935e+00) (15, -4.86799945842765513504e+00) (16, -1.68922664301443203883e+00) 
