FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.07670205248822736799e-01) (1, 6.02155123949303788811e-02) (2, 1.19664912224068699376e-02) (3, -7.96908977329478379614e-02) (4, -3.32182775139555769295e-02) (5, 7.11473425029064826530e-02) (6, -1.08835190865356201684e+00) (7, 1.08786607039056307245e-01) (8, 1.23202983326746062787e-01) (9, 4.91438729161666532086e-01) (10, 1.92284716300445440718e-01) (0, 1.57556402279175844505e+00) (1, 4.01771498900100332285e-01) (2, 3.82373431753560588664e-01) (3, 5.35661416184350591685e-01) (4, 4.33414967786714178111e-01) (5, -1.17942407201401966432e+00) (6, -7.45844882363231764799e+00) (7, 1.97626449308924856396e+00) (8, 4.29048542610528738095e+00) (9, -3.41977250438612534467e+00) (10, 6.70594621204836319889e-03) (0, -9.88358790710139434310e-01) (1, -3.04292613061034299127e-02) (2, -1.23398269096192059191e-01) (3, -4.65491139681899132596e-02) (4, -3.12759601862990441190e-02) (5, -6.95014984090135956585e-02) (6, 1.06265270853920501537e+01) (7, 1.26521272039948645682e-01) (8, -1.00942987411133167086e+01) (9, -5.16306357419586525737e+00) (10, 1.40492236030554024095e-01) (0, 1.26108203764333185598e-02) (1, -1.76679785735423755533e-01) (2, -1.03668998367602988031e-01) (3, -1.22327144629771927820e-01) (4, -2.52194832451160144693e-01) (5, -5.36785747735787688306e-01) (6, 8.53992732483022543022e+00) (7, -5.88076339934505809559e-01) (8, -4.19432408757629904272e+00) (9, 7.06585782453944100112e-01) (10, -4.78829073257204043679e-02) (0, 1.01349940771365565340e+00) (1, 2.30181821604170333551e-01) (2, 1.50174655933775436090e-01) (3, 1.93151161988176944817e-01) (4, 2.86399201472200826135e-01) (5, 2.13021907368493856882e-01) (6, -7.16949904841176177683e+00) (7, 1.71697785968925442646e+00) (8, 3.48846886435030079099e+00) (9, -1.71902566598133477171e+00) (10, 1.49929230704590799039e-01) (0, 7.04051638089633669004e-01) (1, 2.90835592053035218996e-01) (2, 3.74112109742262999301e-01) (3, 2.24859292707542013368e-01) (4, 2.03363779089549612245e-01) (5, 2.07023255567070602057e-01) (6, -2.26158646641591154491e+01) (7, 2.32196540704081355599e+00) (8, 2.32872299475416859593e+01) (9, 7.00356123846650024944e+00) (10, -3.80077810682288130817e-01) (0, 6.84601450399701549898e-01) (1, 4.42909996885586104698e-02) (2, 1.00172574438505176952e-01) (3, 5.68187113780307950783e-02) (4, 4.35612227696705184288e-02) (5, 6.82280691307080133789e-01) (6, -9.47522700975576626092e+00) (7, 1.79608517612603857394e+00) (8, 7.76659829863261097493e-01) (9, 1.52259842465233230513e+00) (10, 2.46909628001851538803e-01) (0, -7.98486284684481573137e-01) (1, -2.34640334066895765719e-02) (2, -4.70181424436120348753e-02) (3, -4.73962370571641422590e-02) (4, 2.35283504906149583402e-02) (5, 2.50740286720777638685e-01) (6, -6.48313168202399370266e-01) (7, -3.46931768790001537894e-01) (8, -1.66339876890075039073e-01) (9, -3.99061621808867561523e-01) (10, 1.27150687220021985091e-01) (0, -7.73215584457162319332e-01) (1, 7.55350577575401999075e-02) (2, 6.09102236968712823506e-02) (3, -1.41125259059233926218e-02) (4, 8.34365027887062488121e-02) (5, 2.50631256486060716160e-01) (6, -1.15788138133425499987e+00) (7, 1.83654010154166241753e-01) (8, 3.53659509573258201698e-01) (9, 5.20592453173974401004e-01) (10, 7.79377868485910119123e-02) (0, -7.63955497356869961401e-01) (1, -1.14432240322998677456e-02) (2, -7.51911590293815740305e-02) (3, -5.61654309228829251577e-02) (4, -1.59114878852742169801e-01) (5, 2.53530927631258229393e-01) (6, -4.79310301269193606011e-01) (7, -3.83702865079159349815e-01) (8, -2.07957315913845336430e-01) (9, 1.98541984072826450947e-02) (10, -3.49226655335359348342e-01) (11, -1.37978591125658772709e-01) (12, -4.22421831076525255977e-01) (13, -1.22480730599878587239e-01) (14, 8.36410771008312403652e-01) (15, -8.31824698196762801761e-02) (16, 1.00255357340312811765e+00) (17, -1.57019326899311639778e-01) (18, 2.39246364166306735299e-02) (19, 4.41679594378210860217e-01) (20, 1.57569179416553240003e-01) (21, 2.64908339634762124426e-01) 
