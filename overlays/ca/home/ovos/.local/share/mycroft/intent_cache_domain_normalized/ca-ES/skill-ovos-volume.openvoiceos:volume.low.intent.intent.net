FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.55203466812311163814e-01) (1, 1.48254417748567096647e-01) (2, 8.10580634785858233915e-02) (3, 2.01437027127858575559e-01) (4, 2.01650508613702234006e-01) (5, 1.82570385690457470673e-01) (6, -1.72848804513049358889e+00) (7, 9.95419252482657501702e-01) (8, -7.01739734028044986891e-02) (9, 1.41563093478778545542e-01) (10, 1.71948877417726908590e-01) (0, 1.12964398813900102070e+00) (1, 9.44394854928078258949e-02) (2, 1.04487122418981989713e-01) (3, 1.02511504116159876676e-01) (4, 2.17570581855875216926e-01) (5, 6.23028694536368124468e-02) (6, -1.52314683064639355692e+00) (7, 7.49866366142895257596e-01) (8, 5.94731787259841007676e-02) (9, 3.12297232605363350721e-01) (10, 2.87327469552555614385e-01) (0, -9.49896430451793705174e+00) (1, -9.55762216671252468059e-02) (2, -4.73219105823780086806e-02) (3, -8.09254297836566882651e-02) (4, -2.15968581460311531695e-01) (5, 3.06315260252969456811e-01) (6, 2.24290013045665848068e+00) (7, 4.08236395929292214535e-02) (8, 6.04114038401765918174e-01) (9, 2.28047914605008616995e-01) (10, -1.85996763691850197642e-01) (0, 9.88598282330094804138e+01) (1, 1.67306527705483283341e+01) (2, 1.68292245329909171403e+01) (3, 1.68305180580906714738e+01) (4, 1.67319306717805709184e+01) (5, 1.67446232739876954554e+01) (6, 1.59567880254476235358e+00) (7, 2.29310605768702380214e-01) (8, 1.08482428776656583125e+01) (9, 4.10031646700250884674e-01) (10, 9.78983952819357128305e-01) (0, 3.78368827079374483446e+01) (1, 3.36341786957497779209e-01) (2, 3.68035171008820827243e-01) (3, 2.89578851140256110508e-01) (4, 4.67493910170312221286e-01) (5, -8.21377369722378425365e+00) (6, 8.88577668798906428194e-01) (7, 5.61775586223069778313e-01) (8, -1.99407286271046779724e+00) (9, -5.82780084843859749744e-02) (10, 2.20989778688311400145e+00) (0, -5.26243965116762790757e+00) (1, -1.69912365562034844979e-01) (2, -9.07432337466013427818e-02) (3, -6.90686305228006697243e-02) (4, -2.08599821961237191781e-01) (5, 1.05900057484544202202e-01) (6, 8.64501914572729468489e+00) (7, -2.74608737518876711015e-01) (8, 5.58711778972792449949e-04) (9, 5.51566002282071754514e-02) (10, -1.31537578987628966942e-01) (0, 1.07687777579980728526e-01) (1, -1.19029882972134862240e-02) (2, -1.02727882904280531928e-01) (3, -2.80899930422199919922e-02) (4, -2.54339013742348272334e-03) (5, 1.64068391249825223932e-01) (6, -8.23466311881349710688e+00) (7, 2.03449733165954382841e+00) (8, 4.59821390889445569261e-01) (9, 1.13533835032629570883e+00) (10, 2.66722257398203765888e-01) (0, 9.89449934207259644836e+01) (1, 8.96164088931241553659e-01) (2, 8.72641369190373938913e-01) (3, 8.86283367362180274363e-01) (4, 7.94345668938317817087e-01) (5, 3.99039785976208420948e+01) (6, -3.81106739197738519920e+00) (7, -1.56695224302938096450e+00) (8, 1.07931721272503331477e+01) (9, -1.83113795322733508009e+00) (10, -2.26068784941982556247e-02) (0, 9.88379523486255635589e+01) (1, 8.53381752457776587839e-01) (2, 8.30621286716619056101e-01) (3, 8.97914200511136573191e-01) (4, 8.91708671536603492136e-01) (5, 3.98947931940354081348e+01) (6, -3.96668656621940485252e+00) (7, -1.48498058277299516128e+00) (8, 5.48124845834073681772e+00) (9, -1.95836550546246113136e+00) (10, 7.45121175895382126253e-02) (0, -5.40101398316645298081e+00) (1, -1.26425219065262051110e-01) (2, -1.59761344379497766122e-01) (3, -7.73763259115946289146e-02) (4, -1.11942668742252587899e-01) (5, -3.00054367990967678359e-02) (6, 8.63754322943105101729e+00) (7, -2.44852645138275121228e-01) (8, -2.46478242756383789103e-02) (9, 7.04704786991991599665e-02) (10, -1.20534978794605313057e-01) (11, 5.39192341220768797672e-02) (12, 4.34716872823628294742e-02) (13, 4.13482809461032385645e-01) (14, 4.04160496576703220928e-01) (15, -5.84269250786543348219e-01) (16, 2.67126269929335080633e-01) (17, -1.60601161280750248661e-01) (18, 3.93195288509572193902e-01) (19, 3.88322407633507893365e-01) (20, 2.91132968209907749824e-01) (21, 3.00492260451923953735e-01) 
