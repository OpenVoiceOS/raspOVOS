FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.05400235352304402769e-01) (1, -8.15831502831320665159e-02) (2, -1.99912664101157599994e-01) (3, -2.55898245230946952411e-01) (4, -1.49933517531190330097e-01) (5, -1.23882535468554516589e-01) (6, -2.10367630273749162129e+00) (7, -1.12111129420457811268e-01) (8, 8.85787736885526101105e+02) (9, -1.52106856350802122080e+00) (10, -8.00598183622065334708e-02) (0, 5.36282251924175223934e-01) (1, 4.25747310248776433816e-01) (2, 5.24606069055959411962e-01) (3, 5.68267216411992959202e-01) (4, 5.84770401445791176975e-01) (5, -2.08478427608155891804e+00) (6, -1.43494944025758330852e+00) (7, 2.69701688304151365738e-01) (8, 1.25150215016685883995e+00) (9, -2.23893453829472388605e+00) (10, 3.26943596116802570606e+00) (0, 2.20105241337705370697e-01) (1, 1.58064182522588414503e-01) (2, 1.13668366941505047385e-01) (3, 2.13370646956258513960e-01) (4, 1.20932969870858761374e-01) (5, 8.27739291815902389349e-02) (6, 1.50000000000000000000e+03) (7, 9.19675273985986613257e-02) (8, -5.47159390307805182374e+00) (9, 1.50000000000000000000e+03) (10, 2.36976381434375854562e-01) (0, 2.55521789716419145400e-01) (1, 1.47844264535974240227e-01) (2, 1.98180133729051383140e-01) (3, 2.82066727309297327064e-01) (4, 1.71645330517362276757e-01) (5, 1.76241118520905459821e-01) (6, 1.50000000000000000000e+03) (7, 2.45470022075161636854e-01) (8, -5.38867799756952159385e+00) (9, 1.50000000000000000000e+03) (10, 2.24743597778007980770e-01) (0, 4.59971631906348710217e-01) (1, 4.58987587921384054823e-01) (2, 4.79644222043517309828e-01) (3, 5.09117266021731351699e-01) (4, 5.20003525398734289809e-01) (5, -1.75930696173289957684e+00) (6, -1.62403033186732415061e+00) (7, 2.02957100370196485972e-01) (8, 4.86373967611557322943e-01) (9, -2.18042330422709040860e+00) (10, 3.35017471751386652912e+00) (0, 5.17934156758557251443e-01) (1, 4.29693844966507476624e-01) (2, 6.21333335392094787686e-01) (3, 4.85258159093475860413e-01) (4, 5.94150920264340576260e-01) (5, -2.92760165008913508800e+00) (6, -9.84479542666749973812e-01) (7, 2.89640625120590911035e-01) (8, 1.10872622067042470029e+00) (9, -1.36571359148454840593e+00) (10, 2.67994097812940390568e+00) (0, 5.12378184140996228990e-01) (1, 1.58607153778200948846e-01) (2, 2.27162981962090365640e-01) (3, 2.50786783729916418206e-01) (4, 2.90943043862706141045e-01) (5, 8.04371557239652312798e-02) (6, 2.47364214681815741681e-01) (7, 1.65995572558747916947e-01) (8, -5.18390794352494310715e+00) (9, 1.50000000000000000000e+03) (10, -6.08388038492119337386e-02) (0, -3.92162417924091177834e-01) (1, -4.46023617168971986402e-01) (2, -4.85031165411779374708e-01) (3, -3.89517016938039972729e-01) (4, -4.22853194406339838451e-01) (5, -2.78320189929152417285e-01) (6, -1.50000000000000000000e+03) (7, -3.68463008543893966173e-01) (8, 4.98879020416102303415e+00) (9, 1.62358024311820425822e+00) (10, 7.17974597023943617025e-01) (0, -3.03501144517208443219e-01) (1, -3.22142796455469782035e-01) (2, -4.01471050320711619896e-01) (3, -4.92175476490107066674e-01) (4, -4.86666204272356628380e-01) (5, -1.08995142323740606960e-01) (6, -2.39383863703817967306e+00) (7, -3.90823378875469612526e-02) (8, 1.02555968011722189459e+01) (9, -1.26256901475282079517e+00) (10, 5.84704535599493840925e-02) (0, 2.97704324649509410872e-01) (1, 1.18717172351426966670e-01) (2, 2.14716040697641247226e-01) (3, 1.42925710585660808993e-01) (4, 2.04249249008245342685e-01) (5, 3.56005909241750795324e-01) (6, 1.50000000000000000000e+03) (7, 2.42717819729142775254e-01) (8, -5.46497398233838005410e+00) (9, 1.50000000000000000000e+03) (10, 2.35478951308869199899e-01) (11, 6.65859886239423492960e-01) (12, -1.44950707638690667878e-01) (13, 2.57815307362585288686e-01) (14, 2.47447519965173501344e-01) (15, -1.49364006901214291245e-01) (16, -1.44176324093768792878e-01) (17, 2.61909308247188110652e-01) (18, -3.34608387432630993708e-01) (19, 7.30001581454809089777e-01) (20, 2.72063964085222875777e-01) (21, 4.41701490741279345631e-01) 
