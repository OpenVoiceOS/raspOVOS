FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=28 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (28, 6, 5.00000000000000000000e-01) (28, 6, 5.00000000000000000000e-01) (28, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.27179231746518484059e+00) (1, -3.39845298175439269883e+00) (2, -3.27733901865960941535e+00) (3, 3.50231289512913879225e-01) (4, 1.61400615311600192925e+00) (5, 6.54278007530288308047e-01) (6, 3.40968026216241559823e-01) (7, -3.23110863222104915948e+00) (8, 1.27472934359833045548e+00) (9, -3.14524365512587111837e-01) (10, 6.09115015516823232744e-01) (11, 1.82147284053076630173e+00) (12, 2.25600401843815800973e-01) (13, -1.44880319080827635325e+00) (14, -1.91304838671007282347e-02) (15, 1.95543094489518759493e-01) (16, 5.42911924105114973571e+00) (17, 1.45514099841294686222e+00) (18, 9.27814595992075968889e-02) (19, -2.52411808254955660757e+00) (20, -2.91975939006243856433e-01) (21, 1.43988643486124767712e+00) (22, 4.95563534237276948069e-01) (23, 1.46014542234354532946e-01) (24, 2.42753734621144934280e+00) (25, 7.15111155349742455556e-01) (26, 2.57989992435544124305e+00) (27, 3.27782337737100970543e+00) (0, -9.98305459508172066130e-01) (1, 1.39925038447657379415e+00) (2, 3.08627248127177589154e+00) (3, -4.68475618666335802409e-01) (4, -6.30272663733032922906e-01) (5, 2.57758863403617921595e-02) (6, 9.19826830467307621220e-01) (7, 3.12194478193876934213e+00) (8, -7.20929565566080343686e-01) (9, 1.02075178956315015810e+00) (10, 1.34692781554849738690e+00) (11, -8.56044408522340649625e-01) (12, 8.02751587883932193890e-01) (13, 3.26794976231082046070e+00) (14, 2.39373730207224255651e+00) (15, 4.22194485905534389047e+00) (16, 8.12087451581543362522e+00) (17, -6.68955587627403480688e-01) (18, -2.25559667026853899463e-01) (19, 3.42467704059872657396e+00) (20, -3.25594976536623059715e-01) (21, 6.26298546009695922265e-01) (22, 6.30268961347962286546e-01) (23, 1.63393599190887384154e+00) (24, -3.09399387363765820957e-01) (25, -2.71588680443837160450e-01) (26, 3.37345079118086133008e+00) (27, -2.22301306134810827686e+00) (0, 9.34699665320452233175e-01) (1, -3.29658254180774124009e+00) (2, -3.22061228729965076667e+00) (3, 4.12775262839597090192e-01) (4, 1.62233375273086055657e+00) (5, 2.52606905646127033460e-01) (6, 2.23481858517142834009e-01) (7, -3.19910423113328823419e+00) (8, 1.49350596979240157758e+00) (9, 7.70264505879713068381e-01) (10, 2.24158840428579864135e-01) (11, 1.84372041202892189560e+00) (12, 1.98943949277430531808e-01) (13, -1.47273519329307478465e+00) (14, 7.70698810365261555155e-01) (15, 3.47295447204057472490e-01) (16, 2.47257127377931235079e-01) (17, 2.31946373465478838938e+00) (18, 1.11386580079268396326e-01) (19, -2.39700693818567645010e+00) (20, -1.78438748842560723773e-01) (21, 1.51973920960051311901e+00) (22, 5.21945935822855866526e-01) (23, -4.62413432860894091370e-01) (24, 2.67447877784307341820e-01) (25, 1.02721915002144048579e+00) (26, 2.62541269372671148830e+00) (27, 3.26976780962961566246e+00) (28, -5.76361442129589551797e+00) (29, 5.61895286783992631285e+00) (30, -4.46315017813286871728e+01) (31, -1.26882841916361854828e+00) 
