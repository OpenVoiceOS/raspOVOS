FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.52002742116608025036e+00) (1, 2.48265652988707286042e+00) (2, 1.77152723315965143769e+00) (3, -2.22780241258926925418e-01) (4, -1.21021084356581498653e+00) (5, -1.31619851153408973232e+00) (6, -1.12228402511361746718e+00) (7, -8.62719376875213272982e-01) (8, -8.39646278936744150379e-01) (9, -9.00620594854662503970e-01) (10, -6.76491780082310034672e-01) (11, -1.11914435534795386751e+00) (12, -7.69687831548972578588e-01) (13, -4.30904548968958189814e-01) (14, -9.70246081758373901671e-01) (15, -1.27606567845774354630e+00) (16, 8.09793917222172282555e-02) (17, 2.67457142995560026577e+00) (18, -1.13070696006141147016e+00) (19, 2.28836072636425846838e+00) (20, -5.53883912641256609399e-02) (21, 4.09531035068658316733e-02) (22, -1.72911109893633874179e+00) (23, -1.95839796607886107438e+00) (0, 3.93692341400596168555e-01) (1, -1.83991074460122805423e-01) (2, -3.90943599440817080026e-01) (3, 2.14002627539909451304e-01) (4, 5.20167172852640913305e-01) (5, 2.90833101045285369324e-01) (6, 4.25528724825964432821e-01) (7, 7.18634605588291175415e-01) (8, 2.75071953382117706521e-01) (9, 2.83935874317183423177e-01) (10, 3.81229725541076702733e-01) (11, 4.99063829084518295609e-01) (12, 3.40189164548671652000e-01) (13, 1.48937765456551729493e+00) (14, 2.91431174516521718232e+00) (15, 3.54354451051500818348e-01) (16, 3.25093946332752681272e-01) (17, -8.96461199159904786882e+00) (18, 1.03433253788753287683e-01) (19, 6.32631211548393412869e-01) (20, -4.58106799012711185526e+00) (21, 4.71563680474364810280e-01) (22, 1.48348067965615793007e+00) (23, 5.07954922631741578876e-01) (0, -3.85260024334639217258e+00) (1, 3.31629221012146446768e+00) (2, 6.37320895410134813375e+00) (3, 1.72834261667691002629e-01) (4, 2.30320101589752423976e+00) (5, 1.16850381793287128041e+00) (6, 9.91571375455464365523e-01) (7, 1.12610730075634091207e+00) (8, 5.86618207439078775955e-01) (9, 6.26873022176092975499e-01) (10, -4.86929521909655119161e-02) (11, 1.12788824795970388237e+00) (12, 1.32881444598108661159e-01) (13, 9.62408603937566442532e-01) (14, 3.85501061254102106446e+00) (15, -4.66357149995159647737e-02) (16, 4.97590797451529343043e-01) (17, 5.33264997365511028704e+00) (18, -2.47678303961716222981e-01) (19, -1.50733666856155288372e+01) (20, -9.32079192234255771154e+00) (21, 8.91569236937896136830e-01) (22, 5.21910153250077168963e+00) (23, -5.13119066634960407924e+00) (24, 1.52274730936092055344e+01) (25, -2.17063640375964705953e+00) (26, 6.94571268431930377574e+00) (27, -2.35383789656690778358e+00) 
