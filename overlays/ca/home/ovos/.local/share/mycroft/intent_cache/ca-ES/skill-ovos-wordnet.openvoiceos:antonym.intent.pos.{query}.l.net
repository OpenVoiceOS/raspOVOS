FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.80748192598035717360e+00) (1, 2.77312588017197692025e+00) (2, 3.13526748156020973468e+00) (3, -7.11456271510050308748e-01) (4, -3.80087090260171178713e-01) (5, 4.44054218200966299701e-02) (6, -3.93500534184046180108e-01) (7, -5.93750106774508457086e-01) (8, 3.64860966272278930411e-01) (9, 5.59042281711673250122e-01) (10, 3.14027442343204565844e-01) (11, 2.36775319348431073641e-01) (12, 3.11659499473496803823e-01) (13, 1.99933408984836336053e+00) (14, 4.25381412312531181907e-01) (15, -4.86799707438608647569e-03) (16, 5.21957760295777228876e-01) (17, 2.98399959570994566249e+00) (18, -1.54085060336610291110e-01) (19, 2.90778154141631484109e+00) (20, 8.44280602334197216585e-01) (21, -4.02577430167383232273e-01) (22, -1.75586486259302576585e+00) (23, -3.60841486451430837334e+00) (0, -9.93763382378887505375e-01) (1, 2.67775829206915938485e+00) (2, 2.95942910795877311969e+00) (3, 5.41813179159736146850e-01) (4, -5.29414612158578545831e-01) (5, 1.80462947693280695294e-01) (6, -3.83701401231474781284e-01) (7, 1.11013558236479018687e-02) (8, 3.09642441041394600454e-01) (9, 6.17311983609771242065e-01) (10, 3.50107311017482825122e-01) (11, 3.05679160426712503984e-01) (12, 3.83845850295945312247e-01) (13, 5.34251791939282183463e-01) (14, 4.58100219771408745384e-01) (15, -5.96947931292260702829e-02) (16, 5.47076617917923946344e-01) (17, 2.90560901231398771571e+00) (18, -5.47603943729606940094e-02) (19, -1.72691862895801795386e-01) (20, -1.77558515714577236366e+00) (21, 3.68301795364672446276e-01) (22, -1.03229773200894325846e+00) (23, -3.33099546147606018209e+00) (0, -2.03897859138309023308e+00) (1, 2.80293969135495268930e+00) (2, 3.19241342607210132343e+00) (3, -6.34575801591799271151e-01) (4, -5.65758658177041406923e-01) (5, 1.13637431171350097858e-01) (6, -4.27669835574694068292e-01) (7, -6.30352752886950473687e-01) (8, 3.47449331946298012319e-01) (9, 5.19042066538905610962e-01) (10, 2.72954075343578406176e-01) (11, 4.01244524191475160357e-01) (12, 2.21633471019193117879e-01) (13, 2.06109868029054377203e+00) (14, 4.39800594836187108694e-01) (15, -7.71256946566308554392e-02) (16, 6.16455321750550289117e-01) (17, 2.83700074321856687831e+00) (18, -2.03287450351735565768e-01) (19, -2.31126803770378363989e-01) (20, -1.59353784220388927650e+00) (21, -3.79811111995166816868e-01) (22, -1.65589259961447199387e+00) (23, -3.13091084888244752804e+00) (24, 5.65456139558704595771e+00) (25, 5.61894095951469640937e+00) (26, 5.61522344762237768379e+00) (27, -7.48274994149291772239e-01) 
