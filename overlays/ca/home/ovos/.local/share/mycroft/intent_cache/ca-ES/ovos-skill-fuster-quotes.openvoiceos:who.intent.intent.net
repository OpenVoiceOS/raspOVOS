FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=14 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.75409962580538336674e-01) (1, -9.95134544833597700642e-02) (2, -7.79905748828349232316e-02) (3, -2.44171558068603050673e-01) (4, -1.98646040753930580580e-01) (5, -1.27421658353995936874e-01) (6, 8.23532847416049151867e-02) (7, 3.22905435463856491651e+01) (8, -1.41448536196272754706e-02) (9, -2.75377408210072782691e-01) (10, -2.28571547315925133192e-01) (11, 1.29769840574157163671e-01) (12, 4.84949483108470299347e-03) (13, -1.39449722022517791364e-01) (0, 2.06789432964209263233e-01) (1, 3.08360847800271009600e-01) (2, 3.13028964369790052569e-01) (3, 3.56114330857293104327e-01) (4, 2.71087947457329725420e-01) (5, -8.01024525730773540033e-01) (6, 2.41591389919000275321e-02) (7, 7.79012493093918010345e+01) (8, 1.21696614432233174430e-01) (9, 1.62173642175867972759e-02) (10, -7.88904757067935072379e-03) (11, -8.30727744584410926487e-02) (12, -4.85285003890313093589e-02) (13, -7.71948633143149445801e-03) (0, 1.25947744620204171717e+00) (1, 4.56381553701067255169e-01) (2, 4.68602770856523798138e-01) (3, 4.70450820318365381389e-01) (4, 4.08683577469492242962e-01) (5, -8.31144149250952479768e-01) (6, 6.91851945499446285837e-01) (7, -4.13931170672993342663e+00) (8, 2.53261368969003100582e-02) (9, 3.61680422046426530702e-01) (10, 1.91096811200696020672e-01) (11, 4.06491818630481532848e-02) (12, 4.60940786385885925558e-01) (13, 4.18644658843120576197e-01) (0, 7.28837227853584068704e-01) (1, 2.19982517119340609257e-01) (2, 3.19092233832768967794e-01) (3, 3.03043087180547399129e-01) (4, 3.25722118075780442403e-01) (5, 3.94944156616623409661e-02) (6, 8.66642016661046343806e-01) (7, -2.93896077229559038457e+00) (8, -6.40973437170248763056e-04) (9, 5.19087716029753232228e-01) (10, 1.19300747820376557007e-01) (11, -5.59643317729794295690e-02) (12, 2.14922354230387774310e-01) (13, 3.78598344678523823781e-01) (0, -6.13530260896028023510e-01) (1, 4.06985973997913072497e-02) (2, -1.92886942938961386540e-02) (3, 3.89066433592639634997e-02) (4, -6.15914666966594775976e-02) (5, -6.39383869899304985163e-02) (6, 6.57410489018452198762e-02) (7, 3.23443567878078255262e+01) (8, 7.65880252168136821389e-02) (9, -1.92936195270357102594e-01) (10, -1.48270516784873795935e-01) (11, -9.10541921141324733791e-02) (12, -3.24417268831830862830e-02) (13, -1.97195206161178637760e-01) (0, 1.28424810839057168543e+00) (1, 3.65370670250559137493e-01) (2, 4.07091556033993051678e-01) (3, 3.83178325287008569866e-01) (4, 3.81888205102587030559e-01) (5, -1.07791889621435349467e-01) (6, 1.04619475304015296935e+00) (7, -4.32314283164848234264e+00) (8, 1.46456185147973566574e-01) (9, 6.61397377402303532357e-01) (10, 1.36840133573132377576e-01) (11, 3.86500159457499881110e-02) (12, 3.71763522636563259471e-01) (13, 5.97264401236614395074e-01) (0, 1.27175785154320514225e-01) (1, -6.65979358379701763537e-02) (2, 7.02549469645162155684e-02) (3, 5.94903798653082047793e-03) (4, -7.32337581937173992541e-02) (5, 1.05066751605114430679e-01) (6, 4.66727185255907117689e-01) (7, -8.46949329968716568828e+00) (8, 1.02000069496510281652e+00) (9, -1.62012857911235624853e-01) (10, -6.47406512414740696604e-03) (11, -7.14238760804124933612e-02) (12, 1.31168912294131606577e-01) (13, 6.34475527714370296506e-02) (0, 2.57912404805216544101e-01) (1, 2.76339763593541010156e-01) (2, 3.45454500806198938623e-01) (3, 4.04917435538636072412e-01) (4, 2.83038826477394922509e-01) (5, 9.75474143809200833211e-01) (6, -4.76195309614464989956e-02) (7, 7.79352775116871043792e+01) (8, 8.41402492999012152630e-02) (9, 8.28130389995861831975e-04) (10, -8.55153355078437232839e-02) (11, -1.37404136705908119787e-01) (12, -8.54761202233213224222e-03) (13, 1.86447209363297013163e-02) (0, 2.31776304096199786686e-01) (1, -5.22744554107050576897e-02) (2, 7.27058750565190842208e-02) (3, -4.69474430208067575188e-02) (4, -1.81643190805773416252e-02) (5, 4.57821683233437248806e-02) (6, 5.28915579623601916914e-01) (7, -8.47802367802884049297e+00) (8, 9.21069605921485567990e-01) (9, -1.04946562615281929753e-01) (10, -3.75420958689384048901e-02) (11, 5.02288760806135284320e-02) (12, 1.67041416409236309626e-01) (13, 4.77465568493484066037e-02) (0, -6.56617081508970801274e-01) (1, -1.67232228563636314833e-01) (2, -5.97124082311091750053e-02) (3, -1.66917665050834190810e-01) (4, -9.77231842740473310993e-02) (5, -1.24983455853652627998e-01) (6, 6.23818693410998839632e-02) (7, 3.22335711172293457594e+01) (8, 7.05134412965256751615e-02) (9, -3.08965690974030871008e-01) (10, -1.91294118518029826470e-01) (11, 3.54746851910343798803e-03) (12, 4.02049025156338765696e-02) (13, -6.67552267021976619699e-02) (14, 3.95333229583823997366e-01) (15, 4.20639513716194068937e-01) (16, -9.39222868119803516729e-02) (17, -1.76437236360428156834e-02) (18, 4.22045096741221259506e-01) (19, -1.17657632131493702921e-01) (20, -1.33586802614036714854e-01) (21, 3.51616888031455909758e-01) (22, -8.30794255098423473083e-02) (23, 3.88692176920497733938e-01) (24, 2.61634952113124763518e-01) 
