FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=14 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.08681353828364124503e-01) (1, 4.42529136496264907663e-01) (2, 5.19802699046809535410e-01) (3, 4.00897326129157516306e-01) (4, 4.83342008846480708506e-01) (5, -1.66187008937858954338e-01) (6, 1.62229739158718100356e+00) (7, -5.82409813920170282842e+00) (8, 6.45890836572126647575e-01) (9, 5.74139077821798182732e-01) (10, 2.22850141579913341161e+00) (11, 2.79411569781788438060e-01) (12, -2.09071663896302117891e+00) (13, 1.08342742015230841801e+00) (0, 2.28251129360959148507e-01) (1, 4.72670752815477768216e-01) (2, 2.87492845467798741055e-01) (3, 4.69226781539194504056e-01) (4, 4.64902911595575729642e-01) (5, -1.66582928914917616225e+00) (6, -7.97451849691376279949e-01) (7, 6.62321886778746815594e+00) (8, -2.21970298392324238979e-01) (9, 1.10107428577367397193e-01) (10, 3.12241594894543117444e-02) (11, 1.12058017188222225347e-01) (12, -6.80560895286210776334e-01) (13, -3.06496020815962888495e-01) (0, -7.03572265761974371262e-03) (1, -1.51919465784803670028e-01) (2, -4.60331591711200180383e-02) (3, -1.52946707134023945907e-01) (4, -9.53117984280742042147e-02) (5, 1.25096260058872976728e-01) (6, -1.14281490719899000985e-01) (7, -5.81923879428235224509e+00) (8, 6.41274605030002775585e-01) (9, 5.65325973195823852646e-02) (10, 6.26060993490404754658e-02) (11, -2.61259654188167704525e-02) (12, 1.95671229098847349048e-01) (13, 1.24235883815758688109e-01) (0, 3.66462671719243460178e-01) (1, 4.31585508981841614595e-01) (2, 4.89294070402282288423e-01) (3, 3.91764323810237458101e-01) (4, 4.17671683827537110201e-01) (5, 2.24304354667003469359e+00) (6, 4.91975734499722316961e-01) (7, 6.71481743813430043133e+00) (8, 2.68824583694799723599e-01) (9, 2.13928087907593933448e-01) (10, -5.99146355287417178848e-02) (11, 7.77744946717331825381e-02) (12, -4.33576916591051075844e-01) (13, 3.69593590793265092120e-01) (0, -1.42535077927318321045e+00) (1, -9.88935089078049056610e-02) (2, -1.18977293964872776755e-01) (3, -2.62605563398848107504e-01) (4, -2.58823194202433159994e-01) (5, -9.65230236040269112818e-02) (6, 3.75321128232754125387e-02) (7, 2.47625920064809035281e+00) (8, 9.60108424603672676312e-03) (9, -5.12462632866895972938e-01) (10, -1.45215887669641163793e-01) (11, -3.05877338308538415657e-01) (12, -1.57135600959298904478e-01) (13, -9.72283055499623405371e-02) (0, -1.38448286948409782227e+00) (1, -9.82962107625106884523e-02) (2, -1.50228396650801204748e-01) (3, -2.30495159175644420690e-01) (4, -1.70998909172068142004e-01) (5, -8.87248883234177804225e-02) (6, -3.80790720256697745594e-01) (7, 2.39383144633116984323e+00) (8, -7.65244684082296428018e-02) (9, -4.76573770796446860576e-01) (10, -1.43082793895322468725e-01) (11, -2.36519674833947868287e-01) (12, 1.95030121602319597707e-02) (13, -4.05526587407049221579e-01) (0, 6.76622486863743960450e-02) (1, -1.10438511158088503716e-01) (2, -1.18359960998157320855e-01) (3, -1.06907956684688387750e-01) (4, -1.28327854360202581185e-01) (5, 8.11664702109769486960e-02) (6, 4.87651087350647716168e-01) (7, -2.04796644614295741960e+00) (8, 7.27827545339050918649e-01) (9, 7.56328986417909854278e-02) (10, 1.08235302750467193844e-01) (11, -1.58992835903179301205e-02) (12, 4.43489203168561663126e-02) (13, 1.09159082634919149535e-01) (0, 4.90526103935887858309e-01) (1, 4.37205943862098267427e-01) (2, 4.19987167814868500582e-01) (3, 4.78860634962218811861e-01) (4, 4.19913891354697754732e-01) (5, 2.10360413520868183568e+00) (6, 4.46938837436467006903e-01) (7, 6.64874655366812916668e+00) (8, 2.34495839879377637738e-01) (9, 2.69442174203721684922e-01) (10, -1.02700041641412609383e-01) (11, 8.82159059583256799364e-02) (12, -3.63372993902089935769e-01) (13, 4.58954885897291886554e-01) (0, -1.40442273912635551270e+00) (1, -1.21234223839292942770e-01) (2, -1.09998331066618382224e-01) (3, -1.66979559358606838293e-01) (4, -2.31668223288307689733e-01) (5, -7.22992250164493366338e-02) (6, -5.11654677363764909259e-01) (7, 2.39411366902611755236e+00) (8, -8.18984306317594584756e-02) (9, -5.05306901546514919410e-01) (10, -2.43303109053689764485e-01) (11, -2.69787284233666158073e-01) (12, -5.78492325237420224049e-03) (13, -3.84835393766817135397e-01) (0, -8.53792844536537920419e-01) (1, -1.09542409667306689380e-01) (2, -1.24232123383813647388e-01) (3, -9.76404498904283324467e-02) (4, -1.76624658295446240741e-01) (5, -1.35546706079116952015e-01) (6, 1.34515407757309718439e-01) (7, 2.25119227775495289734e+00) (8, 1.24282728247039425673e-01) (9, -6.87938626303365302617e-02) (10, -2.16048393491822893209e-01) (11, -1.92815264821890985925e-01) (12, 1.73575895930420942559e-01) (13, -3.68174804966872881717e-01) (14, -1.24696457305018923445e-01) (15, 4.14295802873716922932e-01) (16, -1.75802355922271391631e-01) (17, 4.04428887230501743488e-01) (18, 4.78308427821539039471e-01) (19, 4.31056197475336189129e-01) (20, -2.13156538374234927335e-01) (21, 4.23401664060698124104e-01) (22, 4.83706582080267066814e-01) (23, 4.29817352186582679607e-01) (24, 3.44414259356604190998e-01) 
