FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.10332038432676249329e+00) (1, -2.07325230429491424999e+00) (2, -6.43062494116024119251e-01) (3, -8.11750079314859873669e-01) (4, -7.60935123430685145252e-01) (5, -1.65737709091162122022e+00) (6, -1.29745260097980930070e-01) (7, -2.49593195077908780455e-01) (8, -3.23372385153402053248e+00) (9, 2.00612750238944625991e+00) (10, 1.72343499357975349362e+00) (0, 1.58399557603306595510e+00) (1, -2.16533417890390778027e+00) (2, -7.32741727845863444202e-01) (3, -7.71248589079531199353e-01) (4, -7.28018976168827158801e-01) (5, -8.05501166046921901476e-02) (6, 1.10284612385312441596e+00) (7, 2.64443092881637559222e-02) (8, -1.34119968997703775671e+00) (9, 2.77364874137004235877e+00) (10, 1.14289842770116800708e+00) (0, 1.60896145833439652151e+00) (1, -2.25503368566355133495e+00) (2, -7.09611921923355204456e-01) (3, -8.64877211671026713269e-01) (4, -6.86962745504573923938e-01) (5, -1.29414030468589513756e-01) (6, 1.18873550055304888495e+00) (7, -8.21617162884277357771e-02) (8, -1.38456689702736124303e+00) (9, 2.66756510985453942908e+00) (10, 1.21558210432846025562e+00) (11, -2.75387143920991528390e+00) (12, -4.04252842005851587004e+00) (13, -3.99637019571426233000e+00) (14, -6.52356482881557453446e-01) 
