FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=14 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.57760268657230096068e-01) (1, 2.70479464305549352487e-02) (2, 8.96135934961944380373e-02) (3, 4.54706655217319150042e-02) (4, 5.62691980374961514544e-02) (5, -3.79982586990061377286e-01) (6, 1.13597057689243621792e-01) (7, -3.86321558265553879896e-02) (8, 1.03993317395783976820e-01) (9, -9.17713182004260968894e-02) (10, -1.01417661412888504557e+00) (11, 1.14282192291169107379e-01) (12, 1.57984877277003776808e-01) (13, 3.04452760816517287168e-01) (0, 8.18139153926395135130e-01) (1, 3.42117579055934706300e-02) (2, 6.88344178329998446220e-03) (3, 5.77639726530605746024e-03) (4, 1.44317119695058476703e-01) (5, -4.19245477805796351589e-01) (6, 1.30857168254165434629e-01) (7, 5.81442551107539326583e-02) (8, -5.35147058182911927043e-03) (9, -7.22695724995899430043e-02) (10, -1.13550904347830705632e+00) (11, 4.05373939311445163902e-01) (12, 2.66836433011876816845e-01) (13, 3.99376813507452466112e-01) (0, 4.16509086371188164133e-01) (1, 1.49135775451873620057e-01) (2, 1.60669922416423610612e-01) (3, 2.79712259357189130249e-01) (4, 1.92422877584909252091e-01) (5, -3.33018557426079997441e-01) (6, -2.86730751555312690648e-01) (7, -1.01668177671148260433e-01) (8, 2.33632643857739352722e-01) (9, -1.34761780626612837075e+00) (10, -1.54317090159411152150e+00) (11, 2.68879773272289623876e-01) (12, 3.60841505420691835426e-02) (13, 2.43198495655236934798e-01) (0, 6.11486862938354391872e+00) (1, 3.36287739961515119713e-01) (2, 2.61710844277511289757e-01) (3, 3.55670045404802015465e-01) (4, 3.86738653569589641013e-01) (5, 8.86750891663723805891e+00) (6, 3.14214740018583571501e-01) (7, 3.44760814487434619213e-01) (8, -5.19439557816684605029e+00) (9, 2.36637539828345261350e-01) (10, 9.03506184510512788677e+00) (11, 3.49453039246120256145e-01) (12, 3.27984358127577924069e-01) (13, -4.38377766429728574216e-02) (0, -6.15634029468675403329e-01) (1, -3.85789793753304258161e-02) (2, -1.50352447929350374611e-01) (3, -1.15240864160028891328e-01) (4, -2.84313333058037569223e-02) (5, 7.92004347839119354768e-02) (6, -2.17459361198576589524e-01) (7, -1.34474071490965768616e-01) (8, 2.26554475714185210578e+00) (9, -1.42304906708805245508e-01) (10, 1.68557018504259303882e-01) (11, -1.00325966552466977477e-01) (12, -2.77224716576796210987e-02) (13, -1.09540142943005139320e-01) (0, -1.40666126489023679547e+00) (1, 4.86777007344579501491e-03) (2, -8.73909068131127064749e-02) (3, -1.38583015354839772515e-01) (4, -8.02658048295654957816e-02) (5, 7.64099440725787976136e-02) (6, -5.86449441943892382789e-02) (7, -7.39204663804868961074e-02) (8, 1.89327057329265979746e+00) (9, 2.57718217425915545327e-02) (10, -9.38643653415474205071e-02) (11, -1.11558543375005939091e-01) (12, -9.44345851191760593535e-02) (13, -1.89172775158848838206e-01) (0, 5.96883170081399572204e-01) (1, 1.52359348871100974687e-01) (2, 3.31039178746830101141e-02) (3, 4.51087068396698043227e-02) (4, 1.03350212015498724161e-01) (5, -2.19567687273193173914e-01) (6, 7.78939072920317998605e-02) (7, -1.02220843381830864272e-01) (8, -7.08133823917726501485e-02) (9, -1.21773695048629462812e-01) (10, -5.35346283565377389912e-01) (11, 4.89005800439384838429e-02) (12, 2.54307357866155381299e-01) (13, 1.29433740620847337333e-01) (0, 6.24969967793176550686e+00) (1, 3.10895758955846479576e-01) (2, 3.89666895656953837790e-01) (3, 4.07239194302927043356e-01) (4, 3.05333364098439863366e-01) (5, 8.87452130623751500593e+00) (6, 1.94755140762068096327e-01) (7, 4.12103289544082873608e-01) (8, -5.94541547088970556700e+00) (9, 2.32032112443968735471e-01) (10, 8.99917642913384874248e+00) (11, 2.91447713795370710876e-01) (12, 3.06175510342582002377e-01) (13, 3.75022768673285641916e-02) (0, -5.66115556022306121164e-01) (1, -8.70708629263092642736e-02) (2, -4.62062164915253495434e-02) (3, -1.22994187451665612509e-01) (4, -1.33576455689733281096e-01) (5, -5.92693381754413259332e-02) (6, -9.05064448148333172695e-02) (7, 4.11234121748109901495e-02) (8, 2.16086161189860748166e+00) (9, -9.06999844466233468010e-02) (10, -3.82425903645368173156e-02) (11, -9.15892010314016818961e-02) (12, -1.09247123086023259497e-01) (13, -1.53954326014384690335e-01) (0, -6.11826817720121596267e-01) (1, -8.56873432251333971843e-02) (2, -8.08054396959662080135e-02) (3, -1.58725273058068799825e-01) (4, -1.96212899133813373220e-01) (5, 5.83863712104305196404e-02) (6, -1.79783129457069285051e-01) (7, -3.38906907563329834465e-02) (8, 2.86156908622233308037e+00) (9, -5.23766714488053675147e-02) (10, 2.43884094688086097702e-02) (11, -1.15242876719575310096e-01) (12, -1.92555239943445172246e-01) (13, -1.03682874541148675740e-01) (14, -8.45468878290069336678e-01) (15, -2.33067333457877529090e-01) (16, -1.93761882190222112232e-01) (17, 7.88780469818409102345e-01) (18, 6.83250484404853364317e-01) (19, 5.88822110759823380555e-01) (20, -1.27126107724433862201e-01) (21, 7.14657377822693007374e-01) (22, 5.95611288415997086609e-01) (23, 6.43208498038390752427e-01) (24, 2.48085427135524783093e-01) 
