FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.87457745086419569347e-01) (1, 1.86219170387363075481e-01) (2, 1.05380236800288851207e-01) (3, 1.70760370488738655315e-01) (4, 2.29629218276118873820e-01) (5, -1.08031662743223599854e+00) (6, 2.55635931341650801674e-01) (7, -8.43387994013085395828e-01) (8, 3.49389127522756082200e-01) (0, 2.30044654257353847759e-01) (1, -4.94473049956980284514e-02) (2, -5.24817849117937620940e-02) (3, 1.16008487921532860848e-02) (4, -1.01400400938433693510e-01) (5, -6.66535773228235495225e+00) (6, 5.30486080009975533023e-03) (7, 2.57981403962428990084e+00) (8, 2.26606422729080186906e-01) (0, -2.56616933793573864797e-01) (1, -4.08231484710044889574e-02) (2, -2.75498497306175156585e-02) (3, -2.46398764668769761077e-02) (4, -1.84815565031654388539e-01) (5, 9.58723067852453425530e-01) (6, -1.67355018717917608528e-01) (7, 1.66982934589201748032e+00) (8, -3.48569879162608453615e-01) (0, -3.49611365026415432666e-01) (1, -7.70768206958477308799e-02) (2, -6.25849347953502804787e-02) (3, -7.19666611795131971885e-02) (4, -1.17372660005540113692e-01) (5, 9.45437527808145716790e-01) (6, -5.33067016431418433386e-02) (7, 1.59723718120883306781e+00) (8, -2.09745597450904680548e-01) (0, 2.96362935252245884854e-01) (1, -2.94233435575396969422e-03) (2, 6.50667217951592796732e-02) (3, -1.16242426056090055603e-02) (4, -8.00092252511206136756e-02) (5, -6.64389710228271734849e+00) (6, 6.29535887888157119630e-02) (7, 2.59301575318630161959e+00) (8, 1.43169551096929720257e-01) (0, 5.72792469274270521495e-01) (1, 7.71899086087228236686e-02) (2, 2.17799560412693105071e-01) (3, 1.04692460283565685897e-01) (4, 2.56439955219554927002e-01) (5, -1.03047004904282979432e+00) (6, 1.07513075697915877482e-01) (7, -8.41594852004194371453e-01) (8, 3.55120926231194955491e-01) (0, 4.59688040662336094844e-01) (1, 4.02051367971256012890e-01) (2, 3.57402094814136261913e-01) (3, 2.91731001052215332958e-01) (4, 2.62593929830148564708e-01) (5, 1.85275578195285128835e+00) (6, 2.46953136836666392595e-01) (7, -4.19202096360542064701e-01) (8, 5.69415681140217830314e-02) (0, -4.09209615141897686819e-01) (1, -9.67249178498726797093e-02) (2, -1.12086338660095319320e-01) (3, 3.70959082271496009154e-04) (4, -1.07473535200927824973e-01) (5, 1.10144794693847081213e+00) (6, -2.66092597076026289582e-02) (7, 1.50455426988186369286e+00) (8, -4.02988293236952954679e-01) (0, -2.48927457780390243292e-01) (1, -7.03203621229587932939e-02) (2, -4.68163060864864935540e-02) (3, -1.80600838633483612439e-01) (4, -1.25281469794219668668e-01) (5, 1.07500188759227177648e+00) (6, -2.66965507098761885285e-02) (7, 1.48117182518157819437e+00) (8, -2.31205385534934776404e-01) (0, 4.46077323900101962995e-01) (1, 3.06049352188961232279e-01) (2, 3.01651438375370228862e-01) (3, 3.72273577054397786235e-01) (4, 3.48819700678245747660e-01) (5, -3.67576096666218488096e+00) (6, -6.02681341600510900314e-01) (7, 1.14375224299395554795e+01) (8, 1.60655390855169277753e-01) (9, -3.63963682301589180890e-02) (10, -3.54146568012298434969e-01) (11, 4.57062069092691591887e-01) (12, 3.80372083449324660531e-01) (13, -1.13802846467114776585e-01) (14, -1.01936404869272783519e-02) (15, 4.08780066422472443399e-01) (16, 4.10972350621393034409e-01) (17, 3.64751494193038039437e-01) (18, 3.94801190697795401086e-01) (19, 2.25526301037911214298e-01) 
