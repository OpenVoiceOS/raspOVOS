FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.95960861015685228192e-02) (1, 3.96695206775987185832e-01) (2, 3.56575208618962802287e-01) (3, 4.32725812211358584758e-01) (4, 4.50038391068303622600e-01) (5, 9.76290217650820912887e-01) (6, 1.03514138636553409967e+00) (7, 1.89301540276185908951e+00) (8, 5.61972354932133932870e-01) (9, 7.85557086072500410090e-01) (10, -2.16211731495919101675e+00) (11, 1.10742804931938665369e+00) (0, 1.12688706200251509415e+00) (1, 3.45750755031025647224e-01) (2, 4.17054659087574719489e-01) (3, 3.44545906741535901130e-01) (4, 4.30628260929501294196e-01) (5, 1.41670520517703124597e-01) (6, -1.73086410955337655082e+00) (7, -3.32269933189832844533e+00) (8, 2.72341621919416521092e-01) (9, 2.11835495437411230890e-01) (10, 5.22055645973750692690e+00) (11, -2.89912577862636404447e-02) (0, -1.78901199814927402976e+00) (1, -1.53805559478556896913e-01) (2, -1.39957761369502331483e-01) (3, -3.03081778786933264680e-01) (4, -2.98254324100768408723e-01) (5, -1.62102166481216780625e-01) (6, 1.45859109392672459116e+00) (7, 3.51187354341437085736e+00) (8, 1.47932880254413451349e-01) (9, -3.99846109863335852364e-01) (10, -6.85209274689090389043e-03) (11, -1.53019728185388170782e-01) (0, -1.81814537015807453635e+00) (1, -1.77193259797847058046e-01) (2, -1.44893368683612133729e-01) (3, -2.70311119012391298799e-01) (4, -2.71437177412068575411e-01) (5, -2.33035817660292049469e-01) (6, 1.65719727457761112355e+00) (7, 3.43619295597364082795e+00) (8, 9.99730459171788987671e-02) (9, -3.34731768187100597878e-01) (10, 1.08498654822570747558e-03) (11, -1.46471427799913012091e-01) (0, 1.22661971430907179581e+00) (1, 4.16436707932865857185e-01) (2, 2.90830018330729245246e-01) (3, 3.69061773974812268317e-01) (4, 3.38867796916878460944e-01) (5, 1.88856492850657586846e-01) (6, -1.63525849775222908988e+00) (7, -3.42830025519811787404e+00) (8, 4.12619342907213249028e-01) (9, 1.82518414462832345713e-01) (10, 5.09892897994586569155e+00) (11, -5.44909389098581498079e-02) (0, -7.78034244295294080684e-03) (1, 3.93358799531781710979e-01) (2, 4.33478179290616549846e-01) (3, 3.25547451987588443156e-01) (4, 4.87752589300000927164e-01) (5, 9.58040109885623158981e-01) (6, 1.08045765784943226251e+00) (7, 1.89814444577471697073e+00) (8, 4.99458332939450355692e-01) (9, 7.98396142623956861506e-01) (10, -2.13024923714461200674e+00) (11, 1.13554479705631750086e+00) (0, 9.10464143235407252774e-01) (1, 2.59785309533667019277e-01) (2, 1.90922923485826956380e-01) (3, 2.89241172473024776846e-01) (4, 2.19293441723179327596e-01) (5, 2.15901777026897140344e-01) (6, -7.76512057148637024895e-01) (7, -5.93190944726491586891e+00) (8, 9.05510825079436088014e-02) (9, 2.31367686584528636784e-01) (10, 3.01541762892367448678e-01) (11, 1.78452892127656526089e-01) (0, -1.80020289686572376731e+00) (1, -1.32559454046046520936e-01) (2, -2.70800633333480089693e-01) (3, -2.64084758214509218721e-01) (4, -2.39445438586032177675e-01) (5, -2.05678824253280989609e-01) (6, 1.51552113921641651295e+00) (7, 3.47330600038458570111e+00) (8, 1.01019807787563115076e-01) (9, -3.33902652677113720436e-01) (10, 4.74019995292055268399e-02) (11, -1.62218594969960772101e-01) (0, 1.07435897843874278434e-01) (1, 3.60573633476817645427e-01) (2, 4.89233347490155956461e-01) (3, 3.53064755812013186809e-01) (4, 4.79168760493123790933e-01) (5, 8.27423844680310160982e-01) (6, 1.13699699965679767999e+00) (7, 1.97658520510570445694e+00) (8, 5.50005888028447409432e-01) (9, 6.95449145935114310113e-01) (10, -2.18755881252350681265e+00) (11, 9.81520345085263423712e-01) (0, 1.31293191890845228897e+00) (1, 3.74046323034736782898e-01) (2, 4.33737014565441281189e-01) (3, 4.17304163012478024353e-01) (4, 2.77222496602508805541e-01) (5, 6.79904102467866755521e-02) (6, -1.55707219437507760063e+00) (7, -3.33383870239936985769e+00) (8, 2.77664368851923026860e-01) (9, 1.29861838425425507593e-01) (10, 6.41743582489674579961e+00) (11, -1.04285230874528109246e-01) (12, -1.10953851621235111136e-01) (13, 4.59307037174637333710e-01) (14, 4.39009971826392175753e-01) (15, 5.02646580248194752016e-01) (16, 4.19644303500587956268e-01) (17, -1.20301186125362641333e-01) (18, -8.23105557411300120529e-02) (19, 5.22639915256816078859e-01) (20, -7.59421056319123932710e-02) (21, 5.98090197825146940858e-01) (22, 3.50824155015060590301e-01) 
