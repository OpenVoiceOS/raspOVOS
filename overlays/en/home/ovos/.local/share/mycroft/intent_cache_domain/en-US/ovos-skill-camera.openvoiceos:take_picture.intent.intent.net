FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.17177789476507374644e+01) (1, 2.23783888935996017056e-01) (2, 3.14857908606482606029e-01) (3, 4.20706258237315222637e-01) (4, 2.95701281249476366497e-01) (5, -4.27735403475717479438e-01) (6, 3.19040224639778491333e-01) (7, -4.53009597874004743545e+00) (8, -4.74580744553313937928e+00) (9, 1.20912309444025045657e+00) (0, 1.12543510611549830713e+01) (1, 5.33792880102048616919e-01) (2, 5.79946958198200079870e-01) (3, 5.87492146267543646765e-01) (4, 5.68810143246303412390e-01) (5, -5.37240470776697565114e-01) (6, 2.36094055759388549154e-01) (7, -7.20562449364604162838e+00) (8, -6.91571736252538471490e+00) (9, 1.73709623991664630083e+00) (0, -2.98001684864967086863e-01) (1, 2.72279670922266514577e-01) (2, 3.42148365913139851369e-01) (3, 3.75432128546940413472e-01) (4, 2.80731028406130345143e-01) (5, -1.07947327995315833782e+00) (6, -2.26286274959410838026e-01) (7, -2.38813569285957516541e+00) (8, -1.97508228581019928960e+00) (9, 4.60561683461929494143e-01) (0, 6.00197330133326989454e-01) (1, 1.66224713755185632413e-01) (2, 7.86276565318655557002e-02) (3, 2.51046005023057516858e-01) (4, 1.64368900788362054532e-01) (5, 3.66142839166364975068e-01) (6, 2.30886159979507371576e-01) (7, 1.17670218729628728305e+00) (8, 1.23832764681925084460e+02) (9, -7.46743684563811599419e-02) (0, 1.15365923833840557933e+01) (1, 2.35544337329287700733e-01) (2, 3.71560043093581204854e-01) (3, 3.15034797784705389301e-01) (4, 3.33958452937026140095e-01) (5, -4.92780950329614442218e-01) (6, -2.93802338826187614540e-01) (7, -3.54492608991361057846e+00) (8, -3.84211014027214003974e+00) (9, 1.03588324551621147052e+00) (0, 5.40373297563784826814e-01) (1, 2.68870631693111927785e-01) (2, 3.15904381213890639302e-01) (3, 4.04835323332058460988e-01) (4, 2.23174738226639357563e-01) (5, -8.93509903038287589538e-01) (6, -2.79548769463862589735e-01) (7, -2.24514546838330364409e+00) (8, -2.10862443403286592414e+00) (9, 5.98607165063943846839e-01) (0, 5.98950631932624322218e-01) (1, 2.64779372638423160513e-01) (2, 1.11458333706814904929e-01) (3, 1.88842213278967968604e-01) (4, 2.56722746914584354361e-01) (5, 5.17366700359213838034e-01) (6, 1.78977184744454315135e-01) (7, 7.90156111484882628382e-01) (8, 1.23745586503793504107e+02) (9, -1.50610634365607426455e-01) (0, -4.06261273691952695675e-01) (1, -9.41009224765574775473e-02) (2, -1.84954129289892854615e-01) (3, -1.86435930561331453248e-01) (4, -1.85927961152104082032e-01) (5, 1.28272200456563134630e+00) (6, 9.73423490128736829119e-02) (7, 1.46265330003204807596e+00) (8, 1.81189381401346150113e+00) (9, -1.56309154228375130069e-01) (0, 1.23036328028029706694e+00) (1, 2.88480383080893298953e-01) (2, 2.49070227814369882235e-01) (3, 2.89250035507136127322e-01) (4, 2.72187680674248422275e-01) (5, 1.03107820685939571836e-01) (6, 1.43452779238745331547e-01) (7, -3.86056095040530777851e+00) (8, -2.94786565472308170754e+00) (9, 3.10915209949531701206e-01) (0, 6.88937805609115105909e-01) (1, 2.58523731058795225302e-01) (2, 1.60616240030486218116e-01) (3, 9.98463691532202879397e-02) (4, 1.76449625319201580664e-01) (5, 4.20019897002742448322e-01) (6, 3.43125411124802381924e-01) (7, 7.53658123678085600794e-01) (8, 1.23661380347360875476e+02) (9, -7.36405935674202954955e-02) (10, -1.11108039226031421465e-01) (11, -1.97713487195580933653e-01) (12, -3.32357476311099742095e-01) (13, 4.46088719753750140296e-01) (14, -9.92981686253310708024e-02) (15, -2.94546487586868022124e-01) (16, 4.03733562439311133296e-01) (17, 6.73284107225852967993e-01) (18, -4.11391337788769642647e-02) (19, 3.94476666047328894393e-01) (20, 4.47354602368196296869e-01) 
