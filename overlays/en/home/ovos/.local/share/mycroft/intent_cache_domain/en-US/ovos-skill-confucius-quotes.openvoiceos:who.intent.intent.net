FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.83381628327908807741e-02) (1, -1.08600786547096386792e-01) (2, -1.24361893753440963528e-01) (3, -1.66891357521446376255e-01) (4, -5.33434661430436454777e-02) (5, -7.43279667896348528178e-02) (6, -7.81466002592263730975e-02) (7, 8.58959940818333378409e-01) (8, -9.53306727483758525876e-02) (9, 9.99119568582127887124e-02) (0, 4.07841923251227922442e-01) (1, 1.18620253379488102552e-01) (2, 1.50150439913416033910e-01) (3, 1.48400164420747882055e-01) (4, 1.76459445829534683492e-01) (5, 4.75479933002095553340e-02) (6, 1.37950014996439829229e-01) (7, -3.83120445715765950423e-02) (8, 9.62425235475757034909e-02) (9, -1.32743748922749149610e-01) (0, 2.72467066050038231317e-01) (1, 3.29806042522963638319e-01) (2, 3.84504964263018722548e-01) (3, 2.76658666939315067701e-01) (4, 3.60967410416182632460e-01) (5, 1.68571588909466413275e-01) (6, 2.85193134609049714356e-02) (7, 9.90547222139850092049e+00) (8, 1.82673977982711344126e-01) (9, 1.65515331544456412161e-01) (0, 6.61999902289308383985e-01) (1, 1.72232821699667693061e-02) (2, 6.61133241324492020030e-04) (3, 1.06264090549616899151e-01) (4, 1.03499604773192491192e-01) (5, 1.82207320189069071903e-01) (6, 7.40993979032457339429e-01) (7, -3.00832873926674571052e+00) (8, 7.57175725999528204113e-01) (9, 8.70756392481976781994e-01) (0, -5.49869307871010820632e-02) (1, 1.64693718061082766679e-01) (2, 5.01166630836657814307e-02) (3, 1.55213360890977786211e-01) (4, 6.40461195560626112000e-02) (5, 1.19406921511778285616e-01) (6, 3.36975554176122057970e-02) (7, 7.86659531843556258934e+00) (8, 5.63986610032059798581e-02) (9, 1.07674383603776225443e-03) (0, 5.10994291465677097364e-01) (1, -1.66787147406052861653e-02) (2, 1.45534238230853152363e-01) (3, 1.55963397037653994648e-01) (4, 4.98568863835818342628e-03) (5, 2.33229358052800456180e-01) (6, 7.64154928381860720776e-01) (7, -3.06609676377093043342e+00) (8, 7.58919146958047186047e-01) (9, 7.06001979413682256848e-01) (0, 2.17859711945519174403e-01) (1, 3.38417460829791183485e-01) (2, 3.25265271277007217421e-01) (3, 3.79870658428248519911e-01) (4, 2.65207690805968399061e-01) (5, 2.10566980159123090521e-01) (6, -4.39624581913638096120e-02) (7, 1.00079103434325737965e+01) (8, 1.40373424302143168241e-02) (9, 1.18478147306022574270e-01) (0, -1.27100715036539274605e-02) (1, 1.33244161710374786622e-01) (2, -5.72309155739028282972e-03) (3, 1.63236026868455813554e-01) (4, 1.05189358100526750284e-01) (5, 1.69334464727729956668e-02) (6, 1.63417054916217940885e-01) (7, 8.02522849839819762963e+00) (8, 1.10430979297254289184e-01) (9, -7.03928760341480802554e-02) (0, 5.21693783413566425367e-01) (1, 1.26035949599413971134e-01) (2, 3.10025961366183332862e-03) (3, 3.21256221499926618995e-03) (4, 1.02525500964789476055e-01) (5, 4.08146776404815558870e-01) (6, 7.31136257405698763989e-01) (7, -2.98881937897006544347e+00) (8, 3.00480862247616165028e-01) (9, 8.54691376093083654553e-01) (0, -4.14653339977410356765e-02) (1, 1.63164247974985049394e-01) (2, 4.79023281785182289405e-02) (3, 1.37903263077371551759e-01) (4, 8.80406324120692335145e-02) (5, -5.66458117062362126459e-06) (6, 1.38120858574703381239e-01) (7, 7.90945909720553252953e+00) (8, 2.01538668141458238159e-01) (9, -6.21065042070225517556e-02) (10, 2.73784598795068223609e-01) (11, -2.03787167115104667081e-02) (12, 1.67230366373851913053e-01) (13, -3.37799870374738075984e-01) (14, 3.03092689184194741259e-01) (15, -3.29089597764550545467e-01) (16, 1.72228007222011703092e-01) (17, 5.02082676783843662172e-01) (18, -3.62659865024625216456e-01) (19, 5.66171074341232927196e-01) (20, 4.09372759945294373285e-01) 
