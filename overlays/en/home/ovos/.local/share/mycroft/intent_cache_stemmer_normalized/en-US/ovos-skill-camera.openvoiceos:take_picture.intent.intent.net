FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.90378346546007171103e-02) (1, -3.96398689272419585405e-02) (2, -7.43150721910015576999e-02) (3, -4.73478031398458319018e-04) (4, 6.74985487339480882962e-02) (5, 4.96575908614399375018e-01) (6, 2.77306663760859217760e-01) (7, -1.05520327587031736982e+01) (8, -1.86121519041554904561e+02) (9, 6.91005481296130263935e-01) (0, 1.61050493513394815670e-01) (1, -1.12927974355460758460e-01) (2, 4.45415366766436782164e-02) (3, -9.37005240941207045990e-03) (4, -3.37868194701687468706e-02) (5, 4.93329675747158469257e-01) (6, 2.51899673560578074571e-01) (7, -1.03719085727238073957e+01) (8, -1.86177538981037116628e+02) (9, 5.72404449694701500384e-01) (0, -8.16576895561905435894e-02) (1, 4.09183043849989241947e-02) (2, 4.02072209728285140384e-02) (3, -2.78452348100618023163e-02) (4, -6.63600426303819768137e-02) (5, 1.66232786028358281438e-01) (6, 5.09466724568108028648e-02) (7, 4.87160583986999551342e+00) (8, 7.89723557145088932430e+01) (9, -3.95062585046178291193e-02) (0, -1.45141121491500962870e-01) (1, 2.72640872610136579535e-02) (2, 5.16442794216200179447e-02) (3, 1.00184071672483748783e-02) (4, -5.45248475062326265483e-02) (5, 3.02523209600421894017e-01) (6, 1.92780509730004143143e-02) (7, 3.89053428405839740734e+00) (8, 7.90730605409234783565e+01) (9, -8.06703483306895063887e-02) (0, -1.42899815484592546122e-01) (1, 2.78772253406569074652e-02) (2, 8.10922569160902814711e-03) (3, -6.88836697625593297190e-02) (4, -6.28082838046030156320e-02) (5, 1.57702787666293919866e-01) (6, 8.84747671928747120296e-02) (7, 4.87042972101928750561e+00) (8, 7.89083643094390652095e+01) (9, -1.88385909044276253499e-02) (0, -9.51912519779893051552e-02) (1, 3.29784590614363229411e-02) (2, 3.50644130123182878878e-02) (3, -1.42322566496805059943e-02) (4, -6.49050708996729008859e-02) (5, 1.63361928312751591985e-01) (6, 1.49105938061748294343e-01) (7, 3.92373164230901627647e+00) (8, 7.90524768964141628658e+01) (9, -1.27002002732980873168e-01) (0, 5.93577797163023779259e-02) (1, -7.51151974918858045260e-02) (2, 5.36068369028552260680e-02) (3, -4.94746651175038132386e-02) (4, 6.48649175045474535306e-02) (5, 5.15539007140400351581e-01) (6, 2.37897197673041099764e-01) (7, -1.04004913691782370222e+01) (8, -1.86085514751570201497e+02) (9, 5.50539975874968834368e-01) (0, 1.31102591507502630463e+01) (1, 5.54159368909987182228e-01) (2, 6.20114150978716582863e-01) (3, 4.79413922466429442970e-01) (4, 6.15237388350161285011e-01) (5, -6.56136527085820553395e+00) (6, 2.74294605460135398900e-01) (7, 4.94379319855260401795e-01) (8, 9.71366867329127303687e-02) (9, 8.45650036103545943433e-01) (0, 1.10003414202227544488e-02) (1, -2.44356330158726382795e-02) (2, -1.06249698591472263587e-01) (3, -1.14411958647014255774e-01) (4, -1.08706192267181034339e-01) (5, 5.61139537625377604613e-01) (6, 2.33798625836092704988e-01) (7, -1.03955796186231985700e+01) (8, -1.86222554159657931905e+02) (9, 7.25857762508937187640e-01) (0, -2.60765763385244930816e-01) (1, 2.01762307298704417213e-02) (2, -1.05533340214438803306e-01) (3, 1.46016616237684554447e-02) (4, -1.10613906024642355552e-01) (5, 1.42711958734962285344e-01) (6, -7.27359517762149812570e-03) (7, 5.91376830747736459415e+00) (8, 7.90647906795829555904e+01) (9, -2.11197202646265964898e-02) (10, -1.51242445863633112602e-01) (11, -7.13117185453957941332e-02) (12, 3.88794520623965300654e-01) (13, 1.22596237509528777077e-01) (14, 4.41000632965989514123e-01) (15, 3.51717834685380315030e-01) (16, -5.00668229529624281282e-02) (17, -2.85272188992224506876e-01) (18, -2.10190379046678588182e-02) (19, 3.60403252977516408428e-01) (20, 4.02034663735234276682e-01) 
