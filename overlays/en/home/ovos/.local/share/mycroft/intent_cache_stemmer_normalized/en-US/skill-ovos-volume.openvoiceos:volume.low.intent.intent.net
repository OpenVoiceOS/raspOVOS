FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.14193884499769449103e-02) (1, -4.91041751320746150400e-02) (2, -3.30653736110117571489e-02) (3, -5.14922203238394465830e-02) (4, -6.67103590186026440545e-02) (5, 1.96031598276389296132e+00) (6, 9.46064460153472758241e-02) (7, -1.24708750561712466975e+01) (8, 1.61067283783036974132e-01) (9, -3.31928923346042625830e-02) (0, -1.08730277957348220319e+00) (1, -1.54652756989999765058e-02) (2, -9.54429445208116733479e-02) (3, -3.56044632733865662466e-02) (4, -1.93975487107138244713e-01) (5, 6.18069235798742955268e-01) (6, -2.02209528204843141941e-01) (7, 2.32234647114324621597e+00) (8, -3.39736819783466731382e-02) (9, -3.95393965288374338307e-01) (0, 1.86819782400162948122e-01) (1, 2.00310064737412724112e-02) (2, 7.16264857236954960440e-02) (3, -6.40187697227385249521e-02) (4, 1.84824778024766239737e-02) (5, 2.89091603061576263300e+00) (6, 4.01049512493482807063e-01) (7, -1.05675043792602245674e+01) (8, -9.06304173582055283553e-01) (9, -1.97695590964931076916e-02) (0, 2.54765886760983395476e+00) (1, 4.42540176088195791326e-01) (2, 4.24409009391647273901e-01) (3, 4.90592822307926168524e-01) (4, 4.72826517993789663397e-01) (5, 5.05523375220076953696e+00) (6, 1.87337893855948817157e-01) (7, -3.25103285362072291775e+00) (8, 3.27515031174369575240e+00) (9, 9.25524606479830036498e-02) (0, 9.38548700124603030304e+00) (1, 5.74392345250136826529e-01) (2, 6.48102436662204239859e-01) (3, 6.28154863119609330191e-01) (4, 5.34972411096580224843e-01) (5, -3.97264691392889357502e+00) (6, -7.39077318247739700752e-01) (7, -6.40174606666705114932e-01) (8, -1.05594808064736844777e+00) (9, 4.75414182287389075476e-01) (0, 1.25763119949741625225e-01) (1, -8.14507386433400287773e-02) (2, -1.02650248144797298644e-01) (3, 4.68699106229028897297e-02) (4, -6.36909386860646520301e-02) (5, 1.94475794858229811268e+00) (6, 4.17078983472265740762e-01) (7, -8.73077571563547039091e+00) (8, -3.46615999383593498262e-01) (9, 3.38226288937091834619e-02) (0, 2.61750233866009640593e+00) (1, 4.38497154563368851665e-01) (2, 3.23954118936957358166e-01) (3, 3.13555872589053152844e-01) (4, 3.67683901041449545666e-01) (5, 5.11230126566665088461e+00) (6, 2.33462645240806065949e-01) (7, -2.54863216027310768297e+00) (8, 2.15868707051090380489e+00) (9, 2.15769225249865664873e-01) (0, 8.62861594281026711428e+00) (1, 6.25831494499168861090e-01) (2, 5.46369852889500351445e-01) (3, 5.64797306824646683232e-01) (4, 5.55298326928339691655e-01) (5, -1.86001313639993415272e+00) (6, -1.19072672760328290842e-01) (7, -4.37780450597355219600e+00) (8, -9.08447781730074677142e-01) (9, 3.76274198392351488796e-01) (0, 3.36003038414868182571e+00) (1, 6.14441915326833232314e-01) (2, 4.99635836952447232040e-01) (3, 4.60499378764151756638e-01) (4, 5.89385091238736613661e-01) (5, 7.17833567046562226466e+00) (6, 2.81702507150550285342e-01) (7, -4.56132149297655686837e+00) (8, 3.26969119981325517799e+00) (9, -8.35592106477652807328e-02) (0, 8.56888972691127470682e+00) (1, 5.30829951057121274260e-01) (2, 6.78738668450996285308e-01) (3, 5.88460236677810777373e-01) (4, 5.44149920234367479033e-01) (5, -3.20234798116197882933e+00) (6, -8.47877339148430664295e-01) (7, -1.44680145680715077638e+00) (8, -6.43776271290513513179e-01) (9, 4.59520547545050284111e-01) (10, -1.14090102713437765991e-01) (11, 5.93263714918853324320e-01) (12, -1.07668305950198217591e-01) (13, 3.39771709782225150853e-01) (14, -3.49295057011866416641e-01) (15, -1.36083590786786778892e-01) (16, 4.13615010124784965306e-01) (17, -3.87224417542641030643e-01) (18, 4.17491185183347546239e-01) (19, -3.61144449924652499728e-01) (20, 3.86326594300235304225e-01) 
