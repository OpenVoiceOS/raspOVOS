FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.20356936246914170141e+00) (1, 5.61497087982070416934e-02) (2, -4.50767178628075151914e-02) (3, -2.44536597821342766013e-02) (4, 1.19269149569393583150e-03) (5, 1.18657348565273723651e+00) (6, 6.72471863249934354023e-01) (7, 2.19496418435390028279e-01) (8, -2.16669985028502765090e-01) (9, -1.20790836703392939766e-01) (0, -1.29205411223739119464e+00) (1, -1.80951778385269462790e-02) (2, -1.03956211897957180590e-02) (3, 5.24821157958877057559e-02) (4, -9.19823807272541482671e-02) (5, 1.10610343031101665545e+00) (6, 7.36490389092087083256e-01) (7, 3.49175695974643263142e-01) (8, 4.95638279802775527649e-01) (9, -2.30298760405966723708e-01) (0, 8.14619051068795063664e-02) (1, -1.59106814571909116474e-01) (2, -1.21941832163623919971e-01) (3, -3.21128268626252669216e-02) (4, -1.36089009502224078663e-01) (5, -1.10738190771642575072e+00) (6, -5.21093927743098039862e-01) (7, 6.69557867795948724599e-01) (8, -5.82576562026702271524e-01) (9, -3.50761542972765849591e-01) (0, 2.11231614068127904194e-01) (1, -7.23851819422761388889e-02) (2, -1.98973526516250776019e-01) (3, -1.50361207583240674701e-01) (4, -1.63899385639719175067e-01) (5, -9.62502335622939075854e-01) (6, 1.40153133515855898850e+00) (7, -3.52834234120527678868e+00) (8, -4.87284422750422940851e+00) (9, -2.52561710159496688455e-01) (0, -1.24518699438137314672e+00) (1, 6.25268097427260916010e-02) (2, -3.98118395897972543462e-02) (3, 2.02512996462704108341e-03) (4, 4.79483778980147809512e-02) (5, 1.13958148173504314471e+00) (6, 7.04265093190788560307e-01) (7, 2.52453573692853483479e-01) (8, -1.91798792182593935696e-02) (9, -2.68184891960808691191e-01) (0, 1.65616479776575054039e+00) (1, 5.08306146576522066560e-01) (2, 4.88483653380988258608e-01) (3, 4.12219100608943123110e-01) (4, 4.90028784587500709780e-01) (5, -7.24338038060563960130e-01) (6, 4.37938519308589313539e+00) (7, -2.12345223727315346451e+00) (8, 1.67492164734724768849e+00) (9, 1.41292391670606504173e-01) (0, 1.01518530255157113373e+01) (1, 3.36097463005164354133e-01) (2, 3.72530090593674922950e-01) (3, 4.65540691249945792762e-01) (4, 3.99571723275759960181e-01) (5, 1.71427682180071627727e+00) (6, -4.06718042674491542243e+00) (7, -1.44804810998937671940e+00) (8, -1.90635235119633894563e+00) (9, 6.44537704008242173792e-01) (0, 1.47718640580750737445e-01) (1, -5.64544995215455341908e-02) (2, -1.49420609035782026019e-01) (3, -2.08609287896446393695e-01) (4, -1.21489924648098102100e-01) (5, -1.06619373844567189025e+00) (6, 1.49629127625963298520e+00) (7, -3.43322708191553527257e+00) (8, -4.94357848252007947565e+00) (9, -5.86723161328106312951e-01) (0, 1.23156189375200852965e+01) (1, 2.96593820332785584881e-02) (2, 1.42455062794615838762e-01) (3, 8.25291489838858721706e-02) (4, 5.89053136884470987522e-02) (5, 7.23783206208711282770e-02) (6, -1.90943939311767385547e+00) (7, -8.65147961902617335106e-01) (8, -1.45086331235349175195e+00) (9, 3.87682671218092023135e-01) (0, -1.19904262153640335242e+01) (1, -2.22984395150652325857e-01) (2, -1.85710310165396130788e-01) (3, -2.52204141740312970388e-01) (4, -2.67751134161463233418e-01) (5, 2.53250401859463125653e-01) (6, 2.45475588377327991196e+00) (7, 2.22654885494775989230e+00) (8, 1.52573945292843826671e+00) (9, -4.23359850663534043047e-01) (10, 3.51518270441547653338e-01) (11, 4.06420985150827640542e-01) (12, -9.01638092420941894556e-02) (13, -2.94807964121399368462e-01) (14, 4.00787395307079574724e-01) (15, 5.66759333922980501619e-01) (16, -2.78788569649405126860e-01) (17, -1.64815849799197527981e-01) (18, -8.66566651251117481269e-02) (19, 4.04567372498373933887e-01) (20, 4.24924840196488518007e-01) 
