FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.89868535448669273347e-01) (1, -1.95923686570160307530e-02) (2, -3.30267862028114714268e-02) (3, 5.53455113821990432599e-02) (4, -3.17382082885734953526e-02) (5, -1.90911370863078910798e-01) (6, 1.89744384980832148102e+00) (7, -5.64964116790045694366e-03) (8, 6.00013645335486622834e-01) (9, 2.26470987216732366765e-01) (10, -9.06676242736196014160e-02) (11, -3.37668194658333753466e-01) (0, 1.76893395682330978325e-01) (1, 1.25307810803409469536e-01) (2, 8.49809137484988375011e-02) (3, 1.35503684481140029838e-01) (4, 1.80572149654384506157e-01) (5, 8.65951900682410402599e-02) (6, -2.46535237252172656497e+00) (7, 1.43948508951277198697e-01) (8, -6.87186064243542782393e-01) (9, 1.97235729311768193117e-01) (10, -5.89059641509404735560e-03) (11, 3.43947912191999105591e-01) (0, 1.64633467397370558682e-01) (1, 2.66306275481966003849e-01) (2, 2.41678068394449191425e-01) (3, 2.88549246246602997257e-01) (4, 2.37282225842264132831e-01) (5, 1.18594556650796101316e-01) (6, 6.48671110550497154179e+00) (7, 1.13843009633974950878e-01) (8, 2.72681981245954663251e-01) (9, 1.77780859930472268093e-01) (10, 4.31769547395171801596e-02) (11, 2.43727207941965950955e-01) (0, 2.32266989847179305961e-01) (1, 3.77203350267371409488e-02) (2, 1.53101449211593521049e-01) (3, 1.80362251897807968071e-01) (4, 1.41054307421203506401e-01) (5, 9.62679957351645632091e-02) (6, -2.48038529350814052066e+00) (7, 1.34278329614014091398e-01) (8, -2.70283539775983405740e-02) (9, 1.97696212445561070314e-01) (10, 1.27653103564688064075e-01) (11, 2.58991832470548299927e-01) (0, 7.73171542991882954077e-01) (1, 1.09817623113086448861e+00) (2, 1.25304051999738441658e+00) (3, 1.12889748205235229683e+00) (4, 1.19007294391086326790e+00) (5, 8.12797098268753681616e-01) (6, -5.07791271928775156397e+00) (7, 5.86555570933432579572e-01) (8, 5.06153579142805565283e-01) (9, 6.44543629709095955427e-01) (10, 7.96521727597368167650e-01) (11, 7.66190834354645300408e-01) (0, -5.10587668662282667675e-01) (1, -3.49199604288401632690e-01) (2, -3.18092655435862570190e-01) (3, -4.50564313725295095825e-01) (4, -4.74496495024027853393e-01) (5, -2.45380986502763992485e-01) (6, 5.03040617261159272999e+00) (7, -3.26374751107736615907e-01) (8, -2.21638900657217724488e-01) (9, -2.40958650188489914568e-01) (10, -1.79026153461976977876e-01) (11, -2.50590462760969190370e-01) (0, 5.04870404435996955606e-01) (1, -2.08615468364923978273e-02) (2, 1.19104605771902224975e-01) (3, 9.56188409107953662946e-02) (4, 7.14956267255574678954e-02) (5, 4.38315068318252565316e-01) (6, 2.55331331059307567455e-02) (7, 3.52106154291895900865e-01) (8, 6.22253576256074247830e-01) (9, 3.05121764767914138705e-01) (10, 1.43155146259180354740e-01) (11, 2.51253940910603990044e-01) (0, 2.02301114401498061124e-01) (1, 2.85864086801794037296e-01) (2, 2.44533488507059054706e-01) (3, 2.48005839044836001728e-01) (4, 2.04049749280002551410e-01) (5, 9.52261756869937636694e-02) (6, 6.39958546886776069584e+00) (7, 1.85631871981577767361e-01) (8, 2.93721403847416018262e-01) (9, 1.79604404432730568875e-01) (10, 1.83071045332378334880e-01) (11, 1.96023390455202950466e-01) (0, 1.78335504775620323770e-01) (1, 1.55822217068352919522e-01) (2, 1.37659027776398878995e-01) (3, 9.05681472036029555639e-02) (4, 7.97858457776691176733e-02) (5, 2.17613691633320671670e-01) (6, 6.51749100367162803593e+00) (7, 1.63915731770949257839e-01) (8, 3.83745372216184710279e-01) (9, 2.68064097328143013943e-01) (10, 4.08949685625495593100e-02) (11, 1.65396393103556527127e-01) (0, 9.24289559168084751128e-01) (1, 1.13782087106993423653e+00) (2, 1.21524359051873909188e+00) (3, 1.10448787872483955574e+00) (4, 1.14839187775542961312e+00) (5, 6.59269950200802479223e-01) (6, -5.05815952021705950159e+00) (7, 5.82542166683287621076e-01) (8, 5.72184252825495232031e-01) (9, 1.18606942863352071704e+00) (10, 7.51964916145456241381e-01) (11, 5.98989024769550959526e-01) (12, 3.02868292828556040508e-01) (13, -9.32517146468111235436e-01) (14, 4.28509484713651300769e-01) (15, -2.80287986338352113069e-01) (16, -1.24398868778071339247e-01) (17, 3.19079303344245890361e-01) (18, 3.66760551386840424892e-02) (19, 5.15770841127015655658e-01) (20, 5.23946393018342559955e-01) (21, -1.25889282920679967948e-01) (22, 3.06114622494855825874e-01) 
