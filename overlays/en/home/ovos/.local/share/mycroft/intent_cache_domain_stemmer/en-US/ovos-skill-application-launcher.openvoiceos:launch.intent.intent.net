FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.70104328853434427771e+00) (1, 4.57230460378118486187e-01) (2, 4.26033150884099931499e-01) (3, 4.09753632279821367046e-01) (4, 3.37799828978963823101e-01) (5, 2.09219164119784206690e+00) (6, -5.94697063948328663585e-01) (7, 2.32098107264045294684e+00) (8, 2.65017803741745128221e+00) (9, -1.22244341062536854281e+00) (0, -4.52328649225834877878e-01) (1, -7.99875615836858760987e-02) (2, -6.23617230655431828423e-02) (3, 7.74260030387162873078e-02) (4, -3.13686786891699403990e-02) (5, -1.94677185023236942740e-01) (6, -9.03901840282743118671e-01) (7, -1.59927440086350597381e-01) (8, -2.06260303247876392030e-01) (9, 3.55676091465052301999e-01) (0, -2.57323687824952207492e+00) (1, 4.00967621097730919644e+00) (2, 4.19097265640663430020e+00) (3, 4.01821803341078087612e+00) (4, 4.11092561522888466641e+00) (5, 3.16420057649571440095e+00) (6, 2.58610160254603016483e+00) (7, 2.66861013639682775889e+00) (8, 3.33905550264632200452e+00) (9, -2.56235735345540183161e+00) (0, -3.72216333511475594431e-01) (1, -3.65915766658068131179e-02) (2, 4.75154237149476438296e-02) (3, -3.86917314233065079421e-02) (4, 1.00064666688275308304e-01) (5, -2.50551762974619396385e-01) (6, -9.44552982879941493977e-01) (7, -2.38084820309624828338e-01) (8, -3.12225552794450189609e-01) (9, 2.28985670570763799603e-01) (0, 1.76287571617811544833e+00) (1, 3.48532918605178987370e-01) (2, 4.04886528614133989201e-01) (3, 4.53368834915727769719e-01) (4, 3.16377565029234197880e-01) (5, 1.50072754296068189284e+00) (6, 1.41342862199591107197e-01) (7, 1.24301139192057985561e+00) (8, 1.18436648623420115456e+00) (9, -1.79420770001366181035e+00) (0, -2.98445080283288033396e-01) (1, -6.93830235602140438234e-02) (2, -3.07712427081347043856e-02) (3, 6.39444754718064833909e-02) (4, -6.03369383813619902801e-02) (5, -4.16570891128598755349e-02) (6, -9.27803933692221471929e-01) (7, -1.18519615715898488095e-01) (8, -1.03883074809022188378e-01) (9, 1.83315161054890846115e-01) (0, 1.66620232441871984896e+00) (1, 3.80712277951807176457e-01) (2, 4.63278971376985704289e-01) (3, 4.66572589936823045598e-01) (4, 4.32439200344652330266e-01) (5, 1.28227655612453750322e+00) (6, 1.13031529184620060935e-01) (7, 9.78661915358470912985e-01) (8, 1.03024765526533390592e+00) (9, -1.75220247085520930419e+00) (0, -8.35794040600947063524e+00) (1, 8.36666595801600354587e-02) (2, -9.58143205792823075828e-03) (3, -7.60175318868079423484e-03) (4, 4.93500602111109423764e-02) (5, -2.35568715941584988505e-01) (6, 2.45804240996320011448e+00) (7, -2.68377544491314456998e-01) (8, -3.32400929399010724996e-01) (9, -6.10606200101269022684e-02) (0, -3.68254099275358237620e+00) (1, 2.79355995435660053872e+00) (2, 2.73292686868851353310e+00) (3, 2.75017430711929966591e+00) (4, 2.74792306948845554970e+00) (5, 3.37972316579142439963e+00) (6, 5.90987858981068914233e+00) (7, 3.71664486001301552776e+00) (8, 3.11987780225958477587e+00) (9, -4.19567992848359150315e+00) (0, -8.38228267471483867723e+00) (1, 7.98523305843107655821e-02) (2, -1.24235347916849068334e-02) (3, 2.99360333869688258202e-02) (4, 5.87394713351957545311e-02) (5, -3.02994013015690288881e-01) (6, 2.48191837663132908176e+00) (7, -2.48236792295002478559e-01) (8, -3.47258519597527459677e-01) (9, -1.25516248405207475614e-01) (10, 1.00352130860868871132e+00) (11, -2.20283225510580715767e-01) (12, -2.58466502515955320884e-01) (13, -2.35985022370083619148e-01) (14, 6.11190745097230592187e-01) (15, -2.12336986015347839452e-01) (16, 6.22201362114976563866e-01) (17, 7.90924590080047007490e-01) (18, -4.54927874528983644531e-01) (19, 8.23441050899662907447e-01) (20, 4.59365504614565156594e-01) 
