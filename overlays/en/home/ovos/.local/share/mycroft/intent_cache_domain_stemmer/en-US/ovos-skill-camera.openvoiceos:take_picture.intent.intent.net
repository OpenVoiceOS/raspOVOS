FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.47349399427503158222e+00) (1, 3.14903056429959790630e-02) (2, 1.01297239046011136598e-01) (3, 9.00136104034520850847e-02) (4, 8.71356001304723487566e-02) (5, 3.73016632787940616289e-01) (6, 9.61560450168921998504e-01) (7, 4.54819916893709597083e-01) (8, 2.35005484532575215084e+00) (9, 2.63235500587877757628e-01) (0, -7.92194956150863160982e-02) (1, 1.20730247752421915308e-02) (2, -8.87361693723445893456e-02) (3, 3.74887850449024317631e-03) (4, -4.22581363065487186637e-02) (5, 7.90575452914128007365e-01) (6, 3.12098541387481331899e-01) (7, 1.00432256590439461519e+00) (8, 1.58432776517637385894e+00) (9, -2.54641752157210909946e-01) (0, 7.23374254775403735529e-01) (1, 2.13525610325906112230e-01) (2, 1.29620729295584991014e-01) (3, 7.09250888806317869584e-02) (4, 1.17599232403609588182e-01) (5, -6.02231490298129723548e-01) (6, -2.48305157661418869630e-02) (7, -7.90044744274247867644e-01) (8, -7.19867317211695278978e-01) (9, 2.52302830362581664847e-01) (0, -7.56600719583821912373e-01) (1, 2.96471321773720333792e-02) (2, -7.27677922229707455776e-04) (3, 1.14507281971169029566e-02) (4, -9.57842899668025077320e-02) (5, 7.88609775482223551712e-01) (6, 1.14365860247198622424e-01) (7, 1.53541750081173739018e-01) (8, 1.04467500970790294623e+00) (9, -8.84682301241591917407e-02) (0, -8.28940027561995973482e-02) (1, -2.31576714260822644209e-02) (2, -7.84854624106945397699e-03) (3, 5.08213784949534952418e-02) (4, -7.43574652416950226952e-02) (5, 8.42667252667683275291e-01) (6, 1.39891200789374781088e-01) (7, 9.77135019831563922388e-01) (8, 1.68961539528735293914e+00) (9, -2.05066564891338010135e-01) (0, 6.25723089912342822494e-01) (1, 1.77132821513904414878e-01) (2, 5.47997046845090790557e-02) (3, 1.73411986662639461265e-01) (4, 1.79829484655155025230e-01) (5, -2.14943388392740963866e-01) (6, 2.60875454206369594701e-01) (7, -5.94201616214289685125e-01) (8, -1.96157641787390368826e+00) (9, 7.23286837437418173025e-01) (0, 1.05393454662438279534e+00) (1, 1.82745642639109501237e-01) (2, 2.12267301655718665376e-01) (3, 1.95850297487685065523e-01) (4, 1.43589596874424990647e-01) (5, -2.18679096616798213093e-01) (6, -7.15541362092731558775e-01) (7, 8.00584718024517627555e+00) (8, 5.51558774057424816561e+00) (9, -2.75157156417610460064e-01) (0, 5.89412385182927334171e+00) (1, 5.36018224912646501501e-01) (2, 5.07167371469500749548e-01) (3, 6.74168700831893286107e-01) (4, 5.31890931087496965368e-01) (5, -8.86082475976486150238e-01) (6, -2.39924935213794876532e+00) (7, -1.87701904467274460764e+00) (8, -2.22447338717866971436e+00) (9, 8.02318006222520252457e-01) (0, 3.41552325994848193780e-01) (1, -6.46485266283803594600e-02) (2, 4.19610562726205893469e-02) (3, 5.04488321944421697074e-02) (4, 6.04497316285318303519e-02) (5, -2.56723618490037108764e-01) (6, 8.14311759304554905192e-01) (7, -2.54051458447812805730e+00) (8, -3.32119043750946363325e-01) (9, 2.33485755421777241292e-01) (0, 2.48716162056802636560e-01) (1, -4.46323099803772743721e-02) (2, 1.69467945325526524181e-02) (3, 7.13663418519649289662e-02) (4, 6.33872766721400721091e-02) (5, -4.48762374869878744033e-01) (6, 4.73389448861221640019e-01) (7, -1.99103744729343978825e+00) (8, -1.27455938880770447419e+00) (9, 2.85236031603674666801e-01) (10, 2.39211269838565443457e-01) (11, 5.58341624683725945566e-01) (12, -1.34599896665919954719e-01) (13, 4.66251776849813448500e-01) (14, 5.55599888454499146739e-01) (15, -1.33361741056998717170e-01) (16, 5.63505039614779934531e-01) (17, -2.75731501568148629211e-01) (18, -3.19076708534691055874e-01) (19, -2.81921601870987137417e-01) (20, 4.26700094354806436225e-01) 
