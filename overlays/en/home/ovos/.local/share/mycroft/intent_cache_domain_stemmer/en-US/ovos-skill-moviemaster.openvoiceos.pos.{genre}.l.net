FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.46408861377598831233e+00) (1, 2.01775369318200992197e+00) (2, 1.40798202059568255962e+00) (3, -5.68652777397041009344e-01) (4, 1.74292317015583772544e-02) (5, 3.27086285363705409068e+00) (6, 6.05329720356271444581e-03) (7, 9.26508597571243597280e-01) (8, -3.92872088046183620680e-02) (9, -5.14818067129251710767e-01) (10, 3.30943212004847442387e+00) (11, -1.94870742174274580449e+00) (0, 1.31958642738300779840e+00) (1, 2.53029099872708540531e+00) (2, 2.36055450703347435848e+00) (3, 2.02781691172718003813e+00) (4, 2.38588737112956028596e+00) (5, -3.94960412858011356008e+00) (6, 3.89029417803672528109e+00) (7, 1.90021133685968157678e+00) (8, 1.52073743564392738215e+00) (9, 2.34580780869581051462e+00) (10, -5.05251254172432062717e+00) (11, 2.51803907111689095899e+00) (0, -1.49206982055069969917e+00) (1, 2.04578569801523135752e+00) (2, 1.37916391245426028789e+00) (3, -6.03405582183008215580e-01) (4, -8.01880703883711964952e-02) (5, 3.33596818383605642211e+00) (6, -1.81776100415207919614e-01) (7, 7.11865788079420358514e-01) (8, -2.55029268951525688036e-02) (9, -4.55789158518907833173e-01) (10, 3.23030421229548370121e+00) (11, -1.89844460921771185369e+00) (12, 7.04600025073558899891e+00) (13, -1.92087976384442793432e+00) (14, 7.02515270666153046619e+00) (15, -1.41779803468180354287e+00) 
