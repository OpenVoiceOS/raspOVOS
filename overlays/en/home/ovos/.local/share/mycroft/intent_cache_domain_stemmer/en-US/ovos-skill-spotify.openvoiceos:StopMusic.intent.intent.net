FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.03975149981558545598e+00) (1, 1.13863802148180287555e-01) (2, 1.85682176245527602587e-01) (3, 2.32757716072874321078e-01) (4, 1.54324493004160262499e-01) (5, -1.34189254322241824369e+00) (6, -1.93400900880989018438e-01) (7, -4.28450663290111041781e-02) (8, -4.37834581994430371843e-01) (9, 1.81212465716698356566e-01) (0, 3.11517124458014910138e-02) (1, 5.00872769440405818386e-02) (2, -2.30833849822289667586e-02) (3, 6.56951555098288508816e-02) (4, 9.74042900885336709882e-02) (5, 6.64137027981970806678e+00) (6, 3.11742673484730725697e-01) (7, 1.53974720626537830981e-01) (8, 3.27480687293385114289e-02) (9, -6.77114170266642362295e-02) (0, 1.19313626792562654799e+00) (1, 9.59352836956862464746e-01) (2, 1.00373654906976605972e+00) (3, 1.05584219192493389272e+00) (4, 9.54542570760134712060e-01) (5, -2.00196277914284603838e+00) (6, 5.70121609366651904693e-01) (7, 1.66017803100715455322e+00) (8, -6.08305077229220358959e+00) (9, 5.33881429043875499474e+00) (0, 1.43350763332221808888e+00) (1, 5.96603492451417194431e-01) (2, 5.58415493173110233371e-01) (3, 6.10495174480187641208e-01) (4, 5.36164472056138263767e-01) (5, 2.17530661650875631330e-02) (6, 4.38302978730365222493e-01) (7, 7.04292641720060341726e-01) (8, -2.77354236763460981763e+00) (9, 3.70564148760902201118e+00) (0, -5.61866111288475966745e-01) (1, -1.16775707080391505377e-01) (2, -1.25923589541939356939e-01) (3, -2.37305686547783473150e-01) (4, -1.77591123356846458670e-01) (5, 1.57431332692185899091e+00) (6, -8.07967842503802963217e-02) (7, 1.14058153260070668789e-01) (8, 7.52662248219334861776e-02) (9, -1.67594353440255416920e-01) (0, 1.39396290805014677616e+00) (1, 2.29501314029487452073e-01) (2, 2.66582972869666867677e-01) (3, 2.16001450583728632493e-01) (4, 1.49574234649928833329e-01) (5, 1.07207188031891331725e+00) (6, 4.64689732746215433679e+00) (7, 2.60040848286482551011e-01) (8, 3.50250110157020844159e-01) (9, 3.59214583970138764957e-02) (0, 5.15582313393632585274e-01) (1, 2.02541016830891984490e-01) (2, 2.03257531716317552117e-01) (3, 2.93841839625329170893e-01) (4, 9.80717100639050681776e-02) (5, -8.55057323374779798542e-01) (6, -4.57734169950142932848e-01) (7, -9.70258420059333381857e-02) (8, 4.13324118627338975784e+02) (9, -3.19353997173611667271e-02) (0, -2.46751412537000780478e-01) (1, 1.49224201979566428733e-01) (2, 2.63934700580764791678e-01) (3, 1.94943091663051432105e-01) (4, 1.66515405120778864356e-01) (5, 1.53602527267294242108e+00) (6, 3.80979589892962877684e-01) (7, 2.23680495920383609620e-01) (8, -6.69638848384245420675e+02) (9, 4.84915516242602151475e-01) (0, -8.17376382744157761739e-03) (1, 1.35204701515365427467e-01) (2, 2.59751929732490560720e-01) (3, 2.14305586012531107398e-01) (4, 2.13420755060840433570e-01) (5, 1.66662556863384536676e+00) (6, 2.48345937354901707961e-01) (7, 3.04229588160666197805e-01) (8, -6.69562661123796488027e+02) (9, 5.86247718376782689376e-01) (0, 9.20614885855084774668e-01) (1, 1.40262539131718017016e-01) (2, 1.54637327982263900195e-01) (3, 1.82054339541273452197e-01) (4, 1.36099940730409929568e-01) (5, -9.11728861453636407752e-01) (6, -3.00370850833694857940e-01) (7, -8.54466443008800174974e-02) (8, -6.71276701546212661853e-01) (9, 2.82318637896411483990e-01) (10, -6.73731352080879086763e-02) (11, 9.82102509659463884795e-01) (12, -4.62907116460891387977e-02) (13, -5.97970645475478720932e-02) (14, 4.33948121347050963514e-01) (15, 4.82281342947290317391e-02) (16, 5.15965595962681433662e-01) (17, -3.03684734209214213241e-01) (18, -2.88405422522459986556e-01) (19, -9.75612681566274952960e-02) (20, 3.64329896253949736540e-01) 
