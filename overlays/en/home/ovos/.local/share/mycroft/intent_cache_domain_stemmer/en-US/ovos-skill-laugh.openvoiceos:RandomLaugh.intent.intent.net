FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.83080485856328367689e-01) (1, -1.58723554208509587404e-01) (2, -2.00072056248418950197e-01) (3, -1.30587330653898381350e-01) (4, -2.14475667670003977694e-01) (5, 2.49259428635365209992e-01) (6, 1.04443841408931703540e-01) (7, 6.80954962030782540161e-02) (8, 1.24355901727314449579e-01) (9, 2.16408139537224070148e-01) (0, 8.30429071642790617158e-02) (1, -2.82156681758185090558e-01) (2, -2.47937021893282649732e-01) (3, -2.44432663661261317944e-01) (4, -1.44135905545969639219e-01) (5, -2.37099686071764459427e+00) (6, -1.95751577704747403708e+00) (7, -5.56609848435518861365e-01) (8, -1.45107224356711694835e-02) (9, 7.37361299168537986937e-01) (0, 2.53858814098273100068e-02) (1, -3.14366852980871747114e-01) (2, -1.80336995166559932446e-01) (3, -2.20552271348257777905e-01) (4, -1.49757159990091953672e-01) (5, -2.42198101237904150906e+00) (6, -1.84355887114604199972e+00) (7, -3.87674022510898941274e-01) (8, -5.52286371361792594037e-02) (9, 7.29534702670048607054e-01) (0, 1.15066578345739345401e+00) (1, 2.09221225993766940521e-01) (2, 1.19361390190258181976e-01) (3, 1.34325117634668533828e-01) (4, 1.66507226245536932296e-01) (5, -5.69439251481443031722e-01) (6, -6.10046027746560109994e-02) (7, -1.39094133814370662927e-01) (8, -1.54234667261636287927e-01) (9, -1.90051961727160378945e-01) (0, 9.79760015465651334932e-02) (1, -2.99148796242495129682e-01) (2, -2.56353972595949886060e-01) (3, -1.42694098991175327695e-01) (4, -2.25401198607702968335e-01) (5, -2.08117173750582384884e+00) (6, -1.88663367271025861349e+00) (7, -4.56223742957708899848e-01) (8, -7.06509518991623175488e-02) (9, 7.34564388465355766478e-01) (0, 1.74811836531963793462e+00) (1, 3.73561186128619271418e-01) (2, 3.56253524654868203303e-01) (3, 2.60618959897521040858e-01) (4, 2.71189173096182845057e-01) (5, 1.35974038027811450213e+00) (6, 1.44187672731866722842e+00) (7, 3.93633459898732274151e-01) (8, 2.66150767953017564071e-01) (9, -1.15067219802357650904e-01) (0, 6.50496582127888522962e+00) (1, -2.20050168966293258066e-01) (2, -3.81376797308920906238e-02) (3, -6.65522271742819693241e-02) (4, -1.66411390339374520853e-01) (5, -5.11884515642286541670e-01) (6, -7.93882029129426070035e-01) (7, -3.33026648006552850045e-01) (8, -2.97540520003481301359e-01) (9, 6.31024645935963413024e-01) (0, 1.97574419126120126577e+00) (1, 4.47038749030182092081e-01) (2, 3.43524055352756707560e-01) (3, 4.59820011427948205363e-01) (4, 4.22524923255989282023e-01) (5, 1.15111018860152580778e+00) (6, 2.32078483790519563001e+00) (7, 7.31309341307078142336e-01) (8, 3.27472944538918453450e-01) (9, -3.87166100025957304887e-01) (0, 5.41573011153235084336e-01) (1, 2.16937384912602643228e-01) (2, 6.25949347110912601710e-02) (3, 1.29295005807511603768e-01) (4, 2.39671177575223132150e-01) (5, -4.99077542536701390663e-01) (6, 8.65117875098791733190e-02) (7, -1.33486175380540667001e-02) (8, -1.08731602817558004048e-01) (9, 2.00484095692292446644e-01) (0, 4.14800274331044160903e-01) (1, 1.24523240874992169314e-01) (2, 1.58752731780992334398e-01) (3, 1.25370237778411663943e-01) (4, 2.94744085322604987276e-01) (5, -5.69137972353845222884e-01) (6, -8.11114124686328485936e-02) (7, -1.38726734488690411906e-01) (8, -1.88011300582890672484e-01) (9, -7.94275959736911313369e-02) (10, 4.98170242772615790017e-01) (11, -3.30487344970063490202e-01) (12, -3.31125394065932554533e-01) (13, -1.05068814184131698042e+00) (14, -3.84144723971442503263e-01) (15, 1.93475067256778349156e-01) (16, -3.49368203457544213020e-01) (17, 8.78441298207754961425e-01) (18, -6.55872969813871276035e-02) (19, -9.86437660526159998398e-01) (20, 5.46791162645015038635e-01) 
