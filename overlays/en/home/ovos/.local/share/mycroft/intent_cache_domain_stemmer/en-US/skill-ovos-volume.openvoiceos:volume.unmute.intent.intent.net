FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.24665644835213806907e-01) (1, 3.19130647057841110303e-01) (2, 4.22424092019150543287e-01) (3, 2.81422845149586486890e-01) (4, 3.74867483103821563795e-01) (5, -2.58802489494164200678e+00) (6, -6.92859769295628646901e-01) (7, -4.79630839574234912881e-02) (8, 2.39137082188368071956e-01) (0, 5.38833983954221640289e+00) (1, 5.00398349978564582763e-01) (2, 4.57157318510650056975e-01) (3, 5.16942006566165290771e-01) (4, 5.37434664585231258727e-01) (5, -2.05021374452465554583e+00) (6, -2.08605371964752706049e+00) (7, -1.51042943897027170941e+00) (8, 1.61163858482929939209e-01) (0, 1.23314323954652160786e+00) (1, 6.88017613610378137023e-02) (2, 1.88468254527202304371e-02) (3, -9.28612270036587583721e-02) (4, -9.96616922894368317820e-02) (5, 7.53781702085478055864e+00) (6, 2.48772247616451308572e-01) (7, 1.14776142240503420400e-01) (8, 3.01878722118144871001e-01) (0, 5.51535105299384031952e+00) (1, 4.73164805241464037078e-01) (2, 4.39472151019213941314e-01) (3, 4.54973024346469301360e-01) (4, 5.51360120095847672239e-01) (5, -2.32515632511333913968e+00) (6, -1.52062503714467034399e+00) (7, -1.97545770937478315510e+00) (8, 2.94992662379833903152e-01) (0, 5.33951251547963057220e+00) (1, 4.56360292651294130462e-01) (2, 5.47002379812835171080e-01) (3, 5.77530478157638138548e-01) (4, 5.06846812584040962157e-01) (5, -2.20997435749725790188e+00) (6, -1.90197370532805209997e+00) (7, -1.95806780094182264484e+00) (8, 5.19457050458525415593e-01) (0, 1.26075540416310638570e+00) (1, 8.73002565821758003128e-02) (2, 7.69040889462581089830e-02) (3, -5.88804662803063261212e-02) (4, 5.47348863801112861527e-02) (5, 7.49805497094137418657e+00) (6, 2.26406483832996413552e-01) (7, 2.59259864986875587789e-01) (8, 3.55030955480342746977e-01) (0, 1.23801255159447998189e+00) (1, 6.43580264767757287414e-02) (2, 9.03037793358912876940e-02) (3, -2.13692777434239152001e-02) (4, 4.18557531556239814652e-02) (5, 7.37773922174317586808e+00) (6, 1.46464510742824571832e-01) (7, 2.56136507094839205312e-01) (8, 3.47658516572719455962e-01) (0, 1.22866444222997039937e+00) (1, 5.37586517056575646789e-02) (2, -4.21666285189483281554e-03) (3, 4.28573794087520332230e-02) (4, 5.54178513011089057816e-02) (5, 7.46641426249487150102e+00) (6, 1.18221401158969896539e-01) (7, 1.92256041170099423177e-01) (8, 1.91820250557666827085e-01) (0, 1.11560329355667420259e+00) (1, -2.64470868388065917520e-02) (2, 5.73349899968257636917e-02) (3, 3.39294380864253730667e-02) (4, -3.14002998748669215345e-02) (5, 5.10289549876029546738e+00) (6, 1.77273667339485213601e-01) (7, 2.07105450631120902028e-01) (8, 3.08356912540203087492e-01) (0, 6.56995038415088772332e-01) (1, 1.25650211033068670563e-01) (2, 1.23925833758555425934e-01) (3, 7.87004556326494075780e-02) (4, 9.79541454283819057469e-02) (5, -2.81073488685889882888e-01) (6, 2.17248672383223118132e+00) (7, 1.33718608658459012228e-02) (8, -7.39506410306363326512e-01) (9, -1.44254343763179276872e-01) (10, -5.21234916784595547767e-01) (11, 4.12620440678287403458e-01) (12, -5.24625839927028714271e-01) (13, -2.21905204408471085076e-01) (14, 3.91776126495190557542e-01) (15, 3.91411808005162176194e-01) (16, 4.11637778236660478726e-01) (17, 3.35231789009261982315e-01) (18, 2.29591729469276334408e-02) (19, 2.53685738844570907169e-01) 
