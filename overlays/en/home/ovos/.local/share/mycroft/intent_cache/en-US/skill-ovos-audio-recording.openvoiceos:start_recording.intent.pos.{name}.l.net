FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=33 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (33, 6, 5.00000000000000000000e-01) (33, 6, 5.00000000000000000000e-01) (33, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.72323846535159308502e-01) (1, 5.07698180161546552824e-01) (2, 5.67443892970748198223e+00) (3, 7.66339165304302394333e+00) (4, -3.87538811201052402211e+00) (5, 1.88038885125095522888e+00) (6, 1.50000000000000000000e+03) (7, 1.31875396876850925487e+00) (8, 3.84958450592896781473e+01) (9, 1.09473672620436301983e+00) (10, -2.92960164374123266384e+00) (11, 1.50000000000000000000e+03) (12, 1.47919254998751554808e+01) (13, 1.21127472731668861528e+00) (14, -3.04082079630134805015e+00) (15, 1.50000000000000000000e+03) (16, 4.78525953135030235330e+00) (17, 2.49266928013215988358e+02) (18, 2.58394938035888355188e+00) (19, -1.45302738185736508569e+01) (20, -2.38255105305672199023e+00) (21, -4.09696400819467854149e+00) (22, 1.10774337443875783293e+01) (23, 8.04037118290947594446e-01) (24, 1.70623868031719894134e+00) (25, -1.42631438995545800630e+00) (26, -3.52831112769384891426e-01) (27, 1.39395299216010471355e+02) (28, 2.62666933789612810912e+00) (29, 9.11258457499897822629e+00) (30, -2.74665182446355959911e-01) (31, 4.77148122393362612570e+01) (32, -2.17547152647514385748e+00) (0, 3.95778843818762826601e-01) (1, -2.85242077160514950762e+00) (2, -6.54057487307588392156e-01) (3, 6.93911977643405286642e-01) (4, 3.03861087995917933391e-01) (5, 1.23735227004275055718e-02) (6, -3.00000000000000000000e+02) (7, -1.34408005342796857406e-02) (8, 1.08601539051334975738e+03) (9, 2.34856178232698864505e+00) (10, -1.97807659146027092767e+00) (11, -3.00000000000000000000e+02) (12, 6.18652793503907894035e+00) (13, -1.50000000000000000000e+03) (14, -1.16690357283165326407e+03) (15, -3.00000000000000000000e+02) (16, 1.49966304814360023556e+03) (17, 1.72971290770988872509e+00) (18, 1.49225484958167317018e+03) (19, -3.79866313258263730290e+01) (20, -1.93434657582078917137e+00) (21, -1.31997867463918623798e+02) (22, -5.06549445468597925313e-01) (23, 8.44483138470574767886e-01) (24, -2.27894153226097628817e+00) (25, 3.43964971514791839624e+00) (26, 2.78237012068714706370e-01) (27, 6.07374664075850212441e+00) (28, 7.05146721583083224694e-01) (29, 5.40386140163512251888e+00) (30, 3.12758711438497483126e-01) (31, 2.46992240917898442376e+00) (32, -3.73108380960455954245e-01) (0, -1.29653580157764847236e+00) (1, 1.15903838441547235583e+00) (2, 9.94209570435145240097e-01) (3, -1.44764352923119260508e-01) (4, -4.55863226938234444852e-01) (5, 2.45603270876152413038e+00) (6, 1.50000000000000000000e+03) (7, 2.98800168555717282626e-01) (8, 9.78818442810288180667e-01) (9, 1.71810798000169584476e+00) (10, 2.39991779858557929828e+00) (11, 1.50000000000000000000e+03) (12, -3.47757843855523995913e+00) (13, 2.12055496103393981144e+00) (14, -1.69475698345187342220e+00) (15, 1.50000000000000000000e+03) (16, 3.16857357873135825344e+00) (17, -2.25098053764371197616e-01) (18, 2.88155119212585653088e+00) (19, -3.29973019329577699210e+00) (20, 2.14131161038820527764e+00) (21, 1.03717857714884198472e+00) (22, -1.53293107807855277791e+00) (23, 7.16410942892212521116e-01) (24, 1.32731980610301847356e+00) (25, 4.37183716991672621788e+00) (26, 2.14177729598447186277e+00) (27, -5.43594679593481178159e-01) (28, 3.79419669480562216091e-01) (29, -2.83490147773505984929e+00) (30, 2.15563977814282603518e+00) (31, 2.50386359538197256214e+00) (32, -1.05581893368295176572e+00) (33, 1.03244536606305565840e+01) (34, -8.02069835119909768650e+00) (35, 1.47351953746669313006e+01) (36, -1.30041488378051433017e+01) 
