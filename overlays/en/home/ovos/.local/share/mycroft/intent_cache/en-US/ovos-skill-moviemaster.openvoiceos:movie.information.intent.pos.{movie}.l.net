FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.57965886114957343445e-01) (1, 3.66369235585902508490e-01) (2, -9.04635691904552285969e-02) (3, 1.90790838065057033468e+00) (4, 6.92116340756814385493e-01) (5, -2.19861219209524644258e-01) (6, -5.97369052400564606864e-02) (7, 5.93389893623407771450e-01) (8, 4.04110770214895498320e-01) (9, 4.20138499239675611285e-01) (10, 3.94876389561934104666e-01) (11, 6.86500540081460997044e-01) (12, 2.75725916658400460602e-01) (13, 2.72289261852263375641e-01) (14, -1.49891382239954934485e-01) (15, 1.07613764446364545968e+00) (16, -2.60767423952756871586e-01) (17, 5.21227595551970956933e-01) (18, 5.07056432012687463562e-01) (19, 8.66676705019406162789e-02) (20, 1.63460614167234274952e+00) (21, -6.17401813012649000600e-02) (22, 5.72300695475821061264e-02) (23, -5.51774697281241732760e-01) (0, -3.57275464473682502486e+00) (1, 2.27703441430107433874e+00) (2, -2.98050712098108683268e-01) (3, 7.30883458316284428946e-01) (4, 2.69059923456050587021e+00) (5, -7.49190256945100219177e-01) (6, -6.99261422696948908850e-01) (7, -2.16998856759886060708e-01) (8, 2.28580656836245355024e+00) (9, 2.27991898635406009532e+00) (10, 1.18026530251305117325e+00) (11, 2.78848743273896992889e+00) (12, -5.77278842769441857818e-01) (13, -2.32455288129231579797e-01) (14, -4.02820372363240530866e-01) (15, 1.63485079397501786858e+00) (16, -3.62567642809306711627e+00) (17, -1.77037270648885414204e+00) (18, 7.32450390604172385522e-01) (19, -8.70814441106450010111e-01) (20, -1.26480184654928340393e+00) (21, -7.41617443974310064370e-01) (22, -8.30178711493502530239e-01) (23, -1.86424885270442164398e+00) (0, -2.01279509894561980943e+00) (1, 1.08284146127213398714e+00) (2, 6.29361382622061968362e-03) (3, 1.05189437371866056914e+00) (4, 1.20772602767469661167e+00) (5, -2.13706431628556320357e-01) (6, -6.99130811704023580333e-01) (7, 7.90404852878287211837e-01) (8, 1.08688447611120375669e+00) (9, 9.92023769213640993492e-01) (10, 5.79976731288747160420e-01) (11, 1.27439418636554235853e+00) (12, -1.38475401146370385996e-01) (13, -1.49266982638500134151e-01) (14, -1.34637975784375862887e-01) (15, 7.03289531054752892203e-01) (16, -1.34509899630155538297e+00) (17, -6.06556676305719175146e-02) (18, 2.77517061531995956614e-01) (19, -4.21201800065169218446e-01) (20, 7.73450977846058762566e-01) (21, -2.10629022316884462196e-01) (22, -2.53025186205602325984e-01) (23, -7.99095942098023370725e-01) (24, 3.59625561875270083334e+00) (25, 3.36776519801519782504e+01) (26, 6.77873253521721785830e+00) (27, -2.11722095103349516876e+00) 
