FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.25091706538300184715e-01) (1, -2.06691912160710422608e-01) (2, -2.32136047230557529542e-01) (3, -1.66659018741444731049e-01) (4, -1.27153946803406830979e-01) (5, -1.06816392928088479408e+01) (6, 3.48130904949979935736e+00) (7, 7.30072874530494297929e-01) (8, 1.96304855153041045435e-02) (0, 1.28358040221165103922e+00) (1, 6.24304616918411436899e-01) (2, 6.82142147888984862192e-01) (3, 8.03958097567405882700e-01) (4, 7.48803207745399657114e-01) (5, -2.09309697661389026990e+00) (6, -1.26991302279929030306e+00) (7, -3.46324344811328188598e+00) (8, 7.72995086635856365476e-01) (0, -2.25858460688690809715e-01) (1, -1.64700640902159745060e-01) (2, -2.21454283759234427098e-01) (3, -1.96984781489012716893e-01) (4, -1.73058501050112778508e-01) (5, -1.07279282077873521217e+01) (6, 3.47642890430765305609e+00) (7, 7.01221417590320306168e-01) (8, -1.32905780036739751271e-01) (0, -3.85261077010731312065e-01) (1, -1.67032620419103855491e-01) (2, -2.08294013995964227837e-01) (3, -1.65031174678642506004e-01) (4, -1.99104244370300470512e-01) (5, -1.07161391503835492500e+01) (6, 3.39526676453428422064e+00) (7, 7.09565412207782353349e-01) (8, 9.71607242078353569581e-03) (0, 2.01123097054259625249e-01) (1, 6.82614352739567165074e-01) (2, 7.14898195303196093420e-01) (3, 7.64339957571739336828e-01) (4, 7.26855371332878252844e-01) (5, -3.10905066446631872523e+00) (6, -2.63396502834362200574e+00) (7, -2.29456057112739697512e-01) (8, 2.81325706474966408255e-01) (0, 1.35212807200978679667e+00) (1, 6.56013615025958674032e-01) (2, 7.44749079986295359213e-01) (3, 7.09215867860993998129e-01) (4, 6.23175229473790781576e-01) (5, -2.85686497245796910960e+00) (6, -2.20302375327091404245e+00) (7, -1.73208642896880360418e+00) (8, 6.04006929841658379843e-01) (0, 4.35042587009509124085e-02) (1, 2.25497628324620974505e-01) (2, 1.71182463639371618136e-01) (3, 2.06253285282247317278e-01) (4, 3.32566301757028781605e-02) (5, -6.06981777748280104667e-01) (6, -1.65958853858401633730e+00) (7, -2.42839625271676906593e-01) (8, 1.27166523975599021767e-01) (0, 1.73482699826226161033e-01) (1, -4.58682927092466663499e-02) (2, -4.85106560191068958421e-02) (3, -1.61376901229277613936e-01) (4, -7.96719270547781160952e-02) (5, -1.13179279236715904511e-01) (6, 2.71167973241342163959e+00) (7, 5.56600966519555706569e-01) (8, -9.87555565943335073031e-02) (0, 9.47293447049654124825e-01) (1, 8.78826235996805343875e-03) (2, -4.62422400189724941422e-02) (3, 1.73218593524607292200e-02) (4, 1.21576947026124843054e-01) (5, -2.63921412042576880586e-02) (6, 3.86728744254421441529e-01) (7, 1.83906372176847549005e-01) (8, 1.33142758320178383746e-01) (0, 1.37984263722046390788e-01) (1, 7.21926961336990039020e-03) (2, -5.85390778979216000466e-02) (3, -1.22591771443739921965e-01) (4, -4.32227852543745350022e-02) (5, 9.41825357139276092555e-02) (6, 2.59566111675036959028e+00) (7, 6.23875414050063747951e-01) (8, -5.96877802614718053209e-02) (9, -3.01683744041162993366e-01) (10, -2.16874508176059577202e-01) (11, -2.30625275168538840243e-01) (12, -2.65112002937037072314e-01) (13, -2.02520647835873479625e-01) (14, -4.51709822899418356190e-01) (15, -4.24906914401716601093e-02) (16, 5.00494081295644099860e-01) (17, 1.11236032181559155174e-01) (18, 3.93918836745555056567e-01) (19, 3.99538956514802479081e-01) 
