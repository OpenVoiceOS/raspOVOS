FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.12966975645024070296e-01) (1, -1.06890521210879468894e-01) (2, -3.44473190729324002524e-02) (3, 3.74633379156883647432e-02) (4, -8.71916331474486827613e-02) (5, -1.61597412486338476434e+00) (6, -1.63520744670313189495e-01) (7, -5.55127340160444293637e-01) (8, 1.31418064224176484034e-01) (9, -3.40656112567539401392e-02) (0, 2.53948326484162212324e-01) (1, -8.33163924638930797339e-02) (2, -4.74162168924514362822e-02) (3, -3.52181039874259610434e-02) (4, 2.56695009644325768117e-02) (5, -1.61719529737496237054e+00) (6, -1.54001316655557940472e-01) (7, -5.23536744319036628781e-01) (8, 1.29363700735025483057e-01) (9, -2.00559940821476073713e-01) (0, 2.54797128198362199392e-01) (1, -2.84875624005500351077e-02) (2, 6.16194315131004741182e-02) (3, -5.07533170406524250517e-02) (4, -1.07356271905154371238e-01) (5, -2.35489703116100423941e+00) (6, 2.75190706191838219130e-01) (7, -4.03579330460488883148e-01) (8, 1.51123629845975215868e-01) (9, -6.63534595435333607316e-02) (0, 1.03479075959862019118e+01) (1, 4.63946590088422761156e-01) (2, 5.57679457478339801746e-01) (3, 5.48024294786270016466e-01) (4, 4.21140557043369279100e-01) (5, -2.78158693007032997713e+00) (6, -2.21286555247112692868e+00) (7, -5.93751594041449060057e-01) (8, -5.01224568998107522511e-01) (9, 4.25101206379048912609e-01) (0, 1.68302132406473115012e+00) (1, 5.31243128295300182096e-01) (2, 6.21539776738045390836e-01) (3, 6.07379352267143901578e-01) (4, 6.15755667503235515348e-01) (5, -6.33310740150139661608e+00) (6, 2.37773262674945442541e+01) (7, -7.35892126440019334055e-01) (8, -7.48008656485877443387e-01) (9, -1.87144537851474147827e-02) (0, 1.03792744210899616775e+01) (1, 3.49433590514954761641e-01) (2, 3.65749572260674671309e-01) (3, 4.03493587715920642989e-01) (4, 4.18410909219083027022e-01) (5, -2.29236650092258731348e+00) (6, -2.06094650273438650956e+00) (7, -4.21519172689200194437e-01) (8, -6.88538057250981383461e-01) (9, 6.73700437896365911250e-01) (0, 1.89327070024400034853e+00) (1, 3.55463699755387940726e-01) (2, 2.79529453572946284812e-01) (3, 2.59854321685748679283e-01) (4, 2.96572157499509603262e-01) (5, -1.48606011606320964624e+00) (6, -1.31034761613869665808e+00) (7, -1.04393161373318488216e+00) (8, -4.33094776101776157695e-01) (9, 3.89058245096967292298e-01) (0, -5.60080733324825219555e-01) (1, -1.11079269988846845996e-01) (2, -8.28573945596934313684e-02) (3, -1.58868188007187910449e-01) (4, -1.57982883943629331958e-01) (5, 8.39227048643118367366e-01) (6, 4.42729821251324651143e-01) (7, 7.75695168873140383781e-01) (8, 4.51934414508273873956e-01) (9, 1.96210804232251040391e-01) (0, 2.66196523962236308858e-01) (1, -6.59824155394736905356e-02) (2, 2.32995308811958824757e-02) (3, -3.33445139352981229086e-02) (4, 2.55963279560170349491e-03) (5, -2.34410682466905706534e+00) (6, 4.29214236385576042299e-01) (7, -4.45656931416452073424e-01) (8, 2.10522996224759395556e-01) (9, -1.82936866468734832258e-01) (0, 1.62341272303104355856e+00) (1, 5.45316470380184825650e-01) (2, 6.23229836638329204312e-01) (3, 5.47128846462128337613e-01) (4, 5.97313841398117717496e-01) (5, -6.38810226402805181323e+00) (6, 2.38865193913715962992e+01) (7, -6.41036154805631475107e-01) (8, -9.13141462190947938993e-01) (9, 3.30784956529476398268e-02) (10, -2.30319373364955642947e-01) (11, -1.74196411103782172747e-01) (12, -2.16014992179662829175e-01) (13, -4.51341606909579529106e-01) (14, 4.56013613649465465727e-01) (15, -3.21162202170895305642e-01) (16, -2.33128753896293255954e-01) (17, 6.26713810624443756758e-01) (18, -3.16935163705622024999e-01) (19, 5.21139779397107982817e-01) (20, 2.30833424852808999361e-01) 
