FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.51078745092799981986e-01) (1, -2.18122271415270463368e-01) (2, -1.59837362882174149892e-01) (3, -4.31820206013094690101e-02) (4, -1.70633172210730210683e-01) (5, 2.53981541426611889811e-01) (6, 3.73760005337405554204e-01) (7, -3.30451711772984246807e+00) (8, 3.97146024566887079210e-01) (9, 1.95246434555409048572e-01) (0, 5.16838951903005994204e-01) (1, -1.77596787997940930293e-01) (2, -2.75282441465653539281e-02) (3, -1.76817844697693737910e-01) (4, -2.32424128935710327601e-03) (5, -4.82466862235270799175e-01) (6, 4.95871610954060973442e-02) (7, 5.30400200648157849059e-01) (8, 2.05036047195708726054e-01) (9, 3.05754920044891187469e-01) (0, 1.41015490259578490928e-01) (1, -1.08974409815348338704e-01) (2, -1.67326526310719148061e-01) (3, -1.15957146104849501134e-01) (4, -1.68760446425951615712e-01) (5, 1.94934080870581671885e-01) (6, 3.50019959611106268316e-01) (7, -3.37164769082373361186e+00) (8, 3.53423722845314203234e-01) (9, 1.83670255140421484485e-01) (0, 5.05125443386455930117e-01) (1, -1.49174130597571286128e-01) (2, -1.29486925044516476557e-01) (3, -9.87484558312692051185e-02) (4, -1.71577501186589154170e-01) (5, -4.00519073639117595409e-01) (6, 7.90615350022569052246e-02) (7, 5.80846614105551495300e-01) (8, 8.52147222512125990246e-02) (9, 4.95005925694457726838e-01) (0, -2.00687847774597294404e+00) (1, -8.51637015032096350575e-02) (2, 1.14421060395912647933e-02) (3, 3.68718412644429213709e-03) (4, -7.41996208118720634861e-02) (5, -2.16350359522209864660e-02) (6, -1.79086196416351872696e-01) (7, 1.35202586952422376676e+00) (8, -7.26788683731189877335e-02) (9, -3.43119165201867637460e-01) (0, 4.91456456366786587076e-01) (1, 2.76114130289296988430e-01) (2, 2.24860610336999722225e-01) (3, 1.32601203293542774242e-01) (4, 1.80935645372609976711e-01) (5, -9.19306114608077623584e-02) (6, -1.96663473365120800018e-01) (7, 4.73976026082084533897e+00) (8, -7.99953051043805901665e-02) (9, -1.14278738213902456011e-01) (0, 1.25576747323920989707e-01) (1, -1.39217828926123277089e-01) (2, -1.62985650416887895009e-01) (3, -1.12504889782942457677e-01) (4, -5.01843593683611657874e-02) (5, 1.34219903083277747324e-01) (6, 2.42075046402621701924e-01) (7, -3.40610535203522424297e+00) (8, 3.28897715371845422716e-01) (9, 2.08161427424309347645e-01) (0, 1.18626733984401502853e-01) (1, -1.50359158929861680409e-01) (2, -3.74276093807589388396e-02) (3, -1.77922850069082871816e-01) (4, -1.58287034895695344350e-01) (5, 1.57758857639266059092e-01) (6, 2.53501338762450678654e-01) (7, -3.37843575834339837627e+00) (8, 3.55336547654865442247e-01) (9, 2.55614130542633655185e-01) (0, 1.58456122245242858604e-01) (1, -1.87844348665751115224e-01) (2, -1.28336673196829453847e-01) (3, -2.43145875301730048090e-02) (4, -1.66497820582665101430e-01) (5, 2.22345422537756992609e-01) (6, 3.87449001771617285161e-01) (7, -3.44915321975058297710e+00) (8, 4.46759731334446130724e-01) (9, 1.43588459835407855625e-01) (0, 8.73538314890554001835e-01) (1, 7.55993877009276671330e-01) (2, 8.46669707850340902411e-01) (3, 8.36869221583727895819e-01) (4, 8.64267643944148122870e-01) (5, 1.14036583282452230748e+00) (6, 2.11430304024263104878e+00) (7, 2.07192565749880985848e+00) (8, 2.26355446062725418344e+00) (9, 7.07386648311854826510e-01) (10, -3.89939580796199392054e-01) (11, 4.27850305220535243045e-01) (12, -3.31164066431956782832e-01) (13, 1.48991533391792524421e-01) (14, 8.81004166675592559343e-01) (15, 4.27668225546106617330e-01) (16, -3.09052151380019679561e-01) (17, -3.66375346420245717738e-01) (18, -3.87616027830081533168e-01) (19, 1.00450935176363942425e-01) (20, 2.85785547534739781117e-01) 
