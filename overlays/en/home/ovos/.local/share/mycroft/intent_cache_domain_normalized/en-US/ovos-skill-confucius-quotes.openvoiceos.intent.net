FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.20102131836052422598e-01) (1, -1.48386333711227946797e-01) (2, -1.20397098935923138607e-01) (3, 5.85618185273692123949e-03) (4, -9.17747734261365050168e-02) (5, 3.71596598330097060980e-01) (6, -3.12104725754625333956e-01) (7, -7.81287929704645023321e+00) (8, -1.87372428974279942038e-01) (9, -2.64060565746194852998e-01) (0, 3.23530581680595341609e-01) (1, 4.31309179282793497823e-01) (2, 3.70930434084543680928e-01) (3, 2.86069572783121561788e-01) (4, 3.88716549492487406514e-01) (5, 6.36900217336880680730e-02) (6, 6.60193391881229829643e-01) (7, 9.48325925934479485591e+00) (8, 1.31736829976485919635e-01) (9, 2.84380314953909030251e-01) (0, 1.01073188175617745266e+00) (1, 4.05111365810114421038e-01) (2, 4.51510072544294871477e-01) (3, 4.20798853829580821184e-01) (4, 5.45980923667627848772e-01) (5, -3.66410510655970411698e-01) (6, -2.97327871737755322634e-01) (7, -3.01516206885956528083e+00) (8, 1.35735756926456063720e-01) (9, 5.43612355191344875927e-01) (0, 1.32567417708694318401e-01) (1, 3.91811654782900309346e-01) (2, 3.51295777476438975118e-01) (3, 2.98992347783455347798e-01) (4, 3.57364633000502085469e-01) (5, 9.67238397402035710027e-02) (6, 2.33189826913461850655e-01) (7, 9.46881590652630578120e+00) (8, 5.77098579210507389714e-02) (9, 3.52009615011797061257e-01) (0, -5.44484974311541969350e-01) (1, -1.73058564405449921697e-01) (2, -1.90097565393456513494e-01) (3, -1.25243800323018072973e-01) (4, -1.41273724477299689184e-01) (5, 3.72663485363385782456e-01) (6, 3.87032869821649916364e-02) (7, 3.75792614009601244618e+00) (8, 3.96607137205607779284e-02) (9, -1.93398492972859437078e-01) (0, -4.32157316671561708699e-01) (1, -1.60261678140172059148e-01) (2, -1.76237257759579712957e-01) (3, -2.66001912395962825109e-01) (4, -1.27412962358006476293e-01) (5, 4.10122758254668817735e-01) (6, -2.83871274823087188510e-02) (7, 3.83837587770444521595e+00) (8, 2.40165806872166986974e-01) (9, -2.78206835319758538638e-01) (0, 8.89571215598444431372e-01) (1, 6.87161640814032415037e-01) (2, 5.56869679680552565060e-01) (3, 6.97347284844603398923e-01) (4, 5.31869256487574437742e-01) (5, 4.79680801372218246215e-01) (6, 6.89691681604024720009e-01) (7, -4.16982866505539551127e+00) (8, 1.89287222750865513632e-01) (9, 6.72690864708060609622e-01) (0, 2.67665979353248484340e-01) (1, 3.92944590068468546651e-01) (2, 4.35777873612055277608e-01) (3, 3.00042369282850718282e-01) (4, 3.63049515402922129415e-01) (5, -4.99654064467251024517e-01) (6, 5.94519571206810426567e-01) (7, 9.32533738631174813349e+00) (8, -2.74515933292640151864e-02) (9, 3.17597342737302890114e-01) (0, 1.50726953618164516424e-01) (1, -1.53152268953404002705e-01) (2, -1.30795296855053477802e-01) (3, -1.27866108543953471699e-01) (4, -1.23805445261082211483e-01) (5, 4.03734543624477248969e-01) (6, -2.54299366391069425752e-01) (7, -7.90306019326904163336e+00) (8, -1.23715756138929849905e-01) (9, -3.01542097247011198213e-01) (0, 9.79382861046652286596e-01) (1, 5.82812694451298796139e-01) (2, 5.48891851297106825314e-01) (3, 7.18021126082625249509e-01) (4, 5.51163533321108900509e-01) (5, 3.71495890061545375183e-01) (6, 5.77889585692520024729e-01) (7, -4.02665742168581619609e+00) (8, 1.39134578235827977011e-01) (9, 6.18666321094865190311e-01) (10, -1.56464204083868074768e-01) (11, 4.29839194632181620381e-01) (12, -2.39638452579985228308e-01) (13, 4.50431854344019388936e-01) (14, 5.77719893495676095618e-01) (15, 6.09010875414249475135e-01) (16, -2.51761441280851927527e-01) (17, 3.61037471211561655782e-01) (18, -9.63247237873883360715e-02) (19, -2.11003800084601011999e-01) (20, 2.54851915753492808125e-01) 
