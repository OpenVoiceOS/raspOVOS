FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.22439135565126067107e+00) (1, -2.79105736926232750328e-01) (2, -2.68024942889844353111e-01) (3, -3.55864449456368858726e-01) (4, -2.23441234841977531822e-01) (5, -2.26940445692677739142e-01) (6, 1.24478887783760192032e-01) (7, 1.87382606123325828884e-01) (8, 4.48544584386292854994e-02) (9, 3.79474498177637287188e-01) (0, -1.45712430443967999594e+00) (1, 3.03602487900932645204e-02) (2, -1.91966622015754574682e-02) (3, -1.36937844648055223606e-01) (4, -1.38064722611598161839e-01) (5, -5.47793231903369870484e-02) (6, -2.84000236910370122689e-02) (7, 1.16265268851640524161e+00) (8, -1.69186502613972111764e-01) (9, -2.70474249340661554442e-01) (0, 2.58037491366620019839e-01) (1, 1.99758956633617368315e-01) (2, 1.78145552478839841459e-01) (3, 5.32432519422073452509e-02) (4, 1.80863926611949887846e-01) (5, 2.06690308066249328611e-01) (6, 1.23676576732962895111e-01) (7, 4.93405833888578193580e+00) (8, 1.64305183637465906932e-01) (9, -2.62076942567082082913e-01) (0, 3.85277858600373279696e-01) (1, 2.93782581888893425115e-02) (2, 1.79096546521113231254e-01) (3, 1.02893773963377718750e-01) (4, 7.29933497809627657160e-02) (5, 1.99379970614544654861e-01) (6, 7.92371864312584606171e-02) (7, 9.01285840970347429391e+00) (8, 7.50870290878673102286e-02) (9, -1.75426175657002886288e-01) (0, 8.57607924979075675331e-01) (1, 9.67968598837758154030e-02) (2, 2.24382483297100143727e-01) (3, 9.66202811236287206764e-02) (4, 1.13190338843574642147e-01) (5, 2.04194088360815761973e-01) (6, -4.31042162355915470240e-02) (7, -1.80548069478155825962e+00) (8, 9.99448614886456476736e-02) (9, 3.05941824414191487769e-01) (0, 9.17208658199652915322e-01) (1, 9.15814311141873588218e-02) (2, 1.28999070161094769871e-01) (3, 1.64339319699516400730e-01) (4, 1.08932093613853572811e-01) (5, 3.85154009671504482526e-02) (6, 1.15547994379887372651e-01) (7, -1.76438839585663531651e+00) (8, 1.94897049904879215987e-01) (9, 3.14906020261702779273e-01) (0, 3.24222928509469043856e-01) (1, 1.90041151394770457816e-01) (2, 1.60612609734461619926e-01) (3, 9.93389529489734218748e-02) (4, 1.02793101718352083984e-01) (5, 1.55917469771743338880e-01) (6, 1.22748250955041666999e-02) (7, 9.04751039323280359383e+00) (8, 1.31116922545756880991e-01) (9, -2.99377313879016122844e-02) (0, -1.44298222329820813314e+00) (1, 3.87659044125755747334e-02) (2, -8.76258601158064545644e-03) (3, -1.20179201557330278538e-01) (4, -1.07476352795056531719e-01) (5, -7.37041331826503720581e-02) (6, -1.38702725283482430907e-01) (7, 1.09821140993955435050e+00) (8, -1.58675642188315202397e-01) (9, -2.94225873545504834627e-01) (0, 3.30449837343053465233e+00) (1, 2.86762332020715826619e-01) (2, 3.55392274855093059927e-01) (3, 4.23913558422044811635e-01) (4, 4.08239131270364818960e-01) (5, 5.08403456257396135776e-01) (6, 6.48353501730583481333e-01) (7, -4.55112779831979175071e+00) (8, 6.66455402546547337472e-01) (9, 2.19402618632474954996e-01) (0, 2.86953194663281396792e-01) (1, 1.01434801270888094726e-01) (2, 1.81591790666506602836e-01) (3, 4.35852934920051768297e-02) (4, 1.06319380306461631902e-02) (5, 1.38488178436390663162e-01) (6, 4.48504547470505582352e-02) (7, 9.08838688981602693673e+00) (8, 2.16547812867488365107e-01) (9, -1.94014629188268089566e-01) (10, 4.19263920113729704475e-01) (11, 3.70323934308627977785e-01) (12, 5.00139150913325170045e-01) (13, 4.58685446675387242799e-01) (14, -4.39455843026657966277e-01) (15, -3.38048696600443177029e-01) (16, 4.73581988509264806275e-01) (17, 3.44590377254771818016e-01) (18, -1.32720000625970252495e-01) (19, 5.87690112349143700676e-01) (20, 3.49930562177644288724e-01) 
