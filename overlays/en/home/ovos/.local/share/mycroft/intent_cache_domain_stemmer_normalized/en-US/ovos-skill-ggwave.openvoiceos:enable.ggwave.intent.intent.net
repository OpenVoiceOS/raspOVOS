FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=15 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.85044840665085796871e+00) (1, -1.34252953166849320343e-01) (2, -7.42726538430520943912e-02) (3, -4.19331330906221252941e-02) (4, -4.92837914336411060667e-03) (5, -2.36448235012159252433e-01) (6, -9.18017804729849951073e-01) (7, -5.31060541748907710691e-01) (8, -1.17997292896607736123e-01) (9, -2.24579195377866058791e+00) (10, -1.69698975182638073234e-01) (11, 1.65001455079509182222e-03) (12, 3.08251723353301754216e-01) (13, -2.86723504283332264464e-01) (14, 3.53008233833002893487e-01) (0, 7.71715143264754299679e+00) (1, -5.30265186082193237804e-02) (2, -1.41679025078899567536e-01) (3, -9.62647710095712594303e-02) (4, -1.42303920174724762848e-01) (5, -1.64267934061155224112e-01) (6, -9.72287546950490355613e-01) (7, -3.23550279882204472326e-01) (8, -2.70271897699354113342e-01) (9, -2.47336904456426154297e+00) (10, -2.40485757886467865774e-01) (11, -1.46577542989144798957e-01) (12, 2.24267400507365738394e-01) (13, -1.75161319293879957915e-01) (14, 3.62823277505284202960e-01) (0, -3.69778197951164955271e-01) (1, 6.85732295387200124770e-02) (2, 7.33362814062050588637e-02) (3, 5.50455530755928762465e-02) (4, 2.73571215800561505505e-03) (5, 2.15659160090427778900e-02) (6, -1.11169792890250462847e+00) (7, 6.72028764237294351513e-02) (8, 1.71628127983901979103e-01) (9, -2.10683090645246040573e-01) (10, 9.26834251655083152244e-02) (11, 3.25875599155033973675e-02) (12, 2.78575917747820478443e-01) (13, -1.53177719876228968232e-01) (14, 2.35034304027775420298e-01) (0, -3.85875641366944632793e+00) (1, -1.49391084596764589509e-01) (2, -2.56955861732613588533e-01) (3, -2.19920221403491045198e-01) (4, -2.69560232445847591798e-01) (5, -2.06184363314885710228e-01) (6, -7.07598425243779427518e+00) (7, -3.38196314681406984270e-01) (8, -2.43218974604944987439e-01) (9, -6.53040810537932969737e+00) (10, -2.24640412578363007912e-01) (11, 5.42244522436397646814e-01) (12, 3.66498261310491235676e-01) (13, -1.09237098995002265833e-01) (14, 3.34003871520124839822e-01) (0, 8.44724050696507333669e+00) (1, 2.87308735732515266315e-02) (2, 9.10559786443193713845e-02) (3, -6.76521243567983349143e-02) (4, 9.80185760144670764626e-02) (5, -1.14249869674910672912e-01) (6, -7.84301990543288862767e-01) (7, -2.55693800694480333213e-01) (8, -1.53258664643272091155e-01) (9, -8.03604674934524587648e-01) (10, -1.88012277817233786070e-01) (11, -3.52208419118233140299e-01) (12, -1.53802373282111326525e-01) (13, -5.40975815663454318027e-01) (14, 9.96930134700916986690e-02) (0, 7.90767104120476727047e+00) (1, -8.58110997926065377506e-02) (2, -8.65044359217950753482e-02) (3, -1.65483287359363684388e-01) (4, -3.19645095716783109174e-02) (5, -1.63196935452089214591e-01) (6, -9.67922564703137755515e-01) (7, -5.53382108688261653562e-01) (8, -2.16407679404733432893e-01) (9, -2.21372344789544373000e+00) (10, -1.18726804054841914016e-01) (11, 1.08262241197724477793e-02) (12, 2.90985911790763607243e-01) (13, -3.05969471552276051085e-01) (14, 4.51322019922423212090e-01) (0, 7.77420213015301708737e+00) (1, -3.77707619320222856563e-02) (2, -1.42843848849422638825e-01) (3, -1.46580247963554566315e-01) (4, -2.72959608684846567750e-02) (5, -2.47597425378427438147e-01) (6, -1.01346141855707871926e+00) (7, -4.27546608891737400793e-01) (8, -1.66311298033097632043e-01) (9, -2.11762305048743426639e+00) (10, -1.97982433385715389518e-01) (11, 2.20399056073105059639e-01) (12, 2.03011931252922189772e-01) (13, -1.62326174297236835997e-01) (14, 3.50664236473727075616e-01) (0, 1.18849872154833988702e+01) (1, 3.62307446939588106982e-01) (2, 3.25454975409150637500e-01) (3, 2.38296891493440243792e-01) (4, 3.72919785720944918506e-01) (5, 3.48629023750241961999e-01) (6, 9.45861885857097739461e+00) (7, -7.34899801337725033790e-01) (8, 4.05536472703636574622e-01) (9, 8.03403307377771724873e+00) (10, 3.47011770923551288170e-01) (11, -9.28795903501265507352e-01) (12, -8.13983443657878225075e-01) (13, -4.56175675095107369117e-01) (14, 3.51474779591670893897e-02) (0, 7.90477926225884441891e+00) (1, -8.32636196266481332096e-02) (2, -1.33218123401291077545e-01) (3, -1.51934242631084626129e-01) (4, -5.37482489000627242093e-02) (5, -6.53175405632113598164e-02) (6, -9.95578900086791396262e-01) (7, -3.07543236460936009191e-01) (8, -2.31990945061543885064e-01) (9, -2.13862196800748050052e+00) (10, -1.89036726153955364493e-01) (11, 5.95830779215639066981e-02) (12, 1.80838167373572972219e-01) (13, -2.79384011843108570616e-01) (14, 3.52709376144099084893e-01) (0, -5.85693736537556208788e+00) (1, 7.70278383144844258634e-02) (2, 7.63969380506981099455e-02) (3, -9.86834507337104316349e-02) (4, -9.41095467558394904728e-02) (5, 1.32908620925877990482e-01) (6, 5.75840617128930976065e-01) (7, 1.10478396839037470989e-01) (8, 9.81286675958602597203e-03) (9, 5.60401331923392254097e-01) (10, 5.02909792111081166421e-02) (11, 4.22526114685395845494e-02) (12, 5.74424021787053540322e-01) (13, 1.07604668122209187753e-01) (14, 2.26122547697734099792e-01) (15, -3.57707767832964540489e-01) (16, -2.12334738613361162507e-01) (17, -4.13555947406512303122e-02) (18, -3.59661499333147616220e-01) (19, -1.24825779164000408294e-01) (20, -2.92912787843435884483e-01) (21, -3.84425528819191175689e-01) (22, 1.15635740197540237695e+00) (23, -3.83268098503214582617e-01) (24, 1.81915887510122359361e-01) (25, 3.80267231378196901570e-01) 
