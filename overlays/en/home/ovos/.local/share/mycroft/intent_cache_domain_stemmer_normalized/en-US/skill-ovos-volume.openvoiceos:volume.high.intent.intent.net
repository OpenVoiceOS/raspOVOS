FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.90371844329675177221e+00) (1, -9.42360376583462472366e-02) (2, -9.40368687378292794632e-02) (3, -1.09821132348669150969e-01) (4, -2.03009634243143166632e-01) (5, 2.05937071071930155597e+00) (6, -1.32367396079887067462e-01) (7, -1.73965509159386515214e-02) (8, 7.12442276538501409466e-03) (9, -1.54250545624236318210e-01) (0, 3.86190563842051126642e+00) (1, 7.43740468613281024979e-01) (2, 7.18406885258331073807e-01) (3, 6.93191274396552814530e-01) (4, 5.98747334770335815080e-01) (5, -2.54856278473280628560e+00) (6, 2.17188494771601892097e+00) (7, -7.38875422488404431931e-01) (8, 1.03778736733539145298e+00) (9, -3.64151417337612748337e-01) (0, 4.48241823009417750256e+00) (1, 8.47198292206934655546e-01) (2, 7.04908586632422173857e-01) (3, 7.02945328842810357450e-01) (4, 7.95126288723162377714e-01) (5, -2.47554600339014241328e+00) (6, 2.17018260180833078010e+00) (7, -1.01542932461188506466e+00) (8, 1.02120990001304190464e+00) (9, -1.58235808298863467325e-01) (0, 9.36126525335515502491e+00) (1, 2.85884863281493095677e-01) (2, 3.52494663143401054661e-01) (3, 3.13118188226466087620e-01) (4, 4.04974720025305656712e-01) (5, -5.19055093617583174215e-01) (6, -2.97825005453770064179e+00) (7, 4.95617830692450467289e-01) (8, -7.44642350431008390177e-03) (9, 5.31555987847184718831e-01) (0, 3.95069791778318979425e+00) (1, 7.37339406601562274979e-01) (2, 6.58771581343783996232e-01) (3, 6.70362039796485675858e-01) (4, 6.43305494777335784562e-01) (5, -2.70210234634451662572e+00) (6, 2.17256616175057626350e+00) (7, -6.88141468774033704392e-01) (8, 1.06189126216514151402e+00) (9, -2.76380116269543257834e-02) (0, -1.07798946013529883814e+00) (1, 1.13380759923688304025e-01) (2, 1.43445782332650428881e-01) (3, 2.14958183436623789797e-01) (4, 1.40772376178733116259e-01) (5, 2.17954857809761787246e-01) (6, 1.49012533954268056036e-01) (7, 3.97343723250703273475e-01) (8, 1.34097773869387065782e-01) (9, 2.27196260971937652462e-01) (0, -1.22609921971870416968e+00) (1, -4.93054732204745924107e-02) (2, -1.25677277100212481109e-01) (3, -9.47837128759693031688e-02) (4, -2.21466411602623369781e-01) (5, 2.11255151016206088599e+00) (6, -1.53248398288311993287e-01) (7, -7.08272500487938244662e-02) (8, -3.14633089147234104588e-02) (9, -4.82847273861181786048e-02) (0, -1.20140031407190317481e+00) (1, -1.06343091637235390157e-01) (2, -1.43017762512307855527e-01) (3, -4.41704552475030154390e-02) (4, -2.32062350812966555758e-02) (5, 2.22834244615321930283e+00) (6, -8.89201659351517292862e-02) (7, -1.15631973654897426962e-01) (8, -4.67233595484386823871e-02) (9, -5.69648638115902578027e-02) (0, -1.12995012531591410010e+00) (1, -6.03801801325153306155e-02) (2, -1.74432580125458147613e-01) (3, -2.20369283807403948394e-01) (4, -1.43386897397167589752e-01) (5, 2.62537218076441769554e+00) (6, 3.84494167178939111329e-02) (7, -1.67420183950381940008e-01) (8, -1.37679508610787426637e-01) (9, -2.46356695638676320703e-02) (0, 4.63193178764746882337e+00) (1, 1.07325691800262790210e+00) (2, 1.01452937792684916296e+00) (3, 1.02770228009369257727e+00) (4, 1.01854020427610758581e+00) (5, -4.05517592703264906362e+00) (6, 2.18803039312245584114e+00) (7, -1.03245216529057692867e+00) (8, 9.48699687353206089213e-01) (9, -2.07215855047657576682e-02) (10, 5.68908455830954062904e-01) (11, 3.71423434120319140295e-01) (12, 3.81904568177364123205e-01) (13, -2.57856979791491358611e-01) (14, 3.45736484628818285803e-01) (15, -1.04067075904802353037e-01) (16, 5.21143367899420617562e-01) (17, 4.87166455400946551979e-01) (18, 5.61610727025034783821e-01) (19, 3.29143400889537585119e-01) (20, 2.65011336935271013537e-01) 
