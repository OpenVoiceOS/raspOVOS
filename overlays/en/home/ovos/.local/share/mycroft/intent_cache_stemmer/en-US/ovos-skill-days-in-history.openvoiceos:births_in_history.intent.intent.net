FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.91234003372608718507e-01) (1, 7.17556204589509194491e-01) (2, 7.58436281176709359286e-01) (3, 6.96196433099412370638e-01) (4, 8.40940099152230446933e-01) (5, 4.88826376787061145368e-01) (6, -1.14462610820005084022e+00) (7, 2.41463971552684203425e-01) (8, 6.88811005106554574695e-01) (9, 6.28105501740384308818e+00) (10, -1.09275516536743353413e+01) (11, 4.69882777586491595656e+00) (0, 4.77975637408914466597e-01) (1, -7.35541061442705895734e-02) (2, -6.22568764668316454447e-02) (3, -4.68764864784092516459e-02) (4, 3.60151379424720197164e-02) (5, -5.37084758545733187418e+00) (6, -3.25458859160068980643e+00) (7, -4.75387426445878702452e+00) (8, -2.47102427106039190807e-01) (9, 1.13685820897546197017e+00) (10, -1.56941423519030731626e-01) (11, 6.93304200310024959508e-02) (0, -1.86708488142482892380e-01) (1, 5.94403066250576636587e-02) (2, 3.41232337567105095677e-02) (3, -2.36797488716351048343e-02) (4, -4.48095991698012688365e-02) (5, -4.67520315908991790366e-01) (6, 1.99996476899749364708e-01) (7, 1.69325560841836342263e+01) (8, -6.67295618282435554214e-01) (9, 5.96794342969480182126e-02) (10, -1.96744213641784598812e-01) (11, -1.53570160395114008178e-01) (0, 2.60419312537122471518e-01) (1, -6.40744082355316768584e-02) (2, -9.47008169913109154603e-02) (3, 7.21899050237574581995e-03) (4, 9.96854864335242618623e-02) (5, -9.75436919664438684130e-01) (6, -4.50995500805394211596e+00) (7, 2.27295231577575140847e+00) (8, -3.92179136311842924112e-01) (9, -1.84590732511866173482e+00) (10, -4.96408299265559016522e-01) (11, -7.35283805998697553852e-02) (0, 9.11218460062586554926e-01) (1, -6.37148091217304146650e-02) (2, -3.97992426177288596834e-02) (3, -2.48419040461804289943e-02) (4, -8.41595971604610360028e-02) (5, -8.09820654540271300803e-01) (6, -3.13122963483594274336e+00) (7, -5.19856984418705714290e+00) (8, 6.13792183384510026123e-01) (9, -8.04013900652307533790e+00) (10, 3.92575288725817994617e+00) (11, 6.12841070814387212096e-02) (0, 2.69088755769253729078e-01) (1, -7.60252291319090667265e-02) (2, 5.70501348021310167313e-02) (3, 8.89738610031884091800e-02) (4, -6.60783166048247438962e-02) (5, -1.69815995058428192976e+00) (6, -1.44865518400895720852e+00) (7, 1.82154192022062422218e+00) (8, -2.83939847990205773698e-01) (9, -1.09423767987369924271e+00) (10, -3.97919923157397936730e-01) (11, -7.39438127525271077234e-02) (0, 7.94115603028426075838e+00) (1, 3.57156329686549034452e-01) (2, 2.92808213169482078886e-01) (3, 2.48895698125269848600e-01) (4, 4.24397752518560600343e-01) (5, 5.64962911407764512006e+00) (6, 2.20252026645185061682e+00) (7, 1.93120066883654262213e+00) (8, -7.86747975060206350406e+00) (9, 1.04899172420186914678e+00) (10, -1.08089016309058454368e+01) (11, 2.89414322786591515779e+00) (0, 2.58875799332513700790e-01) (1, -1.67844019721228761288e-02) (2, -5.12645788381774353271e-02) (3, 7.40590445806306174603e-02) (4, -4.49124671409804610001e-02) (5, -7.39394375194405095719e-01) (6, -4.35403248387778718520e-01) (7, 5.97343330707015063297e-01) (8, -1.05607262888111730348e-01) (9, -7.19918490357936535773e-01) (10, -1.41080223680764366145e-01) (11, -6.85403022987972343483e-02) (0, -3.02439166448055962721e-01) (1, 3.21770328515683726178e-02) (2, 2.49355453485165141914e-02) (3, 6.82547869621856571204e-03) (4, -1.58604843593248168165e-01) (5, 6.32042749136348946948e-01) (6, 6.42682274747076398569e-01) (7, -2.69997272769215479471e-01) (8, 1.87372073896618224209e-01) (9, 3.15570000506425807352e-01) (10, 1.32997126306340557322e-01) (11, -1.41873751608470634322e-02) (0, -2.12962749907815412920e-01) (1, 4.91228505318150113212e-02) (2, -2.80231133754269175207e-02) (3, 4.10838716673695217296e-03) (4, -8.80150020773427105292e-02) (5, 1.89170180467605648922e-02) (6, 2.73790097017398537105e-01) (7, 1.51465835477590871072e+00) (8, -8.23249832932192032731e-02) (9, 2.01837821659463789725e-01) (10, -1.94536727202423181948e-01) (11, -1.35195121518923183634e-01) (12, -7.16954064969681920116e-02) (13, 2.62468774426957485169e-01) (14, 1.24771573472932884030e+00) (15, -1.50794539029620089376e-01) (16, 8.67876463120519026084e-01) (17, -3.25446325979112882631e-01) (18, -1.03684606649173449711e-01) (19, -1.86555432154415945512e-01) (20, 1.69252137115483258789e+00) (21, 8.30007821768917297689e-01) (22, 3.53366400886973131001e-01) 
