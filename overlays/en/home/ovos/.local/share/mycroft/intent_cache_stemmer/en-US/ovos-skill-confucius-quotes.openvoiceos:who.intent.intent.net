FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.24103638792069012609e-02) (1, -1.08933135615029597076e-01) (2, -1.02287143216767573151e-01) (3, 6.17600979941699337883e-02) (4, -5.18051509682204355811e-03) (5, 8.68664765220062834450e-02) (6, -1.37340976983313878268e-01) (7, -9.62489678858304031905e+00) (8, 1.64189219723675644547e-02) (9, -1.34748989651838652071e-01) (0, -1.48261734580962534213e-02) (1, -1.25922503445145328449e-01) (2, 3.67202373981787618534e-03) (3, 1.40439173841507558560e-02) (4, -9.43976850545375084645e-02) (5, 6.95317545395271879860e-02) (6, -1.58607895612721760958e-01) (7, -9.63030239342236527023e+00) (8, -1.51310836222386460581e-04) (9, -1.76482597301641813692e-01) (0, 1.84624842071564321255e-02) (1, -4.00356748437850351596e-02) (2, -8.98445458447901940113e-02) (3, -7.54638561344115471607e-02) (4, -1.35922687623497684406e-01) (5, 7.68913416675476302231e-03) (6, -1.35044506877665837496e-01) (7, -9.50050881280088432845e+00) (8, 1.00636082912537852541e-01) (9, -1.84325674484411589082e-01) (0, -1.11740323278900835491e-01) (1, 1.14366165065796498990e-02) (2, -1.41986648116108615802e-01) (3, -9.94605147576300835377e-02) (4, -1.22363218402831430698e-02) (5, 1.06118173287429104490e-01) (6, -7.28221155107071776991e-02) (7, -9.65316910071754463729e+00) (8, 9.05973494301770126969e-02) (9, -2.09660939747741137396e-02) (0, 6.50121911632000282211e-01) (1, 6.12480204300248298743e-01) (2, 5.71584541098439480322e-01) (3, 5.37262517706715847510e-01) (4, 5.74369877324664379614e-01) (5, 3.32423110757939066495e-01) (6, 1.34622779855743868183e+00) (7, -4.99404023710715616602e+00) (8, 5.98759508525006700630e-01) (9, 1.02735908901798378423e+00) (0, -3.41648757531084590333e-01) (1, -1.83009338165679880106e-01) (2, -2.20715981508651681864e-01) (3, -1.13653790737548790468e-01) (4, -1.10627439404884300722e-01) (5, 5.80482153704227066271e-01) (6, 1.26003888381621964587e-01) (7, 3.33130360511238965415e+00) (8, 3.44612088342965139365e-01) (9, -1.75664435825658549195e-01) (0, 3.60901225156981753095e-01) (1, 2.70472762704456193283e-01) (2, 3.06501647055709702805e-01) (3, 2.52643948019111552750e-01) (4, 3.18857995391452653244e-01) (5, -7.62974855470171103855e-02) (6, -3.95466542730485925983e-01) (7, 1.13979027933053913557e+01) (8, 2.66191470669530305670e-01) (9, 9.92302913330153774085e-02) (0, -3.82373282051055307651e-02) (1, -7.81022993087457113176e-03) (2, -1.11778500053879473186e-01) (3, 1.28741017246277456021e-02) (4, 8.97917660713507675974e-03) (5, 8.08366545896904570290e-02) (6, -1.51921852618460972995e-01) (7, -9.61636530010485657272e+00) (8, -6.59360632051494005568e-02) (9, -4.19790483886649523626e-02) (0, -5.59044931028815694773e-01) (1, -1.69200894023338266337e-01) (2, -1.74834106649318643534e-01) (3, -2.04755124236503549540e-01) (4, -1.90641236092010446512e-01) (5, 5.96026955654681778185e-01) (6, 7.06945515411407932049e-01) (7, 3.36450927821095380210e+00) (8, 4.55769643476069463706e-01) (9, -3.17637491724801823700e-01) (0, 6.46201065944610908431e-01) (1, 5.47149147586190487402e-01) (2, 6.30558375017010841468e-01) (3, 7.05508697525822792151e-01) (4, 6.16976249710881385901e-01) (5, 2.73990028803221430387e-01) (6, 1.29510908195988183600e+00) (7, -5.02495452884661997217e+00) (8, 5.82410297189824510689e-01) (9, 9.82765404642697903981e-01) (10, -2.19567829310768042328e-01) (11, -2.09048697292678747894e-01) (12, -1.86074552625291739227e-01) (13, -1.83500567018859778168e-01) (14, -1.69644747715174654124e-01) (15, 5.03148467211728789295e-01) (16, 4.95490030271450554444e-01) (17, -1.83049486517780218842e-01) (18, 5.55421934394841887439e-01) (19, -2.12398339848696687815e-01) (20, 4.14152317566315208985e-01) 
