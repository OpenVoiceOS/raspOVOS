FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.22705981602917102435e+00) (1, -1.26668230040039797579e-01) (2, -1.04101911528076906954e-01) (3, -2.19308682126965193149e-01) (4, -7.49933276009223659386e-02) (5, 1.93184252773442421969e-01) (6, 1.61301129600057685520e-01) (7, -1.41273288443276967552e-01) (8, 9.62578789614187413370e-01) (9, -1.73202408684250491744e-01) (0, -1.13800048287243993350e+00) (1, -1.35375708682503481661e-01) (2, -1.09914452178444643771e-01) (3, -1.59609131855931007937e-01) (4, -1.05324149472679873263e-01) (5, 2.02642135642231158155e-01) (6, 1.42167096001846154918e-01) (7, 4.73118016961265319686e-02) (8, 1.06616348149632078623e+00) (9, -1.09494508239464258259e-01) (0, 1.51213265098488286453e-01) (1, -9.92327886357782656956e-02) (2, -5.03760422304150995432e-02) (3, -1.01741272462892370920e-01) (4, 4.75565088257315082831e-02) (5, 7.33012393018110164356e-01) (6, 1.17841432924765920909e+00) (7, 2.66447903871126046127e-01) (8, -7.15335579241566232866e+00) (9, 2.70381547076854744649e-01) (0, 2.47081390656387817062e-01) (1, -5.03902037553323883801e-02) (2, -2.20952120534910409488e-02) (3, -1.41339612118734567203e-02) (4, -6.40763462705748205323e-03) (5, 7.69411295553548479909e-01) (6, 1.20582996739915548901e+00) (7, 1.66553419885127756972e-01) (8, -7.24783694024138025469e+00) (9, 1.69457484030256289032e-01) (0, -1.73463305133184455542e+01) (1, -2.19842066750107006934e-01) (2, -2.05236172065315386481e-01) (3, -2.59683293983516860770e-01) (4, -3.16159954056320413596e-01) (5, 3.02782283791250339533e+00) (6, 3.11979651933519896989e-01) (7, 1.03531431409005336697e-01) (8, 1.17089668000870172904e+00) (9, -4.85367629703129729868e-02) (0, 4.64836000512171487742e+00) (1, 4.72880641925736144859e-01) (2, 4.89074128675862029869e-01) (3, 4.96655884194775298912e-01) (4, 4.78784638452931121666e-01) (5, 1.08391029762679576010e+01) (6, 1.05198405229378337822e+01) (7, -1.51306676705950021722e-01) (8, -3.44915319303353795632e+00) (9, -1.52320200359570584459e-01) (0, 9.72519679733711117642e-01) (1, 3.96184601741669084607e-01) (2, 2.20323623078701430478e-01) (3, 3.69181760507461931287e-01) (4, 2.85530717032787650922e-01) (5, 1.00644665240779698223e+01) (6, 1.36460411876210718773e+00) (7, -3.00733497052363851765e-01) (8, -2.65196579467424786714e+00) (9, 4.02154158928450140842e-03) (0, -2.60303518011996271042e+00) (1, -7.29166123699805934777e-02) (2, -1.99895575983490614291e-01) (3, -2.53890835089649824496e-01) (4, -1.83894053442444471713e-01) (5, 2.14848946725049172457e-01) (6, 2.33100843718300032581e-01) (7, -3.16270291782577359085e-02) (8, 9.95881901405798131144e-01) (9, -1.01593071548504547408e-02) (0, 4.74376920471716623240e+00) (1, 5.06376376146674300749e-01) (2, 4.53656485075354831693e-01) (3, 4.55216636652350681302e-01) (4, 4.52623454625010746000e-01) (5, 1.15784467396050718691e+01) (6, 1.03572290458608264885e+01) (7, -6.06900623013828632857e-01) (8, -3.74510504138139843633e+00) (9, -3.92916263992287739804e-01) (0, 1.85371360815918401199e-01) (1, -2.03343865386976449527e-02) (2, -2.19024729840292184391e-02) (3, -1.34868484847082345524e-02) (4, -4.99297690503133911877e-02) (5, 8.68059679766996272754e-01) (6, 1.02870495849802789934e+00) (7, -8.10406827849818184317e-02) (8, -6.74959703787464437852e+00) (9, 2.17244345688352602508e-01) (10, 4.51570889574562095437e-01) (11, 5.08039748889480557992e-01) (12, -1.82374932368270403771e-01) (13, -2.69565095576481450479e-01) (14, 5.19763218893066203385e-01) (15, 4.54573500235137928360e-01) (16, 4.85015526046038258912e-01) (17, 4.29106959298852230766e-01) (18, 5.08707705218849337570e-01) (19, -2.60820107748966800720e-01) (20, 2.77498313298868926058e-01) 
