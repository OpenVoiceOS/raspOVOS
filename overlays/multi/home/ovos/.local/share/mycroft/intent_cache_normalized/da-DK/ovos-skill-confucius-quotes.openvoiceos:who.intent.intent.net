FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.34053970338104483373e-01) (1, 2.60195217012694046677e-01) (2, 3.13346988438894913376e-01) (3, 3.10117504476835892380e-01) (4, 2.99100941895773575485e-01) (5, -1.37282025207613012086e-01) (6, -1.72459151565165696995e-01) (7, 1.53120953390547178685e+01) (8, -5.09285844722660863138e-02) (9, 9.84912441578776609585e-03) (0, -3.99693660512917103844e-01) (1, -1.02908755930412598723e-01) (2, -1.29165898354996061537e-01) (3, -9.58686725220568858319e-02) (4, -8.21998522601016246014e-02) (5, 1.40344250384819985156e-01) (6, 5.57387800850992487511e-02) (7, 5.54170840010904974804e+00) (8, -7.75497090433785625507e-03) (9, 7.10986213722353266320e-02) (0, 9.92699416542931409313e-03) (1, 1.89295718077672397994e-01) (2, 2.30463375900042982680e-01) (3, 3.23137530688298757475e-01) (4, 2.85140806440366323393e-01) (5, -3.15260333675612847149e-01) (6, 1.01320742803347046967e-01) (7, 5.79178180261789687933e+00) (8, -9.80411217815374963491e-02) (9, 1.42473413782846891618e-01) (0, -3.46680462435238423424e-01) (1, -9.14351747355349742108e-02) (2, -2.20030120851744059873e-01) (3, -1.53398293348301267836e-01) (4, -9.83745411953814707928e-02) (5, 2.10813985768807860000e-01) (6, 1.64202439967644692187e-01) (7, 5.56583096609377570019e+00) (8, 4.49007483163004206261e-02) (9, -1.08583612403745383840e-02) (0, -3.09248983934872212487e-01) (1, -1.27537350448120451185e-01) (2, -8.35035995564349375897e-02) (3, -1.66359286101806974623e-01) (4, -1.48342470916260099623e-01) (5, 1.54160145107758522753e-01) (6, 4.90485163369303034386e-02) (7, 5.50146465525889105663e+00) (8, 7.12726581479361173677e-03) (9, 7.15570779481058405480e-02) (0, -5.23281820075434320194e-02) (1, 2.44309836629880372527e-01) (2, 2.91116313640130575102e-01) (3, 3.44548904899610097807e-01) (4, 1.93710865084184086227e-01) (5, -3.89437576491107384502e-01) (6, 1.04352138179075654145e-01) (7, 5.77775338008343108953e+00) (8, -4.90630269587047085356e-02) (9, 1.29254161554109986421e-01) (0, 2.31822985616822685451e-01) (1, 2.28358883201077528247e-01) (2, 2.51758597581580201297e-01) (3, 2.27099694102004118212e-01) (4, 3.50024148612216035037e-01) (5, -3.29932338666517055437e-01) (6, 2.64177188067629853396e-01) (7, -3.61808603331638956035e+00) (8, -3.43027125690449075091e-02) (9, 3.39341446547701874881e-01) (0, 4.70177280967723904004e-02) (1, -4.85336285764682712207e-02) (2, -3.00098982388484758488e-02) (3, 3.85776805942546971440e-02) (4, -1.39829362624357994571e-01) (5, -1.24966320257921226222e+00) (6, 2.30013477867138035893e-02) (7, 4.48057494038604353648e+00) (8, -9.05654270882118167529e-02) (9, -1.39607871764372643009e-01) (0, 1.64054060937164569722e-01) (1, 2.88000128149321243942e-01) (2, 1.95445499300291675171e-01) (3, 2.23163126885225909790e-01) (4, 2.58812553166678116501e-01) (5, -1.11719716478918096314e-01) (6, -1.37969445406527807529e-01) (7, 1.52895380506464384496e+01) (8, 1.13211997612389619894e-01) (9, -7.44805409106343019321e-03) (0, 8.95329365742189714483e-02) (1, 3.08748519896795914352e-01) (2, 2.44381091474821704468e-01) (3, 3.13566393136313126266e-01) (4, 1.66393811731865542969e-01) (5, -1.02188754965398809205e-01) (6, -2.17357099025578676121e-01) (7, 1.54180682996460340917e+01) (8, 7.06188456622035276578e-03) (9, 1.15717866285714204855e-01) (10, 2.31003655969431537232e-01) (11, 2.72210991911105426588e-01) (12, 1.11532062589457456325e-01) (13, 6.02434591758653881222e-01) (14, 2.58211827806643756666e-01) (15, 1.19125850796034757351e-01) (16, -2.48721208656782294399e-01) (17, 7.51485427935669469957e-02) (18, 3.02031702279379532516e-01) (19, 2.49408981680205005249e-01) (20, 1.58668032764723437866e-01) 
