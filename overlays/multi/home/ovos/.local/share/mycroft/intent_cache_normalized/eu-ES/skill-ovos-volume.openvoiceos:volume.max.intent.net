FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.83219583476328962135e-01) (1, 1.45746795691162091269e-02) (2, 1.18618896461635571493e-02) (3, 1.35790696598201733603e-02) (4, 1.44806462363114868408e-01) (5, 4.47626603512277856933e-02) (6, -2.14197773137024122247e-01) (7, -9.41367460902592489980e-01) (8, -1.37574487301058034916e-01) (9, 9.93856802858749388552e-02) (0, -6.48765429403131088648e-01) (1, 1.50731607896195420049e-02) (2, -3.39291289824141251152e-02) (3, -2.11548999327315252750e-02) (4, -4.49141607063902673080e-02) (5, 1.15662523574942666116e+00) (6, -2.42687829084345635389e-01) (7, 4.78283949626287396839e-01) (8, 6.20123062396224167259e-01) (9, -1.63072461876061058916e-01) (0, 1.10026773329963065140e-01) (1, -1.64353650915732785176e-01) (2, -6.36093438745645722854e-02) (3, -4.78998691917566499221e-02) (4, -7.84855977774767121780e-02) (5, 1.83954200504391507387e+00) (6, -6.87788633568612706171e+00) (7, 1.01637162261449143230e+00) (8, 7.76187099366958732638e-01) (9, -1.47996482208134050307e-01) (0, 9.84413020088273249542e-01) (1, 1.97995009434447788443e+00) (2, 2.02963601958976314066e+00) (3, 2.04594252419696376322e+00) (4, 2.01943697941527888773e+00) (5, 1.70629963533677582177e+01) (6, 1.20539372066732788369e+01) (7, 3.70215616424420579378e+00) (8, 1.85134207071757010965e+01) (9, -9.97277633738510527195e-01) (0, 8.00106615309643109946e-02) (1, -9.95908794619134174475e-02) (2, 7.05051638931919141297e-04) (3, 1.95060404323050273767e-02) (4, -1.36549834690242094526e-01) (5, 1.79959282634823636293e+00) (6, -6.91067970855561863885e+00) (7, 1.00120761983834549724e+00) (8, 7.76099946315021660403e-01) (9, -2.05793724164129609999e-01) (0, -2.82902192695986265392e+00) (1, -2.23893842800297199203e-01) (2, -2.86239481671490159087e-01) (3, -2.46628455026783321991e-01) (4, -2.81084745331444230132e-01) (5, 1.47282602114777239066e+00) (6, 1.54522325894335899044e+00) (7, 1.58497446225943083853e-01) (8, 1.45428597025672257104e+00) (9, -2.38316522549334081083e-01) (0, 5.41393865683533981326e-01) (1, 3.74564181874267876360e-02) (2, 1.35624844441883211921e-02) (3, 1.39244268448161234719e-01) (4, -2.45578327674940725608e-03) (5, -5.00394678247002705485e-02) (6, -1.80680758901765992075e-01) (7, -1.00123972680773398736e+00) (8, -2.03023538739835612832e-01) (9, 1.01988536389537851057e-01) (0, 1.79574262915021769516e+01) (1, 2.67472448370376203464e-01) (2, 4.46609946510711175449e-01) (3, 4.62176206133285027988e-01) (4, 4.58776714823165399082e-01) (5, -4.24180833360976272672e+00) (6, 1.44032052464101278932e-01) (7, -1.92961768506990538619e-01) (8, -6.71570871460318663537e+00) (9, 2.42366682220382961832e-01) (0, -4.93950942757469591005e-01) (1, -7.47618638788783429483e-02) (2, -2.97383778606974923109e-02) (3, -9.83881988441073496166e-02) (4, -1.63293954065951069099e-01) (5, 1.18830235374384995950e+00) (6, 2.58202702369993986053e-01) (7, 2.20070284157073164932e-01) (8, 5.74057854219931384954e-01) (9, -1.55314962233507380951e-01) (0, 1.80037235660321108810e+01) (1, 2.79745936768239666925e-01) (2, 3.83132391052430909539e-01) (3, 3.77783388273900788690e-01) (4, 4.48846385257428814874e-01) (5, -6.42734061353012720019e+00) (6, 2.30344894478789719017e+00) (7, -2.26855798492068411187e-01) (8, -6.53345927279583449376e+00) (9, 5.18281535740466536843e-01) (10, -2.08826866951118423482e-03) (11, 3.18905654787000947259e-01) (12, -2.60471947606168097167e-01) (13, 7.32494277268114668544e-01) (14, -4.18996599893282972715e-01) (15, 4.01379365647602570633e-01) (16, -5.16558197345863296529e-03) (17, -3.26441703486903989084e-01) (18, 3.51694533771567618974e-01) (19, -4.42503077635147235025e-01) (20, 5.56659013008438452452e-01) 
