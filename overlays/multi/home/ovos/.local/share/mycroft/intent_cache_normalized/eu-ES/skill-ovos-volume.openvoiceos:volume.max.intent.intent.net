FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.33103650560460939900e+00) (1, 8.20107733373945158029e-01) (2, 7.84289242242877993050e-01) (3, 9.44797267680471231088e-01) (4, 9.15571068888013761544e-01) (5, 5.35442951786755605426e-01) (6, 5.12765492006091818666e+01) (7, 4.76661519830702040679e+00) (8, 3.73604440407180371508e+00) (9, -1.22561565789986642860e-01) (0, 3.95271931382587737858e+00) (1, 7.23408960794486244339e-01) (2, 7.19061368202246864456e-01) (3, 6.52164951955355842728e-01) (4, 6.82429985200442512649e-01) (5, 6.21655629671481135823e-01) (6, 1.15315968232884813460e+01) (7, 4.76349581902502272612e+00) (8, 3.60996323297629118088e+00) (9, 1.39948276851119879360e-01) (0, -1.71514532215230675050e+00) (1, -1.02646467093839843798e-01) (2, -9.49753120583440857416e-02) (3, -1.21697579328432253787e-01) (4, -1.13190084737684656252e-02) (5, 8.02018692728124649172e-01) (6, 4.21304723909244316360e+00) (7, -8.36229188856172811484e+00) (8, 2.54577538581032802867e+00) (9, 1.66844908287125642810e-01) (0, -1.22730756122742583614e+01) (1, -3.56398498616171788278e-01) (2, -5.09167229733420434457e-01) (3, -4.85657868883562993112e-01) (4, -3.57023915252638768258e-01) (5, 5.90972664735286090654e-01) (6, 3.14060309624121414274e+00) (7, 1.51164850329687028285e+00) (8, 4.00340483668043489729e+00) (9, -3.10788986704393255245e-01) (0, 1.76772751423434537621e+00) (1, 4.90132121367972684034e-01) (2, 3.95419752224009768415e-01) (3, 5.21861156447451790541e-01) (4, 5.70196157320063790053e-01) (5, 3.12059711565233044439e+00) (6, 3.40350398718156643696e+00) (7, -3.77449075558729241209e+00) (8, 5.75647852238813761971e+00) (9, 1.27399634342883288918e-01) (0, 9.05227855308298606785e-02) (1, -5.09100985581861370521e-02) (2, -2.35575605983720792747e-02) (3, 4.99547924046529964737e-02) (4, -4.51754052991853519150e-02) (5, 4.61559794161420122727e-01) (6, 4.04130416947242032677e+00) (7, -8.43112965475050302189e+00) (8, 1.86788320709153921051e+00) (9, 1.65732938935357149157e-01) (0, -1.72487455667846556473e+00) (1, -1.77238244177972875670e-01) (2, -1.66933465363657079772e-01) (3, -1.35182398917352758483e-01) (4, -3.14305599393522427931e-01) (5, 1.20886668868194643855e-01) (6, 1.13331764787079958268e+00) (7, 8.74694438679501029554e-01) (8, 1.23374324279683222905e+00) (9, -3.00223551711750524795e-01) (0, 1.63371224945550324037e+01) (1, 8.71021273753868285894e-01) (2, 8.95989987275825683355e-01) (3, 8.47183953247295562505e-01) (4, 1.00758377762817019629e+00) (5, -1.00111916811132140026e+00) (6, -8.40237548481684903834e+00) (7, 3.12995338389428168213e-01) (8, -8.30243917466834524532e+00) (9, 9.31912145464663055350e-01) (0, -1.80841176273219939041e+00) (1, -1.11486380651533559250e-01) (2, -1.82936781749069687919e-01) (3, -8.65992062836288961636e-02) (4, -1.49720025911867615775e-01) (5, 9.66632518245087585251e-02) (6, 1.20708709458035334805e+00) (7, 4.54269263356731789472e-01) (8, 8.52600737447812173642e-01) (9, -3.92058774458932668416e-01) (0, 7.47304791371643239994e-02) (1, -3.21694204326080437917e-02) (2, -6.26936966295646713743e-02) (3, -2.70963499064850003861e-02) (4, -4.46000845845149970770e-02) (5, -7.91782865385735168395e-01) (6, 3.32628940930107086515e+00) (7, -9.45878718787513861344e+00) (8, 5.53068528777430667986e+00) (9, 8.20681234548160803977e-02) (10, 4.99546814237464387176e-01) (11, 4.80360686265362990532e-01) (12, -1.92747423190626959721e-01) (13, 4.77916308448181725854e-01) (14, 3.01059966656776645255e-01) (15, -2.42167274802550486212e-01) (16, 5.02115401806932593054e-01) (17, -4.65070094063930628003e-01) (18, 4.82292663361853890525e-01) (19, -1.28457116380480990125e-01) (20, 3.69655415578803936416e-01) 
