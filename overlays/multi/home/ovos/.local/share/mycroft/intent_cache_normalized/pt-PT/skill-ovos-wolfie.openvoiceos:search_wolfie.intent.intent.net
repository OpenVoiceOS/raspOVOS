FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.96641514768295238014e+01) (1, 5.83099856022001095113e-01) (2, 7.16924103888869956869e-01) (3, 5.91713163051009960469e-01) (4, 6.01932550761104412373e-01) (5, -5.35555410792105934803e+00) (6, 5.85660114253583330424e-01) (7, -4.83613046816196212596e-01) (8, -5.96358902076035946038e+00) (9, 8.34855937537377412738e-01) (0, -5.43360353585784161545e-01) (1, -2.77149753347217808752e-01) (2, -3.40123550668537610875e-01) (3, -1.64884099438965175954e-01) (4, -1.86190509870827081151e-01) (5, -9.48492538456174827388e+00) (6, -6.14566722789415376127e-01) (7, 1.52756569279599158095e-01) (8, 4.15708629782348104698e+00) (9, -1.47876820395434760425e-01) (0, -3.70107141622120106028e-01) (1, -9.58954296644426440466e-02) (2, -2.18727981262991449940e-01) (3, -1.99039091878721735585e-01) (4, -1.94961672240088007557e-01) (5, 1.77644296450674255006e+00) (6, -7.45320343791206763040e-02) (7, 5.49040657050584535170e+00) (8, 1.70242953140062880379e+00) (9, -1.02726832094716391541e-01) (0, -5.53341583487097943284e-01) (1, -2.50277614774312373580e-01) (2, -1.50102297397460310302e-01) (3, -1.43918166490401594482e-01) (4, -1.86912010045852033935e-01) (5, -9.23737878723330396724e+00) (6, -6.30415142133946448944e-01) (7, -3.82664847664983098774e-01) (8, 4.06614153827577151645e+00) (9, -2.05109704256620561935e-01) (0, 6.32070666909389955457e-01) (1, 5.57157824653821576177e-01) (2, 6.49458344001012322089e-01) (3, 6.76895419973569389960e-01) (4, 5.48108505922990429937e-01) (5, -3.13692521742124386108e+00) (6, 7.71944738824260623389e-01) (7, 1.96379105576375412312e+00) (8, 1.43788403110208418134e+00) (9, -7.11088040744761312739e-02) (0, 8.54477272960533107415e-01) (1, 6.91416374926830834546e-01) (2, 5.33112071042324719983e-01) (3, 6.11373789196278272229e-01) (4, 7.11446828727985924878e-01) (5, -3.69482328573212415179e+00) (6, 5.59025275322927783783e-01) (7, 2.17089976065924838977e+00) (8, 9.76884558581941453426e-01) (9, 5.78512588167719554733e-01) (0, 1.16774459500121285949e+00) (1, 5.44828490435828260985e-01) (2, 7.03938626765955866027e-01) (3, 7.26160892367114008117e-01) (4, 7.13116892695177972961e-01) (5, -3.41860639331422655474e+00) (6, 5.95960880184617347588e-01) (7, 1.83326238869151869615e+00) (8, 1.05283986941444163143e+00) (9, 8.96897965191359447523e-01) (0, 4.83270989189944089048e+00) (1, 4.92647887155186647856e-01) (2, 3.92010726913582796538e-01) (3, 4.42880303546559328520e-01) (4, 4.29060251399647707427e-01) (5, 1.17124339611675871708e+01) (6, 1.44756051273192909434e+00) (7, -5.18341888907470460524e-01) (8, -1.96055870680598420819e+00) (9, 8.42577501003848983174e-01) (0, -3.87880365164876506068e-01) (1, -2.04265130486707024993e-01) (2, -2.22210569110135314208e-01) (3, -2.20987884130696532470e-01) (4, -3.24724664714554689393e-01) (5, -3.40449044452318494436e-01) (6, -3.49366147268381499469e-01) (7, 1.38079701551628364342e+00) (8, 3.95683026095670564715e+00) (9, -8.24623682225657850253e-01) (0, -5.07757089863204780222e-01) (1, -3.27892062541955020549e-01) (2, -3.91712439534180612011e-01) (3, -2.70681117949002292278e-01) (4, -3.33559093353264779491e-01) (5, -1.66368585638585244624e+01) (6, -5.84636703192768725224e-01) (7, 6.44037094166937329476e-01) (8, 4.22769726063161233043e+00) (9, -1.29333640146797351766e-01) (10, -2.17447801799081963381e-01) (11, -4.24798156854393260673e-01) (12, -1.63742966975095632920e-01) (13, -3.80687040529603337724e-01) (14, -2.34076455177865988544e-01) (15, -1.83674007596574900836e-01) (16, -2.40607052983842856220e-01) (17, 4.75839492178314671378e-01) (18, 1.41012301306463605499e+00) (19, -4.18966840740921275810e-01) (20, 4.52722152023862733916e-01) 
