FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.06383752997308156374e+00) (1, 1.51788415177469521167e-01) (2, 1.36516058607702550631e-01) (3, 9.80677732962419584917e-02) (4, 5.69619925457289025261e-02) (5, 1.09372824519777533947e-01) (6, 3.87846275832549380880e-01) (7, -5.72063603799061702604e-03) (8, -2.00894256491066902637e-01) (0, 7.29683395903412246319e-01) (1, 1.55496042626110747564e-01) (2, 1.50345538215843843588e-01) (3, 2.99192767994610697713e-01) (4, 2.73683872478215184376e-01) (5, -2.49576043293646021581e+00) (6, 1.84716013538895573731e+00) (7, -1.19432271646557230937e-01) (8, 1.22801659696763976193e+00) (0, -2.19512018751094301061e-01) (1, -5.53676110969082702074e-02) (2, 4.76715738911467467459e-03) (3, -1.01266190157939653393e-01) (4, -1.23843762771894155827e-01) (5, -1.71283491473703169961e-01) (6, 2.89962578993649133796e-01) (7, 1.76450349672041040261e-01) (8, 1.69571928171768138149e-01) (0, 3.51597944339099033328e+00) (1, 1.62057991486304620032e-01) (2, 7.93800459916528394766e-02) (3, 1.33952315312140801673e-01) (4, 1.12218949359172190383e-01) (5, 7.55949242046678193674e+00) (6, -1.86842256490634239796e+00) (7, -1.41322506548069282140e+00) (8, 5.89867727189673285437e-01) (0, 4.17913654168172943315e+00) (1, 1.46367765303195562776e-01) (2, 1.27456530268729772981e-01) (3, 1.13650552268565796510e-01) (4, 1.11800304885448120729e-01) (5, 4.65676600963469056182e+00) (6, -2.04405761662355223152e+00) (7, -3.30080082757676085414e-01) (8, 1.20773219097037665115e+00) (0, 7.55891873419356929986e-01) (1, 1.18607225823135556397e-01) (2, 1.64963941085071591486e-01) (3, 2.80671874987812597357e-01) (4, 1.27172040748329245874e-01) (5, 2.05558133885364174853e-02) (6, 8.00263477763891728500e-01) (7, -5.23062177662756311314e-01) (8, -3.79847301425323746749e-01) (0, 1.94365813092732286904e+00) (1, 1.10847293524231046979e-01) (2, 1.87351911453689623510e-01) (3, 3.86056966466561402029e-02) (4, 1.90377785949195910131e-01) (5, 8.41852164989631890357e-01) (6, 1.59042992458350684881e-01) (7, 3.54853594074781494849e-02) (8, 1.41320918848462845352e-01) (0, -5.44142071776556490725e-01) (1, -5.69138395356732426644e-02) (2, 1.26376209092539330131e-02) (3, -1.28185396896560943603e-01) (4, -7.88403096365529187928e-02) (5, 4.60942191100704237727e-02) (6, 2.95605122308485512850e-01) (7, 1.95042133937029710244e-01) (8, -7.03743813207009238919e-02) (0, -1.42771215366449553130e+01) (1, -2.93480655721129579661e-01) (2, -3.21221037379206819651e-01) (3, -2.54805362394751711008e-01) (4, -1.95294609836043381312e-01) (5, 1.83210074249225995935e+00) (6, 2.54691482860157991652e+00) (7, 2.42377884405096066800e+00) (8, -8.57142485301082612814e-01) (0, 5.83303721274219739712e+01) (1, 3.31133352597766039693e+00) (2, 3.19217086216025469625e+00) (3, 3.18224022915177462423e+00) (4, 3.33363697310500262105e+00) (5, -2.84047771886532984809e+00) (6, -1.30046268308298662575e+00) (7, -2.59404346689007914151e-01) (8, -1.06159547414559494172e+01) (9, 1.15619865308938390980e-01) (10, 7.49888643806647520185e-02) (11, 3.72388021064485041922e-02) (12, 1.98057706960807516916e-01) (13, 1.92728315267218230922e-01) (14, 9.00518430780901102395e-02) (15, 1.58587632878431444849e-01) (16, 4.22006520678589236439e-01) (17, 1.23811623350614752326e+00) (18, 2.78855059387532078219e-01) (19, 4.28824953180728496438e-01) 
