FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.41034059693886559828e+00) (1, -2.90466610501837141367e-01) (2, -2.69389230917524702402e-01) (3, -2.86937575946878797861e-01) (4, -2.72565458129476911875e-01) (5, 1.60638138254909335068e+00) (6, 9.63309145674825728634e-01) (7, 1.77242377599820710721e+00) (8, 1.32280857931520245963e+00) (9, 5.93183986533356161219e-02) (0, 1.87076137216873128466e+00) (1, 6.05294391651814978061e-01) (2, 4.97199058671658977726e-01) (3, 4.96548541029160961369e-01) (4, 5.88407665630048315464e-01) (5, 8.42807746630812282262e+00) (6, -1.22758263349165552825e+00) (7, -5.30130219062954122222e+00) (8, -4.02121522836116129795e-01) (9, -2.72932301512455843806e-01) (0, -4.87375341157095937072e-02) (1, -9.93112480987652368469e-02) (2, -1.54399239157591794402e-01) (3, -1.08507931863222939484e-01) (4, -5.37756911267384188347e-02) (5, 9.12045414847793112223e-01) (6, -1.25127032895200634988e-01) (7, -5.16880724045569617253e-01) (8, -1.26120873528763288718e+00) (9, -1.67084098503442385342e-01) (0, 1.22627846804497728783e+01) (1, 4.66380111312973022475e-01) (2, 5.37139698302852464096e-01) (3, 4.62576969897853851332e-01) (4, 5.37515803611385178939e-01) (5, -6.53102584305452094071e+00) (6, -6.12424888477808071485e-01) (7, -5.96758920650097945959e-01) (8, -1.15019095959892214687e+00) (9, 5.83171636517816449619e-01) (0, -6.21946855384270191891e-01) (1, -7.27771452416523523254e-02) (2, -1.51624158655558505249e-01) (3, -1.85421243940745328338e-01) (4, -1.96843252216731046111e-01) (5, -3.70680371044272774506e-02) (6, -1.57650978922668244531e-01) (7, -5.94691942843730392276e-01) (8, -8.77377701155337530459e-01) (9, -2.49361403111627466522e-01) (0, 8.31427822493719048680e+00) (1, 5.40004356038748412061e-01) (2, 4.71653437447726142651e-01) (3, 4.25714621526181113964e-01) (4, 4.39133255016981971508e-01) (5, -4.46319595846274363993e+00) (6, -2.21524594466181090624e+00) (7, -9.79351635610767434770e-01) (8, -1.34965384386573061803e+00) (9, 8.52148278536560832563e-01) (0, -1.66641108448218489002e+00) (1, -1.61376915446446916880e-01) (2, -1.93830783984588223001e-01) (3, -1.89471393397973614237e-01) (4, -1.47136598399804557902e-01) (5, -9.46493129904880881043e-01) (6, -4.58943013134941957265e-01) (7, -5.67835309931216530854e-02) (8, -7.03531022910130476866e-01) (9, -2.98054419283082905334e-01) (0, -3.47122027447296899183e+00) (1, -3.01891759197544462534e-01) (2, -2.89394837032389051767e-01) (3, -1.85732539902757926020e-01) (4, -2.79676180492472059580e-01) (5, 1.54017375757722674301e+00) (6, 8.61644529686093951781e-01) (7, 1.75737753709897615018e+00) (8, 1.31363654207135938101e+00) (9, 1.34770102482091314045e-01) (0, -1.07356012592710770015e-01) (1, -1.13734968637381417267e-01) (2, -6.16545161952122347526e-02) (3, -2.06877336536799405486e-01) (4, -6.88364437569721765442e-02) (5, 7.81741562587680349772e-01) (6, -1.54092882324569663277e-01) (7, -4.99158631476695147100e-01) (8, -1.05768314320772605086e+00) (9, 2.45609070315782988814e-03) (0, 1.99130896480865438036e+00) (1, 4.76771106222894314186e-01) (2, 4.47364763567474010841e-01) (3, 5.62814098993566158669e-01) (4, 5.19511503378179195778e-01) (5, 9.07422421584376515113e+00) (6, -1.13039236089875649860e+00) (7, -4.52320032461543242164e+00) (8, -2.27164504380351361945e+00) (9, -2.21478066425805225625e-02) (10, 6.03552232422970735826e-01) (11, 4.29192838087783912204e-01) (12, -9.55645830188080469547e-02) (13, -1.74498748164581801712e-01) (14, -1.17765438242576805927e-01) (15, -2.93602305134867236358e-01) (16, -1.67462056480953247473e-01) (17, 5.94531877692519916678e-01) (18, -8.97570938620850244938e-02) (19, 4.56202556207882026218e-01) (20, 3.68611006550326858466e-01) 
