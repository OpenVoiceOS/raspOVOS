FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.90320578656503591741e-01) (1, 3.25241565012230685050e-02) (2, -1.54352460870813001925e-01) (3, -4.58297774887785822062e-02) (4, -1.09884214470456681445e-01) (5, -8.19648744507044391128e-02) (6, -3.74202394760670298268e+00) (7, -4.19927652253850702824e-01) (8, 9.33007630136858523429e+00) (9, -3.06403835338031504953e-01) (0, 2.89979553284098745536e-01) (1, 5.65731444399629634923e-01) (2, 6.51911281984124735267e-01) (3, 6.20632075708185015905e-01) (4, 6.99258060198102771032e-01) (5, 1.27273522230839697400e+00) (6, 2.24690567276598107682e+00) (7, 2.04630269505943251929e+00) (8, 9.48611310478000113733e+00) (9, -1.25765829244276439169e+00) (0, -4.59898225896320289596e-01) (1, -4.85313308588395830867e-01) (2, -5.39647181681524146235e-01) (3, -3.77245319239030596492e-01) (4, -3.79815799347291815913e-01) (5, -9.21032273846241644755e-01) (6, -1.28244438761404611071e+00) (7, -8.96587148394115462935e-01) (8, 8.57115994814267523338e+00) (9, -2.34071225514082548180e-01) (0, -9.67277410944898247136e-02) (1, 3.84153443634566299503e-02) (2, 3.20419538080748411701e-02) (3, 6.97218644678647692103e-02) (4, -4.47944533765260444191e-02) (5, 6.06750770395935307144e-02) (6, 5.84113429625556790370e-01) (7, 6.90846438123036976631e-02) (8, 4.38747169748992110749e-02) (9, -3.67321380939127972720e-01) (0, -1.33424906855235642089e-01) (1, -1.27409590633338551391e-02) (2, -7.70913927109664609549e-02) (3, -7.44366837890571286795e-02) (4, -1.23706244513553970110e-01) (5, -3.57153438737518452717e-02) (6, 2.77536388457509886063e-01) (7, 1.05558374247637865029e-01) (8, 4.59315681567009248543e-01) (9, -3.65413565385811212050e-01) (0, 1.43019083891689247068e+00) (1, 2.06819485729540258889e-01) (2, 2.52305593198145272638e-01) (3, 1.13642383223379592194e-01) (4, 1.89633410280550390725e-01) (5, 9.18695077551105221403e+00) (6, 1.50437148155474353928e+00) (7, 2.49416003413198827943e+00) (8, -5.44970985372437866090e+00) (9, 3.46025659955657774458e-02) (0, 2.39838947965986148958e-01) (1, -4.58642549507384950092e-02) (2, -6.40425838224655402664e-02) (3, 4.04752346947138529759e-03) (4, -5.14958545260196243198e-02) (5, -1.03317020938488435267e-01) (6, -2.41237080772700174247e-01) (7, -1.75359223747202364052e-01) (8, -5.68644080239447347047e-01) (9, 4.34100033043176347647e-01) (0, -9.12584290513466511729e-02) (1, 1.07713991228622855273e-02) (2, -2.68690234597640451031e-02) (3, -7.89599290665107395037e-02) (4, -8.31112137611823703631e-02) (5, -1.51086577867691751464e-01) (6, 1.68328902052519123467e-02) (7, -3.09000244409013413716e-02) (8, 1.47476757924044044046e+00) (9, -3.45056127186230077175e-01) (0, 5.59667772943690189358e-01) (1, 3.27006021159999438197e-01) (2, 1.97267496603839603830e-01) (3, 3.19841870683543749720e-01) (4, 3.50666412729137011439e-01) (5, -7.96442236274931547602e-02) (6, 1.90995333151475925604e+01) (7, 2.02930355758655256437e-01) (8, -6.48831905874488423791e+00) (9, 2.02482106501647662888e-01) (0, 1.44981015728858486646e+00) (1, 6.59440098231924953787e-01) (2, 6.13926993584526958792e-01) (3, 7.05833012139691073905e-01) (4, 7.70616250014198977958e-01) (5, 1.42716081249796089558e+00) (6, 1.52324376428674823636e+00) (7, 1.40375285064275256985e+00) (8, 1.89797480772477804578e+01) (9, -6.22297159036956509803e-02) (10, 7.17564550344502394275e-01) (11, -1.60432628947939692754e-01) (12, 4.12510455037927603605e-01) (13, 8.28072501908717728547e-01) (14, 4.53124171153637567144e-01) (15, 4.71933168500743682738e-01) (16, -1.32145387552132703712e-01) (17, 4.19641587340230604042e-01) (18, 7.34815663705231325586e-01) (19, -1.60242826194638615656e-01) (20, 3.01263942441783227899e-01) 
