FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.41682346763296713732e+01) (1, -1.27435144562078217501e-01) (2, -1.33088645119024018282e-01) (3, -1.24330122548890822931e-01) (4, -4.96854973619707401822e-02) (5, 4.21918864659646608573e+00) (6, -3.36656533315597417122e-02) (7, -1.63193700337447955562e-01) (8, 1.93410159985489471524e+00) (9, -5.19918266364782638567e-02) (10, -2.47878142792000133454e+00) (0, 7.84084427252302702982e+02) (1, 2.54984738363648801851e+02) (2, 2.54832088640655427980e+02) (3, 2.54945749177361875581e+02) (4, 2.54915148659373670625e+02) (5, -2.11735489346234146524e+02) (6, -1.52447920180435350090e+01) (7, 1.03046243372296708607e+00) (8, -4.95274388315854707798e+02) (9, 5.62284384979032991758e-01) (10, 1.85834927831426610645e+00) (0, -8.74694169709584201655e+00) (1, -1.96089032468636181861e-01) (2, -1.84873107251961432684e-01) (3, -1.99244144735176736960e-01) (4, -2.19707000431854954092e-01) (5, 8.45807229659725545723e-01) (6, 7.77537667608785021400e+00) (7, -1.20799466381177267316e+00) (8, 1.63960507204242000867e+00) (9, -1.17809146119203034253e+00) (10, -5.71729994959888632167e-01) (0, 3.54531404370631664236e+00) (1, 3.64144720284713119263e-02) (2, -5.89818231613856713835e-02) (3, 5.44613354055655668473e-02) (4, 8.80148165075553268188e-02) (5, -7.39138972205898081569e-01) (6, 7.70098287622422077447e+01) (7, 1.91293548038274652257e+00) (8, 8.86726193862411946611e+02) (9, 1.04623830643115312000e+00) (10, 1.36701016279398923636e+00) (0, 2.23910026900864300714e+00) (1, -2.40221350352369071579e-02) (2, -1.07158864931305469748e-01) (3, 8.69243190725242920180e-02) (4, 3.62565712173379961492e-02) (5, 5.20282278389613761505e+00) (6, -2.26506996470321588788e+01) (7, 4.70088876416450085483e-01) (8, 1.24735240833025358143e+01) (9, 5.66466056017798758049e-01) (10, 6.24926674995865960582e-01) (0, 4.66879212557826228647e+00) (1, 2.55830753309059022449e-01) (2, 1.75808366102504859407e-01) (3, 2.12066236597824003818e-01) (4, 1.94927740556526202242e-01) (5, -1.50664367127781750888e+00) (6, 7.70727986927121975214e+01) (7, 1.38406091520034491005e+00) (8, 8.86261101579056798982e+02) (9, 9.39180783476521563458e-01) (10, 9.96858479597568680752e-01) (0, 7.84127922236810263712e+02) (1, 2.54949419556881338167e+02) (2, 2.54897209039653688478e+02) (3, 2.54970627649451643038e+02) (4, 2.54965273468519598055e+02) (5, -2.11356190709778729797e+02) (6, -1.52531523555095365197e+01) (7, 2.20632427008078613184e+00) (8, -4.95333919110475221714e+02) (9, 5.28757860077643027097e-01) (10, 9.43405561229059053119e-01) (0, 7.84046233311186369974e+02) (1, 2.54955033316041379976e+02) (2, 2.54935893430138975191e+02) (3, 2.54955271421696096468e+02) (4, 2.54887639364923387575e+02) (5, -4.84262475927953687460e+02) (6, -1.52406984529967477471e+01) (7, 9.97223687497133304269e-01) (8, -4.95223560902057329258e+02) (9, 4.80861765457415157865e-01) (10, 2.19668264679370217607e+00) (0, -1.06596159754709862710e+01) (1, -1.27553055562633937958e-01) (2, -1.25398735084194551392e-01) (3, -1.82086529709953842682e-01) (4, -2.48729212709326380493e-01) (5, 3.76279541665972105946e+00) (6, 2.00774331901734104378e+00) (7, -1.44933624468046251543e-01) (8, 1.64054313479782454266e+00) (9, -8.13215003351849402558e-02) (10, -4.29028150424285925624e+00) (0, 1.44256894604794155157e+02) (1, 6.78148077106250113388e+00) (2, 6.59324092840922570957e+00) (3, 6.61942961489928460850e+00) (4, 6.63339913686884141697e+00) (5, -1.04510328833344168231e+01) (6, -1.52042247391815354973e+01) (7, -1.38424389942144934196e+01) (8, -1.04254331981419969821e+01) (9, -1.40161935045318877258e+01) (10, 5.34268458815949642826e-01) (11, 5.54572314050496562032e-01) (12, 4.81311477139339805031e-01) (13, 5.93002806096053602936e-01) (14, -1.99433218458614086588e-01) (15, -2.13404742002134190093e-01) (16, -2.29010075586993905317e-01) (17, 4.65290833097985745415e-01) (18, 4.59288705992206114370e-01) (19, 5.52429479144445512162e-01) (20, 4.60933038016119844826e-01) (21, 4.38122240373987559270e-01) 
