FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.88896266407894397599e-02) (1, -5.96166742496000018336e-02) (2, 6.04861932344926966909e-02) (3, -1.23380337422321864627e-01) (4, -4.25288719586835728403e-02) (5, 7.58454725214246394671e-01) (6, 1.86567220006932432685e-01) (7, -9.99984672454035603550e+01) (8, 4.94492462765649509748e-01) (9, 4.31400355779241073684e-01) (0, -1.52158446668931107704e-01) (1, -3.18262089272222381542e-02) (2, -1.05429996033391711052e-02) (3, -7.09720622976503373591e-02) (4, 6.47773485402384080478e-02) (5, 3.09803041713633708909e-01) (6, 1.33750339378416210900e-01) (7, 4.83535299398132210058e+01) (8, 2.07013733482185185997e-01) (9, 1.24254946936666693658e-01) (0, 1.24914099021763536079e-01) (1, -1.16051208739708464068e-01) (2, -4.16414035014615879771e-02) (3, -2.77900514654622898814e-02) (4, 4.70828818626894129995e-02) (5, 6.77268728681806209124e-01) (6, 3.95915915154527287001e-01) (7, -9.99688318607247197178e+01) (8, 4.98563936840966892561e-01) (9, 4.62315467082570541457e-01) (0, 7.34784945619155416274e-01) (1, 4.62603628954602608125e-01) (2, 4.34776675275279411714e-01) (3, 5.62099088302565941255e-01) (4, 4.63070348224355110567e-01) (5, -1.04543044323178777044e-01) (6, 4.80868847567738622040e-01) (7, -3.69542282796866849992e+00) (8, 3.41625213582218534292e-01) (9, 5.61151382495112205362e-01) (0, -2.22471237241574387733e-01) (1, -4.78353906651220184276e-02) (2, -2.80672494550428322513e-02) (3, 4.10103391627588825807e-02) (4, 1.61378493111517308002e-03) (5, 2.04638916151919536546e-01) (6, 7.97448804274198536080e-02) (7, 4.83667797915764694494e+01) (8, 2.11964659190002263633e-01) (9, 5.92854743495580607804e-02) (0, -1.27638334986986290431e-01) (1, -4.15252555390081268261e-02) (2, 1.10634755114832165901e-02) (3, 7.06315379361429351857e-02) (4, 5.45317422370233811924e-02) (5, 2.29500974612631969407e-01) (6, 3.28697516004011966451e-02) (7, 4.83034446001180057806e+01) (8, 2.16394208168807805626e-01) (9, 1.13440876235067558686e-01) (0, -1.04470293932033032880e-02) (1, 2.05936836548341953290e-02) (2, -1.05645318096111814898e-01) (3, -1.06162835424374144000e-01) (4, -3.95534006409154759165e-02) (5, 6.95370242067578914202e-01) (6, 2.04756009493817503486e-01) (7, -9.99090812888777577427e+01) (8, 5.45891082775071811994e-01) (9, 3.76267962985347259597e-01) (0, 2.47088056521210935879e-01) (1, 7.76785039429296886304e-02) (2, 1.67769423228942254900e-01) (3, 7.53008672122587596753e-02) (4, 3.91100854699244285251e-02) (5, 1.73716334820270157380e+00) (6, 1.74103021022126297490e-01) (7, 8.47010632647469119405e-01) (8, -1.97887499021761642526e-01) (9, 1.73503106210706303791e-01) (0, 5.41144439137477339941e-01) (1, 2.86317102422374236692e-01) (2, 3.83717715551513238736e-01) (3, 2.05908700635093339093e-01) (4, 2.77369871546882140745e-01) (5, -3.38552602444433387019e-02) (6, 2.18467410128545869163e-01) (7, -2.04004981177761335331e+00) (8, 3.24137939045924181047e-02) (9, 2.56488088390673329986e-01) (0, 2.24375946518092728166e-01) (1, 3.74860404651058548575e-02) (2, 5.84931871514213844176e-02) (3, 1.22201108805407271385e-01) (4, 5.51702654580963555708e-02) (5, -6.03659660540204701107e-01) (6, 1.80475373600812588615e-01) (7, 1.56081512984539955147e-01) (8, -2.19502208719352082111e-01) (9, 2.43465729339751218996e-01) (10, -1.59634166422522066897e-01) (11, 4.46292059280924358067e-01) (12, -2.46113042748907745461e-01) (13, -1.21824876259268063960e-01) (14, 5.62723608597131441655e-01) (15, 5.91799251376224577648e-01) (16, -2.19338515620420448915e-01) (17, 3.84538023515382659800e-02) (18, -4.46477710922795409387e-02) (19, -3.81407242012634251777e-03) (20, 2.64147118856012719235e-01) 
