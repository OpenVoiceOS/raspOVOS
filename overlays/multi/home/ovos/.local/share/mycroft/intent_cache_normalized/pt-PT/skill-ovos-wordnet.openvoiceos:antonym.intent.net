FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.04707500602743203144e-01) (1, -1.80757977622546320284e-02) (2, -7.43747838395633353858e-02) (3, -1.42032541888751032838e-02) (4, -1.25984121169427754072e-01) (5, 4.10623494517808385051e-01) (6, 2.78330593246630189630e-03) (7, -1.20234110283513218054e-01) (8, -1.30120568271409933203e+01) (9, -9.67956191480753291856e-02) (10, 1.71586996282365547017e+01) (11, -5.45852154249551815846e-02) (12, -4.60066851983184643693e-02) (0, 1.56720748405960619287e-01) (1, 3.55522961885167687601e-01) (2, 2.84487166971398919291e-01) (3, 2.24415247858001015713e-01) (4, 1.93521642655564513058e-01) (5, 2.38589784837527218997e+00) (6, -4.75771950853172281848e-02) (7, -8.61741716016914231779e-03) (8, 7.97221525377734785422e+00) (9, 2.18744400312449821522e-01) (10, -7.11076870139039218799e+00) (11, 5.67560846481146019649e-02) (12, 1.56958109107922183512e-01) (0, -1.47326852945332265055e-01) (1, -6.47432954761937018429e-02) (2, -6.94508405182316795878e-02) (3, -1.93320334121938053329e-01) (4, -8.33996685001806847826e-02) (5, -5.72913736207947943413e-01) (6, -2.05259532720591608701e-01) (7, -2.84996278152854554122e-01) (8, -6.28085629287708085977e-02) (9, -7.73368213387080755128e-02) (10, 3.05069471354792476347e+00) (11, -9.31773571303656789055e-02) (12, -7.56060667183883761133e-02) (0, -1.55865375838820069410e-01) (1, -2.06433479093990727982e-02) (2, -1.01092720439382693920e-01) (3, -1.80481510271974482373e-01) (4, -5.97104076647242826281e-02) (5, -8.40248024704566831566e-01) (6, -1.93939438609278619330e-01) (7, -1.81835463050835033361e-01) (8, 2.93221469683044688725e-01) (9, -1.26320921854334689005e-01) (10, 2.75960323957958353347e+00) (11, -1.88587993102027756676e-01) (12, -6.33944362900741575917e-02) (0, 4.19237750213155790924e-01) (1, 4.02233911813025701854e-01) (2, 5.25785183668856181960e-01) (3, 5.18355040014509715895e-01) (4, 5.14520278335337200026e-01) (5, 4.19664065546569375886e-01) (6, 7.32352568855562435779e-01) (7, 9.85653679315463104871e-01) (8, -5.02052688567767413375e-01) (9, 6.98189836597854829314e-01) (10, 1.28759675913976607831e+01) (11, 5.16197549221492302252e-01) (12, -3.86492120669786842768e+00) (0, 8.52948033036161901155e-02) (1, 2.56044287953581750639e-01) (2, 1.77668292794432747250e-01) (3, 2.32651483986582724439e-01) (4, 1.89347375903334724789e-01) (5, 4.66427284686445689510e-02) (6, 3.64546631274155819025e-01) (7, 5.56680362387011240521e-01) (8, 7.07495616607229305117e+00) (9, 3.18226866646088957236e-01) (10, -3.33290634182090350635e+00) (11, 2.49195142472807995571e-01) (12, -1.69539093007136210112e+00) (0, -1.34097127988818409783e+00) (1, 3.09386890574383066621e-01) (2, 4.86221675022530219756e-01) (3, 3.01801566227363926576e-01) (4, 4.55189604504990241729e-01) (5, 1.49950789592158548658e+03) (6, 2.56498115227785472570e+00) (7, 1.77879687908394118478e-01) (8, -1.64509439742528797979e+01) (9, 3.74838521741112595809e-01) (10, 7.70833185074798610259e+00) (11, 3.65910333373254514910e+00) (12, 1.70554659631775984430e+00) (0, 7.54761418948588919120e-02) (1, -6.22745230427655394045e-02) (2, -8.27605947485838683297e-02) (3, -9.19181331625853331735e-02) (4, 1.70940310129251010762e-02) (5, -2.81819406880499834234e-01) (6, 6.40533256353968960539e-02) (7, -5.18734344589463283737e-02) (8, -9.79522149366154692984e+00) (9, -1.13332944399855486961e-01) (10, 4.99892614155076397964e+00) (11, -3.11630382711547276875e-02) (12, -3.55532263859354852320e-02) (0, 1.40747610362727182398e+00) (1, 3.75835129998282224673e-01) (2, 3.45220165334299722293e-01) (3, 3.45566401265219369510e-01) (4, 3.09565762065008798221e-01) (5, 4.01618561570200860444e+00) (6, 1.04440577686134350444e+01) (7, 1.93742393259000195149e-01) (8, 4.58528023255911065803e+00) (9, 1.99073329099928586494e-01) (10, -3.36342767867347269828e+00) (11, 3.20769918756810212823e-01) (12, 1.65958857940718906843e-01) (0, -1.51838586489636107046e-01) (1, -1.17370921894232871363e-01) (2, -2.51803975328128148981e-01) (3, -2.55769777818839305628e-01) (4, -1.35769713445822892695e-01) (5, -1.56830108787840011297e-01) (6, -1.89703981160636830916e-01) (7, -1.40847279193174301781e-01) (8, 1.29347594957674716376e+00) (9, -3.97848373827563550620e-01) (10, 2.35780961123451104910e+00) (11, -1.11432764857684218907e-01) (12, -8.67154390063600011285e-02) (13, 5.90469122736852036759e-01) (14, 4.67717412498171225543e-01) (15, 4.42991354801173131683e-01) (16, 4.68998865522856633881e-01) (17, -2.62905399904503178643e-01) (18, 7.63663066718864191884e-01) (19, -7.04916814120898072016e-02) (20, -2.60810199497973072003e-01) (21, 1.08322798722093313617e-01) (22, 4.38654818151580194741e-01) (23, 2.72762780141457605865e-01) 
