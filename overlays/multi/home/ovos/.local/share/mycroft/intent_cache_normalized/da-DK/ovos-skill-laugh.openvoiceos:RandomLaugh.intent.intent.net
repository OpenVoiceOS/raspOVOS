FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.17741855991735366871e+00) (1, 8.67290533622854104001e-02) (2, 3.76203842004888613926e-02) (3, -1.57307051578409184955e-02) (4, 5.71336186966054995762e-02) (5, -1.20875181353184757427e-01) (6, -6.01278254306143677965e-01) (7, 1.50873088929951881809e-01) (8, -1.63790782979402943509e-01) (9, 4.18445832513900523031e-02) (10, 1.82573054281005592303e-01) (0, 1.37839854841642983629e+00) (1, 1.94088834239873025966e-01) (2, 1.59494507028493021084e-01) (3, 3.70037806171503655395e-02) (4, -8.92100022402706263613e-04) (5, -6.78731388952738989850e-01) (6, -3.49371378242112728962e-01) (7, -1.99818805033375235247e-01) (8, -2.44645526698503895657e-01) (9, -9.56941475638431460204e-03) (10, 5.10177501187896939583e-02) (0, 1.03783584572015752379e+00) (1, 4.43120337566488345371e-02) (2, 1.42409540256612822395e-02) (3, 1.45651575132285909797e-01) (4, 1.61950793071662740852e-01) (5, -8.45607535005541421924e-02) (6, -3.42744016020633313069e-01) (7, 4.32521083216146629002e-01) (8, 3.38002156445019741327e-02) (9, 1.56819342770490199879e-01) (10, 9.88239561310831626795e-03) (0, 3.36081457377769465822e+00) (1, 3.75122718211515771003e-01) (2, 3.08545455035074522865e-01) (3, 3.94154064055784569831e-01) (4, 2.74582221802576409431e-01) (5, -1.17847516241117489244e+00) (6, 6.86811086056574549019e+00) (7, 4.04959068614214867665e+00) (8, -1.43197854127144763581e+00) (9, -5.49543451348964651082e-01) (10, -3.94250442051584382153e-03) (0, -2.15325032903784796545e+00) (1, -1.41742864320547057311e-01) (2, -8.67977902987308175264e-02) (3, -1.66630690614254006743e-01) (4, -1.05681398580343186011e-01) (5, 9.62341790260120122369e-01) (6, 1.43674487988675658734e+00) (7, 4.26425290561480430096e-01) (8, 1.20657201222653309713e+00) (9, 1.05154845354567538784e+00) (10, -5.65216408145381432604e-01) (0, 2.37332798333735262020e+00) (1, 2.70557331170978077051e-01) (2, 3.60031785693110950586e-01) (3, 3.48445268597545154687e-01) (4, 3.13246170308532190241e-01) (5, -1.13876446934982311632e+00) (6, 6.79959491161450113594e+00) (7, 4.00828482377499550893e+00) (8, -1.35004351551985690705e+00) (9, -4.33249268511955221150e-01) (10, 1.05606144627365033939e-01) (0, 3.26508543880083079713e+00) (1, 3.47668654915197716804e-01) (2, 3.41268635984762480629e-01) (3, 2.83380575176580773444e-01) (4, 2.41241451051338595679e-01) (5, -1.15583386870666515733e+00) (6, 6.90016677496775354683e+00) (7, 3.99687288123339623525e+00) (8, -1.46918218846774051300e+00) (9, -4.56289533356849630330e-01) (10, 1.96398644109996661777e-01) (0, -1.48384952881762224308e+01) (1, -2.12544886615217976100e-01) (2, -3.24591016616762761959e-01) (3, -3.11744598891676549801e-01) (4, -3.41541560586632375607e-01) (5, 8.10676195363806861849e-01) (6, 3.10257790569433167249e+00) (7, 3.41880151202224036311e+00) (8, 1.33329560149449943829e+00) (9, 8.19006011971562974949e-01) (10, -1.37076585680125095923e-01) (0, 2.46275490688056741817e+00) (1, 2.34836094089434566090e-01) (2, 2.88364946850226511188e-01) (3, 1.59443229444907186299e-01) (4, 2.59892955430434224873e-01) (5, -1.17820712404891025926e+00) (6, 6.93000074742182459175e+00) (7, 4.76242046003553820555e+00) (8, -6.05902121396921233831e-01) (9, -3.98572552780334432576e-01) (10, 7.35220968330229790455e-02) (0, -2.09753103538388296911e+00) (1, -1.29703828185435909859e-01) (2, -1.25431888788577694527e-01) (3, -6.74175555404393084258e-02) (4, -4.07511839234513464914e-03) (5, 9.71095179380222051080e-01) (6, 2.25573698289251289850e+00) (7, 3.69951961470340262572e-01) (8, 1.30292365811343113791e+00) (9, 1.01708783445368777798e+00) (10, -4.61274958818785663084e-01) (11, -7.29916626611876312447e-02) (12, -2.07384051434015170834e-01) (13, -9.11382222572493655433e-02) (14, 4.20401914136878496198e-01) (15, 4.86871043555908600275e-01) (16, 3.76567764299384599713e-01) (17, 3.95386634486190324811e-01) (18, 7.75032574577351862644e-01) (19, 4.18467400687209611920e-01) (20, 5.16629116945438671138e-01) (21, 3.32970422109015729006e-01) 
