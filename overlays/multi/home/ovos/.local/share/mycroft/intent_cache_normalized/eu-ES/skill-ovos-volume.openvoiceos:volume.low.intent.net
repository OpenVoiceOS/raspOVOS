FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.76626504926082095182e+00) (1, -1.75492012951481812788e-01) (2, -7.33068828321580268081e-02) (3, -6.78255055881623603042e-02) (4, -1.58442223522770819777e-01) (5, 1.19848335060414412645e+00) (6, -2.44460409244732251866e-01) (7, 1.19535434129176665330e+00) (8, 1.03062468059855261160e+00) (9, 6.06195240284984171453e-01) (10, -1.84912627997893569409e-01) (0, 7.95420776502700155319e-01) (1, -1.59030796265751783736e-01) (2, 3.11454224823408398759e-02) (3, -2.23734539510316542132e-02) (4, -1.40120336091668074019e-01) (5, 1.53739276887876963329e+00) (6, -6.76707636423170377782e+00) (7, 3.19879259250706837747e+00) (8, 1.41164974581696633926e+00) (9, -7.61516047969228893066e+00) (10, -2.43823033555777418657e-01) (0, -1.20252575669874822717e-02) (1, -9.96484432602138398005e-02) (2, -1.41723771789094926676e-01) (3, -9.25474960589618561579e-02) (4, -4.59699232363910345600e-02) (5, 1.08317580345210151549e+00) (6, -2.25954508146480881337e-01) (7, 1.18787326734654019589e+00) (8, 7.22112963869233959180e-01) (9, 1.28846689180818962939e+00) (10, -1.32905466702449875926e-01) (0, 6.50142246714244809169e+00) (1, 5.95601998384204356363e-01) (2, 4.94688972945418858895e-01) (3, 5.41888445730414836099e-01) (4, 6.28147564943042246988e-01) (5, 1.32975654337109787662e+01) (6, 5.69686991107384166355e+00) (7, 5.20230353090524344495e-01) (8, 1.35035576485812143233e+01) (9, -2.59848255901695956993e+00) (10, 5.92768786589913110330e-03) (0, -2.78842801569100817716e+00) (1, -6.90261815525178290542e-02) (2, -1.75075175318825715376e-01) (3, -2.23261499855626099897e-01) (4, -1.12784797403920111769e-01) (5, 1.20914623412427046922e+00) (6, -2.63580841681198385640e-01) (7, 1.32319469448399895661e+00) (8, 9.90541915601579336936e-01) (9, 7.16766252185885965886e-01) (10, -2.36787204147262675402e-01) (0, 8.04837105778549499746e-01) (1, -6.65223242752883830997e-02) (2, -2.52178328149650667067e-02) (3, -1.10520867448363105390e-01) (4, -1.54708491676185770636e-02) (5, 1.06730472281372557042e+00) (6, -6.09044184845173663945e+00) (7, 3.25566073961204693887e+00) (8, 6.98720730082695529184e-01) (9, -5.79022469039978648908e+00) (10, -2.08298851534159501497e-01) (0, 1.13583144201583650101e+01) (1, 4.50885596182850789670e-01) (2, 3.68421091195849370603e-01) (3, 3.22496617641953364775e-01) (4, 4.36503107157257985715e-01) (5, -3.35311377742757255049e+00) (6, -6.96860081145407178616e-02) (7, -6.01674116833456729125e-01) (8, -1.75068204939411575793e+00) (9, -3.05713964878701838224e-01) (10, 3.22120199099698134582e-01) (0, 9.59666015563104712882e-01) (1, -1.29632902568728392012e-01) (2, -1.09946784800440719443e-01) (3, -4.27251767875261104224e-02) (4, -1.16207764721066406088e-01) (5, 7.91556515219548062490e-01) (6, -7.20012188624898907818e+00) (7, 3.14878253347820447061e+00) (8, 1.33337068387211443721e+00) (9, -6.64325732614950670296e+00) (10, -7.22862458135229285494e-02) (0, 1.14808526626474645127e+01) (1, 4.86170443203953583922e-01) (2, 3.50224221554306935911e-01) (3, 5.10933475997952246672e-01) (4, 3.41809364464787435178e-01) (5, -3.43705781368103213680e+00) (6, 1.68442481948270583736e+00) (7, -1.66795437592661999204e+00) (8, -1.07269923963107616238e+00) (9, -8.11040919449218966619e-01) (10, 3.44168390554669967329e-01) (0, 1.95687739991337359413e+01) (1, 5.71450743312071907098e-01) (2, 6.49764410639237621758e-01) (3, 6.87722421670388439630e-01) (4, 6.85081950807999828790e-01) (5, -6.05901440579375805129e+00) (6, -3.39265875974513519964e-01) (7, -8.49945087377110830573e+00) (8, -4.12794413060177500796e+00) (9, -1.06011868085736082890e+00) (10, 4.89356136811217090621e-01) (11, 3.74055300948804514416e-01) (12, -2.47458743432056593736e-01) (13, 3.35462385456332723432e-01) (14, 1.07188107750801098206e+00) (15, 4.11932104376739161022e-01) (16, -2.00419566345275079744e-01) (17, -5.57211135364655829605e-02) (18, -2.33289892354499955873e-01) (19, -9.36303384329240234729e-02) (20, -7.83933533045100938708e-01) (21, 5.39906076572881810094e-01) 
