FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.96712686325958996392e-02) (1, 1.13460407804340704385e-01) (2, 9.20927647758430084624e-02) (3, 1.50419906925053026292e-01) (4, 1.64869443725437547776e-01) (5, -8.73020681298486067590e+00) (6, 4.74995849420095872517e+00) (7, 2.32117483338661045877e+00) (8, 1.01369543206458390117e+00) (9, 4.77561256654601307137e-01) (0, 6.04175685729842815164e+00) (1, 4.02187640833447546118e-01) (2, 4.13220721351693132117e-01) (3, 4.58738233017514318579e-01) (4, 3.86534369605372518652e-01) (5, -2.42605104343185740134e+00) (6, -2.79873011656282066895e+00) (7, -9.74254281905312047307e-01) (8, -9.41845741525847435227e-01) (9, 7.54113476808694005449e-01) (0, 1.09595686790657143028e+00) (1, 7.60198849756829053703e-01) (2, 6.45895439703575657830e-01) (3, 7.60610315520874769035e-01) (4, 6.69151890595070408807e-01) (5, -3.84388056543301637191e+00) (6, 5.66499740654748773494e+00) (7, 2.99904513144680162640e+00) (8, 1.19253364339428613583e+00) (9, -6.73314080053516783586e-01) (0, 6.09784964855771693948e+00) (1, 3.66369682418892950171e-01) (2, 4.78178138899396143469e-01) (3, 4.69200800227711767310e-01) (4, 4.71463824677060217017e-01) (5, -2.40861453906784372947e+00) (6, -2.33331867934055070535e+00) (7, -1.00976104446949421778e+00) (8, -1.25873509605670830247e+00) (9, 9.42949938215549288145e-01) (0, 4.21363671657729310649e-02) (1, 2.20328841929056766513e-02) (2, 1.60904024970970366271e-01) (3, 1.77906294596634068084e-01) (4, 1.53790612948379729064e-01) (5, -9.11303794889822960101e+00) (6, 7.73165973964557906584e+00) (7, 2.13128334459986179539e+00) (8, 2.95927605864931475566e+00) (9, 1.48748853409892967115e-01) (0, -2.80238661621924922684e+00) (1, -2.43239309057994734786e-01) (2, -1.22819270357890850121e-01) (3, -1.97154241964622389816e-01) (4, -2.81285676524444416824e-01) (5, 2.58249812776665077507e+00) (6, -2.72943431536682323824e-01) (7, -3.53454119693604129626e-01) (8, 7.90730525481713186764e-02) (9, 6.89554088368850987001e-02) (0, 6.05282050754886302713e+00) (1, 3.54490613144696820047e-01) (2, 3.62963592213452923563e-01) (3, 3.42454729181588757303e-01) (4, 4.96710894209207276528e-01) (5, -1.45750109827004914465e+00) (6, -2.77527395285842537476e+00) (7, -9.22337198343891606633e-01) (8, -1.23288097043777367112e+00) (9, 7.22868654962209089554e-01) (0, 2.04480950963936009002e-01) (1, 1.16646479343482392665e-01) (2, 9.35221980264867858157e-02) (3, 1.81838821147986773319e-01) (4, 8.40003709247793273196e-02) (5, -1.06865860805261423394e+01) (6, 1.30167035681954357251e+00) (7, 3.42417045167395439620e+00) (8, 3.87717155292709891867e-01) (9, 5.45513804848855921037e-01) (0, 6.09740137692552242044e+00) (1, 3.86200404780696004980e-01) (2, 4.26965306567738622778e-01) (3, 4.11432239281724065894e-01) (4, 5.01312161850522297613e-01) (5, -2.38461979674059909584e+00) (6, -2.35183116675204972879e+00) (7, -9.02265766349453435247e-01) (8, -1.33252885003829857347e+00) (9, 9.30403473414714632383e-01) (0, 1.02529958483886796117e+00) (1, 7.47407082040421277824e-01) (2, 6.74912351687065648065e-01) (3, 7.42384243328682691399e-01) (4, 7.49028835017792493645e-01) (5, -3.86115907651018197555e+00) (6, 5.63895805204433298030e+00) (7, 2.62814024723702921449e+00) (8, 1.32523369178133654245e+00) (9, -6.11401076255288167260e-01) (10, -8.33696985251826810925e-02) (11, -2.17849414268439622866e-01) (12, 5.71532539282638918365e-01) (13, -1.51385762601796924898e-01) (14, -1.73976001102840102663e-02) (15, 7.97672980571082934631e-01) (16, -2.40312005797332139956e-01) (17, -1.07275962979309039125e-01) (18, -1.73621983140413105318e-01) (19, 4.97859559212524560579e-01) (20, 6.58769149812814425182e-01) 
