FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.89924889052706158399e-01) (1, 1.47331985580904767374e-01) (2, 1.37763026106341168742e-01) (3, 1.49373802292330548624e-01) (4, 1.03072429943068241687e-01) (5, 8.06978745574898681525e+00) (6, 9.63668722371541636162e-02) (7, 1.13975330060892048323e+01) (8, 8.73447062992122047476e-03) (9, 2.51094626522048391948e-01) (0, 1.00007680038870438999e+00) (1, 1.01048314183189200111e-01) (2, 7.74444762460726049413e-02) (3, 6.50342788390654014119e-02) (4, 1.20369353502227591224e-01) (5, -1.92618177336367324415e+00) (6, 1.99534449107915679011e-01) (7, -1.15283115334370078742e+00) (8, -1.14645509626836547556e-01) (9, 1.55722658454269219375e-01) (0, -6.55597455747894269917e-02) (1, -1.00458025260605127160e-01) (2, 3.14694239955766036365e-02) (3, -1.42578023745455029214e-01) (4, -1.09933886005319850221e-01) (5, 4.23630717955089330928e+00) (6, 1.45612103090711764164e-01) (7, 4.78483486493845955323e+00) (8, 6.23983880105441812702e-01) (9, 2.74433316922171988139e-01) (0, -1.27642527962522872587e-01) (1, 1.93333255994303510050e-01) (2, 9.98731282830073591184e-02) (3, 6.27313805103137250851e-02) (4, 1.43214913952334210734e-01) (5, 8.05600904489703140143e+00) (6, 1.67075050220915011234e-01) (7, 1.14714759952001514876e+01) (8, 9.50332584404017799429e-03) (9, 2.86113890147193350444e-01) (0, 5.84043575505624579236e-01) (1, 3.48862294854979104741e-01) (2, 3.64289258422712869390e-01) (3, 4.59659595789770669683e-01) (4, 3.77790280433754510625e-01) (5, -2.33015325679096063638e+00) (6, 1.96868003014095294123e-01) (7, -1.56879135110833689559e+00) (8, -6.93738311936804907809e-01) (9, 4.97184244758644422468e-02) (0, -1.72335245455103314161e-01) (1, -5.21386966842787569210e-02) (2, -6.26828030485289400264e-02) (3, -8.82549465436117952510e-02) (4, -3.25095311540739562162e-02) (5, 4.27362615428424597042e+00) (6, 2.74527144775816023259e-01) (7, 4.84481965323706642579e+00) (8, 5.73855263712829355427e-01) (9, 2.41478259003146566997e-01) (0, 2.99107926301784066148e-01) (1, 2.30240353784421064587e-01) (2, 3.37672704300740367245e-01) (3, 2.66381205460885228664e-01) (4, 2.93479570588925542385e-01) (5, -1.15701757226212920138e+00) (6, 2.70342451921561421901e-01) (7, -1.40202354075025370506e+00) (8, 1.67850847401083275168e-01) (9, 1.18923108453301273890e+00) (0, -1.38176225865679180860e-01) (1, 1.31499621665300853168e-01) (2, 1.81005779301943309223e-01) (3, 1.80758732950510508930e-01) (4, 5.60336891768593650665e-02) (5, 8.23855797762818298224e+00) (6, 1.43121351645418337650e-01) (7, 1.13198882034592571699e+01) (8, -3.59677910564038805230e-02) (9, 3.01934721207602896342e-01) (0, -2.12430008495645944455e-01) (1, 1.18308368074877517939e-01) (2, 8.96031958341433759641e-02) (3, 1.39197426784022137980e-01) (4, 1.92260610806925580363e-01) (5, 8.07185651923365554694e+00) (6, 1.77599136875101204502e-01) (7, 1.14986819690637531721e+01) (8, -6.54860600588414720757e-02) (9, 2.94421630239470877299e-01) (0, -1.51825361693697369336e-01) (1, 1.50269198167307660441e-01) (2, 1.78016456711275861124e-01) (3, 1.37048614501788339204e-02) (4, 1.92404898750765607218e-01) (5, 8.09980617652482948188e+00) (6, 1.57458816812463930912e-01) (7, 1.13564922428302708113e+01) (8, 1.23462958657970689469e-01) (9, 2.04398194587214920848e-01) (10, 2.83944152960464157864e-01) (11, -3.54409222466384177253e-01) (12, 4.40764639289579540637e-01) (13, 2.27789574036285025205e-01) (14, -1.66202847434915423896e-01) (15, 4.59637988121709972766e-01) (16, -2.13136958027677597682e-01) (17, 2.27855340311214071836e-01) (18, 3.12950097689315365201e-01) (19, 2.52840303549453360166e-01) (20, 2.14964228010161795268e-01) 
