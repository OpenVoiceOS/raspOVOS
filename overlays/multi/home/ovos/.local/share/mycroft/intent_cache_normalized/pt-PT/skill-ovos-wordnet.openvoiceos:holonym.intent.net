FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.88222835300157564919e-02) (1, 3.57294143520812734760e-01) (2, 3.63134422682742818989e-01) (3, 2.92717484169225439228e-01) (4, 4.13396285258750662006e-01) (5, 5.48398954086975809474e-01) (6, 3.60642538528714529100e-01) (7, 3.12780565061228421619e-01) (8, 1.50000000000000000000e+03) (9, 1.31240813399450872989e-01) (10, 4.68281120736500702795e-02) (11, 4.35117862427912671652e-01) (0, -1.00605453160078975317e-01) (1, 4.19089492571961375056e-01) (2, 4.39571496260773630915e-01) (3, 4.32270910752427073298e-01) (4, 2.74465669108044652003e-01) (5, 4.97535773777441736598e-01) (6, 8.47712789534342259223e-01) (7, 3.40550024677565899012e-01) (8, 1.50000000000000000000e+03) (9, 4.92822249304750437116e-01) (10, 6.15115681343599507436e-01) (11, 3.27107585151090785036e-01) (0, 4.31128269555282828129e-01) (1, -2.90514046314456597653e-01) (2, -4.40402837458350904232e-01) (3, -4.52155889931419030514e-01) (4, -3.77492832008102074948e-01) (5, -3.01308824092822502561e-01) (6, -3.16595018411765960487e-01) (7, -7.09563660957974295940e-01) (8, 1.97459522265171361077e+00) (9, -5.46223155220790901332e-01) (10, -7.94603094007527988030e-02) (11, -1.13383661904330648729e-01) (0, 7.44860759191295684900e-01) (1, -2.14058936213108279289e-02) (2, -1.45931721304508547205e-02) (3, -6.81258395885083190002e-02) (4, -5.94667649017298783481e-03) (5, 7.02015125291926833651e-02) (6, 1.49286335831570332600e-01) (7, 3.20426625709269274900e-01) (8, 3.75451122078889909517e+00) (9, 1.91982014983410470554e-01) (10, 6.68491017327019676486e+00) (11, -8.07751106436863375304e-02) (0, 1.18532782182105736468e-01) (1, -2.54619586337266334830e-02) (2, -1.16925002919500892196e-01) (3, -1.37574316846197697295e-01) (4, -4.41268402207551160843e-02) (5, 6.19365399458717547088e-02) (6, -8.47976081320994529156e-02) (7, -8.70798061973130227420e-02) (8, 5.25379116521494360370e+00) (9, 5.51122112045693626770e-03) (10, -3.10761991347009463027e+01) (11, -1.38880957502007795767e-01) (0, 5.49434584521690583259e-01) (1, -1.80381995557506030758e-01) (2, -2.09836822866161148982e-01) (3, -2.95537096379955011027e-01) (4, -3.10060963897664743083e-01) (5, 9.48905348118606467578e-02) (6, -1.60620702828050188060e-01) (7, 1.87839234035249824650e-01) (8, 1.50000000000000000000e+03) (9, 2.26743089568967409742e-01) (10, -1.81564152052975380514e+00) (11, -2.77268525740505977772e-01) (0, 1.50109069453712468123e-01) (1, 6.37835537571709076943e-01) (2, 7.16997069794933605813e-01) (3, 7.72980941016475964211e-01) (4, 6.39861085940401475014e-01) (5, -1.78751045704483724208e+00) (6, 2.04740256692995075127e+01) (7, 8.82402184291554481099e-01) (8, -3.97371935515092289393e+00) (9, 4.87581737501253387190e-01) (10, 1.07524421994414476345e+00) (11, 3.08471327618335644516e+00) (0, -2.06600414016073485879e-01) (1, 3.89754823001136785354e-01) (2, 3.77586937101593023147e-01) (3, 4.05264279397239690628e-01) (4, 2.87233057023992544021e-01) (5, 6.75127745830492731471e-01) (6, 4.43159523982248282348e-01) (7, 3.11803756828031408688e-01) (8, 1.50000000000000000000e+03) (9, 2.58249199355738090489e-01) (10, 5.27884997382436771396e-02) (11, 2.77520327500016705802e-01) (0, 3.28186086543322659281e+01) (1, 5.57482441280330309752e-01) (2, 5.22980233047450782102e-01) (3, 6.54812862489665525878e-01) (4, 6.48892839763606565917e-01) (5, -5.09182559614552276983e-01) (6, 1.74567703433713177219e+01) (7, 7.48151688233809508688e-01) (8, -3.02808342451872825052e+01) (9, 4.73239998633789349380e-01) (10, -1.46549032734046158488e+00) (11, 1.72696375147967806640e+00) (0, 1.17238508317580938933e-01) (1, 6.93433334607879925393e-01) (2, 5.90213221986095937233e-01) (3, 6.92120758373539257668e-01) (4, 7.43144494969646740579e-01) (5, -1.68020994020321756679e+00) (6, 2.04636295389164928338e+01) (7, 1.00804134724922267452e+00) (8, -3.94756996302293261536e+00) (9, 5.90011820358862126845e-01) (10, 7.27016994674757222050e-01) (11, 3.06104662984419029215e+00) (12, 4.44314493359897255687e-01) (13, 4.53555182707217841021e-01) (14, 5.98627825097448607039e-01) (15, -5.25915962024002148212e-01) (16, -1.03016619845018864154e+00) (17, 9.75135036965015689070e-01) (18, -2.43517476343985628251e-01) (19, 4.88449783217814959002e-01) (20, -2.96891700399423530410e-01) (21, -2.40045900666590761308e-01) (22, 4.27689382687009678197e-01) 
