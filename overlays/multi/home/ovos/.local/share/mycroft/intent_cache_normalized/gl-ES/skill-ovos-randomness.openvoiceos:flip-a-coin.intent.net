FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.37221036019766962077e-01) (1, -2.88980413579613792940e-01) (2, -3.30594573521286905216e-01) (3, -2.58653868341118808871e-01) (4, -2.45911497974068665728e-01) (5, 1.50912957494567651073e-01) (6, 1.33223817627349916393e+00) (7, 2.40147265987801628029e+00) (8, 6.20084541115462073435e-01) (9, -2.21480359973724949540e-01) (0, 6.85019406094532601337e-01) (1, 5.85657504742151724386e-01) (2, 7.12902297620779390463e-01) (3, 5.96312662010199057150e-01) (4, 6.71791849081522340903e-01) (5, 5.78846738990832720972e-01) (6, -3.37581360495170512692e+00) (7, -1.51803685015406197856e+00) (8, -1.25003745858828652082e+00) (9, 4.26911545480992593582e+00) (0, 5.67178156823814560994e-01) (1, 3.13050100798404840052e-01) (2, 2.03212803448236362103e-01) (3, 2.31485540265834704998e-01) (4, 2.60719055528438492519e-01) (5, 1.30717292232026882637e-01) (6, 5.40599949585933825524e-01) (7, -1.67035687266285748365e+00) (8, 1.09465683807783761949e+03) (9, 2.10088604076263785192e-01) (0, -3.38715642604077271649e-01) (1, -2.89563331187308592440e-01) (2, -4.07892744422495900913e-01) (3, -3.14006093323767832004e-01) (4, -3.18192127526343515598e-01) (5, 8.39572430778770528725e-02) (6, 1.14246601570850070395e+00) (7, 1.74479552835276296996e+00) (8, 1.75948464145685923299e+00) (9, -2.74510073238559804132e-01) (0, 4.95978613049686434255e-01) (1, 2.91894832844532048366e-01) (2, 2.16514656538761035565e-01) (3, 2.22245546276367084149e-01) (4, 3.31631103749073230524e-01) (5, 1.26418262524118252266e-01) (6, 4.97566066610355517419e-01) (7, -1.80328700242932216113e+00) (8, 1.09475510364376941652e+03) (9, 2.84232572598812460729e-01) (0, 4.10562914162015180075e-01) (1, 2.57763410205638809902e-01) (2, 3.02946562166011845729e-01) (3, 2.72361519033706644954e-01) (4, 3.30746257896221362849e-01) (5, -1.48911225090267440585e-04) (6, 5.56951425897617480310e-01) (7, -1.76868325023348704761e+00) (8, 1.09482672348224559755e+03) (9, 2.08100073917267203161e-01) (0, 6.74360113754253975848e-01) (1, 5.99029731209504756606e-01) (2, 6.44402906502711814163e-01) (3, 5.75339451636302623427e-01) (4, 7.49713540281283896682e-01) (5, -1.08347221439358917805e-01) (6, -4.52584721607391315956e+00) (7, -3.07444738237281178783e+00) (8, -3.49676682661608895231e+00) (9, 5.33925200249054299206e+00) (0, 4.98050656466817176504e-01) (1, 3.41073549836498124410e-01) (2, 3.10301430075984707724e-01) (3, 1.71116962581496750984e-01) (4, 2.04816404282670477821e-01) (5, 8.01521686739824074097e-02) (6, 9.41560642160730654204e-01) (7, -1.73561283497507901075e+00) (8, 1.09477409442865291567e+03) (9, 1.63733789526023604255e-01) (0, -4.47278221821061916508e-02) (1, -3.23552543490624594513e-02) (2, -3.33581546514725851837e-02) (3, -2.64508033364510702912e-02) (4, 8.15035870105528942320e-02) (5, 1.25467848993559533133e-01) (6, 3.17375633092470277319e+00) (7, -2.27710508725471522107e-01) (8, -1.65835523899052475372e+02) (9, -1.28692090839525648954e-02) (0, 5.16353514642417854574e-01) (1, 3.33417754275446620582e-01) (2, 2.40215841335897767328e-01) (3, 1.59768376154547114831e-01) (4, 1.53244834048395534021e-01) (5, 4.45218605823419349976e-02) (6, 5.17636801975507876428e-01) (7, -1.74506401567156643750e+00) (8, 1.09465349604540506334e+03) (9, 2.23594860120174765417e-01) (10, 7.42570882574122848041e-01) (11, -1.21885491753896096911e-01) (12, 2.45822760829938452565e-01) (13, 6.23093265888721936641e-01) (14, 3.03845231811960991841e-01) (15, 2.94170651206983158055e-01) (16, -1.25426931525548374102e-01) (17, 3.10156423220647459171e-01) (18, -2.00375606172838477415e-01) (19, 2.43725668261064093434e-01) (20, 1.94918944896020185364e-01) 
