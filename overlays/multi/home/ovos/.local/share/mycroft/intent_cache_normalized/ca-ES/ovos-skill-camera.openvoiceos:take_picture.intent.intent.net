FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.53499931396374500459e-01) (1, -9.87587027995153604598e-02) (2, -2.76546158639951605851e-02) (3, 7.31180257351831258683e-02) (4, -2.02210225908323187882e-02) (5, 2.38206667289243512187e+00) (6, 6.69251407192548053438e-01) (7, -9.21513261561305618841e+00) (8, 1.70475263241814278814e+00) (9, -1.31144630680383844634e-01) (0, 1.27816360966477859940e+00) (1, 4.30382779327311948414e-01) (2, 4.89458187011161116597e-01) (3, 3.98181474295535520191e-01) (4, 4.19036994216123059864e-01) (5, -1.60750231207792482202e+00) (6, -2.05302155768571426009e+00) (7, -5.00522408531173357282e-01) (8, -2.05795638184758011846e+00) (9, 8.08849619447773560132e-01) (0, 7.54077345898848006023e-01) (1, 4.18634721778714635754e-01) (2, 4.03614097975575902844e-01) (3, 2.42472843967759477124e-01) (4, 4.11862069510304906750e-01) (5, -3.62324220768748095356e-01) (6, 3.55586495088206433479e+00) (7, 1.10601503562548693083e+01) (8, 4.02585196059415326153e-02) (9, 3.02630978638815273385e-01) (0, 2.84022006974419838343e+00) (1, 3.52763532854918293591e-01) (2, 3.87094474591616444226e-01) (3, 3.95964949585799030896e-01) (4, 5.29393053807620139750e-01) (5, -1.28214604119356079259e+00) (6, -2.50434803792158122704e+00) (7, -2.68067682509994742457e-01) (8, -1.64040813353071368574e+00) (9, 8.66297015289443250730e-01) (0, -5.46262058942589057153e-01) (1, -1.35937379578569494942e-01) (2, -1.75835462192514474511e-01) (3, -2.46446067372777938287e-01) (4, -9.96250676908283366862e-02) (5, 1.56959302213035978291e+00) (6, 3.52542362791907537556e-01) (7, 7.78922544418067963612e-01) (8, 1.44269276165328030892e+00) (9, -5.19334011279687035589e-01) (0, 3.29118183554539367464e-01) (1, -7.14196094123884378524e-02) (2, 5.10063238458195299802e-03) (3, -3.70767989007993528650e-02) (4, -7.11902358381315408797e-02) (5, 1.83365630128045653535e+00) (6, 6.15181947754224078828e-01) (7, -8.36304158015835419349e+00) (8, 1.74934567231820725652e+00) (9, -2.68247536763367919188e-02) (0, 2.94361032084094587091e-01) (1, -6.23014954224784880954e-02) (2, 1.14150478194598378745e-01) (3, -1.41176742807586578371e-02) (4, -1.19536605969627306167e-02) (5, 3.23535260542415681329e+00) (6, 3.35582585697932644919e-01) (7, -9.50119054445460697877e+00) (8, 2.56736935586379644292e+00) (9, -1.54940047058783170186e-01) (0, -5.83961486370360161047e-01) (1, -4.90349729184187677067e-02) (2, -3.50825835589445994556e-02) (3, -1.33472730648902776496e-01) (4, -1.23238314513243654019e-02) (5, 1.54139556970440350092e+00) (6, 9.03438866141235696894e-02) (7, 7.97405117748470337879e-01) (8, 1.40155767031869915584e+00) (9, -4.54324374260862640096e-01) (0, 5.25786829430579527589e-01) (1, 2.88548310598151225292e-01) (2, 2.75570621093527812207e-01) (3, 3.06507696708457011425e-01) (4, 3.54983014365450877392e-01) (5, -1.56321432501093027234e+00) (6, -1.75310996128345242262e+00) (7, 1.10778693121293123625e+01) (8, -4.41978420808037342216e-01) (9, 1.71121408541430847228e-01) (0, 3.72408335390812639254e-01) (1, 3.85240250967824438000e-01) (2, 3.10907484732949657147e-01) (3, 4.13009101294362523937e-01) (4, 2.53427671037995683179e-01) (5, -1.55050007313505289197e+00) (6, 3.54919787334071301643e+00) (7, 1.08970078762987192533e+01) (8, -9.01866515416433756069e-02) (9, 3.41246809455772848185e-01) (10, -1.41827650518555559156e-01) (11, -1.91299325442491591209e-01) (12, 3.27789221015856946373e-01) (13, -2.05809669064441841391e-01) (14, 6.16447446367781148879e-01) (15, -1.33212694097563033591e-01) (16, -2.08522607484325564475e-02) (17, 6.33497291526216699253e-01) (18, 3.87771130802944063998e-01) (19, 3.08924268988059247398e-01) (20, 3.36432833100019146322e-01) 
