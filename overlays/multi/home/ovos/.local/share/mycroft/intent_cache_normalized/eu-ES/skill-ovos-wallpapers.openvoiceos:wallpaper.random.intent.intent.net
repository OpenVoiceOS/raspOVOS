FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.96453462267583311984e-01) (1, 4.06975412725227442268e-02) (2, 4.13453692554252710822e-02) (3, 1.57309491371990906039e-01) (4, 4.20171583055275049690e-02) (5, 3.88671020651482512775e-01) (6, 5.92877162176640104541e-01) (7, -3.33405996723898256917e-01) (8, 2.69221367681680812112e-01) (9, 3.63330878923361577648e-01) (10, 2.85594045979734589835e-01) (11, -1.45750973305721009954e-01) (0, 4.54992704185163632236e-01) (1, 1.65467381026062454463e-01) (2, 2.66607939745697519740e-01) (3, 2.00556545998367752315e-01) (4, 9.24319620387882845414e-02) (5, -3.63149016932822199522e-02) (6, 7.55860847771093080638e+00) (7, -1.09005506517412545375e-01) (8, -1.36292757440891476595e-01) (9, 5.48831646636310210852e+00) (10, -1.28000274137831659971e-02) (11, 5.00546406012413250264e-03) (0, 5.91425634157454638284e-01) (1, 3.11643259287166463078e-01) (2, 4.05374044239806941015e-01) (3, 2.47208194494533378682e-01) (4, 2.94359923959064295751e-01) (5, -3.39762835138848251493e-01) (6, -3.17288488052476225221e+00) (7, 1.29276570898501419471e-01) (8, -7.37366153614106845104e-02) (9, -2.49519092220640725799e+00) (10, -2.57618522578290043423e-01) (11, 1.59555661917018282159e-01) (0, 5.16333617361700247805e-01) (1, 2.38065073865674131648e-01) (2, 3.39964109140656556285e-01) (3, 2.89854961115143860972e-01) (4, 2.91452380496285523570e-01) (5, 6.92599073215149907412e-02) (6, 7.51714394777938554881e+00) (7, -1.47539391549351084354e-01) (8, -2.58803786684360714876e-01) (9, 5.39643999681058517126e+00) (10, 9.20333370729111699404e-02) (11, 8.77923891971671005452e-02) (0, 4.82038863094961300693e-01) (1, 2.76950384157918061412e-01) (2, 3.42027115303299988902e-01) (3, 2.92766871529839600719e-01) (4, 2.55813109356187007304e-01) (5, -2.55284875468588801084e-02) (6, 7.57208703994676302074e+00) (7, -1.95957693638326990726e-01) (8, -1.69297771502819272005e-01) (9, 5.42826771483007064489e+00) (10, -7.16147839860297175107e-02) (11, 1.73448995779120658522e-02) (0, 1.88830198906549329152e+00) (1, 3.77095544621801725960e-01) (2, 4.01797624215937010383e-01) (3, 4.68093873844004026985e-01) (4, 3.80686925635195128059e-01) (5, -6.30383000272213056547e-01) (6, -2.22953583188304804708e+00) (7, -2.65052966212531770918e-01) (8, -5.38504655907733886799e-01) (9, -2.24432731307992838765e+00) (10, -3.29953595434924806806e-01) (11, 3.67578143482852892632e-01) (0, 2.85641077858778957843e-01) (1, 3.58675645529539011136e-01) (2, 4.04447069256812952176e-01) (3, 3.89446517317802332059e-01) (4, 4.45661911606103799954e-01) (5, -3.14421421255502042680e-01) (6, -8.33926710572727603044e-01) (7, -1.57586866475890485795e-01) (8, -6.07750862356036397616e-02) (9, -8.46655155804642123307e-01) (10, -3.99425168150842058168e-02) (11, 6.74486385856522097093e-01) (0, 5.25963522585546683352e-01) (1, 2.87204342561982239879e-01) (2, 2.39803018647454374568e-01) (3, 3.03686516958497132457e-01) (4, 2.06018316227219638881e-01) (5, 1.34326547547005681338e-02) (6, 7.59534611344262788890e+00) (7, -1.65780934872152674320e-01) (8, -2.10467176486339779817e-01) (9, 5.50236754611316314367e+00) (10, 3.38648215099000005068e-02) (11, 1.16919681532200517293e-01) (0, -1.40425226114822598866e+00) (1, 2.48250748823958741762e-02) (2, -2.62400645900887144468e-02) (3, -9.86840862919014655263e-02) (4, 3.46469815682250298350e-02) (5, 1.02996629602677303161e+00) (6, 2.90019170007045223869e+00) (7, 2.93535348372936821804e-01) (8, 4.03963973623279293257e-01) (9, 2.07640853720973295182e+00) (10, 9.91004916984996708784e-01) (11, -1.32686092065063265810e-01) (0, 4.74781669768011227450e-01) (1, 2.77847992855332459605e-01) (2, 3.49095183092377747691e-01) (3, 2.70255962985776032603e-01) (4, 1.97972501295827024714e-01) (5, 8.31483408971451787295e-02) (6, 7.61709113955423067210e+00) (7, -1.70048448624136316898e-01) (8, 7.56708179021399196529e-02) (9, 5.38367189213815322546e+00) (10, 8.67438718839310674014e-02) (11, 1.65183380348499969648e-01) (12, 1.29277347341834769612e-01) (13, 2.07440237429799390068e-01) (14, -8.48511342148106750827e-01) (15, 1.54613594439687085380e-01) (16, 2.00354049828709912529e-01) (17, -5.88497495009013382727e-01) (18, -2.65927175141540753089e-02) (19, 4.00377471414270436068e-01) (20, 4.69628264472856271627e-01) (21, 4.07569636073770558138e-01) (22, 3.64625388189246446569e-01) 
