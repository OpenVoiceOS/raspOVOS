FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.10543398344186361015e+00) (1, -1.31307577331559177658e-01) (2, -1.03191142519013331902e-01) (3, -1.19490837295548366082e-01) (4, -7.34455339508218035816e-02) (5, 2.88258035697287140486e-01) (6, -6.08998911687356481170e-02) (7, 9.34001847477545638077e-02) (8, -2.50249852039153175554e-01) (9, 2.23433532914832477800e+00) (10, -4.62801876643353204965e-01) (0, 8.38058839565982793829e+00) (1, 5.44341679318584348302e-01) (2, 4.02142021461166287999e-01) (3, 4.24133546306527997594e-01) (4, 4.79526523156799222569e-01) (5, -8.09689228285388140627e-01) (6, -1.16648184199646109960e+00) (7, -6.33223594540835588163e+00) (8, -5.89356799080591908790e-01) (9, -1.92181784673688205167e+00) (10, 4.14890545610057337456e+00) (0, 1.11214861691467645222e-01) (1, 1.36422805838563865333e-01) (2, 1.45092070453145927100e-01) (3, 1.60710573546865409522e-01) (4, 1.53508112184980338721e-01) (5, -4.76254863753051482789e-01) (6, -6.48432956178112834822e-02) (7, -6.13279562715286274965e-01) (8, 1.09169348486782571972e-01) (9, 7.33798273897675379374e-01) (10, 1.44043675420431529360e-02) (0, -8.64966716027360527086e-01) (1, -6.73904245087382641755e-02) (2, -3.95636384674785193671e-02) (3, -1.74876195687937580070e-01) (4, -9.26243936011073437653e-02) (5, 5.58410467315537534239e-02) (6, -1.32069461128833026686e-01) (7, 2.62449117964857620011e-02) (8, -2.12525224702404785804e-01) (9, 2.60166011677635822252e+00) (10, -2.51409799569098590943e-01) (0, -1.45306073805228175289e+00) (1, -1.13425182340959621041e-01) (2, -1.28219956694463788072e-01) (3, -1.30671451030592022935e-01) (4, -1.10570388077119899362e-01) (5, 2.38315926792643656418e-01) (6, -1.31837591738365345062e-01) (7, 1.31580357191144442508e-01) (8, -2.83782974429661882798e-01) (9, 2.59829378916198416860e+00) (10, -6.78563630530134798136e-01) (0, -1.44941724767819346553e+00) (1, -2.40585324553810875337e-01) (2, -1.18219276158177163949e-01) (3, -1.50851612178646843354e-01) (4, -8.85989416521423267525e-02) (5, 6.74060107307310335534e-02) (6, -3.57788405542067367016e-01) (7, 3.64178198780065354168e-01) (8, -2.02423131869421846218e-01) (9, 3.15333083861280538684e+00) (10, -2.84780292862207518034e-01) (0, 4.29621191251470779804e+00) (1, 4.33419290868740147982e-01) (2, 5.51502887098293426149e-01) (3, 6.02103460518818023317e-01) (4, 5.45470748035411956423e-01) (5, 1.43950605978293522114e+00) (6, 2.08892502723850048696e+00) (7, -4.40802555267762308233e+00) (8, 2.93568579337099011539e+00) (9, 1.71827997154072846797e+01) (10, 1.40178323083517342162e+00) (0, -2.04214181271242845028e+00) (1, -1.30464486531874063191e-01) (2, -1.50860041134020211873e-01) (3, -1.96053620181938531575e-01) (4, -2.26636133842131021199e-01) (5, 6.31871274618813427715e-01) (6, 6.67432665546254022537e-01) (7, 5.64698518395558957117e-01) (8, -1.22944485417209703471e-01) (9, 2.19599815890250749106e+00) (10, -1.88424621348556087241e+00) (0, -1.52890659427181185848e+00) (1, -1.31703237233976422349e-01) (2, -9.53204503043690448694e-02) (3, -1.41498023806432782212e-01) (4, -6.05483075364628628434e-02) (5, 3.38977287363194379477e-01) (6, -2.33505092770717792572e-01) (7, 1.41703744170247530887e-01) (8, -1.25633268075035858802e-01) (9, 2.21702923974708010491e+00) (10, -5.99992164201093136633e-01) (0, 3.05598864270918957331e+00) (1, 1.29641985996989128616e+00) (2, 1.32419423117665169265e+00) (3, 1.33512014254359123733e+00) (4, 1.38661937519339439895e+00) (5, 2.06754477074705071971e+01) (6, -1.08250550356130492702e+00) (7, 1.60094933863706998523e+01) (8, 2.27620630657710432132e+00) (9, -1.20542530510024796797e+01) (10, 4.22752437070004899455e-02) (11, 2.96103437273331937529e-01) (12, -1.80578395632606136800e-01) (13, 7.09364559240959868802e-01) (14, 3.44700609175988492705e-01) (15, 3.09834596543141660430e-01) (16, 3.59492887584992704131e-01) (17, -1.60248347347968916887e-01) (18, 3.08604672064067553361e-01) (19, 3.30865987418719587065e-01) (20, 8.97380169751431977510e-01) (21, 6.77021429733689839026e-01) 
