FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.19697012997656904165e-02) (1, -2.30895219449917532550e-02) (2, -8.01925821309010800064e-02) (3, 4.51818318958361539450e-02) (4, -6.91379917864720361376e-02) (5, 1.54047104819240443518e+00) (6, 4.06272651841450074817e-02) (7, 3.16985296515103265325e-01) (8, 3.43909062679481236646e-01) (9, -1.70081854752375498663e+01) (10, -2.38839071058098498246e-02) (0, -2.46032659828289701487e-01) (1, -4.68738947484671139576e-02) (2, -5.70810858581243737997e-02) (3, -1.72971860734003723969e-01) (4, -9.63795755479513599484e-02) (5, 1.06100115564405417246e+00) (6, -1.10843886532373883669e-01) (7, 1.24818967380506504194e-01) (8, -7.09863262406317391262e-02) (9, 7.01668935676938421153e+00) (10, 5.45590588931826325769e-02) (0, 7.80319965790923486537e+00) (1, 4.53451034010280029651e-01) (2, 5.42345423580039454059e-01) (3, 5.31058360219825220661e-01) (4, 4.47733339250911133167e-01) (5, 6.30096024675685395522e+00) (6, 9.80992808207811983756e-01) (7, 8.97790245388363246093e+02) (8, 9.62033889504155026451e-01) (9, 2.59940375067702973411e+01) (10, 8.29720073346188802255e-01) (0, 2.19902388016388599112e+01) (1, 7.76411683755311221589e-01) (2, 6.88948133485707714385e-01) (3, 8.02351416545304507721e-01) (4, 6.84331738846692516631e-01) (5, -2.29057518961429540383e+00) (6, -6.77027834101975423131e-01) (7, -1.18467383979827936002e+01) (8, 4.82410477337197746150e-02) (9, -3.34935085993199210819e+00) (10, 6.41734341379642270198e+00) (0, -5.65922373057612171365e-01) (1, 2.53640977038871277827e-02) (2, 5.46074104799758666684e-02) (3, -5.02051743374336487125e-02) (4, 1.05133135367823746242e-01) (5, -3.96846390969164131146e-01) (6, -3.11625702162234563541e-01) (7, -6.60514860980176699012e-02) (8, -3.28207735233110656226e-02) (9, 1.06874230945840960061e+01) (10, -6.94349594813528508963e-02) (0, 2.30740239014366999015e+01) (1, 7.88423036208922400903e-01) (2, 7.52295468917662857322e-01) (3, 7.43867863884742019920e-01) (4, 7.28985306790644882469e-01) (5, -2.23648288041445031382e+00) (6, -4.79728650263625433503e-01) (7, -1.13886600160761375378e+01) (8, -8.54269506362466790605e-01) (9, -1.87543839590472227741e+00) (10, 5.17242706055121281850e+00) (0, 1.53844448262199975375e+01) (1, 6.61881758600012526372e-01) (2, 7.80931285351053716681e-01) (3, 7.92014374166265966437e-01) (4, 7.47511422961489202521e-01) (5, -2.57325700267828993972e+00) (6, 1.51248534984441573847e+00) (7, -5.08349119885170619426e+00) (8, 1.36530252090062509396e+00) (9, -1.49624449857003956055e+01) (10, 1.41915838371677427432e-01) (0, 1.75855033645728187075e-01) (1, -3.12725020651738044863e-02) (2, -4.34703728263298797008e-02) (3, -2.89812175636212261687e-02) (4, 8.11482580299456301987e-02) (5, 1.70658294959487788489e+00) (6, -1.02522759246745379103e-01) (7, 3.20379989651318475286e-01) (8, 3.68301667507362207044e-01) (9, -1.68644158235861674200e+01) (10, -1.18605418112165114652e-01) (0, 2.43021613787934409601e+00) (1, 1.30830855988183281102e-01) (2, 1.72815935634293815770e-01) (3, 1.30029359780469200292e-01) (4, 2.87490369700112546880e-01) (5, 4.30935836776682833715e+02) (6, 9.13999351138519671167e+01) (7, 7.97504996138243740234e+01) (8, 9.40678447992836481717e+01) (9, -6.99739440582705540805e+00) (10, 1.83756805807021006416e+00) (0, -4.91609924556025201792e-01) (1, 3.66864097609054459759e-02) (2, 5.87449265017043822934e-02) (3, -2.04657497511375845167e-02) (4, 3.37131736173164192616e-02) (5, -4.52597453898794355176e-01) (6, -3.82627246756999273014e-01) (7, 3.64638900635707238762e-02) (8, -5.26851836852830907043e-02) (9, 1.06924395555988436257e+01) (10, -5.83059825402441472830e-02) (11, -9.23723607513548816694e-02) (12, 2.13201785867051796242e-01) (13, 5.68654195433654918723e-01) (14, -4.39167482294076927385e-01) (15, 1.85551568781119169405e-01) (16, -5.09092626608842802050e-01) (17, -2.83357218690404644157e-01) (18, -4.86876918441082467970e-02) (19, 3.63994389451659738910e-01) (20, 1.53162926657323422708e-01) (21, 4.44310498491468530702e-01) 
