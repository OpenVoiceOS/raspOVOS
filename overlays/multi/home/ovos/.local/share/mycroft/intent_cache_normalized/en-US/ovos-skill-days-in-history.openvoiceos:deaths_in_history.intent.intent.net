FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.59963271934919104567e-02) (1, -3.99884250008423758338e-02) (2, 1.59439738846461724620e-02) (3, 4.74488954997698830773e-02) (4, 6.65466558194796192760e-02) (5, 1.94891562902218921927e-02) (6, 7.56625494119025461259e+02) (7, -2.51031243327504427487e-02) (8, -1.59161283444141203602e-02) (9, -1.66165746165896771602e-02) (10, -2.06380693355259908772e-02) (0, 1.40308567231082848004e+00) (1, 2.07720602303324369808e-01) (2, 3.19422731548131444423e-01) (3, 3.14280787854970433681e-01) (4, 2.71795699745000229886e-01) (5, 1.13668227582205932924e-01) (6, -5.57678232452946964770e+00) (7, 5.46809839390944674165e+01) (8, 2.04541309084930089668e+00) (9, 4.84368829299804190214e+02) (10, 2.45598942022106719874e-01) (0, 1.13761489328009601785e+00) (1, 2.98717847454902596382e-01) (2, 2.75303861487266376962e-01) (3, 1.83087261754626362542e-01) (4, 3.07596927869674630074e-01) (5, 3.54408604148377590071e-02) (6, -5.51615038344005625959e+00) (7, 5.46772223570179178864e+01) (8, 1.94223213436145791810e+00) (9, 4.84342179228660086210e+02) (10, 1.95182936807700629922e-01) (0, 6.66475722005502535517e-01) (1, 1.75863820002064374926e+00) (2, 1.68914925367221502306e+00) (3, 1.64969292715773252489e+00) (4, 1.65247627035364774706e+00) (5, -3.67295976947069968688e+00) (6, 7.23029951007425175646e+00) (7, -3.54020483567301891270e+00) (8, 5.18301518652671511234e+00) (9, -6.66696911353986454429e+00) (10, 1.18184868966831113646e+00) (0, 1.34983249777290059690e+00) (1, 2.75387188161393570152e-01) (2, 3.19458221758386173850e-01) (3, 1.56152000392455109212e-01) (4, 2.75079434479257034507e-01) (5, 1.70226250056168121327e-01) (6, -5.54017165862965921264e+00) (7, 5.47742871128749087006e+01) (8, 1.81829147285413306179e+00) (9, 4.84410575335022429044e+02) (10, 2.00557730559286162553e-01) (0, 7.53054948456873263218e-01) (1, 1.02260717529741018694e+00) (2, 1.00615060854640891996e+00) (3, 9.92595089263591745521e-01) (4, 1.00443149138179732560e+00) (5, -2.34713657475945858266e+00) (6, 2.36136556257775875878e+00) (7, -2.99950558055219884679e+00) (8, 5.60814313496377536694e+00) (9, -5.41676245994280947116e+00) (10, 1.15562553834816217346e+00) (0, 1.40213380802057807628e+00) (1, 2.61512288373150436627e-01) (2, 2.10637663971818406283e-01) (3, 2.54643203240073612292e-01) (4, 1.87378571849502045810e-01) (5, 7.05515450892173351383e-02) (6, -5.07140585879934668867e+00) (7, 5.43878836710338120497e+01) (8, 2.31657967961435939941e+00) (9, 2.22896721510097677310e+02) (10, -5.66675872700397528781e-02) (0, -1.04183807647315140876e+00) (1, -2.89729501913205622632e-01) (2, -3.67697510729447729627e-01) (3, -3.08200653503552857160e-01) (4, -2.84789856384412343182e-01) (5, -1.36352459175694828986e-01) (6, 8.68288021029064971401e+00) (7, -2.25142787207970185293e+00) (8, -1.67376053037124106204e+00) (9, 3.84591466193731079670e-02) (10, 5.08249310322854003230e-02) (0, 7.48233213727680368521e-01) (1, 8.53100804791444899955e-01) (2, 8.87480555281633498588e-01) (3, 8.89610754505390288749e-01) (4, 8.88152191594833495536e-01) (5, -1.46315200440218928790e+00) (6, 2.78292326059427619356e+00) (7, -1.94498949360670247977e+00) (8, 5.70442209121449028686e+00) (9, -5.37013620395741142488e+00) (10, 1.05025258062741233545e+00) (0, 1.48914320626280360926e+00) (1, 3.08183985760616341310e-01) (2, 1.98431967755958199584e-01) (3, 2.00506850144073128783e-01) (4, 2.34372931530877709472e-01) (5, 1.69835898333282664385e-01) (6, -5.57761595823386535642e+00) (7, 5.46356004633735850007e+01) (8, 2.05471945755596019367e+00) (9, 4.84371522066291788633e+02) (10, 2.66267768240500635191e-01) (11, 1.12639464082458573557e+00) (12, 3.07919223561685440060e-01) (13, 2.86393900170724746701e-01) (14, -2.17062828070556435023e-01) (15, 2.69874189749159942853e-01) (16, -1.56826413992067231762e-01) (17, 1.37924050577569762277e-01) (18, 8.47863790395375183095e-01) (19, -2.07416482620534942116e-01) (20, 3.08754105821054336545e-01) (21, 1.66405885558785299194e-01) 
