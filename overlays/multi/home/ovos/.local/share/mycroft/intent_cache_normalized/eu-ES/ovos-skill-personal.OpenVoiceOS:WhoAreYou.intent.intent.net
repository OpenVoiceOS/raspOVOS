FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.14105123867421243133e+00) (1, 2.85505935822801870660e-01) (2, 4.29008763556556926844e-01) (3, 4.12362780695038066980e-01) (4, 4.20932110672073589441e-01) (5, -1.98333578053796411034e+00) (6, 2.52628797606744992521e+00) (7, 1.32486863077586258797e+00) (8, 3.41829640988837779592e-01) (0, 2.46072178144226383356e-01) (1, -1.00888370749979083829e-01) (2, -1.12558423755197589688e-01) (3, -1.49035147604970913404e-01) (4, -1.44184003797798138136e-01) (5, -1.78801546559803381520e+00) (6, 1.88552083648726803711e-01) (7, 1.46196075116329060606e+00) (8, -9.25011071556025299412e-02) (0, 2.09834093441395852508e+00) (1, 3.73456187835885522475e-01) (2, 2.86938503674222411544e-01) (3, 2.33215347222043484221e-01) (4, 2.31471292964173763762e-01) (5, -1.49565116859220670342e+00) (6, 2.42044049309349285082e+00) (7, 7.80320906033251326939e-01) (8, 4.47790118660321312394e-01) (0, 9.85449456975603865772e+00) (1, 6.18448981743737191685e-01) (2, 6.10099630158825845250e-01) (3, 5.99001237851067513951e-01) (4, 5.99718669157906503209e-01) (5, -4.09231105870184475037e+00) (6, -5.59217275408054170782e+00) (7, 5.72008629732330353690e-01) (8, 2.57348513169343640072e+00) (0, 2.04021391113429162445e+00) (1, 3.36588982765751110193e-01) (2, 3.82102187995987163660e-01) (3, 4.23669856314735637781e-01) (4, 4.10014253382759319422e-01) (5, -1.95291754100406289574e+00) (6, 2.37828731344795452074e+00) (7, 1.32190999777024353889e+00) (8, 3.74603206254749521165e-01) (0, 4.96719951461751796362e-01) (1, 3.40116792372810727851e-01) (2, 2.01830559424507699484e-01) (3, 2.56728948108303434150e-01) (4, 2.78676190427887326972e-01) (5, -4.72336621139484424958e+00) (6, 3.60568939033630231350e+00) (7, 4.35547614973817864836e+00) (8, 2.58004994590109504315e-01) (0, 1.56962776588689867374e+00) (1, 5.61148816365319769162e-01) (2, 5.48596882838326971310e-01) (3, 5.57331928628999273556e-01) (4, 6.22505785543042478025e-01) (5, -4.49256315760490121392e+00) (6, -4.26144768113275329569e+00) (7, 7.39317520447983045351e-01) (8, 2.01536366072572770136e+00) (0, 2.76898977443139626686e-01) (1, -1.33345075460979456405e-01) (2, -1.20829236271688400528e-01) (3, 4.18832847206884566205e-03) (4, -5.29127200570792405321e-02) (5, -3.33159908758457135036e-01) (6, 7.38393827744595165896e-01) (7, 8.58725934860871231713e-01) (8, -5.95986758470957375677e-02) (0, -5.55092540672482703812e-01) (1, -6.05811249974734650214e-02) (2, -9.35522091153628831961e-02) (3, -1.87468882328606312182e-01) (4, -1.03294372237063170061e-01) (5, 6.52769256943200537613e-01) (6, 2.57537664517060393976e-01) (7, -3.48512405547814485551e-01) (8, 6.31016607597232742632e-02) (0, -8.13385937264862746154e-01) (1, -2.42499360167142574696e-01) (2, -2.88412549816724483875e-01) (3, -3.69106986843702133960e-01) (4, -2.19299205862638180164e-01) (5, 2.30980260198862641374e+00) (6, 3.14377908597453015194e-01) (7, 2.51376257727045360202e-01) (8, -1.89779574489090351042e-02) (9, 3.11481521952751749804e-01) (10, -2.96291986099240733932e-01) (11, 3.33363296096102545985e-01) (12, -3.65861170863684137533e-01) (13, 3.13633793596998999842e-01) (14, 3.75966507055217724620e-01) (15, -3.16818504758740793203e-01) (16, -1.36957859668928677577e-01) (17, 6.37657718017261121446e-01) (18, 6.86384259431849774735e-01) (19, 1.97767654065863357493e-01) 
