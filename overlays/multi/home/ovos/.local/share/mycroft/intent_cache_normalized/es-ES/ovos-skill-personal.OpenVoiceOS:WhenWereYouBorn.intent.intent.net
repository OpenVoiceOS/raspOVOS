FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.16592655204647819289e+01) (1, 4.60429652425845215014e-01) (2, 3.57754415664275238207e-01) (3, 4.12497429940302917650e-01) (4, 4.15234221908648559740e-01) (5, -4.16369403979149232953e+00) (6, -2.14683794537459737839e+00) (7, -8.26050104274441920893e-01) (8, -7.45425680117915878675e-01) (9, 4.69912976783010971626e-01) (0, 1.16833394714111129531e+01) (1, 3.88456308560026108978e-01) (2, 3.68935925231826722381e-01) (3, 3.91434350328100144623e-01) (4, 5.12047664539468261324e-01) (5, -3.83234343072222705118e+00) (6, -2.12000566283141500534e+00) (7, -9.33935015581085936631e-01) (8, -8.96392772473284971113e-01) (9, 5.58266426191555420466e-01) (0, 1.33625649084965791857e+00) (1, 2.53603985935112852257e-01) (2, 1.58652434527537300468e-01) (3, 2.79090485006234234611e-01) (4, 2.95823043614289349357e-01) (5, -5.74505013704609712732e+00) (6, 9.99041736754140430321e+00) (7, 4.41278623641627909535e+00) (8, 2.20496779112664889055e+01) (9, 3.67845779394197769374e-01) (0, -2.91842973015755513533e-01) (1, -9.59804638915116338505e-03) (2, -8.04480536251550304438e-02) (3, -1.17237992432642545992e-01) (4, -8.73871146111970531489e-02) (5, 7.11064527631808163122e-01) (6, 4.80705318329514186271e-01) (7, 7.96526133878789205367e-02) (8, 3.90613112505670323493e-01) (9, 2.29904283483258337073e-01) (0, 2.85770636998713301047e-01) (1, 9.06959374854155592205e-02) (2, 6.12341550597735456707e-02) (3, 1.69565656543690823632e-01) (4, 1.68973991037327908593e-01) (5, -1.31746257970574709439e+00) (6, -2.74593478291073223030e-01) (7, 2.08487780207897460683e-01) (8, -7.31328215774557088835e-01) (9, 1.53696608848655907886e-01) (0, 1.21574028005520906603e+00) (1, 2.60358646786554626118e-01) (2, 1.57257296419485187444e-01) (3, 1.57316968119485950384e-01) (4, 2.41725147045000171575e-01) (5, -4.10914980730506229634e+00) (6, 9.98128750058373981346e+00) (7, 4.44742393345731379384e+00) (8, 2.21738825319854448992e+01) (9, 4.53786073361921560299e-01) (0, -1.85803963647165282236e-01) (1, -2.78239829667582729694e-03) (2, -7.34714997626786979826e-05) (3, -4.54899383915282826130e-02) (4, 1.30372183190964226196e-02) (5, 8.58163317267121028564e-01) (6, 4.86521309444331306882e-01) (7, -2.34870708818294832154e-01) (8, 3.81550498043069508114e-01) (9, 2.27740694482556432776e-01) (0, 2.63777249715207218195e-01) (1, 2.21177505811090135968e-01) (2, 1.62375526984567281064e-01) (3, 3.08928484578961992657e-01) (4, 3.56275791784162076947e-01) (5, -2.60279167943971367905e+00) (6, -4.78016813181918354125e-01) (7, -1.43902428957584288538e-01) (8, -5.94558802071146197399e-01) (9, 6.69081651740988103683e-02) (0, 5.56586945583890380096e-02) (1, 1.46524139205128051122e-01) (2, 2.28506014207512236913e-01) (3, 2.12253988245636265875e-01) (4, 2.12554246643692296148e-01) (5, 9.23209103428703414806e+00) (6, -2.77193960227434610388e+00) (7, -5.25626714038399667217e-01) (8, -3.18559104951992910770e+00) (9, -8.95492952192976643389e-02) (0, 2.07329676340649776689e-01) (1, 1.31641964048613363536e-01) (2, 1.53770061761606957607e-01) (3, 2.72116507024038944973e-01) (4, 1.78091781765688683681e-01) (5, -9.78279303000978539551e-01) (6, 1.60848259765143075661e+00) (7, 1.09400939279761866274e+00) (8, 1.00470878149088083120e+00) (9, 1.84298520580059160823e-01) (10, -3.74070464925648216159e-01) (11, -3.67556452112080156436e-01) (12, 2.98832606237975695329e-01) (13, 5.96607564199763573676e-01) (14, -6.92101254576424629317e-02) (15, 2.98264603775588610368e-01) (16, 5.85253093246677735806e-01) (17, -9.14673044794777900801e-02) (18, 2.94263824354333125566e-01) (19, 2.25714515224424455697e-01) (20, 1.39091017988078297085e-01) 
