FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.94452987600763749221e+00) (1, -1.47043895289354642486e+00) (2, -6.40881550553509482526e-01) (3, -6.03597872187834449953e-01) (4, -1.24937159932909525040e+00) (5, -7.17910259529689231961e-01) (6, -7.68004812677744674865e-01) (7, 4.08563912887956459663e-01) (8, -8.44822569670685585841e-01) (9, -1.94084528501969932890e+00) (10, 2.23198861891824390513e-01) (11, -3.39243533838261002167e-01) (12, -7.21057252892430833313e-01) (13, -3.89161332512768132208e-01) (14, -7.92107268037076983624e-01) (15, -7.36956159681081524049e-01) (16, -5.29788065533814633845e-01) (17, -8.18284446356688510704e-01) (18, -1.01760034033008683885e+00) (19, -6.67392606607368543692e-01) (20, -2.30835079992254179615e+01) (21, 2.29248550977628120506e+01) (22, -2.32229353630979460377e+01) (23, 1.41204731718033382748e+00) (0, -3.16860376742420823959e+00) (1, 1.38632122004476654453e+00) (2, 1.52035194682517582621e+00) (3, 5.87776785437205795404e-01) (4, 2.14101672979581891809e+00) (5, 1.40327714300687822480e+00) (6, 1.94735085528501850050e+00) (7, -3.60369481653436893320e-02) (8, -3.33050908140135326629e-01) (9, -9.70110308746677252323e-01) (10, -6.38830364469812894690e-02) (11, 6.44871997364938387420e-01) (12, 8.73700646653775114814e-01) (13, 5.89108123562270047380e-01) (14, 2.14286640220108193233e+00) (15, 1.45024600211765308799e+00) (16, 4.89395616449587178565e-01) (17, 1.39245519196103262338e+00) (18, 1.79550463930444648142e+00) (19, 8.82224292657631359305e-01) (20, 1.44465823617183605165e+03) (21, 1.44469371212624946565e+03) (22, 1.44478914644920268984e+03) (23, -9.48342537569723975643e-01) (0, -8.89010073618407559159e-01) (1, 4.49576523484805201658e-01) (2, 2.89490071040324481455e-01) (3, 1.99155109241288053035e+00) (4, 4.36410531502992082853e-01) (5, 5.62994173137698283860e-01) (6, 1.04139440372253622158e+00) (7, -1.99968257126478421437e-01) (8, 6.38625560615863729907e-01) (9, 4.42707633078339657384e-01) (10, 4.27729901694843372972e-01) (11, 4.74418567301911842105e-01) (12, 1.90328123577603591787e-01) (13, 7.36815610872185944302e-01) (14, 5.02106631925417823403e-01) (15, 3.05328983808622222984e-01) (16, 1.03383746660931463701e+00) (17, 2.39795786265432353535e-01) (18, 4.32070111938334278090e-01) (19, 1.33268691787378101843e+00) (20, 9.64573136736881451725e+02) (21, 9.64453288582396226047e+02) (22, 9.64475017366242127537e+02) (23, -3.02456734982716690663e-01) (24, -1.80242123296985852221e+01) (25, 2.31274182510564152437e+01) (26, 7.94674405580622411627e-01) (27, -7.50126023115049500589e-01) 
