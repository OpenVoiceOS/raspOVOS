FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.82039117309456899285e-02) (1, -5.93823751363576693429e-02) (2, -1.22773904160004956876e-01) (3, -6.67064299735845023243e-02) (4, -2.28947270468217251027e-01) (5, -4.26252449943024303014e-01) (6, 1.93851003241796568943e+01) (7, 5.29077925663566039916e-01) (0, -3.48053265831715386014e+00) (1, -2.04209747875572555920e-01) (2, -1.70205357635857035259e-01) (3, -2.35594685340763443371e-01) (4, -2.39133264089466446300e-01) (5, 1.05465542880440854567e+00) (6, 2.30391281727768726384e+00) (7, -3.16806024271202968379e-01) (0, 1.05051620132763208204e+01) (1, 5.10392418165035333111e-01) (2, 5.75435480136699872844e-01) (3, 3.99203991551227488355e-01) (4, 5.13333952088184441997e-01) (5, -4.65356455553553427507e+00) (6, -2.31040033929785648681e+00) (7, 5.20049692455538337121e-01) (0, 3.15007104561612294447e+00) (1, 4.74664036210526496529e-01) (2, 4.71180964287270576119e-01) (3, 3.19021221276272803902e-01) (4, 4.19674549277771979927e-01) (5, 7.11372782004350145968e+00) (6, -2.46777779054123813651e+00) (7, -1.43274317206337570285e-01) (0, 1.32495733151138550543e-01) (1, 1.11092785943035926577e-01) (2, 8.41416889910744092429e-02) (3, 5.55031137650058709054e-02) (4, 9.12690708522842786277e-02) (5, 2.46127821490176479369e-01) (6, 9.07771974715803064981e-01) (7, 1.96513035464429219878e-01) (0, 1.48008501330316732947e-01) (1, 5.38125993793056450754e-02) (2, 1.49715083289627792773e-01) (3, 1.23727636981491889712e-01) (4, 5.40844934170291863351e-02) (5, 2.22279593333609859496e-01) (6, 9.86822761509035029093e-01) (7, 2.41385237736136515352e-01) (0, 5.47015306542335633111e+00) (1, 2.64532689301931134285e-01) (2, 1.73983890860044287940e-01) (3, 2.67149705736600628914e-01) (4, 2.72713367192708777687e-01) (5, -2.98685343224662869233e+00) (6, -1.30438653521411640490e+00) (7, 1.33862952870611051637e+00) (0, 3.02231519133732007276e+00) (1, 4.31289564551574022833e-01) (2, 4.44296892465811998907e-01) (3, 4.29499339045745165411e-01) (4, 4.69452064217788012090e-01) (5, 6.27384777601107046507e+00) (6, -2.59885151129443103812e+00) (7, 8.71563640813766832283e-02) (0, 2.39751242806354125658e-01) (1, 1.27518380630497779604e-01) (2, 7.24347928648041150534e-02) (3, 1.30392375040535690722e-01) (4, 6.31232584004447899728e-02) (5, 2.71499328300364772826e-01) (6, 9.19873873003907105428e-01) (7, 4.14015771896284023867e-01) (0, 5.12610186791232769199e-02) (1, 1.29940869856362106738e-01) (2, 1.42354318981216497464e-02) (3, 5.57111637775943718820e-02) (4, 4.16975269203231774240e-02) (5, 1.36665390296432487371e-01) (6, 9.15054291400525965372e-01) (7, 2.48956309122473795625e-01) (8, 2.51946473536658388515e-01) (9, 3.04980961354022861443e-01) (10, -7.90917718041013517727e-01) (11, 4.66740050053288113574e-01) (12, 1.47001197305197006671e-01) (13, 1.11152080562586130785e-01) (14, -1.14923404324141387178e-01) (15, 4.62486275171925198535e-01) (16, 5.90021463195805097313e-03) (17, 1.35958945122236496417e-01) (18, 1.23263258527496047390e-01) 
