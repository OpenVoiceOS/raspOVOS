FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.54013261051004185509e-01) (1, -5.29360227271513592018e-02) (2, -3.79434727117018491538e-02) (3, 6.33001871422334133621e-02) (4, 1.13696182520727648302e-01) (5, 7.48596316496308589183e-02) (6, 1.30699005907307874708e+00) (7, 3.53990346250735332667e-01) (0, 8.28444452566878541955e-02) (1, 4.30206242365290147944e-01) (2, 4.59207403821398296717e-01) (3, 4.24838322562624437495e-01) (4, 3.51854930979658586665e-01) (5, 3.13889480039361057351e+00) (6, 4.24322137726935444402e-01) (7, 3.43768213245069731432e-01) (0, 5.39115363085457710568e-01) (1, 7.55660291675203210637e-01) (2, 9.16750993493669397161e-01) (3, 7.83949412319534189031e-01) (4, 9.02096163395517236516e-01) (5, -4.92159561417166457886e+00) (6, -2.57368273654475832046e+00) (7, 1.36837643070096048881e+00) (0, 1.21727308033205722237e-01) (1, 7.53948785379929681261e-02) (2, -3.51704187675909718536e-02) (3, -3.74140195533232480796e-02) (4, 1.10797653348783983751e-01) (5, -4.21378114899222111500e-02) (6, 1.26021923309098493604e+00) (7, 3.08324374315939953028e-01) (0, 1.46162740038584249014e+00) (1, 4.78613152396641261532e-01) (2, 3.52202634555063787136e-01) (3, 3.77811915469131953671e-01) (4, 4.76697891247234828427e-01) (5, 3.68065063304636153063e+00) (6, -1.26155265544603478745e+00) (7, 3.42793822741469855764e-01) (0, 1.76670401586484326906e+00) (1, 3.64436657938295160974e-01) (2, 4.68038083824449335779e-01) (3, 4.25461644145780359949e-01) (4, 5.01659067186647211756e-01) (5, 3.83475879292700083667e+00) (6, -1.53991931650193736303e+00) (7, 1.69150720687920586016e-01) (0, 1.42437008665750997061e+00) (1, 4.55911397230587545071e-01) (2, 4.06117632281742579892e-01) (3, 3.17736513209305349026e-01) (4, 4.93834435236416346982e-01) (5, 3.68985836974713476977e+00) (6, -1.20409625147531640366e+00) (7, 1.98813237702807926732e-01) (0, 2.51321345010536401077e+00) (1, 4.17672509855318452310e-01) (2, 3.51962427205133876473e-01) (3, 4.59144050783205415200e-01) (4, 2.98759790665197755288e-01) (5, 5.00136941916732791213e+00) (6, -4.15568527861131520318e-01) (7, 2.07832294984883869660e-01) (0, -6.30912671810584146925e+00) (1, -5.05365395753013424418e-01) (2, -4.64927071539985581339e-01) (3, -4.87333917824851914347e-01) (4, -4.66141799299346848429e-01) (5, 4.81754694523467108525e+00) (6, 8.31763021910303379514e-01) (7, -6.31617415404647220001e-01) (0, 1.13885185841257481343e+01) (1, 4.27423877613042180190e-01) (2, 4.36446515814755742202e-01) (3, 3.75783910946343724380e-01) (4, 4.73875617579911534438e-01) (5, -7.19944045089482109745e+00) (6, -6.35639336294317125464e-01) (7, 1.44319203159370879064e+00) (8, 4.71980627738633973234e-01) (9, 2.20914317995014375384e-01) (10, -2.31310221361199164214e-01) (11, 1.69836376873923333708e-01) (12, 1.75280539068376955969e-01) (13, 2.23562171432173162344e-01) (14, 1.07350939390860933287e-01) (15, 9.90187464930643024275e-02) (16, 5.65305633262820905749e-01) (17, -4.73706247544343983513e-01) (18, 3.60057577548228313624e-01) 
