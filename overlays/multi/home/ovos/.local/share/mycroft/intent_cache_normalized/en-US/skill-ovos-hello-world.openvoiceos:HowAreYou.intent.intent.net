FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=15 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.58918150708411118899e+01) (1, 4.33201492739753168948e-01) (2, 5.46240598870352922489e-01) (3, 4.55153373045758646853e-01) (4, 4.54975009871558588870e-01) (5, -6.60567949096440898415e+00) (6, -1.96802220754473511377e-01) (7, 1.06215117828113506104e-01) (8, -3.83474852194618298640e-01) (9, -2.79699909004554436720e-01) (10, -5.20446339446856365285e-01) (11, -6.31019696244112693329e-01) (12, -2.07752806472765033652e-02) (13, 6.71704115296645476452e-02) (14, 2.83504745414159653460e-01) (0, -6.77613151462187257579e-01) (1, 3.59294173665362817464e-04) (2, -1.88956375064901843652e-01) (3, -1.63582692685179248437e-01) (4, -1.42411264421991839990e-01) (5, 1.69067189395523254092e+00) (6, 2.56422673595087420584e-02) (7, -2.23833966992596777867e-01) (8, 2.01469029353719658593e-01) (9, 1.04173809155782975955e-01) (10, 2.82324696464722579847e-01) (11, 2.73890272027529801946e-01) (12, -1.06369468414710621751e-01) (13, 1.57215957726649056825e-02) (14, -1.23712251275940293693e-01) (0, -5.58672192311204574011e-01) (1, 1.35376594587643343109e-02) (2, -8.92506100610415964436e-02) (3, -1.16244212575308536461e-01) (4, -1.40061841197363534661e-01) (5, 1.81042464929210189517e+00) (6, -4.53434813956483037667e-02) (7, -1.53024694453570541536e-02) (8, 3.59819308301904172698e-01) (9, 8.68026352686087632193e-02) (10, 1.97738526396916053374e-01) (11, 3.61486133929848907353e-01) (12, -5.62164746768571491065e-02) (13, 1.23034896069295129895e-01) (14, -2.65251383692189091068e-01) (0, -5.18931197738564997657e-01) (1, -9.30841860582462266027e-02) (2, -6.80683550645938828527e-02) (3, -2.01365945150485739501e-02) (4, -6.53301549365154221594e-02) (5, 2.02424976877734419389e+00) (6, -3.88078917006715110039e-02) (7, -2.01096862520327462898e-01) (8, 4.03181318363173335495e-01) (9, 1.30277633009762638938e-01) (10, 3.81464698492008091879e-03) (11, 2.84604682213550119751e-01) (12, -5.93007914932400029273e-02) (13, 9.97545179226556749663e-02) (14, -5.23758328856663152306e-02) (0, 8.64177052763284714310e-01) (1, 2.36423984057096164824e-01) (2, 3.54799918717530859968e-01) (3, 3.25341313964513434431e-01) (4, 3.00011567658570954542e-01) (5, 3.71676779880004470868e+00) (6, 7.05401366814070618361e-01) (7, 2.09358719079877880764e-01) (8, 9.91227700074153866838e-02) (9, 1.11239678838463862398e+00) (10, 3.11232572256955375423e+00) (11, 2.26199046515465873597e+00) (12, 7.25215637750174502152e-01) (13, 1.61489813619865096861e+00) (14, 7.93801676133871203511e-01) (0, 1.38865359417162992361e-01) (1, -1.12364798238924409879e-01) (2, -9.98659799010071097536e-02) (3, 4.45804750412193140363e-02) (4, 5.58564072340217432355e-02) (5, -1.77817270236575497577e+00) (6, 1.78589295947770981821e-01) (7, 7.97013820278390100471e-02) (8, -2.21790347293413292462e+00) (9, 2.16832261923545627225e-01) (10, -7.61356459385355011094e-01) (11, -1.19836921046437727689e-01) (12, 1.10875798159512387042e-01) (13, 2.93113814412678586052e-01) (14, 1.19841554860516896763e-01) (0, 2.10049777299780998652e-01) (1, -8.51012730973537828705e-02) (2, -9.02446547525699999115e-02) (3, -6.37174399572189853469e-02) (4, 1.62785647434417306278e-02) (5, -1.79790657835566891620e+00) (6, 8.93072191419407995783e-02) (7, 1.27121330199100240899e-01) (8, -1.83158795380536743025e+00) (9, 1.90642688814395694363e-01) (10, -7.27579222446878337571e-01) (11, -2.22440673228251978299e-01) (12, 1.48600413651928026093e-01) (13, 3.01946585743750439690e-01) (14, 2.04697319964810747761e-01) (0, 2.38091320829621411193e+00) (1, 8.74264152246839731930e-01) (2, 9.06824105876810282467e-01) (3, 7.98615091937906473873e-01) (4, 8.42868702012426584957e-01) (5, -6.58264272923121751546e+00) (6, 1.51095392598752926716e+01) (7, 1.52966136543899615674e+01) (8, 3.54591722180516200069e+00) (9, 8.17774575972630302090e+00) (10, -8.64605363424082118406e-01) (11, -1.46617044001203256087e+00) (12, 1.87727845307543681486e+01) (13, 6.06274797880722721155e-02) (14, -2.06690187826488208644e-01) (0, -1.55530130435475513195e+01) (1, -3.24522008157904273684e-01) (2, -3.56144254065687837496e-01) (3, -3.10655933774645509615e-01) (4, -2.46592995680506382739e-01) (5, 2.50406627806027870520e+00) (6, 5.06301063368886500315e-02) (7, 1.75333168145217999090e+00) (8, 1.10321548293040150313e+00) (9, 1.67345424235266854174e-01) (10, 1.87863259687988759516e+00) (11, 4.51205159854969228839e-01) (12, 1.75961422424751989801e-01) (13, 5.25195047628025601938e-01) (14, -1.73472147715557523107e-01) (0, 2.51163416904505520932e+00) (1, 5.25205940843094798431e-01) (2, 4.56118487656582805023e-01) (3, 4.58970428348053904877e-01) (4, 5.52451253772248240814e-01) (5, -6.71975479501220807066e+00) (6, 1.23327372952033460507e+01) (7, 1.59655457456538107941e+00) (8, 2.98736813494690123250e+00) (9, 8.17702562385870734829e+00) (10, -2.91847576191687330116e-01) (11, -4.50436977776922431449e-01) (12, 8.60920877044339327711e+00) (13, -3.05248429775742714798e-02) (14, -3.50164685088608096386e-01) (15, -4.02588465134893422337e-02) (16, 4.18005529268094477846e-01) (17, 4.67318687064954219057e-01) (18, 3.91846412225076157210e-01) (19, -6.92965268580547077981e-02) (20, -3.02724166282433093667e-01) (21, -4.08850535077070309509e-01) (22, 3.93275143871539001328e-01) (23, 4.27079553418662605235e-01) (24, 4.61877059163001035813e-01) (25, 3.09584438181369214771e-01) 
