FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.20618159092922105913e-01) (1, -5.52604487661901774831e-02) (2, -2.09101322156626356907e-01) (3, -1.47080428016621245213e-01) (4, -1.73967315864998472996e-01) (5, 3.19828372875240962703e-01) (6, 1.59996120834483157580e+00) (7, 7.27135234082614267948e-01) (8, 1.20871267492703493573e+00) (9, 3.05653945398823123636e-01) (10, -1.17524643081798357835e-01) (0, -9.24320926286239519243e-01) (1, -1.87096322936255110569e-01) (2, -9.34474310402455682345e-02) (3, -7.06985733036580715760e-02) (4, -1.65792628241020811863e-01) (5, 2.23676576312376945710e-01) (6, 1.85566488383865735301e+00) (7, 5.43488331640635813358e-01) (8, 1.57274949230244520670e+00) (9, 2.41668418837086201867e-01) (10, 3.13310654576875874389e-02) (0, 8.14220899822323929129e+00) (1, 1.44404296814045851605e+00) (2, 1.62348679690203612225e+00) (3, 1.62102394788107817547e+00) (4, 1.55450884489855711834e+00) (5, 6.99801770303232117953e+00) (6, -6.39033327487432156744e+00) (7, 9.82822791213524027398e+00) (8, -5.06406889556966088861e+00) (9, 6.87719029278240334691e+00) (10, -1.94292254038030876018e+00) (0, -8.88352861024398476886e-01) (1, -8.36462514839561854796e-02) (2, -5.92633473120125764400e-02) (3, -1.93922060205737017968e-01) (4, -1.88543754293719195703e-01) (5, 1.99632578890518636028e-01) (6, 2.00375729529714963206e+00) (7, 3.65171003542533456621e-01) (8, 1.47868553228667143351e+00) (9, 2.29972769088339384913e-01) (10, 8.21815174323880653917e-02) (0, 4.58136829352811947302e+00) (1, 3.82224264416956338586e-01) (2, 4.82352654311918538355e-01) (3, 4.46708123061918649377e-01) (4, 4.05785071525835427941e-01) (5, -3.15339365678660588088e+00) (6, -5.92474345767961652065e-01) (7, -3.03541789897893821149e+00) (8, 2.26310745228596565948e-01) (9, -6.39650433895758818714e-01) (10, 9.06505068766912058820e-01) (0, 1.55404607844472693046e+01) (1, -4.21732531344206351687e-02) (2, 1.99846981609552061532e-02) (3, -7.04623812293321966083e-02) (4, -1.07426071301630260413e-01) (5, -3.53702319918505914131e+00) (6, 7.30090039733340745443e-01) (7, -4.09121700468144222640e+00) (8, 1.48754930457422496204e+00) (9, -4.75235188411232289951e+00) (10, 3.06649169472871241382e-01) (0, -4.62935268266703392470e-01) (1, -5.58602621763205492433e-02) (2, -1.44328582844064218227e-01) (3, -1.00549723765180107349e-01) (4, -8.42070689409231826206e-02) (5, 1.06223765378884144051e-01) (6, 1.96662012963152310618e+00) (7, 2.98958341538913874302e-01) (8, 1.47830763138821486002e+00) (9, 1.96088358843968496581e-01) (10, 1.06063230843634934142e-01) (0, 1.11547093427599364190e+00) (1, -2.52565024006216498620e-01) (2, -2.75885348725168622064e-01) (3, -1.27308530318586687891e-01) (4, -2.22204146492330972817e-01) (5, -2.55442228238929203155e-01) (6, -2.77904003083830307419e-02) (7, 5.81820308816205944424e-01) (8, -2.37611309054965236243e+00) (9, 8.57729537311437972846e-01) (10, 5.14754501527822871942e-01) (0, 1.55542011451841162284e+01) (1, -1.59556290147368107224e-01) (2, -2.24811660138432151124e-01) (3, -2.40282757220331794068e-01) (4, -1.88917687175337467576e-01) (5, -3.48528007922999627510e+00) (6, 7.53859820726802354329e-01) (7, -4.16377611550173654109e+00) (8, 1.76690319093617720370e+00) (9, -4.73026734994407949131e+00) (10, 6.66842599771999777758e-01) (0, -1.06920676108345809041e+01) (1, -1.56703097302254484857e-01) (2, -1.11873155016239941850e-01) (3, -8.85294578259551850907e-02) (4, -2.22187047380741881097e-01) (5, 9.10584392063191527811e-01) (6, 9.81273162363570872202e-01) (7, 3.39787251083171648602e+00) (8, 9.01123605141830874565e-01) (9, 1.53217644462478141953e+00) (10, -2.20644738324498906890e-01) (11, 2.95372576958656429813e-01) (12, 2.92525590903282284305e-01) (13, 6.54936072055452234153e-01) (14, 2.98094318754196285770e-01) (15, -6.73820794927616345538e-02) (16, -2.15055434333766753996e-01) (17, 1.34217876387059564802e-01) (18, -5.00727238245819994411e-01) (19, -1.91665215718234777098e-01) (20, 4.75091504115634388761e-01) (21, 7.70904101481610704028e-01) 
