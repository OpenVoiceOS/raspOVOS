FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.34208200568410318532e-01) (1, -6.26036739428056931978e-02) (2, -6.65475642759813523774e-02) (3, -3.85508453924669133861e-02) (4, -8.83930167634500996154e-02) (5, 5.53653359854341803326e-02) (6, 1.51050393749575573299e-01) (7, 9.42835100609000775762e-01) (8, 1.22260123012956700705e+00) (9, 3.44603494101479779221e-01) (10, 1.52068405428666952872e-01) (0, -5.58585667802236063295e-01) (1, 4.49370256029917817392e-03) (2, -5.67478422228162027174e-02) (3, -1.28639157504207457539e-01) (4, 1.92324261959726967863e-02) (5, -4.08836278740894121242e-01) (6, 2.16207535619054730391e-02) (7, 9.29714922857580949866e-01) (8, 7.56681633838666156677e-01) (9, 3.11475505188856527372e-01) (10, 1.65184101351944861991e-01) (0, 1.37903735960915013736e-01) (1, -1.17939100239027733208e-01) (2, 1.81066909697162950477e-02) (3, -7.58070951435458606493e-02) (4, -1.14221733633030647637e-01) (5, -6.73857780068735134904e+00) (6, 6.49759389554855210092e-02) (7, 2.05181547269218667040e+00) (8, 2.40031967826548520151e+00) (9, 1.15449259657387170996e+00) (10, 1.94258689768675510412e-02) (0, 6.39131514674210254867e-01) (1, 4.53130074514461675395e-02) (2, 1.73024892128856327966e-01) (3, 2.02839955009372380212e-01) (4, 4.27112498058391729105e-02) (5, -4.14573784758426600039e-01) (6, 1.60162958338920136114e-01) (7, -1.78438367502428429923e+00) (8, -2.22329351432285826640e-01) (9, -8.99077361364200355887e-01) (10, 1.75132644986913443841e-01) (0, -9.83541506594602932267e-02) (1, -1.36572316858519310356e-01) (2, -4.52553039524447794917e-02) (3, -1.20490857038248772026e-01) (4, -1.64512232515562739632e-01) (5, -6.83746978567642482716e+00) (6, 1.54568573648842189083e-01) (7, 2.24062208846204935497e+00) (8, 3.10888876597673080582e+00) (9, 8.11687895199573072880e-01) (10, -2.70478837303753938404e-02) (0, 6.74932868581771483463e-01) (1, 4.22990127816400940386e-01) (2, 3.80772470846376831499e-01) (3, 4.30486559286318237749e-01) (4, 2.93777286424837524859e-01) (5, 5.33134066618255175740e+00) (6, -7.77862509390215728367e-01) (7, -2.64566427203493104159e+00) (8, -7.92927202924865875966e-02) (9, 4.30299939804412012734e+00) (10, 4.27009638190574636329e-01) (0, -6.26289576949514217863e-03) (1, -2.41190479933487883502e-01) (2, -1.40919843553769130740e-01) (3, -3.12741653858887747042e-01) (4, -2.95624019443261221163e-01) (5, -5.62023308599228865745e+00) (6, 1.78500554720103427053e-01) (7, 1.44492952387736561803e+00) (8, 2.87467305308556531074e+00) (9, 1.08432992402438532764e+00) (10, -6.67696885763398723102e-02) (0, 1.15799094045166111044e+01) (1, 5.46111780376971833739e-01) (2, 5.36255243392528058166e-01) (3, 5.23854467244685539917e-01) (4, 4.81067891390860868928e-01) (5, -5.85008875604352862609e+00) (6, 3.33097919715420964781e-01) (7, -1.69980752630469034159e+00) (8, 7.57103653532658293912e-01) (9, -2.23302781494941671170e+00) (10, 1.09422533716559322592e+00) (0, 5.78896893764738784682e+00) (1, 4.54362940398141623710e-01) (2, 4.86358847824022055839e-01) (3, 5.82401220110341788505e-01) (4, 5.35462689009591819023e-01) (5, -5.70886901807214641735e+00) (6, 4.72437720195184818195e-01) (7, -1.83856211752704168383e+00) (8, -1.70307380051812962130e+00) (9, -3.47430805877940862558e+00) (10, 6.82258958387193858997e-01) (0, 1.15854455435279941611e+01) (1, 5.52155355914624945690e-01) (2, 5.42527924283536688854e-01) (3, 5.60968752010854498913e-01) (4, 5.36467122837098853161e-01) (5, -6.22097369442195535783e+00) (6, 3.29967260254399541441e-01) (7, -1.65998868061539361918e+00) (8, 8.15462716477945770421e-01) (9, -2.12923101993885000027e+00) (10, 1.08431442584395321127e+00) (11, 5.53430423995835751860e-01) (12, 4.74777680391213929845e-01) (13, -2.22488747788312291043e-01) (14, -7.07838166091904474886e-02) (15, -1.42750017926771305410e-01) (16, 4.94244898680676392200e-01) (17, -2.15280108034623191005e-01) (18, -3.80497287782310900095e-01) (19, -1.25617950275338952082e-01) (20, -4.14628159078239966195e-01) (21, 5.28812306944359766803e-01) 
