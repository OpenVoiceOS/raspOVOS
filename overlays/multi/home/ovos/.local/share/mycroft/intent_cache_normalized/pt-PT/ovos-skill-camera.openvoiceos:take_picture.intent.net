FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.11760231309593116578e+00) (1, -1.14797583670663977395e-01) (2, -2.15161836595583022547e-01) (3, -1.15259877295541907083e-01) (4, -2.38611037732410491419e-01) (5, 6.78149037516567410044e-01) (6, -2.18932119566277200162e-01) (7, 1.91414362053996289781e+00) (8, 3.37573397513391992852e-01) (9, -3.83756703060311621378e-01) (0, 3.74044350276908077468e-01) (1, -2.40287203338115581963e-02) (2, 8.00032485280067484634e-02) (3, -4.10856138911216695053e-02) (4, -2.48733367767303356621e-02) (5, 2.41816260100273705547e+00) (6, 1.24850148255022622146e-01) (7, -3.43894179284815777464e+01) (8, 2.23221075073491892482e+00) (9, 1.50882075899816697762e-01) (0, 4.34252302627635611287e+00) (1, 3.20679397920978936920e-01) (2, 2.70201118330372247467e-01) (3, 2.86341817716968927154e-01) (4, 2.16521845797909395781e-01) (5, 9.11174439458415292847e+01) (6, 2.15675822862243959932e+00) (7, -4.41169862234406195967e+00) (8, 4.17857950062811500658e+00) (9, -1.13223057752677713772e-01) (0, 1.72235664720430636798e+00) (1, 5.27369660205568857592e-01) (2, 5.48827093906130381029e-01) (3, 4.18752410329308211168e-01) (4, 4.91845165259566008409e-01) (5, 1.60223649983540816777e+01) (6, 3.18628444260401433308e-01) (7, -2.03901913665360901007e+00) (8, 6.96192136247621817802e+00) (9, 1.77329324165139190495e-01) (0, 6.38827017449606859856e+00) (1, 5.98545509919726659298e-01) (2, 6.29048652544820119381e-01) (3, 7.27321482792698925657e-01) (4, 6.39855295017564107418e-01) (5, 1.02452529395128300038e+00) (6, 5.60390429302287995661e-01) (7, -1.23753607443652025033e+00) (8, -6.00922846276758004791e+00) (9, 1.03846996602671426402e+00) (0, 4.03261191140135921707e-01) (1, -3.25574707236259419663e-02) (2, 5.47228176150352241258e-02) (3, 5.91036994013816596727e-02) (4, -7.22404029216735521501e-02) (5, 3.70150496153529073862e-01) (6, -2.56486704638674900547e-01) (7, -3.43247024610881794615e+01) (8, 2.19476187512885889674e+00) (9, 2.84322612969734767052e-01) (0, -4.08952478894055282410e+00) (1, -8.01692669106007504976e-02) (2, -2.51721366198110640955e-01) (3, -2.39542345405864776087e-01) (4, -2.42558642180013717127e-01) (5, 8.07353104000586796474e-01) (6, -1.05604602558794710698e-01) (7, 1.80377720700756905003e+00) (8, 3.87812557684330483365e-01) (9, -3.30172097604913061808e-01) (0, 3.32752141920220734228e-01) (1, 1.82861551172853811775e-02) (2, 9.75414379961611066605e-02) (3, 6.99295416004778180863e-02) (4, -1.04195386640905003628e-02) (5, 3.92296780733759786752e-01) (6, 8.05594193879687475723e-02) (7, -3.42580045283083904906e+01) (8, 1.83619990128969123866e+00) (9, 5.40170547272377440939e-02) (0, 1.86207173268178682868e+00) (1, 6.21281358695634611244e-01) (2, 6.31504400915511854286e-01) (3, 5.93252963668712385292e-01) (4, 7.62780464536555791177e-01) (5, 9.58428108935604261553e-01) (6, 6.57518036606357103580e-02) (7, 2.57828920357614954639e-01) (8, -6.27167283186139545847e+00) (9, 9.47185234047381086064e-01) (0, 3.26693272204336138120e-01) (1, -7.56810810413329759783e-02) (2, -1.26450117673843343002e-02) (3, -7.03936628961257786913e-03) (4, -3.54880522932975728256e-02) (5, 1.59317385607215866727e-01) (6, 3.52796751746238868019e-01) (7, -1.44988418613117246991e+01) (8, 6.81482098160667737474e-01) (9, 1.78908288134666498825e-01) (10, 4.78680343306005451343e-01) (11, -1.79797066734079996619e-01) (12, 5.25770494032175017551e-01) (13, 5.32494985747606230930e-01) (14, -1.20313351831295572980e-01) (15, -1.58622431465415603125e-01) (16, 4.98947287785036941443e-01) (17, -1.98279333753418884889e-01) (18, -1.08542671284534944509e-01) (19, -3.66484726327229615173e-01) (20, 3.27032990088042430088e-01) 
