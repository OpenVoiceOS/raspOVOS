FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.36728609078539875554e+00) (1, 4.48316325639000146097e-01) (2, 4.67123759184589593119e-01) (3, 5.16678591464271752542e-01) (4, 4.79851362500896660990e-01) (5, -5.36173105713317266208e+00) (6, -8.09811693628059936501e-01) (7, -6.72463294526918220484e-01) (8, 2.59253189013715079625e+00) (0, -6.41468762787273494297e-01) (1, -1.66184216342397272914e-01) (2, -1.42172667733855839778e-01) (3, -1.34075320861764546443e-01) (4, -1.08927003643937730937e-01) (5, 2.17921928587441460223e+00) (6, -1.58499376044427719989e+01) (7, -1.89118805439172987803e+01) (8, -9.26898189153096963011e-03) (0, -2.12696384910853408812e-01) (1, -2.85826999228119341123e-02) (2, -1.02812502067207729023e-02) (3, -1.23893745569479477031e-01) (4, -1.17092885402929766658e-01) (5, 1.00276898268382108625e+00) (6, 2.39623356833416512046e-01) (7, 9.92630355315519796733e-01) (8, -2.10161372368426219159e-01) (0, -5.66536552639892665439e-01) (1, -1.66217831291795514748e-01) (2, -1.01639372624994228644e-01) (3, -7.99654921075114988316e-02) (4, -1.75171843969911347240e-03) (5, 9.60963239658301882073e-01) (6, -1.58337524772440758625e+01) (7, -9.19622595548521104547e+00) (8, -2.02993369571451594269e-02) (0, -7.82858293366856972106e-01) (1, -8.45015873331119438117e-02) (2, -1.17861260789920516828e-02) (3, 1.03678325992534788730e-02) (4, 2.81072477680157049862e-02) (5, 7.87135020778482741299e-01) (6, 6.20126325273650969017e-01) (7, 9.47806730849190426369e-01) (8, -3.60777157392031810890e-01) (0, -6.23431792574529519690e-01) (1, 1.70451770406673565328e-02) (2, -1.20967444511084751269e-01) (3, -8.15505241173793693488e-02) (4, -2.59540607351352349552e-02) (5, 7.62099043414896315518e-01) (6, 7.25138919454763497541e-01) (7, 1.05047081409160747434e+00) (8, -3.37346332626460743143e-01) (0, 8.35542589896334675359e+00) (1, 5.44313297430622955453e-01) (2, 4.62406259785044571053e-01) (3, 4.58787617097247024667e-01) (4, 5.31854354600060363900e-01) (5, -5.78713887853296338193e+00) (6, -8.69066911067536751467e-01) (7, -5.18859966413725004486e-01) (8, 2.83774691565755876610e+00) (0, -9.06058502626999273666e-01) (1, -3.43056070534452917098e-02) (2, -7.39304768769011161345e-02) (3, -3.66447019306883267631e-02) (4, -1.91352997991250439735e-01) (5, 1.16891278239218254775e+00) (6, 7.41563105596522387231e-01) (7, 1.07001674173538297019e+00) (8, -8.11221410754656147013e-01) (0, -6.39352827700069514805e-01) (1, -1.75497568748422205775e-01) (2, -1.30884579918809557109e-01) (3, -2.00223132572598994106e-01) (4, -3.08810245017487224051e-02) (5, 8.92894958460394239097e-01) (6, -6.73450263465248433192e+00) (7, -1.90106254988311533793e+01) (8, -1.52910306202578810675e-01) (0, 2.81941572376586835347e+00) (1, 5.77253077451417295762e-01) (2, 6.59991015021035520860e-01) (3, 5.13003286246487943956e-01) (4, 5.29859017852971403428e-01) (5, -4.95865452377426585429e+00) (6, -1.16576377002493525303e+00) (7, -6.96393073553760011407e-01) (8, 2.66122896432649103104e+00) (9, -1.23746210629470235198e-01) (10, -3.26200617125609881874e-01) (11, 4.57611603940610678354e-01) (12, -2.92490784123820235507e-01) (13, 4.36086338842958221029e-01) (14, 4.24366640205268652597e-01) (15, -1.32619360382087131400e-01) (16, 4.21865338737849981943e-01) (17, -3.18042611351588733193e-01) (18, -1.19889666359249746908e-01) (19, 6.96985994404559328075e-01) 
