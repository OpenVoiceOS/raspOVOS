FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.87804921290500081987e-01) (1, 2.80308971439029337713e-02) (2, -7.07102840508793545338e-02) (3, 3.04277489219333258097e-02) (4, -2.04719504083965796182e-02) (5, 2.03997322302493011570e-01) (6, -1.92636643189964484879e-01) (7, 1.00610870864092944998e+01) (8, -3.55534978900696393977e-02) (9, -1.45645869592263887959e-01) (0, 8.34840705115021841642e-01) (1, 2.48558205290313860569e-01) (2, 3.55190989299293657933e-01) (3, 3.04307163430925509129e-01) (4, 2.48724695964332720433e-01) (5, -3.54200014410948504917e-01) (6, -7.77842647626754424284e-02) (7, -3.14123740045864874304e+00) (8, 3.87667675240512987767e-01) (9, 3.61032775754541679358e-01) (0, 1.07840477852904892409e+00) (1, 2.51930405123706957493e-01) (2, 2.86333725525613924656e-01) (3, 3.66151016874786516819e-01) (4, 3.29952922387596270237e-01) (5, -3.61640238700842608921e-01) (6, 3.52552064463737893640e-02) (7, -3.12757889925082022131e+00) (8, 2.86869317962404390965e-01) (9, 2.26021236891359666998e-01) (0, 5.14761133877678522808e-01) (1, 8.17577746404546112924e-02) (2, -5.94577583776575574470e-02) (3, -5.06021398411852368904e-02) (4, 5.10221850766080370354e-02) (5, 1.95302274068401143792e-01) (6, 4.48331268126353696402e-02) (7, -7.56694498085023203870e-01) (8, 5.68879228724378099846e-02) (9, -3.14995364903721958294e-02) (0, 7.58889911922431381619e-01) (1, 3.53876591311337862500e-02) (2, 1.05185338913047529696e-01) (3, 9.32222173200490250577e-02) (4, 9.36293095932843461027e-02) (5, -4.22253531845931062705e-01) (6, 1.15394429746750043497e-01) (7, -3.13112915369044175762e+00) (8, 2.57994864567690718182e-01) (9, 1.99293225097388004841e-01) (0, 1.03765200191544892938e-01) (1, 2.67618895520011834677e-01) (2, 3.04612056363861016806e-01) (3, 2.80531913985053948934e-01) (4, 1.87704396445791066306e-01) (5, 4.86784581922389270048e-03) (6, 4.03317717563633701405e-02) (7, 2.42270953338961803070e+01) (8, -3.68146944701216935480e-02) (9, 1.22989340672023883538e-01) (0, 6.37047996970630081570e-01) (1, 1.24794268666351043651e-01) (2, 7.48428121791722689160e-02) (3, 6.81757346378209505566e-02) (4, 1.39570789097392788936e-01) (5, -3.38854407402400026328e-01) (6, 2.75766679528835489954e-01) (7, -3.19695571126709809917e+00) (8, 1.67593907996588575848e-01) (9, 1.40329874145716404499e-01) (0, 8.41616590124465296929e-02) (1, 2.00234813839312908446e-01) (2, 2.47767938524600495054e-01) (3, 1.65284862965461160078e-01) (4, 2.77895195633288849546e-01) (5, 1.94403558049426494758e-01) (6, 2.29364166991349482938e-01) (7, 2.43851020243387424102e+01) (8, -7.67566163002990076158e-02) (9, 1.32961033830173602777e-01) (0, 3.76895860600460541612e-01) (1, 8.46412404503578547077e-02) (2, 1.11472308548902929171e-01) (3, 1.50124959560846760187e-01) (4, 2.24555373105024741465e-01) (5, 4.89801281810351762935e-01) (6, 2.63236623140022441003e-01) (7, -2.05521514063274111095e+01) (8, 2.31428574653312790765e-01) (9, 1.47354091155517619161e-01) (0, 8.82967164236725943205e-01) (1, 3.96602158172603747044e-01) (2, 2.53531922324176928196e-01) (3, 2.51032200379844805394e-01) (4, 2.49216046853538653050e-01) (5, -3.61591526804899920933e-01) (6, 5.53506442114952493250e-02) (7, -3.06222949920733267248e+00) (8, 4.37295366747852465306e-01) (9, 3.29637837334152361546e-01) (10, 5.85571037563300200723e-01) (11, -2.01108812481050003296e-01) (12, -1.84192895084504620895e-01) (13, -3.83806457259084493616e-03) (14, -1.64600028782968060836e-01) (15, 5.16054963527415089253e-01) (16, -1.43956720024232404098e-01) (17, 5.15320187268946461323e-01) (18, -2.15546774803027973988e-01) (19, -1.58308251085275603076e-01) (20, 2.17315814552313774088e-01) 
