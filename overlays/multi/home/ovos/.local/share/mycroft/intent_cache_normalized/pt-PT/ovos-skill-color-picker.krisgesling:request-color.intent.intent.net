FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.12046954902643447483e+00) (1, 1.15688185530930098821e+00) (2, 1.16104389864235457708e+00) (3, 1.12629424545198020269e+00) (4, 1.17843014884024155364e+00) (5, 1.37256328121446280477e-01) (6, 1.90330454967984841197e-01) (7, -2.54252052146342888417e-01) (8, -1.47632647838511110727e+00) (9, -1.27112688204339252529e+00) (10, 1.41951962499024508801e+00) (0, 1.48144345790340237201e+00) (1, 4.00558165175550928705e-01) (2, 4.11987318558329096430e-01) (3, 4.43859695357912531488e-01) (4, 2.82324909133547297113e-01) (5, 6.37053228929100545663e-01) (6, 1.96763439878953882989e+00) (7, 1.32092618498950696448e+03) (8, 1.50000000000000000000e+03) (9, -3.68213035541497246683e+00) (10, 8.32916971463729449709e-01) (0, -9.07892802581615532276e-01) (1, -1.45555436064744103675e+00) (2, -1.59167726536536280335e+00) (3, -1.54451564152979958777e+00) (4, -1.46295746614480126624e+00) (5, 6.61468565513144479695e-01) (6, 9.46743727553490233007e-01) (7, 4.37759204209654750883e-01) (8, 6.68978380141560413641e-01) (9, 7.08453656323447478194e-01) (10, -6.84020142315236334696e-01) (0, 1.05409158295462668242e+00) (1, 7.72304926704907357404e-01) (2, 7.33792722862505852888e-01) (3, 8.54759757113003448836e-01) (4, 8.44212610911869720809e-01) (5, -2.22706000637525880492e+00) (6, 3.75723159849096211005e-01) (7, 5.58335855076412326814e-02) (8, 2.29901817847984052401e-01) (9, -1.04915876110426770085e-01) (10, 1.17596612415760892745e+00) (0, -9.21206201384945910782e-01) (1, -2.78207514669949473873e-01) (2, -1.05340760436112457210e-01) (3, -2.74803783979470195309e-01) (4, -1.12104948844964080745e-01) (5, -1.41276156631151506016e-01) (6, -2.24051795866378300470e-01) (7, -1.53460918111531119390e-01) (8, -8.63656649592183245367e-01) (9, -1.47500000000000000000e+03) (10, -1.29594109582479855014e-01) (0, 1.25042042178025258892e+00) (1, 3.77219662098136843120e-01) (2, 4.29335966734138430034e-01) (3, 3.13728343723264635479e-01) (4, 3.55417452780452669536e-01) (5, 6.14006480254091435711e-01) (6, 1.07899709909208407765e+00) (7, 7.18994297821892280886e-01) (8, 1.01197270290524476977e+00) (9, -2.51815463589360799546e+00) (10, 4.30592938868383123818e-01) (0, 6.39793955086864429838e-01) (1, 3.70713342233878750953e-01) (2, 3.96133993073684353980e-01) (3, 2.44774487122279671425e-01) (4, 3.90202690168601651344e-01) (5, 8.19344260732175921902e-01) (6, 6.73004345443671048166e-01) (7, 6.15502105491663620285e-01) (8, 1.49394821457071813597e+00) (9, -2.46891293289606483796e+00) (10, 4.47419346669773676517e-01) (0, 5.59601065899674043891e+00) (1, 1.18863676614231472684e+00) (2, 1.30376943699187597403e+00) (3, 1.30496151498622259268e+00) (4, 1.24914359799689611563e+00) (5, -3.81538475342735994289e+00) (6, -1.34060972484857776621e+00) (7, -3.21252933423262598822e+00) (8, -2.65083718124757039547e+00) (9, -2.62974632303781419296e+00) (10, 2.35195893231521324651e+00) (0, -5.77767834101572175243e-01) (1, -3.07643757789945071490e-01) (2, -3.03514258592938845904e-01) (3, -2.45332674711560672076e-01) (4, -2.45113523333882754596e-01) (5, -5.17004787700410473050e-01) (6, -3.31841897291763054945e-01) (7, -3.28668015652533063164e-01) (8, -1.42608884612836739336e+00) (9, 1.50000000000000000000e+03) (10, -3.41332890189777748979e-01) (0, 7.98144446341468527528e-01) (1, 8.61012327735058202727e-01) (2, 7.20776657824150679410e-01) (3, 6.98076370422474501432e-01) (4, 7.14012074534527418912e-01) (5, -3.04028530499809990228e-01) (6, 5.50164716448364621293e-01) (7, -1.45569601691117017639e-01) (8, 5.14979139797640206311e-01) (9, -3.16882889273849138734e-02) (10, 1.10536462978398941637e+00) (11, -1.97367353597548339517e-01) (12, 5.05931462359623718150e-01) (13, 4.75647731158034048349e-01) (14, -1.86712094785834198385e-01) (15, -4.92904529487610432170e-01) (16, 5.71709988518203315877e-01) (17, 5.92916745070518724781e-01) (18, -2.57492969472653987495e-01) (19, 1.22380584393594804560e+00) (20, -2.04667384997847423556e-01) (21, 3.90008428849257515747e-01) 
