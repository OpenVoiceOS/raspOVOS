FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.13356743734480369667e-01) (1, 1.68003664797609260362e-02) (2, 8.91573864824104144952e-04) (3, -6.91078899913961097745e-02) (4, -1.05106949668520188723e-01) (5, -1.34007102753155443731e-01) (6, -4.12714750187543000237e-01) (7, -1.83115954357566057542e-01) (8, 1.45751991261392443988e+01) (9, -3.63813337444824635991e-01) (0, 1.52992636214837079978e-01) (1, -7.54831928953516029246e-02) (2, -7.37613562688219093211e-02) (3, -5.01161266311990830080e-02) (4, -3.19119256183493099632e-02) (5, 9.18987371694354460150e-02) (6, 6.16110507879557983690e-02) (7, 2.46228376730298556541e-02) (8, 2.33866424098652725405e+00) (9, 2.60506340761107124671e-01) (0, 3.51499931453261083014e-01) (1, 2.77007997524343241302e-01) (2, 2.28880160045228431276e-01) (3, 3.90946202468476888825e-01) (4, 2.70220704865060501465e-01) (5, 1.46609918653464399441e+00) (6, 4.41708362511903285252e+00) (7, 2.09975224728487486203e+00) (8, 4.30281369070500030460e+00) (9, -5.26446041989547808271e-01) (0, -6.20278528308507270950e-01) (1, -1.02123412176021777231e-01) (2, -4.87622868856279548244e-02) (3, -6.55066919168321992739e-02) (4, -1.92875231488594284235e-01) (5, 7.31001820396101509303e-01) (6, 5.23339975590148887008e-01) (7, 4.16080580795445964526e-01) (8, 3.58676300714273166292e+00) (9, -2.77885638749630414779e+00) (0, -4.43500209494323949233e-01) (1, -7.79436936455801671064e-02) (2, -8.50646550236499286723e-03) (3, -4.39769958931044216421e-02) (4, -5.20986949878767882649e-02) (5, -1.88337229348245177585e-01) (6, -2.87531137936818004253e-01) (7, -1.93556677117516534592e-01) (8, 2.46901617439495275619e+01) (9, -2.36418795346779425648e-01) (0, 6.46291309279258041620e-01) (1, 4.72426242256670625430e-01) (2, 5.54595491910486848575e-01) (3, 5.42972481871157319766e-01) (4, 4.49571966255217225772e-01) (5, -3.95052521578165283245e-01) (6, 1.31293976501313167660e+01) (7, 3.08533125018314924315e-01) (8, -4.65572920232375331295e+00) (9, 8.88139127758408641888e-01) (0, 3.35904599665197922675e-01) (1, 2.33169447868019380499e-01) (2, 3.14671550183445447590e-01) (3, 3.91802314906269433248e-01) (4, 3.75722456960827233541e-01) (5, 8.43783592266722393127e-01) (6, 4.90552718378064689375e+00) (7, 1.94423415693605505794e+00) (8, 4.20783932426869178300e+00) (9, -6.16151337850315394817e-01) (0, 4.86524292510802314204e-01) (1, 2.82096992637418053640e-01) (2, 4.59337297286294299337e-01) (3, 4.59454584326051074239e-01) (4, 4.37665853108666735860e-01) (5, 1.83064327232687090730e-01) (6, 3.05538997281997986022e+01) (7, -3.18543698111153350538e-02) (8, -4.05178490936007484891e+00) (9, 2.59803470165351046983e-01) (0, -7.75737299000855751174e-01) (1, -6.16657195675055294637e-02) (2, -1.79703144549099663729e-01) (3, 9.39706147940912997138e-04) (4, -8.17032886731306751127e-02) (5, 8.03806390594160591334e-01) (6, 3.17747834032003073634e-01) (7, 3.41228404784837291430e-01) (8, 3.67676464984674167269e+00) (9, -2.86892932480604612167e+00) (0, 5.50864094179923213801e-01) (1, 1.13695756412885162767e+00) (2, 1.08120888538501236376e+00) (3, 1.13167800821206543382e+00) (4, 1.11194659091374847826e+00) (5, 3.48830324670564850820e-01) (6, 3.06030125324338264647e+01) (7, 5.49054116589723251174e-01) (8, -7.19598881806926549132e+00) (9, 2.71305451467946312505e+00) (10, 4.46263534170048881133e-01) (11, -3.45204809566281467514e-01) (12, -5.85755639837147873417e-02) (13, 4.35286917946015428083e-01) (14, 4.94110554167558835292e-01) (15, 3.81320945028953639522e-01) (16, -5.40816270873906573824e-02) (17, 3.65194722120456782832e-01) (18, 4.28773893838233555176e-01) (19, 3.83392325644188014522e-01) (20, 2.57137247417762393464e-01) 
