FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=33 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (33, 6, 5.00000000000000000000e-01) (33, 6, 5.00000000000000000000e-01) (33, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.54702093689259179143e+00) (1, -3.72787536400090102617e-01) (2, 8.10840150089521038979e-01) (3, 1.80771221014348992817e+00) (4, 4.51328607498832135025e-01) (5, -4.01078378187935147281e+00) (6, 7.66077804902382411001e+01) (7, 1.40987703555193077953e+00) (8, 1.14812018286528125799e+01) (9, 1.03088639963642858532e+01) (10, 1.27382224024630570369e+01) (11, 1.33400059583474153158e+01) (12, 1.44532977639064199593e+01) (13, -1.06643538281925831512e+01) (14, -3.04810529867306989615e+00) (15, 1.50000000000000000000e+03) (16, 2.09076252967352615997e+00) (17, -1.03589391070742475875e+00) (18, 1.82414211061598541264e+00) (19, 8.05008390679801677514e-01) (20, 3.27299760968758512991e-01) (21, 1.50000000000000000000e+03) (22, -1.69402922177691817041e-01) (23, 1.85720549150317495446e+01) (24, -1.08037293383560442095e+01) (25, 1.80224763846479119067e+00) (26, 1.23419139443890424346e+00) (27, 6.21711091524802839103e+00) (28, 1.50000000000000000000e+03) (29, 4.94192399812523586178e+00) (30, 8.81677584570326722258e+00) (31, 2.19881004019830541552e+01) (32, -3.21064215796060281605e+00) (0, -1.66615216622796213919e+00) (1, 1.47489987896939678258e+00) (2, -1.08273833164432931042e+00) (3, 4.37076027517902776509e+00) (4, 1.62149795889516079583e+00) (5, -1.56054625448859574099e+00) (6, 1.30505834517933938521e+00) (7, -6.73251702149127151387e+00) (8, -1.74107956093023763522e-01) (9, 5.83523207404174959478e-01) (10, 1.05217193505300610212e+00) (11, -9.04750619927705113099e-01) (12, -8.25286226444730042218e-01) (13, -7.80937212701801275472e-01) (14, 7.49099981387524982424e-01) (15, 1.50000000000000000000e+03) (16, 3.78006217898406182698e+00) (17, -3.02757143764786462725e+00) (18, 1.65160675716347316033e+00) (19, 8.98230787023339583008e-01) (20, -6.71478502965697665594e-01) (21, 1.50000000000000000000e+03) (22, -1.51414960934370879109e+00) (23, -2.24353685858512053031e+00) (24, -1.69076392302893596664e+00) (25, 5.52065841167364346198e-01) (26, 3.90128172390099114963e+00) (27, 1.49657278991687947567e+00) (28, 1.50000000000000000000e+03) (29, -2.13398193592534513030e+00) (30, 1.87183264145281125224e+00) (31, 1.84973935209149439873e-02) (32, -1.18599494713917374966e+00) (0, 4.91052336658702692773e+00) (1, -2.26950366026854766233e+00) (2, -2.33316908819334889458e+00) (3, -5.98486622621601682681e-01) (4, -2.22747459789559698606e+00) (5, 4.77382618107308420718e+00) (6, -1.88356460732008335057e+00) (7, 2.91503363553396610541e+00) (8, -4.98698738743415637131e-01) (9, 8.29517039536158584667e+00) (10, 1.66426645339703149773e+01) (11, 9.98034809009758355769e-02) (12, 1.89272837057450654674e-01) (13, 2.26584859127242621568e+00) (14, 8.54833719862617247287e-01) (15, 5.00000000000000000000e+01) (16, 1.50000000000000000000e+03) (17, 3.06491054437247489872e+00) (18, -3.12211082819976759595e+00) (19, -4.97734537889201356098e-01) (20, -1.70041517023426624888e+00) (21, 2.50000000000000000000e+02) (22, 1.67210277142650554083e+00) (23, 3.25822908819403744829e+00) (24, 1.04054696502033294792e+01) (25, -2.98127506001146480585e+00) (26, 1.39386388994868093505e+03) (27, 1.50479715178395401232e+00) (28, 7.50000000000000000000e+02) (29, 4.63456752756022094530e+00) (30, 3.24669607996214626411e+00) (31, 9.96285810751253642081e+00) (32, 8.58883901057440612981e-01) (33, 7.01462301355969763961e+00) (34, 1.27253310436204216671e+01) (35, -1.25316730174043069468e+01) (36, -7.58010086863164178617e-01) 
