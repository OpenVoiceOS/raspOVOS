FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.14555615550329772390e+01) (1, -4.46029436092520367718e-02) (2, -4.62390240531111371136e-02) (3, -5.41654508810186854917e-02) (4, -6.16139006118918072796e-02) (5, 7.73611222838603285190e-01) (6, 4.64733297123904098846e-01) (7, 1.05556945142950664440e+00) (8, 9.78680082500154799319e-03) (0, -4.28657689648720918729e-01) (1, -7.73165860297182067074e-02) (2, 7.60992950675985352360e-02) (3, 1.20558476923010582382e-02) (4, 7.22986793993017212712e-02) (5, 1.48415752753465435276e+00) (6, 1.81999188819480212098e-01) (7, 7.83469837798370982718e-01) (8, 5.02523520329430581355e-02) (0, -3.43444398681520546290e-01) (1, 1.10250539798016702897e-02) (2, 3.12623060960049783952e-02) (3, 6.53910614270443307783e-02) (4, 5.76100272123766105059e-03) (5, 2.05653489678860035283e+00) (6, 1.92570795276713613298e-01) (7, 1.37864044966458432206e-01) (8, -2.53026074430510519719e-02) (0, -4.24241730528924165800e-01) (1, -1.39812017698072920888e-03) (2, -9.64265802027681473430e-02) (3, 5.45512325046560789255e-02) (4, 8.79946994592909707139e-04) (5, 1.53731570188828414736e+00) (6, 1.97503712931227926042e-01) (7, 1.19391179742573780298e-01) (8, 7.76550749295266407035e-02) (0, -2.08114716121625353829e-01) (1, 1.18359000191374241773e-02) (2, -1.04245889116795581453e-01) (3, 6.76601798042936186661e-02) (4, 8.31526786789579253067e-02) (5, 2.11932510037789123558e+00) (6, 3.09151788213801514971e-01) (7, 2.44086056115388000398e-01) (8, -7.84359088799520959290e-02) (0, 5.10852827288747323581e-03) (1, 7.08877586482853511152e-02) (2, -7.30530104876666447344e-02) (3, 5.65349601863713233096e-02) (4, -7.87889591694980045977e-02) (5, 2.53741939326549115208e+00) (6, 2.46078503289771294282e-01) (7, 1.28368548216580474763e-01) (8, 3.31563443644598311588e-03) (0, -4.22151015657040773466e-01) (1, -4.00605910541512941214e-02) (2, -6.05798895377898227038e-03) (3, 5.85906243799230938563e-02) (4, 3.56721467254660154489e-02) (5, 1.63442366091812107953e+00) (6, 1.31709557929587606218e-01) (7, 3.72393093291357668573e-01) (8, 2.84049251416161573081e-02) (0, 5.98764839933405745853e+00) (1, 6.58249868669393417564e-02) (2, 2.27953159681785422208e-01) (3, 1.86648735276687460782e-01) (4, 2.55338185898292491238e-01) (5, -5.28568636337644992551e+00) (6, -3.78138756490357597073e+00) (7, -4.17108929291840269116e+00) (8, -3.71824301596052508856e+00) (0, 5.67494729069361047991e-01) (1, 6.61588835279083159469e-02) (2, -6.60764125426673426533e-02) (3, -5.15992564400100453548e-02) (4, 6.05692642490005331291e-02) (5, -8.35471632700126365378e-01) (6, -1.04673199774166336695e+00) (7, -1.66458055179986819105e+00) (8, 7.27828918514921152649e-02) (0, -5.56423942650393055231e+00) (1, -1.31099041974641450370e-01) (2, -1.08653020536996450240e-01) (3, -3.40975005687251600528e-02) (4, -5.32755855978503875536e-02) (5, -1.38892868647644058910e+03) (6, -2.58374511985337163011e+00) (7, -6.75401391545904949965e+00) (8, 5.81033844806696064822e-01) (9, 6.11378086598331260682e-01) (10, 3.69546000166517896179e-01) (11, 6.87062043753207563057e-01) (12, 5.54754443014797482547e-01) (13, 3.05399004888379954625e-01) (14, 5.26174353613787615380e-01) (15, 2.63962749448657663098e-01) (16, 2.09762912365772130618e-01) (17, -2.74354747199469055363e-02) (18, -5.74225767461804120773e-02) (19, 6.10778663188632831016e-01) 
