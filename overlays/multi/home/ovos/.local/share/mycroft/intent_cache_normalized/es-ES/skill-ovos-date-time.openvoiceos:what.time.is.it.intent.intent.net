FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.90108474935630700209e+00) (1, -2.69774649296470825366e-01) (2, -3.44118036333986465625e-01) (3, -1.93776745353409080019e-01) (4, -1.84508714829155207049e-01) (5, 1.47344141164343311878e+00) (6, 2.24162423562924456588e-01) (7, 8.00210610567372193636e-01) (8, 9.20422197309385903274e-01) (9, 8.63296175639794993728e-01) (10, -9.30047350931662158979e-02) (0, 3.92498287680901025709e+00) (1, 6.03502866608160659645e-01) (2, 5.87989968043821975563e-01) (3, 5.74011307937163040016e-01) (4, 5.50104629975813441689e-01) (5, 6.11018676349823053329e+00) (6, -1.51283078118892855279e-01) (7, 6.12180567643946016432e+00) (8, 6.65028731199774636451e+00) (9, 6.62857048131134529712e+00) (10, -2.34625844400923311284e+00) (0, 5.23988319972126781465e+00) (1, 5.39856882616116862117e-01) (2, 4.29355012103154576319e-01) (3, 5.97160601838662596919e-01) (4, 5.07233248873784403621e-01) (5, -3.75700339684098993942e+00) (6, -1.98210142725518886908e-02) (7, -7.13065025528593410264e-01) (8, -7.11798269441766606747e-01) (9, -1.56296770331307094404e-01) (10, -3.18814203188892142382e-01) (0, 6.57834354230619422488e-01) (1, 2.46851134570990719819e-02) (2, -5.78469198671425904879e-02) (3, 5.52311423148261256694e-03) (4, 4.32833167637930883026e-03) (5, -1.32974154991342441434e+00) (6, 2.57410544571384403145e-01) (7, -8.36818243758089441720e-01) (8, -1.46826290322073305106e+00) (9, 3.87885417020201517246e-01) (10, 1.03129753000474444491e-01) (0, -1.71727945422178729373e-01) (1, 1.56575452175835877489e-01) (2, 1.18993188825349135995e-01) (3, 6.69838824580123309849e-03) (4, 1.52163963404397278856e-01) (5, 4.26865036482530046946e-01) (6, 8.46053605022932364577e-01) (7, 2.12013272160046062353e+00) (8, 2.48937531075981288708e+00) (9, 5.33929279697277792138e+00) (10, 7.94236794241353294410e-01) (0, 3.79036799659322243272e-01) (1, -1.17181406028160725596e-01) (2, -1.14298597581276570323e-01) (3, -1.56284427713248401381e-02) (4, -1.21008834313246892850e-02) (5, -2.56996137429858251267e+00) (6, 3.12105042472846705426e-01) (7, -1.59269165963859737900e+00) (8, -4.44440745593516339795e+00) (9, -6.02262673634379375187e+00) (10, -2.87995019582086175802e-01) (0, 6.67241211070703332808e-01) (1, 1.27044047799805909227e-01) (2, 1.53634424892167359422e-01) (3, 5.02726916343968210921e-02) (4, 8.50431803734105068449e-02) (5, 5.11258865589814592845e-01) (6, 8.99086978217741750186e-01) (7, 2.20460417085640392187e+00) (8, 2.51229554675129040930e+00) (9, 5.43745139119365461511e+00) (10, 7.30214215942307731666e-01) (0, 6.33730466499017541793e-01) (1, 1.47846217838029148073e-01) (2, 2.39407863588135573496e-02) (3, 1.42639945831994324754e-01) (4, 9.06536463768284755949e-02) (5, 8.88254823283926131516e-01) (6, 6.27453046299146999232e-01) (7, 2.25041738861553630713e+00) (8, 2.39841149737183689794e+00) (9, 5.31219387677648313684e+00) (10, 8.24814438947125694312e-01) (0, -2.07792591150144501100e+00) (1, -2.47574929152199030291e-01) (2, -2.93560650203891937426e-01) (3, -2.61503193531700317553e-01) (4, -2.69608926032253448657e-01) (5, 1.78880184197125724488e+00) (6, 3.08500582934175704430e-01) (7, 9.58161001034381620833e-01) (8, 8.39895711270224221145e-01) (9, 8.85421285669969360121e-01) (10, -6.20280904185896847514e-02) (0, 4.24470082511495094835e-01) (1, -1.22257374830136003596e-01) (2, -1.07033946223149004084e-01) (3, 2.57740109454659494306e-03) (4, -1.04309102963301824490e-02) (5, -1.60780871105820843958e+00) (6, 1.47822242540223552920e-01) (7, -7.95847369551466954363e-01) (8, -4.55460426242558469312e+00) (9, -5.92926828670590388981e+00) (10, -3.62580725577645979207e-01) (11, 1.34478918151434290174e+00) (12, 7.76887538486147555261e-01) (13, -1.64187078246342182952e-01) (14, 3.23542807538788945720e-01) (15, 5.86724141316207620234e-02) (16, -1.97340981953698091367e-01) (17, 1.36983209259966293159e-01) (18, 9.22339964175738075136e-02) (19, 6.06500264522440546422e-01) (20, -1.79831081920224122861e-01) (21, 7.50821464281464456825e-01) 
