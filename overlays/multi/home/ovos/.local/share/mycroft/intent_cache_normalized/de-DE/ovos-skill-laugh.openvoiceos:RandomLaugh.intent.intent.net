FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.85868483807355389104e+00) (1, -1.88494393515542202344e-01) (2, -2.61770578014805910261e-01) (3, -2.32638114976838283887e-01) (4, -2.50171745109513343763e-01) (5, 2.18939918242661413217e+00) (6, 1.18024984976474689446e+00) (7, 4.85592677236210745750e-01) (8, 2.90381192438372437437e+00) (9, 1.25885836650164906203e+00) (10, 1.39700657308597220307e+00) (11, 4.00632992217050398764e-02) (12, -6.92617749585169972804e-01) (0, 1.12598669334901169137e+00) (1, 2.46325047079070463818e-01) (2, 2.03547784450992058636e-01) (3, 2.76556396249278524380e-01) (4, 2.33201855185969725293e-01) (5, -1.77164979945276712670e+00) (6, -1.88210271794221895014e-01) (7, -1.69798252749166822539e+00) (8, -1.41660199198737446480e+00) (9, -1.48583014628503473631e+00) (10, -1.25560625279176663049e-01) (11, -9.76681388457092847233e-01) (12, 2.59121039274676723263e-01) (0, 4.35536569604042078652e+00) (1, 3.90591047098722943254e-01) (2, 5.48729732027140038042e-01) (3, 4.44107025256243181932e-01) (4, 4.25079751154270601976e-01) (5, -4.49676486283220189222e+00) (6, -4.67422040096717894553e-01) (7, -1.58296527454349356123e-01) (8, -4.06134211770831132782e+00) (9, -2.03714736461003420587e+00) (10, -4.90765203799465254964e-01) (11, 6.36916895357720613813e-02) (12, 8.19429837552843043369e-01) (0, -2.35121867591820243870e-01) (1, -2.20244735972308369742e-01) (2, -1.04675829903506503737e-01) (3, -2.35511623815917225944e-01) (4, -1.97821133331679555045e-01) (5, -6.78045635841673188793e+00) (6, 2.78077890400409810656e-01) (7, 5.91868599059065247925e-02) (8, -4.39487336322751254158e+00) (9, 1.16207663423453833040e+00) (10, 1.78965527186219897082e+00) (11, -1.11761734382533298171e-01) (12, -7.02223776192026916121e-02) (0, -1.89499518806419853245e-01) (1, -2.38223016755007954703e-01) (2, -9.90996216696731768714e-02) (3, -2.35177360968016835319e-01) (4, -1.08478129403018222487e-01) (5, -6.83930836789196305858e+00) (6, 1.86517172728300234530e-01) (7, 5.75508316161116029175e-02) (8, -4.32233571752991885262e+00) (9, 1.22623284242188002047e+00) (10, 1.77438836166684832385e+00) (11, -1.00978687898539754020e-01) (12, -8.79451630920725646590e-02) (0, -3.77558153893262371525e+00) (1, -3.39040946267794407465e-01) (2, -4.55910474114369079768e-01) (3, -4.09386742912481949030e-01) (4, -3.44608467124651707270e-01) (5, 2.88361712862698205129e+00) (6, 7.90895672549204675761e-01) (7, 3.90824719310414236961e-01) (8, 3.20138004369675943650e+00) (9, 1.36923194546731274990e+00) (10, 1.41172665536899222261e+00) (11, 3.05019007841479505849e-01) (12, -2.65748440908845917630e-01) (0, 8.44012596198835840511e-01) (1, 4.55725707804650048693e-01) (2, 3.67637307142704705676e-01) (3, 4.17676382457703332385e-01) (4, 3.58386927043884973010e-01) (5, 5.73459065427777670010e+00) (6, -8.29787109031851211061e-02) (7, -2.47957072089237881563e-02) (8, 7.18179213837424246236e+00) (9, -1.42312642846541409503e-01) (10, -1.14816484175705846305e+00) (11, -3.43592799636428081200e-01) (12, 8.46857782257570135265e-02) (0, 1.15741874828589752511e+00) (1, 1.40506724344907518720e-01) (2, 9.18433652095181629615e-02) (3, 1.93397796230731666700e-01) (4, 2.25445164816795051710e-01) (5, -1.19405608189777145967e+00) (6, -2.56848339486740184778e-01) (7, -4.91443356504619899283e-01) (8, -1.05689116103190539064e+00) (9, -1.01452114761187406344e+00) (10, -3.89131133505597082145e-01) (11, -8.91194197823080846987e-01) (12, 1.95293400213190138093e-01) (0, 7.89133824893751723017e-01) (1, 3.94219339584797601184e-01) (2, 3.64969962036102990588e-01) (3, 3.49766523336857537707e-01) (4, 3.16487540250510013262e-01) (5, 5.74870690425631902798e+00) (6, -1.92240469528692559109e-01) (7, 6.47412167062240695437e-02) (8, 7.11346151516476510324e+00) (9, -1.20009963129000668536e-01) (10, -1.20152094535612952164e+00) (11, 1.36192452337014102692e-01) (12, 2.77362247555959173795e-01) (0, 1.10737729623568847970e+00) (1, 2.01446821910187756632e-01) (2, 1.33926065635726065928e-01) (3, 1.37508990240141959482e-01) (4, 2.51655636352345501994e-01) (5, -9.76252860119398713223e-01) (6, -2.22447388369463039393e-01) (7, -5.06736954679668727408e-01) (8, -9.73736102707568274006e-01) (9, -9.90450154546039907011e-01) (10, -4.48788267621293035514e-01) (11, -8.70883795906576940737e-01) (12, 1.24043548275953055549e-01) (13, 6.75599254016400196932e-01) (14, -6.38589122726266888996e-02) (15, -1.15114038512885666354e-01) (16, -1.39964778597801653426e-01) (17, -3.00071740717278087618e-02) (18, 6.75547770504475453279e-01) (19, 5.62049632293891487933e-01) (20, -7.07928269775093821359e-02) (21, 5.84634487850379525042e-01) (22, -2.75121769043056886572e-02) (23, 3.12775929275584452238e-01) 
