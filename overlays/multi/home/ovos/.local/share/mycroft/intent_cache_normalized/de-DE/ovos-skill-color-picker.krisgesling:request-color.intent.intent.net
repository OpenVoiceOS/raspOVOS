FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.05180105710495919169e-01) (1, -6.15867749546148909867e-02) (2, -8.65239278171637538062e-02) (3, -6.70018569324591362069e-02) (4, -5.32533005569555753511e-02) (5, 8.06135765294630907141e-02) (6, -8.23894472681599432384e-01) (7, -1.12149714153304297382e-01) (8, 1.01428216260506296464e+01) (9, -3.90748246736780879829e-01) (0, -6.49327356692768375979e+00) (1, -1.73231058987954184003e-01) (2, -7.70895865291147813769e-02) (3, -1.88581102761605307050e-01) (4, -9.45484575360804463395e-02) (5, 1.68705881002523883083e+00) (6, 8.67702292085089088580e-01) (7, 1.04301868183885293462e+00) (8, 2.97791319479473193255e+00) (9, -4.13380019894374939327e+00) (0, 7.66531303311721257110e-01) (1, 7.31532695839255953096e-01) (2, 7.79109838554709832614e-01) (3, 6.80633614907115602755e-01) (4, 8.66856026599257867282e-01) (5, 4.71339555299336132599e-01) (6, 1.15974559910994101664e+00) (7, 1.34635250229098235586e+00) (8, 3.16931840848812029776e+00) (9, 4.93036390373596977721e-01) (0, 7.71801653610084903434e-01) (1, 8.01475647041648309177e-01) (2, 7.45107541928142214083e-01) (3, 6.86378146657794618868e-01) (4, 7.57060284862369203829e-01) (5, 3.57098588562065999419e-01) (6, 1.26952526994448233744e+00) (7, 1.28418937063721250169e+00) (8, 3.16903406241066809557e+00) (9, 4.21302470727599465139e-01) (0, -5.51868496144975351214e-01) (1, -9.54950448531228512916e-02) (2, -9.76970341462213009986e-02) (3, -2.45867676700981308002e-01) (4, -2.26966593082578826923e-01) (5, -2.81898552462079010628e-01) (6, -2.34905000662756435759e-01) (7, -1.02274279410756419040e+00) (8, 1.30529122249235491893e+01) (9, -5.39070439208150120614e-01) (0, 1.46323551366335843221e-02) (1, -3.29989136180165107404e-02) (2, -1.44436360987115264276e-01) (3, -1.66697950752663970331e-01) (4, -3.02926839312794536629e-02) (5, -1.22807815095537453676e-01) (6, -9.63251754119464898007e-02) (7, 5.50225382099121737567e-02) (8, -2.25475862809309729462e-01) (9, 2.29748090783369718348e-01) (0, -5.98445990225619610381e-03) (1, -1.39806736981454377000e-01) (2, -1.90563544388441183375e-02) (3, -3.14410522337583292485e-02) (4, -1.31355964368167404954e-01) (5, -1.34998301229472733587e-01) (6, -2.73990166921291300461e-01) (7, 3.08171288437274690231e-02) (8, -1.41825015935782838827e-01) (9, 2.82136335972299756580e-01) (0, -1.05845561181797023081e-02) (1, -1.06659637434242962617e-01) (2, -1.01543703717945812959e-01) (3, -1.37868510229348040230e-01) (4, -8.35725233385551519172e-02) (5, -1.31749142111787592713e-01) (6, -1.75422833428516100618e+00) (7, -1.58193427117786389324e+00) (8, 1.13620272483265560837e+00) (9, 2.57220252510775571064e-01) (0, 3.03957426064270730404e-01) (1, 5.48222685027860534568e-01) (2, 4.88455200362943486869e-01) (3, 5.66243486274026763816e-01) (4, 5.54194049704812896628e-01) (5, 2.43170148833065047356e+00) (6, 5.04737217438695662253e+00) (7, 1.45572354223934663509e+00) (8, -7.12435267230427804463e+00) (9, 1.38500849537145009904e+00) (0, 1.87527197172512732903e-02) (1, -1.45027671730103974168e-01) (2, -4.10332277174619564075e-02) (3, -1.23177894180598726526e-01) (4, -2.32772973734416549485e-03) (5, 6.67694751263081965470e-03) (6, -9.16689587642545600232e-01) (7, -4.54335078343342357865e-01) (8, 7.68179751574829122740e-02) (9, 2.67993482696486040595e-01) (10, 4.93014354759186812505e-01) (11, 5.04984910070445769392e-01) (12, -8.55225138004193780050e-02) (13, -1.39837320857800068152e-01) (14, 5.17357220297547604204e-01) (15, -9.11846529819833190311e-02) (16, -1.36204774380518450760e-01) (17, -1.54515886404481411764e-01) (18, 7.68790241793733675202e-01) (19, -1.81686185439846242806e-01) (20, 3.70090846467001022280e-01) 
