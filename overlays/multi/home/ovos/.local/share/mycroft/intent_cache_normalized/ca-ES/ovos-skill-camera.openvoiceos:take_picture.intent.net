FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.56130776315258334996e-02) (1, 7.81525239171459856768e-02) (2, 5.56692905547097258157e-02) (3, 6.43185801627114139833e-02) (4, 1.04712081682868260457e-01) (5, -1.18637156097502738383e+00) (6, -1.46457855507279299800e-01) (7, -9.06490362964203377771e-01) (8, -1.53804076852446525159e+00) (9, 3.21046999221545836800e-01) (0, 5.83888914856346197269e-01) (1, -1.90110039989284135276e-01) (2, -9.04560136597667013847e-02) (3, -7.78235542576823507988e-02) (4, -7.49031948845896994316e-02) (5, -1.05858497516774852087e+00) (6, 3.11400651784954851653e-01) (7, -1.90414109567784284316e+00) (8, -3.71852401691032952158e-01) (9, -1.07542468513600955604e-01) (0, 1.89292389638866048740e-01) (1, -2.12366946601706851894e-01) (2, -8.25842252014460376230e-02) (3, -2.53657162749606701624e-01) (4, -2.60725200736362128229e-01) (5, 2.02330914869005029644e+00) (6, 1.72374207659663314374e+00) (7, -1.76418321765491583619e+02) (8, 4.36912700422700872593e+00) (9, 3.15230654023767251082e-02) (0, 2.38605715073789109715e-01) (1, -1.75875318916385692258e-01) (2, -2.21594521524255794187e-01) (3, -1.49357327939813655515e-01) (4, -1.41227500261610128263e-01) (5, 5.86545329991764730071e-02) (6, 4.47267839768372865716e-01) (7, -3.14483177753599498772e+01) (8, 3.86669766313822771409e+00) (9, 4.54468026682559450569e-02) (0, 6.77622080480866778585e-02) (1, -2.33487169069451661052e-01) (2, -1.21669283879203171672e-01) (3, -9.84104786042397927659e-02) (4, -2.58011250567836247782e-01) (5, -1.90280540443528600747e+00) (6, -1.47903448954895488932e-01) (7, -8.75079091219759797049e-01) (8, -6.96513479619405906362e-01) (9, -1.90114874575827513814e-01) (0, 3.71776368208373342306e-01) (1, -2.86314152330955418169e-01) (2, -1.16821929962238182932e-01) (3, -1.13172859103282799631e-01) (4, -2.66395434887012338976e-01) (5, 2.17330728455478539018e+00) (6, 8.12265479015111924177e-01) (7, -1.74259491014079344495e+02) (8, 4.22035429493647917809e+00) (9, -6.33316918705184167537e-02) (0, -1.52599577365737482104e-01) (1, -3.38326890875738806042e-01) (2, -3.14652000476759674541e-01) (3, -4.03743558486145681652e-01) (4, -2.62516532947462744030e-01) (5, 1.13331046756799969089e+00) (6, 1.83525597471147516870e+00) (7, 3.82666147061641148674e-01) (8, 1.14610798972486604974e+00) (9, -5.78370578754308972691e-01) (0, 4.55888557314344133875e-01) (1, -1.75886495286485200484e-01) (2, -2.26913435632249360641e-01) (3, -2.33727244907876441360e-01) (4, -1.81298567229768281539e-01) (5, 1.36368537704633263630e+00) (6, 6.44500873171868660094e-01) (7, 5.73062926498943969733e-01) (8, 1.41077607681548222729e+00) (9, -3.58719644700535467141e-01) (0, 3.00888593979323659688e-01) (1, -2.22705676031512589397e-01) (2, -2.06145441902083725871e-01) (3, -2.10578634214801163616e-01) (4, -2.48731533807916016521e-01) (5, -3.71416568722142625969e-01) (6, 1.36629732155907623881e-01) (7, -1.89236610123212956047e+00) (8, -7.53222969890638555102e-02) (9, -5.54752456671164240198e-02) (0, -6.61630306153820763049e-02) (1, 6.90618147975393809057e-02) (2, 7.03120818263479746557e-02) (3, 1.04004438025374110199e-01) (4, 1.21500390571970581788e-01) (5, -1.32822732238383345305e+00) (6, -1.75485693930766184501e-01) (7, -1.11462939616329670400e+00) (8, -1.48170315491205162317e+00) (9, 4.55678175608209778957e-01) (10, -2.56659555253571425304e-01) (11, -1.84228880740649997305e-01) (12, -2.35267979964034090745e-01) (13, -2.10031059350209714509e-01) (14, -2.41741923899783967000e-01) (15, -1.98230085281527079744e-01) (16, 6.18126923915411907728e-01) (17, 6.74411796790475026597e-01) (18, -1.92629212923295795035e-01) (19, -2.48813818213528714640e-01) (20, 4.66713879415169452525e-01) 
