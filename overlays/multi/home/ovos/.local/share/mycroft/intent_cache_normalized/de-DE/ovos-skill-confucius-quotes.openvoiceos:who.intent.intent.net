FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.76388397470768265585e+00) (1, 5.43857397430472677691e-01) (2, 7.12208831601672365252e-01) (3, 6.05286585085921480243e-01) (4, 6.96949699812464906756e-01) (5, -7.52470877212993438654e-02) (6, 1.15698012509074979470e-01) (7, -6.59709628717442786439e+00) (8, 1.41060184075761013700e-01) (9, 8.41884034739684650184e-01) (0, 1.09162497479635778319e+00) (1, 6.20302470458494736860e-01) (2, 6.16197945607649399946e-01) (3, 4.58467552495943508895e-01) (4, 5.75737597478376827986e-01) (5, 8.11754587942816852042e-01) (6, 2.88974738414192522384e-01) (7, 8.94794166888827476214e+02) (8, 8.29936939519321903447e-01) (9, 4.25808952638783932976e-01) (0, 1.72933545739110283712e+00) (1, 6.28608385019831628071e-01) (2, 5.64737008803420259540e-01) (3, 5.93080075376563264911e-01) (4, 7.15968379669718935077e-01) (5, 3.80634402804451519448e-03) (6, 4.27216393730316321142e-02) (7, -6.59362261788388526185e+00) (8, 6.85776006685254180262e-02) (9, 8.02122489105173031021e-01) (0, 6.14687775988562390417e-01) (1, 1.97093476230665448634e-01) (2, 2.87042473132177622386e-01) (3, 2.07370401049419644801e-01) (4, 2.65330028409525187083e-01) (5, 6.46742471660803786015e-01) (6, 1.50028982820996165115e-01) (7, -8.94833525780374202441e+02) (8, 4.31027177507289305236e-01) (9, 2.58641346246076431203e-01) (0, 2.46827963276153194982e+00) (1, 8.04103513305044037551e-01) (2, 8.94073114787196754349e-01) (3, 8.87934067343330024613e-01) (4, 8.33475151156043869705e-01) (5, -5.67453096708377888180e-02) (6, 4.38054374155584680395e-01) (7, -9.13871603148216138379e+00) (8, 4.41790523518879263420e-01) (9, 1.60462540716126711438e+00) (0, 2.29107031419794626714e+00) (1, 6.52353664167082514247e-01) (2, 6.76593994028723222378e-01) (3, 6.71613213844454270962e-01) (4, 7.08383714087164384487e-01) (5, 1.13123002377828445891e-02) (6, 1.34236511159165766705e-01) (7, -7.02532735031552668659e+00) (8, 1.95425506702290280314e-01) (9, 7.96890080815827905880e-01) (0, 7.13859092022055108373e-01) (1, 4.63798900427054461293e-01) (2, 3.39621749998759325795e-01) (3, 4.47242220224570330434e-01) (4, 3.02830335976313702595e-01) (5, 8.11838680425346681524e-01) (6, 3.22485297403134252292e-01) (7, 8.94823210995430144976e+02) (8, 6.67534426949839332366e-01) (9, 4.51936499664464474968e-01) (0, 6.76019815523608014196e-01) (1, 2.51101697530032808015e-01) (2, 1.84922891403915101716e-01) (3, 2.00725829895021135041e-01) (4, 1.72622318114520723054e-01) (5, 6.72262386585902205205e-01) (6, 1.17937786391627802418e-01) (7, -8.94747913513118419360e+02) (8, 4.73348381442646737316e-01) (9, 5.09139174856373721845e-01) (0, 6.30964530427439496130e-01) (1, 1.79663786189467156174e-01) (2, 1.65892296926886284592e-01) (3, 3.09107543425470920884e-01) (4, 2.59844818608671868088e-01) (5, 7.07186796869467726445e-01) (6, 2.01634893926501308770e-02) (7, -8.94643561821216735552e+02) (8, 4.50347723331226246213e-01) (9, 6.61531943730820581884e-01) (0, 6.87085218305462319677e-01) (1, 4.15503953875731524281e-01) (2, 4.24391721667479571156e-01) (3, 3.72661766888331358327e-01) (4, 3.94021337212752398305e-01) (5, 6.47452958083310048387e-01) (6, 3.37189655235804519595e-01) (7, 8.94816876467103156756e+02) (8, 6.77236781619410255217e-01) (9, 2.93211677560487271599e-01) (10, -2.00190694015295517216e-01) (11, 3.55239335569588032815e-01) (12, -2.38092363755972397099e-01) (13, -2.06082757317930576058e-01) (14, -2.30941467046268805730e-01) (15, -2.18886904477604254948e-01) (16, 3.74483544501510945413e-01) (17, -1.41173895203977939339e-01) (18, -1.69739097112327930184e-01) (19, 3.57856910797802296731e-01) (20, 3.00615120813453762239e-01) 
