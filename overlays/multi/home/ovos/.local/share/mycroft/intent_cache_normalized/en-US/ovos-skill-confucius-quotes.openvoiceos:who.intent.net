FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.86653853156590043838e-01) (1, 4.34685536613908296566e-01) (2, 5.00358344009366518002e-01) (3, 4.57178384950604921322e-01) (4, 4.02324528387036806087e-01) (5, -8.63893910140176468637e-01) (6, -2.18007581626753044191e-01) (7, -3.07044469143532516853e+00) (8, -1.65124069511273507960e-01) (9, 3.97597018527160672718e-01) (0, -1.86922561649325469357e-01) (1, -2.55638267711530975390e-02) (2, -2.20129681737793569951e-01) (3, -2.24938256652725820928e-01) (4, -2.25092714639080648809e-01) (5, 7.74679633323574368120e-01) (6, 2.43458089991684459297e-02) (7, 3.68090147909146914174e+00) (8, -1.21739960694471016645e-01) (9, -4.69136889890562208683e-02) (0, 2.97358773591540503922e-01) (1, 1.58474575210309054363e-01) (2, 1.86514634121155764568e-01) (3, 8.61678379065752564347e-02) (4, 1.07069197524285383838e-01) (5, 1.31350627008792214534e-01) (6, 1.76324920091723957860e-01) (7, -1.47184509852082801018e+00) (8, 1.86565008893455563932e-01) (9, 2.52565215755200411785e-01) (0, 2.81914309676645047364e-01) (1, 3.04055349048135525880e-01) (2, 2.17681766565797574220e-01) (3, 2.48280190940854822435e-01) (4, 2.27241271253583704270e-01) (5, -7.97058540013139471547e-01) (6, 3.39899281542291945013e-02) (7, 1.04236503488585920962e+01) (8, 3.06346223767755276857e-01) (9, -1.03432089598895021743e-01) (0, 2.27632041963360981507e-01) (1, 1.79854165244793917644e-01) (2, 1.15629258979058319179e-01) (3, 1.33346400637126050182e-01) (4, 1.80354486633038546550e-01) (5, 1.03635301653262443256e-01) (6, 2.19224364791011372411e-01) (7, -1.49286215447933745537e+00) (8, 1.18609760835613337049e-01) (9, 1.27430542785620770641e-01) (0, -3.17312810842040160519e-01) (1, -4.09796144679914625675e-02) (2, -9.69786550716291578800e-02) (3, -1.10105385990513449102e-01) (4, -3.35343684867750319034e-02) (5, 2.37077886959816047652e-01) (6, 7.72624848052139850951e-02) (7, 3.76959356304628023793e+00) (8, -1.95755950594106331586e-01) (9, -1.11764935763252859502e-01) (0, 2.33845570202825342454e-01) (1, 2.88754166182039029298e-01) (2, 2.17728995796201474366e-01) (3, 3.08381275351999051271e-01) (4, 1.93888274099586227495e-01) (5, -7.81248184469049200551e-01) (6, -3.23610310871610407091e-02) (7, 1.04182567841575117740e+01) (8, 3.32413883026597745118e-01) (9, -6.91608791668424371935e-02) (0, 5.21345213004374086196e-01) (1, 3.72575172176805025082e-01) (2, 5.06427139928784852962e-01) (3, 4.33127158275094514828e-01) (4, 4.27198977163281923275e-01) (5, -8.59147137791295700815e-01) (6, -2.28114830648283195558e-01) (7, -3.02971843208454849616e+00) (8, -1.24619204162934427149e-01) (9, 3.80676384913097409779e-01) (0, 5.68883765437626420791e-01) (1, 4.44616460195031648617e-01) (2, 5.20255998661962038021e-01) (3, 3.72218974819627290707e-01) (4, 3.59949649265256410580e-01) (5, -7.55045956761022263315e-01) (6, -1.69469015991071891847e-01) (7, -3.08451881583117248908e+00) (8, -1.32677416860440378077e-01) (9, 3.80744714187751798207e-01) (0, -2.04922069136145718060e-01) (1, -3.97144462779890211612e-02) (2, -7.79575910285841139347e-02) (3, -3.09237595514189056445e-02) (4, -7.44792427734266432315e-02) (5, 2.78494561812187291228e-01) (6, 5.01543817683334849922e-02) (7, 3.71179898467284807850e+00) (8, -1.79176471614995613812e-01) (9, -8.29778220371137770206e-02) (10, -9.50731541828046949894e-02) (11, 5.44764537313007890518e-01) (12, -4.43950947240720900089e-02) (13, 3.68204360759101123612e-01) (14, -4.06565125898252638370e-02) (15, 5.33367175557636796768e-01) (16, 4.42270932650408954423e-01) (17, -1.04269264252556448369e-01) (18, -9.01299323753248365909e-02) (19, 2.58266687335990119401e-01) (20, 3.65535348085987310540e-01) 
