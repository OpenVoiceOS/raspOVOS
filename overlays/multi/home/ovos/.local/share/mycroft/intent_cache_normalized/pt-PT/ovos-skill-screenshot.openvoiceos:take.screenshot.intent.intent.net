FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.71936772486012356964e-01) (1, 7.58523627241262210497e-01) (2, 6.88422086705573810228e-01) (3, 7.84981741626867068895e-01) (4, 6.40762976427682651170e-01) (5, 3.96116877165361203073e-01) (6, 9.67759220456720692383e-01) (7, -8.35630351188524755912e+00) (8, 5.82448720990120261121e+00) (9, 9.05997337000389202366e-01) (10, -4.50369070832399576165e-01) (11, 1.50443724440902726336e+00) (0, 1.04270420419284781666e+00) (1, 1.98072568737254373072e-01) (2, 2.72152804993376906673e-01) (3, 2.04582260214076272486e-01) (4, 1.10506952964053536959e-01) (5, -1.30297839924747371754e+00) (6, 1.58732625604193405833e-01) (7, 4.49198053788469167102e+01) (8, 9.50272764881301523765e-01) (9, -1.87955686749670936031e+00) (10, 2.91682303307949308824e-01) (11, 2.65761873671298110011e-01) (0, 3.02474075724709856594e-01) (1, 1.59456950041278411323e-01) (2, 2.21115988108142202950e-01) (3, 7.16745074715457175518e-02) (4, 2.38668855639918603417e-01) (5, -1.85066583392522110429e+00) (6, 1.32341060815619387947e-01) (7, 4.50861874755547376026e+01) (8, 2.98010451378123153443e-01) (9, -2.41688169079591119726e+00) (10, 8.83742841633938097656e-02) (11, 1.30002060651215001208e-01) (0, -2.62095575639187061689e-01) (1, 1.87085673912889202675e-02) (2, -2.07568674579733242203e-02) (3, 3.49411324366456638169e-02) (4, -1.24758844007598720949e-01) (5, 1.66485226157460516561e+02) (6, -6.07445932192064719235e-02) (7, -1.17422661147735057918e-01) (8, -4.48406293757729890181e-02) (9, 9.91894040630534212788e-01) (10, -1.85453871844688082671e-02) (11, 9.59594001005370685065e-03) (0, 1.04737833565220950227e+00) (1, 6.57573160227571618108e-01) (2, 8.21936738189493310003e-01) (3, 7.10873995419775139837e-01) (4, 6.55645709928308617620e-01) (5, -6.56215547107413477157e-01) (6, -3.09556643754397375901e+00) (7, -6.48067857019564641519e+00) (8, 9.71593406886375299258e-01) (9, -2.06221245923564344693e+00) (10, -1.02270986563261123692e+00) (11, 1.18004295130124003954e+00) (0, 1.03771956664935527392e+00) (1, 1.82877479984820845438e-01) (2, 1.59145577743113997293e-01) (3, 2.15633957579196455789e-01) (4, 2.82357095673144875558e-01) (5, -1.98483900916384925495e+00) (6, 2.40154440463106716441e-01) (7, 4.49540892552659840931e+01) (8, 6.22084558314715208027e-01) (9, -2.43836126762200677831e+00) (10, 9.27751495381689550435e-02) (11, 2.97223770308089219050e-01) (0, 1.58329151861280631453e-01) (1, 1.02268157169222037584e-01) (2, 7.51577444523564841550e-02) (3, 1.05377969905733268052e-01) (4, 1.07116935417055289537e-01) (5, 3.52575728377240160683e-01) (6, 9.17606781337156340861e-02) (7, 3.59586512330441532281e-01) (8, 1.88879883684432120505e-01) (9, -4.67589979980119441194e+00) (10, 2.28980704899363007865e-01) (11, 8.76548787414602459389e-02) (0, 1.15896076160107400210e-01) (1, 3.71612840779912134703e-01) (2, 3.84045356401097492949e-01) (3, 4.06293259450089705442e-01) (4, 3.86378200241219715849e-01) (5, 5.85802245403239663091e-01) (6, 1.42314343106387991567e-01) (7, 3.67213707802985622752e-01) (8, 3.01183395454145907966e-01) (9, -6.18822922941916431228e+00) (10, 2.60067513691453588986e-01) (11, 5.40901831787934175844e-02) (0, 7.24352447859835213428e-01) (1, 7.06707625904101188752e-01) (2, 7.17249996283072288605e-01) (3, 6.81591636755484397980e-01) (4, 7.84707672216910179230e-01) (5, 1.58192158415951689143e-01) (6, 4.01265358281181760969e-01) (7, -6.73835184045826807164e+00) (8, 5.91241090057789087098e+00) (9, 1.04707252184251209393e+00) (10, -4.29631214205889011559e-01) (11, 1.37732865956030914312e+00) (0, 3.03880386785673772820e+00) (1, 2.68656946907809501823e-01) (2, 2.93824158798030143913e-01) (3, 1.88692420910170632897e-01) (4, 9.54152496560125712444e-02) (5, -2.28276978356265036751e+00) (6, 1.51753013304198436373e-01) (7, 4.49099030878470273365e+01) (8, 6.60562098116329599051e-01) (9, -2.86282925551533118380e+00) (10, 4.05093432364129923950e-01) (11, 2.99020827777864206531e-01) (12, -1.66328506471870862793e-01) (13, 2.27955722025844770284e-01) (14, 3.05196279546464332988e-01) (15, 1.44722616739209186676e+00) (16, -1.73244568970383122641e-01) (17, 2.20243253520939069601e-01) (18, -1.46337274296327951584e-01) (19, -3.25293811155950574054e-01) (20, -1.54550092222450696777e-01) (21, 2.38475933203940643201e-01) (22, 1.95627263049908489689e-01) 
