FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=14 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.84539762360969117339e-01) (1, 5.76942662996688060417e-01) (2, 6.24819222194590850883e-01) (3, 6.38088959557452484184e-01) (4, 5.72237576646247081413e-01) (5, 2.16247117555137008393e-01) (6, 1.74809789646071661595e-01) (7, -6.20086443505053264147e+00) (8, 1.64147000866460390789e-01) (9, 4.11471365451118176182e-01) (10, 4.38843930140343896351e-01) (11, 1.87917561148862516385e-01) (12, -1.93073140056196079772e-01) (13, 3.51234915115717805101e-01) (0, 2.55959885171098466827e-01) (1, 5.30465460148215162128e-01) (2, 4.08541875657200626026e-01) (3, 3.92298835095524656147e-01) (4, 4.61587867465376722187e-01) (5, 4.96701418833581764822e-01) (6, 1.54455311551679130844e-01) (7, 1.04471375780903736086e+03) (8, 1.69988760482986639433e-01) (9, 5.21622887573859106425e-01) (10, 3.87344466062458314681e-01) (11, 1.95834093426739325183e-01) (12, 3.24364228538395971135e-01) (13, 4.64013939493492844068e-01) (0, 1.34340175889088975225e-01) (1, 3.46296081390494947527e-01) (2, 2.73643778708095197771e-01) (3, 2.97760965373630170916e-01) (4, 2.55769999768848010913e-01) (5, -2.42145783353574922669e-02) (6, 2.02991180077184196762e-01) (7, 1.04479786792003551454e+03) (8, 3.35750931632240512403e-01) (9, -4.47007202660433311525e-01) (10, 3.55132592561464954795e-01) (11, 3.11627492639293790511e-01) (12, 3.34497878692271322087e-01) (13, -1.26608803341256639929e-02) (0, 1.53693386561079836650e-01) (1, 6.75014511828706087471e-01) (2, 5.95453255956456484199e-01) (3, 5.14403105860040010811e-01) (4, 6.55676753406808199287e-01) (5, 4.81245308594552834158e-01) (6, 2.09429405584920402816e-01) (7, 1.04472271117919126482e+03) (8, 3.33265984189232089552e-01) (9, 5.92538935011663436825e-01) (10, 3.99022534096555803185e-01) (11, 3.83072578745045522197e-01) (12, 3.82843179808931455277e-01) (13, 7.71233610223802878991e-01) (0, 3.60391878509164931277e-01) (1, 7.01863352130922435457e-01) (2, 7.33456227849992870027e-01) (3, 6.41777690421613811189e-01) (4, 6.51029076348814128572e-01) (5, 7.79564789958915038692e-02) (6, 2.42563848577023150055e-01) (7, -6.44347984168283094419e+00) (8, 1.16311359986370599362e-01) (9, 4.58409542512288770144e-01) (10, 4.40823173779627652813e-01) (11, 1.34839364372328907038e-01) (12, -4.58930212694049599609e-01) (13, 3.60053400595982064925e-01) (0, 1.04008870208331341556e-01) (1, 5.01319891538977491230e-01) (2, 4.50063190188765394062e-01) (3, 4.45780559208750593037e-01) (4, 4.97124782529234754413e-01) (5, 2.99960925481199014442e-01) (6, 2.62911140874017235092e-01) (7, 1.04475824807190338106e+03) (8, 3.59331169855316323591e-01) (9, 3.33753078005930847727e-01) (10, 2.28568715096239771789e-01) (11, 3.37463185822044986484e-01) (12, 3.83590430135550719548e-01) (13, 6.36351310486814703005e-01) (0, 9.05573991915896048255e-01) (1, 2.13272446277460725472e-01) (2, 3.06831003609022767709e-01) (3, 3.14186894777140290902e-01) (4, 3.65565614285787987559e-01) (5, 9.10870474106236782674e-02) (6, -9.28160944980074426036e-02) (7, -8.04668853575161733716e+02) (8, -1.57485174601527222471e-01) (9, -1.77364336434690655908e-01) (10, 2.86149497989022394417e-01) (11, 3.70046843579193485141e-01) (12, 7.19087935789401000442e-01) (13, 4.62058511940282967689e-01) (0, 1.51205329280757333477e-01) (1, 4.92473519173025953144e-01) (2, 3.63928249802946857105e-01) (3, 4.95914182391524183124e-01) (4, 4.43990177240729200214e-01) (5, 3.97842317125676914191e-01) (6, 1.73828616693604942611e-01) (7, 1.04467596790545621843e+03) (8, 2.98733884226997536970e-01) (9, 2.60673883741933815061e-02) (10, 3.81825444341425568329e-01) (11, 3.02931078409229892490e-01) (12, 4.56445463115992711156e-01) (13, 3.67828574710746203369e-01) (0, 1.17289870223648851066e+00) (1, 5.00778245133420285562e-01) (2, 5.66323468786736339275e-01) (3, 4.13146848184129111825e-01) (4, 5.07175939482709003947e-01) (5, -5.99841705580596906699e-01) (6, 1.77987206608841330713e+00) (7, -5.62167261904659820715e+00) (8, 1.80953507006952674097e+00) (9, 1.81003054737904900406e-01) (10, 7.15340180645041567864e-01) (11, -7.46203241081996315742e-02) (12, 1.86254824563919257896e-01) (13, 4.01321425064060877119e-01) (0, -5.91214986644529094661e-01) (1, -1.65089745039934593374e-01) (2, -2.43852723355287986928e-01) (3, -3.00329815561766078069e-01) (4, -2.22419459338182884389e-01) (5, -5.73226217442701302396e-01) (6, 3.32653387963110225289e-01) (7, 8.04845248263052781112e+02) (8, 1.66482165734786136113e-01) (9, 2.75197376700392487558e-02) (10, -4.32502214669801099411e-01) (11, -6.52472408571744155736e-01) (12, 2.82902934166617929523e-02) (13, -5.50261949108365677752e-01) (14, -1.06569356318484131929e-01) (15, 2.57826408913278126711e-01) (16, 2.70489609410905273990e-01) (17, 2.31780073216104026690e-01) (18, -1.09859204884539429781e-01) (19, 2.27417728474282737627e-01) (20, -3.40203728553241879773e-01) (21, 2.46989926865243430987e-01) (22, -3.14427990060627660096e-01) (23, 5.16337760708978965596e-01) (24, 1.57697248546903645572e-01) 
