FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.03061779080323785707e-02) (1, 2.66950064763967431780e-01) (2, 2.99462185666505731341e-01) (3, 1.78710216150228418108e-01) (4, 3.15115915105287469622e-01) (5, 8.02651598641941710355e+00) (6, 4.00895339129883898632e-01) (7, 9.13657893483638128274e-03) (8, 9.78201990300893581276e-02) (0, 6.13994324225223153668e-01) (1, 3.76681885785415115908e-01) (2, 5.25097373045041448947e-01) (3, 3.99792987025334778384e-01) (4, 4.19260378099038544253e-01) (5, -3.26870094887603102052e+00) (6, -5.18769503529196152058e-01) (7, 2.73219737620877922701e-01) (8, 3.93330276157218328148e-01) (0, -2.47339953245230316503e-02) (1, 3.42604942941927392841e-01) (2, 2.04100840115808868092e-01) (3, 2.20237631672882461231e-01) (4, 3.71045984649919946552e-01) (5, 8.04660975897977515103e+00) (6, 2.33312775073964473460e-01) (7, 8.47529088432072835735e-02) (8, 6.66281347448109823040e-02) (0, -5.86323340000219905832e-02) (1, 3.58981825733446557880e-01) (2, 3.67739253068232019306e-01) (3, 3.29064555788301904560e-01) (4, 2.85197556340956170917e-01) (5, 8.06656848604152365567e+00) (6, 3.23497299729306408977e-01) (7, 4.43379645520924903224e-02) (8, -2.43475707894085791061e-02) (0, -1.05463241317789657714e+00) (1, -2.42358170801369565694e-01) (2, -1.88262097889153379171e-01) (3, -2.06924550586907285421e-01) (4, -3.09428818875519651144e-01) (5, 1.91091555446384964156e+00) (6, 4.11554748279180759862e-01) (7, 1.07065260677327751815e-02) (8, -1.75400209903408293988e-01) (0, 1.92059103449141543862e+00) (1, 2.88862760531442275269e-01) (2, 3.00981502401368727906e-01) (3, 3.27561247515218367798e-01) (4, 3.60038320886628626649e-01) (5, -2.62159833251969187629e+00) (6, 3.89550223156162889193e-02) (7, 3.01578214860355187099e-01) (8, 5.48854856241608568546e-01) (0, -1.06148584464113815429e+00) (1, -2.23655104988781827657e-01) (2, -2.04022504740921872823e-01) (3, -2.44970038884846585958e-01) (4, -1.86377875858513730734e-01) (5, 1.82737340122459945846e+00) (6, 3.66069423121538395360e-01) (7, -1.99462887923779544352e-02) (8, -1.44922029708704047657e-01) (0, -1.02413845339338882567e+00) (1, -1.44778319054810422628e-01) (2, -1.92631461077896970480e-01) (3, -2.98598345720736402242e-01) (4, -1.92189492636887448995e-01) (5, 1.75974482387302932906e+00) (6, 4.78760147554006809667e-01) (7, -3.94265991728367862224e-02) (8, -8.48565814245548777350e-02) (0, 6.76849657315051644879e-01) (1, 3.43906822717740479067e-01) (2, 5.12409764445378668185e-01) (3, 4.14458180881097260073e-01) (4, 3.50184346652581635073e-01) (5, -3.15982799134839353883e+00) (6, -5.21457754964952835408e-01) (7, 2.07411970408487023043e-01) (8, 4.18069191421824803978e-01) (0, -1.75415177406378387792e-02) (1, 3.09453942203783471943e-01) (2, 3.56967531466745813251e-01) (3, 2.27630559677147292774e-01) (4, 2.55189344609045409840e-01) (5, 8.06139060074756308438e+00) (6, 4.14777603624779889202e-01) (7, 8.68484889442204671672e-02) (8, -3.48202707892178442428e-02) (9, 3.25552355659918191133e-01) (10, -1.04026538239999938318e-01) (11, 3.78222186280207040010e-01) (12, 3.45916498614267708955e-01) (13, 5.22513189892613416632e-01) (14, -1.39313803161661697860e-01) (15, 5.54357966016375547369e-01) (16, 5.65530849228941701057e-01) (17, -5.95136256089650664269e-02) (18, 3.43143437219576241670e-01) (19, 5.37267866987024445002e-01) 
