FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.30432490174411741535e-01) (1, -1.47991381796231280532e-01) (2, -2.10804090114464770522e-01) (3, -1.34642355354657128341e-01) (4, -1.91221151711573611465e-01) (5, 7.58890714093785473393e-02) (6, -1.90884035743020485931e-01) (7, 1.21466761965639408194e-01) (8, 2.38037612702243384089e-01) (9, -3.40738220627819665687e-01) (10, 9.43036875226600290745e-01) (0, 1.03358676227736268061e+00) (1, 8.21163981115545782430e-01) (2, 8.43681122070278788350e-01) (3, 8.22088348573174032552e-01) (4, 7.91615868812527101461e-01) (5, 9.63383922582954799196e-01) (6, -9.58316249618639304231e+00) (7, 9.69339849802904995890e-01) (8, 2.16504279644636454805e+00) (9, 3.52634812686389853553e+00) (10, -7.77448385617374837508e-01) (0, -3.68651773060822363082e-01) (1, -1.82110577819659502641e-01) (2, -5.87160550037167314197e-02) (3, -1.06312241403176591104e-01) (4, -1.51382353154732973710e-01) (5, 1.89544961546463691660e-01) (6, -3.50292688032479815341e-01) (7, 2.39874965797397782241e-01) (8, 6.85588879561942587948e-01) (9, -1.89656731271898942870e-01) (10, 7.66955116458007513103e-01) (0, -1.14307130663748354737e-01) (1, -8.74715125513646774014e-02) (2, -1.88297731275615415347e-01) (3, -2.46166591937598933093e-01) (4, -1.25369561309871452304e-01) (5, 5.28889777795703674990e-01) (6, 8.00190722285787803258e-01) (7, 1.40710787785518764981e-01) (8, -2.13486326397998027460e-02) (9, 4.36919564481650368748e-01) (10, -1.22655078693341829110e-01) (0, 4.89201304275074910777e+00) (1, 7.01292136795582776720e-01) (2, 6.88978219516339307482e-01) (3, 7.62422250695290570910e-01) (4, 8.28144321329655652697e-01) (5, -3.56861330808656451730e-01) (6, -8.98194716542903393020e+00) (7, 9.41230305040342551948e-01) (8, 2.16684904187481264248e-01) (9, -2.75273605749087835193e+00) (10, 2.24870166038087480886e-02) (0, -1.99412714723265382943e-01) (1, -8.53390967798803024014e-02) (2, -1.77540575559196195377e-01) (3, -1.62309718723354062808e-01) (4, -2.60458079571780909411e-01) (5, 4.64995125965507183352e-01) (6, 1.03790092684283674629e+00) (7, 4.19833901648408169827e-02) (8, -8.46034789783923768525e-02) (9, 4.53630014610653109486e-01) (10, 1.89370873956809966654e-02) (0, -4.20265164528029033786e-01) (1, -5.93801997581265214587e-02) (2, -2.25987698880746157304e-01) (3, -2.12030176071240694657e-01) (4, -2.28522095827176363603e-01) (5, 1.34895623420281163263e-01) (6, -3.62241115879200437089e-01) (7, 1.29373028229209957596e-01) (8, 7.07518915370352274863e-01) (9, -2.41868030810511253081e-01) (10, 8.03901444574049883762e-01) (0, -1.88980963114416755655e-01) (1, -1.37953428025302610171e-01) (2, -2.20821117456016263736e-01) (3, -1.14749205703792350741e-01) (4, -1.22262460584697474353e-01) (5, 6.33061478571326996523e-01) (6, 8.09784297421904053493e-01) (7, -4.28640004868620777545e-02) (8, -6.22523955637874146229e-02) (9, 4.22520265492061453116e-01) (10, 1.36222122946275198130e-01) (0, -2.74255718898258782357e-01) (1, -8.28189190183455270500e-01) (2, -8.22811495219046395988e-01) (3, -9.02048613582426939139e-01) (4, -1.01212614372807219176e+00) (5, 6.97012183682684582919e-01) (6, 1.15869336035767460658e+01) (7, 8.47206535289529438781e-02) (8, -1.64705914565411482009e+00) (9, 2.69201187931774832407e+00) (10, 2.84574000097833124112e-01) (0, 1.68334331026505745754e+00) (1, 2.04878606851888717122e-01) (2, 2.22379946168256847905e-01) (3, 2.29355835374189465092e-01) (4, 9.83161265214215762676e-02) (5, -1.42302713272980635439e-01) (6, -1.03387219018744538346e+01) (7, 3.99315290278763290743e+00) (8, 3.05389957112395862282e+01) (9, 2.77688246099122748589e+00) (10, 1.30259867110083443764e-01) (11, -1.32018006953640576473e-01) (12, 4.59726175315089635731e-01) (13, -1.83057258097668262842e-01) (14, 3.17019164093561289786e-01) (15, -4.27674744272891538266e-01) (16, 3.55899008730830912484e-01) (17, -2.25564362673302293283e-01) (18, 8.97113728016340206128e-02) (19, 6.12339130715028434615e-01) (20, 5.50675488840482896258e-01) (21, 2.86034500914892686474e-01) 
