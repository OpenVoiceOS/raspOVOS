FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.84530684032735681210e-01) (1, -1.06194308096635964267e-01) (2, -1.08639864320028450839e-01) (3, 1.22598738027748397836e-03) (4, 1.90563145334833525246e-02) (5, -4.34813434274388233014e-01) (6, 6.05299016216772955978e-01) (7, -2.05209629779254640880e+01) (8, -5.61773077053904223988e-01) (9, -2.34992541828682427463e-01) (0, 7.62899256866776731556e-01) (1, 4.57261867586757131399e-01) (2, 3.24983332071687058829e-01) (3, 4.42308701340342946828e-01) (4, 4.04247797791148610891e-01) (5, 5.78940625458953217475e+00) (6, -4.07055750968196780604e-02) (7, 2.42982995193820201507e+01) (8, -3.21659262180661054131e+00) (9, 4.53517228836983893325e-03) (0, 2.17226743378934772366e-01) (1, -7.20066223983651804152e-02) (2, 4.48362919743173979348e-02) (3, -1.55648124163037873680e-02) (4, 4.28573283608072660988e-02) (5, 1.19273896967189574347e+00) (6, 4.99856786558407650833e-01) (7, -2.05550081749951090160e+01) (8, -5.24780499938837241558e+00) (9, -1.95738696017792174198e-01) (0, -7.82739303342734893398e-01) (1, -2.76661896163501591639e-02) (2, -1.31478794758943501320e-01) (3, -4.84578990394153516497e-02) (4, -1.04595095759061784690e-01) (5, 4.83563934187066946091e-01) (6, 3.78721140444930381985e-01) (7, 2.29505071822879536114e+00) (8, 2.09394218022365841136e+00) (9, -3.78661412240839587162e-02) (0, 2.24774501898584277981e-01) (1, -8.21814891641026862290e-02) (2, 2.83488723690622709817e-02) (3, 7.18452960802254229911e-03) (4, -1.04290423983801047725e-01) (5, -1.88214751231314744717e-02) (6, 5.02639384696263236130e-01) (7, -2.05566590001379694286e+01) (8, -1.05938435046304935128e+00) (9, -1.51400939086010405399e-01) (0, 2.08360887744722278470e-01) (1, -9.20609292333013223830e-02) (2, 2.87762972767465971535e-02) (3, -1.03113373810518424434e-01) (4, 1.42193678076380156106e-02) (5, 6.47820809010247328219e-03) (6, 5.28828559199351233566e-01) (7, -2.04027773310934747997e+01) (8, -1.08224411754240268380e+00) (9, -1.28672890821030061481e-01) (0, 5.22642402752323587123e+00) (1, 2.24028505598408977928e-01) (2, 2.35528193627698223533e-01) (3, 2.47565016363961526435e-01) (4, 1.79145347540481031379e-01) (5, -1.75373991051081401515e+00) (6, -8.51978045185640409098e-02) (7, -4.72638788928936071088e-01) (8, -1.25023628501941530544e+00) (9, 7.52055150933697569293e-02) (0, 3.24658006110486840878e-01) (1, -3.70937406467261848036e-03) (2, -8.00008532349950202134e-02) (3, -3.30368250058951911513e-03) (4, -7.46797491555100945160e-02) (5, 1.19504708130972647773e+00) (6, 4.61571579555052624588e-01) (7, -2.04888938610946382823e+01) (8, -4.07556839963223627166e+00) (9, -7.47503121285938987306e-02) (0, 5.38464527606053788844e+00) (1, 6.63501145522632840290e-01) (2, 5.30236037652531133624e-01) (3, 6.71221332829036954060e-01) (4, 6.82232858817615861469e-01) (5, -4.00618872085043342679e+00) (6, -3.49679354768203110027e-01) (7, -4.48599386324832982709e-01) (8, -1.17371064155151216823e+00) (9, 2.53570842425673959042e-01) (0, 7.59510628503167417591e-01) (1, 4.29975442353869863332e-01) (2, 3.61872508887435384572e-01) (3, 3.22385202858830766104e-01) (4, 3.41431773964549489797e-01) (5, 5.80929405212399796454e+00) (6, 4.18224329927175536570e-03) (7, 2.42209234815459453216e+01) (8, -3.57846388888727373612e+00) (9, 8.75569024729247469274e-02) (10, -1.18196649545896662059e-01) (11, 3.84254321221496053518e-01) (12, -1.72026723322010577366e-01) (13, 7.32906055591159844020e-01) (14, -8.34670048897153266099e-02) (15, -5.05055320207959679291e-02) (16, -3.57071750510566832126e-01) (17, -1.78806091150809726154e-01) (18, -3.57182078615527587306e-01) (19, 4.57741774384166189016e-01) (20, 2.43225139875463847172e-01) 
