FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.84653508252707709847e-01) (1, 6.04841264539599451910e-02) (2, 1.08116552477443200742e-01) (3, 6.89690674298643890960e-02) (4, 1.72158561890685568585e-01) (5, 7.96957262335539540210e-01) (6, 1.09958997224825702488e-01) (7, 2.90458256576972040364e+00) (8, -1.04341187990173391853e+01) (9, 1.03538554643604965855e-01) (0, 2.34475270684050052239e-01) (1, 2.70325392680688669778e-01) (2, 2.53750518160386906441e-01) (3, 1.32987767653985844429e-01) (4, 2.65006199675126841164e-01) (5, 1.33221048548770215625e+00) (6, 2.18829157568100701736e-01) (7, 4.85628655793125396656e+00) (8, -9.11082233124013152192e-01) (9, 1.59934868697595045095e-01) (0, 1.87194803157211347999e-01) (1, 2.69879296618028452492e-01) (2, 2.14862004118486271675e-01) (3, 1.58760324316545353707e-01) (4, 1.95739686685129032906e-01) (5, 1.00886875380676491187e-01) (6, 6.41627882557045808865e-02) (7, 5.25179191559186797633e+00) (8, -9.60388595991368498872e-01) (9, 1.29759911049664777849e-01) (0, 8.78404616038453767146e-01) (1, 6.43615521499253051552e-01) (2, 7.84398630270100372108e-01) (3, 8.10097560295201080116e-01) (4, 6.93162992605305450233e-01) (5, -1.49581667948211882724e+00) (6, 1.70729013790336447975e-01) (7, -4.70835191176119849388e+00) (8, -1.12279952667936200328e+00) (9, 3.73038738578625905795e-01) (0, 4.30497925349152266161e-02) (1, 7.37012985714352031330e-02) (2, 1.10772969908324470101e-01) (3, 2.09607782549468268929e-01) (4, 1.19496549255458106575e-01) (5, 4.31055618990018041270e-01) (6, 2.34447358404654332409e-01) (7, 2.91293847822925333624e-01) (8, -4.65057784568257481794e+00) (9, 1.50101905917185668438e-01) (0, 1.24863599785924941910e-01) (1, 1.71931311684175358589e-01) (2, 1.83605067627950535591e-01) (3, 2.60348603325410654641e-01) (4, 2.43499130206628666695e-01) (5, 3.99192912511588171576e-01) (6, 9.21846901016365738446e-02) (7, 3.75106352235022866282e+00) (8, -9.01154088609452452729e-01) (9, 1.58532870276464121773e-01) (0, 8.64966227333200166072e-01) (1, 5.30612307860042542451e-01) (2, 6.29934127701904045260e-01) (3, 5.52725679500486344331e-01) (4, 5.17445701433803639802e-01) (5, -2.63629610875817110838e+00) (6, 7.12338829583962329650e-01) (7, -2.90004009050955824378e+00) (8, -1.51835987785519765936e+00) (9, 4.34741347772146791151e-01) (0, 2.61535362699390427910e-01) (1, 2.36015469031854496773e-01) (2, 1.82165160971208439644e-01) (3, 1.49473533230348454293e-01) (4, 2.14972943263574467476e-01) (5, 2.21518383909862615067e-01) (6, 1.76058602793706553413e-01) (7, 5.56036050852173868719e+00) (8, -1.00131503754162332065e+00) (9, 1.52979587479127543403e-01) (0, -3.25917828473233528452e-01) (1, -1.70076020473515165943e-01) (2, -5.91072444262854129748e-02) (3, -1.04994401747261656421e-01) (4, -1.96919944548880232471e-01) (5, 5.24953300030036151824e-01) (6, -1.75277701998462209776e-01) (7, -8.22029180027046557644e-02) (8, 2.56427292015377883416e+00) (9, 2.49301958532137768465e-01) (0, 2.62476445534587876640e-01) (1, 2.74704396920724680520e-01) (2, 1.77446045177503453072e-01) (3, 1.93334944742246495064e-01) (4, 1.20538912909551487740e-01) (5, 1.38507583727043359634e-01) (6, 1.54925485415948527290e-01) (7, 5.32422125964990478053e+00) (8, -8.40760159127946105073e-01) (9, 9.13489659266602249676e-02) (10, -3.84284731332330986575e-01) (11, 2.55327508049531803902e-01) (12, 2.79746581376657199591e-01) (13, -2.25548624637507799662e-01) (14, -1.68481990144196458470e-01) (15, 1.99303604858442173775e-01) (16, -2.41729758325003984964e-01) (17, 2.37825855808778630074e-01) (18, 6.32574610852547625228e-01) (19, 2.44603161276445130179e-01) (20, 1.34964179443641529854e-01) 
