FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.48005919215504722075e+00) (1, -2.19364672791918291495e-01) (2, -2.49260857593973539359e-01) (3, -3.60205382001360596700e-01) (4, -3.12903631371220292134e-01) (5, -5.30241692852372215050e-01) (6, 6.26053197376567199806e-02) (7, -1.54816899708046351591e+00) (8, -1.26274221562222055404e+00) (9, 2.78376500062331277974e-01) (10, -4.32064068972613402053e-01) (0, 4.59978153922436516776e-01) (1, 4.72247538069092087643e-01) (2, 4.96463430026375107662e-01) (3, 5.13527464965187419033e-01) (4, 4.05125089833341889278e-01) (5, -4.67622888276708448263e-01) (6, -3.34309140178452501857e+00) (7, 6.60226504423493842921e-01) (8, 4.33273253240636257999e-01) (9, 9.53742095997263672480e-01) (10, 3.09241373139708397577e-01) (0, 1.07362170869574491405e+00) (1, 4.03075199682178808569e-01) (2, 5.36282304782333740789e-01) (3, 3.81010409552517137488e-01) (4, 4.53155424553814523136e-01) (5, 1.08319268939263713136e+00) (6, 4.05609726111185397990e-01) (7, 3.92244895288244732612e+00) (8, 1.12233618488868924779e+00) (9, -3.59882486476189233926e+00) (10, 8.54135000514167019858e-01) (0, 1.43962897165194531057e-01) (1, 4.48729657729671771449e-01) (2, 5.16083934505985331143e-01) (3, 3.68900672694252251826e-01) (4, 4.53375564118431384486e-01) (5, -1.61765075501544619563e-01) (6, -3.46016797284967925208e+00) (7, 7.87328484573239895106e-01) (8, 2.57672183459672576866e-01) (9, 1.53906556343778255780e+00) (10, 2.41622282322020931478e-01) (0, 1.61387699999825322550e+01) (1, 3.29127720827876544263e+01) (2, 3.28727530548988795545e+01) (3, 3.29386408562480426099e+01) (4, 3.29140134836255526807e+01) (5, 1.96528752182861983500e-03) (6, 1.81676792187172231330e+00) (7, 9.69145265572564640344e-01) (8, 2.98947153701380252677e-01) (9, -3.34576449780536577805e+01) (10, 4.51059494583043507632e-01) (0, -9.63701388778000933577e-01) (1, -3.51115670556648329370e-01) (2, -2.48807739967926155877e-01) (3, -3.76664355898721769922e-01) (4, -2.89304357523544275477e-01) (5, -1.45195896851153261053e+00) (6, 1.50000000000000000000e+03) (7, -3.16820223564019398665e+00) (8, -2.22374614880027898778e+00) (9, 1.99533607893321507376e+00) (10, -5.69976399042428583108e-01) (0, 7.68939742536981007959e+00) (1, 1.09831926212690911271e+00) (2, 9.74148429790960279639e-01) (3, 9.98696297267900323646e-01) (4, 1.06823788569353661515e+00) (5, -5.18803571625215731444e-01) (6, -3.96159300607664777161e+00) (7, 7.52365521377184376384e-01) (8, 1.82311977144539838491e-01) (9, -4.67603124935114078387e-01) (10, 2.89931138062452853355e-01) (0, 3.65309548415522922227e+00) (1, 1.08835808918856224992e+00) (2, 9.71939742425905195411e-01) (3, 1.02379873381041108793e+00) (4, 9.10375900427327855446e-01) (5, -4.48954236968023556731e-01) (6, -3.86533014130814267517e+00) (7, 6.37088071069388028889e-01) (8, 2.64440568980038759328e-01) (9, -4.50967431325399570330e-01) (10, 3.20538880433508199808e-01) (0, 1.24262155397565465798e+00) (1, 4.69202251099388623068e-01) (2, 4.68149454258720898459e-01) (3, 4.79739979766647894888e-01) (4, 4.15677935742180093559e-01) (5, 8.35335963794404667837e-01) (6, 4.80708101662067288640e-01) (7, 3.08691252797059867419e+00) (8, 1.30176691494572716046e+00) (9, -3.42323737642764802658e+00) (10, 1.00481416403891921085e+00) (0, -4.04377843900859534898e+00) (1, -2.30900146720393106836e-01) (2, -1.74917072710974286220e-01) (3, -1.65073201713545392177e-01) (4, -1.51837453899366869869e-01) (5, 1.02854332561104522270e+00) (6, 7.22289875349621190992e-01) (7, -5.43508003955424645604e-01) (8, -1.56155607047622463357e-01) (9, 8.15303132453308321281e-01) (10, -2.47947182989657149976e-01) (11, 5.95467286379127602736e-01) (12, 4.50738210872455247191e-01) (13, -1.42228442425586326658e-01) (14, 4.78843082383914597777e-01) (15, 4.20188878202104820758e-01) (16, 1.13738090580360728943e+00) (17, 4.34450063637324079835e-01) (18, 4.44418094545705466558e-01) (19, -1.56442734594203630705e-01) (20, 4.72616575758329438006e-01) (21, 2.63656670083082911304e-01) 
