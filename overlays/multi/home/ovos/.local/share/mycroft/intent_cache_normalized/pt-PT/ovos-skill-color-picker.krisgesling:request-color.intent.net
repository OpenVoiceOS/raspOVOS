FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.23923497497201062778e-02) (1, 1.58666327643538912495e-02) (2, -5.47932542812679598820e-02) (3, -4.02282521080826113713e-02) (4, 5.57155787992622275606e-02) (5, 5.66268061658708576900e-01) (6, 6.78315953987864594943e-01) (7, 6.52134096870809809587e-01) (8, 2.00316805115470675247e+00) (9, -9.98987957632920853257e+01) (10, 4.07796319908977702995e-02) (0, 7.73600313003149075985e-02) (1, -7.25945644442110016303e-02) (2, -6.59647994104890778022e-02) (3, -1.26867353952315270460e-01) (4, -1.18553229037789732703e-02) (5, 6.69306491836430095255e-01) (6, 2.16903127690697888896e-01) (7, 3.07409341887619091960e-01) (8, 5.82498928030778517773e-01) (9, -2.15207866395430158502e-01) (10, -1.96674511036331212122e-01) (0, 1.01787741547568133527e+00) (1, 2.64251327417578008028e-01) (2, 1.94583995543207405321e-01) (3, 2.22224472366060493700e-01) (4, 1.22703237734522116464e-01) (5, 5.45120140837909694653e+00) (6, 3.03206103708387797457e-01) (7, 6.29037945320314539899e-01) (8, 9.10136846689323486537e-01) (9, -3.58966960934464873745e+00) (10, -1.00427145940242779076e+00) (0, 2.37338830295433567130e+00) (1, 2.53373476609223324818e-01) (2, 9.68566638674667468312e-02) (3, 2.44471746429436476156e-01) (4, 1.48279759034149971608e-01) (5, 1.36003848749211169178e+01) (6, 5.15038524012505050109e-01) (7, 5.74626773413650648870e-01) (8, 2.64068135104169154914e+00) (9, -5.19634287905044622846e+00) (10, -1.13250330844147178988e-01) (0, 5.49467085896688178792e+00) (1, 6.25631720568465721222e-01) (2, 7.28236411507653835784e-01) (3, 6.86134305592107307525e-01) (4, 6.34006486083793285857e-01) (5, 4.11261940855570662379e-01) (6, 1.33134577407605869670e-01) (7, 4.33513045121142692739e-01) (8, -7.66055301295741619683e-02) (9, -1.03695517618339447807e+01) (10, 4.29967944876931629228e-01) (0, 1.74892811013190263569e-01) (1, 8.87258585257330811835e-01) (2, 8.89396261138716615058e-01) (3, 9.45441152615347668586e-01) (4, 8.43196768028536602912e-01) (5, 2.56716305394356469893e-01) (6, 2.56099963394138596673e-01) (7, 3.92034308801987363413e-01) (8, 2.16039691488477503256e+00) (9, -1.30398000956773678638e+01) (10, -8.94086755373557195981e-01) (0, -1.35899537539288600696e-01) (1, 5.17178764520747139000e-02) (2, -9.22204861463444963698e-02) (3, 4.05477425037485891823e-02) (4, 8.47667148290736360838e-02) (5, 3.72929769418753886967e-01) (6, 3.90519788349124319371e-01) (7, 5.11553903868952830614e-01) (8, 1.38755138182878496877e+01) (9, -4.61811530919874435597e+00) (10, -2.64000657769141167108e-01) (0, -1.21600060639701024190e-01) (1, -6.25661343131430347508e-02) (2, -8.73246446047194480045e-02) (3, -1.04240524748361873542e-01) (4, -8.71195003185637473209e-02) (5, -2.45945837164258773733e-01) (6, 4.54247781167724865026e-02) (7, -1.82491488790865075131e-01) (8, -3.78377430101018807918e+00) (9, 8.86395263551902701238e+00) (10, -1.97848166909787404055e-01) (0, 5.20231103823254104057e-01) (1, 4.82743195163096550093e-01) (2, 5.32839654849852184526e-01) (3, 5.51236725317324371964e-01) (4, 5.47168507145727844865e-01) (5, -2.82192431546646804730e-01) (6, -3.57347172633007192921e-01) (7, 3.53286566775069588164e-01) (8, 7.04901044846183388870e+00) (9, -7.02816327249150685219e+00) (10, 9.92101688283481220054e-01) (0, 2.31168510262867693550e-01) (1, 9.05293510291046016336e-02) (2, 7.73202800187534206033e-02) (3, 1.71029268297857667269e-01) (4, 2.16738788876242066683e-01) (5, 6.78709760678538498446e-01) (6, 1.84420459706341439698e+01) (7, 7.09355640856409341843e-01) (8, -3.11035531162712874931e+00) (9, -5.24773512881094994498e+00) (10, 1.95952921552423137141e-01) (11, -5.83362656563105597129e-01) (12, 4.66377818197178106718e-02) (13, 8.23060374937954891683e-02) (14, 8.28842770539227474691e-02) (15, -1.17730766558903160446e-01) (16, -1.27035908745428138822e-01) (17, 6.58317020857113965882e-01) (18, 4.79363221907794678778e-01) (19, 3.88262193921759701798e-01) (20, 8.48453668917527464854e-02) (21, -1.27736718400258061901e-02) 
