FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.48625080315303081946e-01) (1, -9.68005493545378709053e-02) (2, -1.03068093236669447443e-01) (3, -4.24248747789706115441e-02) (4, 1.70730255282078961787e-02) (5, 1.06440796654643854424e+00) (6, -1.80678214766466682661e+00) (7, 1.66478939719673646458e-01) (8, 1.86580316710162286142e+00) (9, 1.30675191165359572132e+00) (10, 1.84440664296229428487e+00) (11, 2.33288112813418713198e-01) (0, -5.54485085653744214085e-01) (1, -2.69838139624065442845e-01) (2, -1.74698725552028560903e-01) (3, -2.29856580705112417684e-01) (4, -1.33838609070247582800e-01) (5, 4.70130612358162203179e+00) (6, 1.56023873554452841006e+00) (7, -3.82028379054346611809e-01) (8, -9.33726230630980857939e+00) (9, -2.00948648971874810343e+00) (10, -6.85815462960088684241e+00) (11, 4.06444106506065605533e-02) (0, -5.01376306002070726286e-01) (1, -3.99810428196485587171e-02) (2, 1.39083956902925336835e-02) (3, -1.49585595207839816556e-01) (4, -2.47661823803480181383e-02) (5, 1.50529021676899321669e+00) (6, 4.93223298432143408832e-01) (7, -8.30295938048144499533e-02) (8, -3.12947052342634757238e-01) (9, -6.69583991049065296863e-01) (10, 2.55145463510094872017e-01) (11, -1.05883828162635057479e-01) (0, 3.93394504486964535772e+01) (1, 4.00411056762236261530e-01) (2, 3.57937464898127222224e-01) (3, 3.06972904538410806818e-01) (4, 3.38766808097857141657e-01) (5, -5.44815820660009886289e-01) (6, 4.45337872092993192208e-02) (7, 1.93841838957003687050e+00) (8, -1.30172029180514652325e+01) (9, 9.13251492347125104487e-01) (10, -1.13394584836666041383e+01) (11, 3.60063025175189732607e+00) (0, -6.81098292815170758274e-01) (1, -2.33558144629663427816e-01) (2, -1.76043637306159878042e-01) (3, -1.79344937414592647817e-01) (4, -1.56185426027244472769e-01) (5, 4.90350568455310664717e+00) (6, 1.48811768906101171694e+00) (7, -4.07257862897196287744e-01) (8, -8.78754033295058079034e+00) (9, -2.00811237913925744181e+00) (10, -6.64181994958261068263e+00) (11, -1.31713632841233663218e-01) (0, 3.27781021390708804386e-01) (1, 2.88319144102785057671e-02) (2, 1.75526395783111799354e-01) (3, 3.42980552169534561036e-02) (4, 2.17095941648170753790e-01) (5, -4.87346897848024818156e-01) (6, 8.33938157563458792865e-01) (7, -3.29990731040611218194e-01) (8, -6.41247208654220468560e+00) (9, 9.00135081251635660315e-02) (10, 4.51713055581977407371e+00) (11, 2.92423872452598140881e-02) (0, -8.28354920872646727226e-01) (1, -2.00977900826189333217e-02) (2, -1.61071514507458046772e-01) (3, -1.34065868129656151631e-01) (4, -2.28440740906450563685e-02) (5, 1.00389913867528601799e+00) (6, 3.67111606191950157196e-01) (7, -4.88312975774880669855e-02) (8, 3.06732189390275966634e-01) (9, -4.42251297779448493408e-01) (10, 4.99778577024414971675e-01) (11, -3.39747489870301344617e-01) (0, -8.35298141801328886125e-01) (1, 5.60948010926878674887e-05) (2, -9.10589999202246064280e-02) (3, -1.72171787047719487829e-01) (4, -1.21197090173100915922e-01) (5, 1.14264196502564496782e+00) (6, 3.15839750360803916962e-01) (7, -1.44371251563902069925e-01) (8, 2.29815209482554266840e-01) (9, -4.85827309470551860215e-01) (10, 4.24162043078885220293e-01) (11, -2.16720309126551935464e-01) (0, 3.52716808124791336709e-01) (1, 5.00188299832680441370e-02) (2, 1.62227215003762470502e-01) (3, 7.56242812989094265186e-02) (4, 1.00325384866986513921e-01) (5, -1.06211137310109648979e+01) (6, 4.81260409961388052613e-02) (7, 1.75420550623892196329e-01) (8, 3.79758533507314033351e-01) (9, 1.78712259644172988260e+00) (10, 7.09219100734409080289e-01) (11, -1.69306628764882838301e-01) (0, -4.58147933070589985505e-01) (1, -9.92799349370556381833e-03) (2, -6.02507645660932608656e-02) (3, -8.13768113428647993368e-02) (4, -3.28840518766935416273e-02) (5, 1.25219908054477047088e+00) (6, 7.46294989070727221581e-01) (7, -1.47601905742623301654e-01) (8, -1.94162323882874826575e-01) (9, -6.44671236555951487901e-01) (10, 3.30431754040898528757e-01) (11, -2.34332977592433211456e-01) (12, -1.12599340851520041129e-01) (13, -4.72546246823958959737e-01) (14, 5.42063023698125756589e-01) (15, -4.71841398464631023302e-01) (16, -6.25847298487502201603e-01) (17, 1.40801727704758430221e-02) (18, 3.25281252673342680115e-01) (19, 4.80425376248155511227e-01) (20, -1.46212127645361344985e-01) (21, 4.56912483823095239011e-01) (22, 6.31898483623930085074e-01) 
