FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=15 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.87375871794800463732e+00) (1, -8.24776177512589114826e+00) (2, -5.26410249433537824615e+00) (3, 1.22810538394357560144e+00) (4, 2.91303653664732342676e+00) (5, -8.28828554541401274491e+00) (6, -4.61614110822967493863e-01) (7, -8.27758958743412520676e+00) (8, -8.24312497400690880056e+00) (9, -8.09176604365842777611e+00) (10, -7.95528912419442946202e+00) (11, 3.01949073080922003598e+00) (12, 1.41979518550935086552e+01) (13, 2.16313961983659286403e+00) (14, 3.83059666923372077463e+00) (0, 6.75046846100382014200e-01) (1, -7.89655464219311320484e-01) (2, 8.28086233850721953331e+00) (3, 5.51859227126356355342e+00) (4, 1.16081655497157232304e+00) (5, 7.18059110569036374017e-01) (6, -2.23411962950847664544e+00) (7, 5.23125045249344888809e-01) (8, 6.20333430328976920265e-01) (9, -2.67172264423136518463e-01) (10, -1.76474872684263955902e-01) (11, 1.14184797864497400433e+00) (12, -1.29558282344854269752e+00) (13, 1.52965022193156530150e+00) (14, -9.76664901714763278306e-01) (0, 1.93967236040155466270e+00) (1, 1.45935899382996159268e+00) (2, -2.18246068785613900332e+00) (3, 7.14564623178516211688e-01) (4, 1.18968165603037734357e+00) (5, 1.40058529874819193140e+00) (6, -4.06901184451419206667e-01) (7, 1.40482255394675248361e+00) (8, 1.40460427358749795346e+00) (9, 1.42179473949591272941e+00) (10, 1.42344320176088490193e+00) (11, 1.17072698594974489161e+00) (12, 6.37186346486946220136e-02) (13, 1.36408825768985186855e+00) (14, -1.72739725893200724016e+00) (15, -2.14156967809192870789e+01) (16, 7.88145698821433970949e+00) (17, 8.09952928049493721119e+01) (18, -4.86679139909952707121e-01) 
