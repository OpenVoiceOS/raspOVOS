FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.48050071166200547523e-01) (1, -6.85436643730552436216e-02) (2, -5.97415782581717999533e-02) (3, -6.67281068931968313063e-02) (4, -1.51039495326176387291e-01) (5, 2.17609300919109349692e+00) (6, 3.84351832922932012959e-02) (7, -6.49539866643748797781e-02) (8, 2.52462480634964725468e+00) (9, -2.29776893556469186120e-01) (10, -1.78092799971405313375e-01) (0, 2.29707466775340485299e+00) (1, 4.54702693327482587726e-01) (2, 4.37082770570333845050e-01) (3, 3.84350481732900983722e-01) (4, 3.28461951865967161091e-01) (5, 4.09329815534258116827e+01) (6, -2.25621023556623084838e-01) (7, -1.02229316905202294308e+00) (8, 1.91224286064483209202e+02) (9, -8.92342880203379762438e-02) (10, 2.12951697408585050031e-01) (0, -8.28308708983454655694e-01) (1, -6.67246200214774709547e-02) (2, -1.18470571197167182098e-01) (3, -1.73145230121508342247e-01) (4, -5.18905587564857037619e-02) (5, 1.50895282680807896192e+00) (6, 4.98053622109936658391e-02) (7, -1.78932723937116511248e-01) (8, 2.56331278832866793493e+00) (9, -1.41853726989082357113e-01) (10, -2.07762783609056200795e-01) (0, 1.90107116992856706172e-01) (1, 1.46892379068106010420e-01) (2, 1.23692209862440463675e-01) (3, 2.12037677906721427901e-01) (4, 1.32468084834783866865e-01) (5, 4.07957271588349570379e+01) (6, -1.58244096650365984047e-01) (7, 3.19197100344261949778e-02) (8, 1.91245117507852597782e+02) (9, 1.19650011021325873919e-03) (10, 3.62038993438778378131e-01) (0, 6.33992833454326665255e-01) (1, 1.75332688138950865131e-01) (2, 1.48381054745186369281e-01) (3, 1.63465194747913877826e-01) (4, 2.15636752889622251850e-01) (5, -2.39060975409250042745e+00) (6, 4.49205930053633128995e-01) (7, 1.73358147188610700606e-01) (8, -2.43348148464957381165e+00) (9, 2.97415864521852590929e-01) (10, 1.19458287590795769750e-01) (0, 1.72439628654621923687e+00) (1, 5.01957267354515068725e-01) (2, 4.80914771388557482634e-01) (3, 6.24820254574802391723e-01) (4, 6.35224364529636265075e-01) (5, -2.62231865739279568217e+00) (6, -2.30937893831114937626e+00) (7, 5.27325545453534827445e-01) (8, -6.59075639189140538576e+00) (9, 9.06244029683087592986e-01) (10, 1.32826366075058488470e+00) (0, 2.01072716456004751961e+00) (1, 5.14725174586561196044e-01) (2, 5.73385633359935753539e-01) (3, 4.68320116232421923552e-01) (4, 4.78050544689682055388e-01) (5, -2.76037208734168038049e+00) (6, -2.25912987210731674992e+00) (7, 5.28431036585059521471e-01) (8, -6.90149560560651753605e+00) (9, 1.07270659373847565554e+00) (10, 1.47757766940374857256e+00) (0, 5.14255215181744107511e-01) (1, 2.90770072959973036042e-01) (2, 1.81784179531647299699e-01) (3, 2.12334748827530478410e-01) (4, 1.74512792848660086564e-01) (5, -2.42003722283636113488e+00) (6, 2.38325557740225069114e-01) (7, 1.33808580279663358326e-01) (8, -2.76317135086269916044e+00) (9, 2.76915070468774893175e-01) (10, 1.25680279857829646506e-01) (0, 3.36608512844230378658e-01) (1, 1.66035323183250427270e-01) (2, 5.96287239000320781757e-02) (3, 1.01964744518709168886e-01) (4, 2.04791835288715362573e-01) (5, 4.08913221684599150763e+01) (6, -2.99576092615459865787e-01) (7, -1.14290476149026418162e-01) (8, 1.91309547468997521946e+02) (9, -7.43781277426054376889e-02) (10, 2.95598757958270397239e-01) (0, 1.90780014660307517538e+00) (1, 5.73099113832500450805e-01) (2, 5.68257354031589501098e-01) (3, 6.21402524243381493285e-01) (4, 6.62104673515346409118e-01) (5, -1.63963611865896385922e+00) (6, -3.41898495698131288378e+00) (7, 4.21943379212298130820e-01) (8, -8.01073919887504182213e+00) (9, 1.53303052304479114909e+00) (10, 1.37782834269781617742e+00) (11, 6.73282930114971422952e-01) (12, 3.89690985417283253245e-01) (13, 7.26170660415397906107e-01) (14, 4.28187312764906569118e-01) (15, -2.09425726780942920990e-02) (16, -1.09213253195953929886e-01) (17, -9.02509173465778358203e-02) (18, -5.27210621449067176614e-02) (19, 4.20149040485837232950e-01) (20, -1.02459677131276308271e-01) (21, 3.41431209010686909089e-01) 
