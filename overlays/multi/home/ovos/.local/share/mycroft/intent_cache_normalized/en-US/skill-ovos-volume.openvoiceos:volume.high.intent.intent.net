FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.46293758926198469439e+00) (1, 5.85349932440058839944e-01) (2, 5.05478665359752166175e-01) (3, 5.24063490458266723060e-01) (4, 5.48426196106212016090e-01) (5, 6.69187930117203233493e+00) (6, -3.02982176918675065458e-02) (7, -2.99161016705492333045e+00) (8, 1.60370952472240113629e+00) (9, -6.79106219399966626327e-01) (0, 6.47009186857384754887e+00) (1, 6.09609988182451822958e-01) (2, 5.75557124465372660360e-01) (3, 5.14571872204210967183e-01) (4, 5.65001261084940531454e-01) (5, -2.26559699843476058945e+00) (6, -1.13771050957321165353e-01) (7, -2.32857465201168523095e+00) (8, -5.27336972188818142726e-01) (9, 5.87842878887802778448e-03) (0, 6.50208568238658024541e+00) (1, 3.45002422098274696971e-01) (2, 4.76506704453583174175e-01) (3, 3.77599729214067980632e-01) (4, 4.01251407329197340434e-01) (5, -1.44819945263927585266e+00) (6, 7.73358347142944074770e-02) (7, -2.93383095316987585477e+00) (8, -9.68537208670422755663e-02) (9, 1.16763875183658966117e-01) (0, 4.41278570263396507922e-01) (1, 4.76186869678908775150e-01) (2, 5.63052339492255526920e-01) (3, 5.74366224942618686100e-01) (4, 5.83006849525386172672e-01) (5, -3.55885470602964271158e-01) (6, 4.18378432549323275857e-01) (7, -1.27306288570828964879e+01) (8, 1.06495828961977645477e+00) (9, -1.85411090704831277298e-01) (0, 2.50847518024251447954e+00) (1, 5.97518498240586004577e-01) (2, 4.49861454008694539031e-01) (3, 6.02954859076615057312e-01) (4, 4.47878422378178486785e-01) (5, 6.89689636704403596923e+00) (6, 1.87155963743179221126e-01) (7, -3.98604969076869553035e+00) (8, 1.29671080105557812168e+00) (9, -7.95377466515858499996e-01) (0, -9.16194763710258985867e-01) (1, 2.68200532039380191984e-02) (2, -2.92053699055933833895e-02) (3, 3.91949907382702911196e-02) (4, -1.26609343246581518283e-01) (5, -4.14761692097270262547e-01) (6, -2.67306961108819199358e-02) (7, 6.18529565762465205481e-01) (8, 3.61017995570203503730e-02) (9, -1.42908179247757172181e-01) (0, -1.17484014335680653218e+00) (1, 1.57034044789746800308e-02) (2, 1.12124966614194257475e-01) (3, -2.83248776865526602498e-02) (4, 1.23299898736424787260e-01) (5, -7.11374526942451179679e-01) (6, 3.97009860563860006444e-03) (7, 8.11721463378141105949e-01) (8, 2.75205521379483453170e-01) (9, -7.29051894326154387160e-02) (0, 6.47803729438227726689e+00) (1, 4.75546751767065734029e-01) (2, 6.06770974248316385946e-01) (3, 5.70989940911200144491e-01) (4, 6.53688353150751799703e-01) (5, -2.46432297874118777514e+00) (6, -8.38604548976606550825e-02) (7, -2.83724429776389541757e+00) (8, -1.58338902264012149068e-01) (9, 8.31540669217159800208e-02) (0, 6.09161686198993357344e-01) (1, 4.93714508573682098191e-01) (2, 5.34740773002774449907e-01) (3, 5.07387866239220941544e-01) (4, 4.81643010835320684038e-01) (5, -3.20366567135505653230e-01) (6, 2.44531037232693759798e-01) (7, -1.27638237491913368871e+01) (8, 3.56468430782995726602e-01) (9, -4.34153857764627115756e-01) (0, -1.12856918068275002831e+00) (1, -5.52987850432838396603e-03) (2, 1.24180080525822980619e-01) (3, 9.78142639326527729704e-02) (4, 3.79378741311505937595e-02) (5, -1.36503638566358165285e+00) (6, -8.50205342845068018365e-02) (7, 9.85311451686334827116e-02) (8, -2.68634844535354633255e-01) (9, -2.38835035655820066003e-01) (10, 6.37824848441911007590e-01) (11, -2.56754700133330238110e-01) (12, -3.05994655975825258221e-01) (13, -2.40972618547443673265e-01) (14, 6.68960243611169125266e-01) (15, 6.60611968469084542832e-01) (16, 1.16349460065784865437e-01) (17, -3.17361194679266878094e-01) (18, -2.93429291782144885392e-01) (19, 1.62433478951782978017e-01) (20, 4.71684170460382024004e-01) 
