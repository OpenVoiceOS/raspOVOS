FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.06828547598851719691e-01) (1, 2.88531393689081094855e-01) (2, 2.48658501488134259239e-01) (3, 1.64778315407201697562e-01) (4, 1.84382413458988092536e-01) (5, -1.19913197910103096200e-02) (6, 3.55116007262009147905e-01) (7, 4.02675864137543249033e-01) (8, -3.95387104110410225744e+00) (9, -3.41246276102024115318e+00) (10, 3.10319616869832337613e-01) (0, -3.97463088509417250549e-01) (1, -1.78465757095660731979e-01) (2, -3.21102853441085522856e-01) (3, -1.98950442993487824905e-01) (4, -1.75093862736072108932e-01) (5, 3.52142824267653420378e+00) (6, -9.59454925205262321164e-01) (7, -2.61841848255819631408e-01) (8, 1.08868636454002687408e+00) (9, 1.40940994327049096135e+00) (10, -1.20000048235250039719e-01) (0, 3.42549197957880413590e-01) (1, 3.98445060714054222206e-01) (2, 4.15578937395382042030e-01) (3, 4.30606415732669944862e-01) (4, 3.13248081370163189430e-01) (5, -6.38424308071911017493e+00) (6, 2.02159088542153941859e+00) (7, 7.45896361357550774507e-01) (8, 7.52753240749906016305e+00) (9, 6.98872022020053584868e+00) (10, 2.31507161164053260061e-01) (0, 1.04251705503862646118e+00) (1, 4.30619975853848313552e-01) (2, 6.00342585075783641280e-01) (3, 4.57587814260411118727e-01) (4, 5.20068204332280070723e-01) (5, 4.46242759256218857189e+00) (6, 1.96754048730763275721e+00) (7, 2.24650925248297594905e+00) (8, -6.50999965361336574432e+00) (9, -6.05234568260502570070e+00) (10, 1.87025308062213957427e+00) (0, -4.79741709131427884749e-01) (1, -9.74473817343914222588e-02) (2, -1.48867586075802998957e-01) (3, -1.11265437125703067767e-01) (4, -1.62970529317399193125e-01) (5, 3.65821798205893333744e+00) (6, -8.85533151199493828720e-01) (7, -6.18914562569041204476e-01) (8, 1.07763299671751044961e+00) (9, 1.21076573537189613461e+00) (10, -1.03635043835171927751e-01) (0, -6.11359778251379770708e-01) (1, -2.53465351071076316902e-01) (2, -3.61285899188237058510e-01) (3, -2.80653778817372245857e-01) (4, -2.02025976385788896827e-01) (5, 3.42046328288206513690e+00) (6, -9.31629418458986169327e-01) (7, -5.57155534068908386836e-01) (8, 1.66176650500066003247e+00) (9, 2.18355875446303926424e+00) (10, -3.46498924772501937230e-01) (0, 2.69724531964720459776e-01) (1, 4.09944525225925560097e-01) (2, 3.74143606289196128944e-01) (3, 4.21644738181400413612e-01) (4, 2.65826044841576070166e-01) (5, -6.21145485771427630084e+00) (6, 2.01011682366421329249e+00) (7, 5.73769688195567173494e-01) (8, 6.58724418508853215570e+00) (9, 6.92188459324073512846e+00) (10, 2.65841165089376718633e-01) (0, 2.21552847159898291807e+00) (1, 5.29935106223977880902e-01) (2, 5.29518127030290441937e-01) (3, 4.68265659696019798108e-01) (4, 5.61045631355203466839e-01) (5, -2.40761256935443945792e+00) (6, 1.21393291640016354194e+00) (7, 1.24076332024070667970e+00) (8, -8.28973040548171979935e+00) (9, -7.72367864628533862259e+00) (10, 2.35571375432206231437e+00) (0, -2.96017872370070211918e-01) (1, -1.03323145926933999961e-02) (2, 1.70603776055480965690e-01) (3, 1.24324300962592990127e-01) (4, 4.25027624546546051176e-02) (5, 5.87733981546112005390e+00) (6, -8.70235845416108683148e-02) (7, -4.55392674119348417339e-02) (8, -1.18569026860636683729e+00) (9, -1.17200029621532109125e+00) (10, 3.62313479803806834378e-02) (0, 1.52529577302090202373e+00) (1, 4.41013321438675276465e-01) (2, 5.14965750435238067695e-01) (3, 4.00300778606777540869e-01) (4, 4.80978630641346327490e-01) (5, -2.08848740005797850472e+00) (6, 7.58138342581550217503e-01) (7, 1.33848314157835424076e+00) (8, -6.52843925118045653733e+00) (9, -5.92171251783370244937e+00) (10, 1.33133304282767817028e+00) (11, -8.62341547897020437030e-03) (12, 3.90082758810102125935e-01) (13, 5.61277933012791052647e-01) (14, -2.21972662532176484573e-01) (15, 3.69175856935083035459e-01) (16, 4.12303776439010283283e-01) (17, 5.29624556229696175080e-01) (18, -1.51257471706327223382e-01) (19, 4.39850912187979004031e-01) (20, -1.45797939564641682031e-01) (21, 3.80685537076977664750e-01) 
