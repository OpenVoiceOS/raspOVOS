FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.84966783887611130321e-01) (1, -1.34101165713527120671e-01) (2, -1.40970709057309545598e-01) (3, -6.28758764581465318111e-02) (4, -1.24966973693826075009e-01) (5, -8.50115988636952657487e+00) (6, -1.69933458833789768905e-01) (7, -2.95562820226000084745e+01) (8, 4.27364320671921049666e+00) (9, -4.18948783013488729177e-02) (10, -6.24653701757933166316e-02) (11, -2.15811492677625837988e-01) (0, 1.03047613016472694447e-01) (1, 6.46240643817911686320e-01) (2, 6.07154804874191822428e-01) (3, 7.44503762233982624430e-01) (4, 7.73313011635075153727e-01) (5, -7.02975402731377130294e+00) (6, 6.76216427725340740729e-01) (7, 4.34375915799081813162e+00) (8, 1.73356913762434272641e+00) (9, -1.16994601794014307927e+00) (10, 3.08895877412079244984e-01) (11, 8.58915325459675638164e-01) (0, 3.54530990785823341138e-01) (1, -1.78232915305125472205e-01) (2, -1.51586493157124008353e-03) (3, -1.66705421709048451362e-01) (4, -1.02265879117476685134e-01) (5, -9.28047716224250685002e+00) (6, -1.29047365831570892691e-01) (7, -3.01764465665015606533e+01) (8, 4.64260060924282758066e+00) (9, -1.44091706461001289180e-02) (10, -1.27012004285528029568e-01) (11, -2.14460720907371588106e-01) (0, 5.52076725837754467285e-01) (1, -9.52862780979658596792e-02) (2, -2.38194596460845307850e-02) (3, 1.92954334923241405120e-02) (4, -1.82144400170828925367e-02) (5, 8.32831611889246814506e-01) (6, 3.18834692613102210768e-02) (7, 1.87790299703263796616e+00) (8, -5.98046122721123509791e+01) (9, 8.26546982963293624946e-02) (10, -1.44788473390727201462e-01) (11, -2.08625746937805084391e-01) (0, -1.90044491783125768514e-01) (1, -1.04577995316557606498e-01) (2, -1.01989231483511647025e-01) (3, -1.14178321735434268325e-01) (4, -1.68759323136381783614e-01) (5, 2.36795142312311268640e+00) (6, -5.53421160946478085663e-01) (7, -3.23099571185626732728e+00) (8, 5.77009593087646976528e+02) (9, -7.06435861872039216891e-01) (10, -5.57270740687546894954e-01) (11, -2.68645078829601147152e-01) (0, 6.83651949898887334456e-01) (1, 5.78117008852026326160e-01) (2, 7.18267108844778401355e-01) (3, 6.47754195677301747303e-01) (4, 7.49083797978422505359e-01) (5, -8.05913029965710947522e+00) (6, 3.70701436743844786603e-02) (7, 4.38218362039451747592e+00) (8, 6.17869201397838851975e-01) (9, -2.04180401070819961262e+00) (10, -5.56435268602406662986e-01) (11, 1.67081694586847362416e+00) (0, -5.28110218544747311853e+00) (1, -4.51097180546983334004e-01) (2, -4.94155844153627066273e-01) (3, -6.09134723843797187826e-01) (4, -4.79028006495698543965e-01) (5, 2.37572055664408088305e-01) (6, -7.28375815572320561841e-01) (7, 3.67938471940712288899e-02) (8, 7.35977688863874046632e+00) (9, 8.16754800911134393182e-01) (10, -6.70774742543508439852e-02) (11, -3.23226302219978556263e-01) (0, 2.77814843698934332838e-01) (1, -1.14158953817652092377e-01) (2, -5.48399717529281446882e-02) (3, -1.65621239038275164246e-01) (4, -7.11087242682441611485e-02) (5, -1.12653792281930886787e+01) (6, -2.41103047400636788522e-01) (7, -5.88780621843435199025e+01) (8, 4.39109741231283656759e+00) (9, -7.97233913935988941502e-02) (10, -1.06763423256416273288e-01) (11, -5.37434802383221568722e-02) (0, 2.96747920383027663505e+00) (1, 5.08511280590504433086e-01) (2, 3.67989243889063399884e-01) (3, 4.24547603303402465436e-01) (4, 4.82451057011097528271e-01) (5, 9.27900386836497759191e+00) (6, 1.29211485918944068985e+00) (7, 8.19705764821241977813e+00) (8, -4.68260550056550606257e+00) (9, 1.40295551180241737654e+01) (10, 5.27573696451123397289e-01) (11, -7.03772409716203473096e-02) (0, 4.52010551995251419477e-01) (1, -2.34729793726539542886e-02) (2, -1.87050126200828559231e-01) (3, -2.05093547409687104732e-01) (4, -1.86999827331218726467e-01) (5, -6.52594110377944125467e-01) (6, 5.16890569594455756564e-02) (7, 5.56723254662150002225e-01) (8, 9.16696895880276230173e+00) (9, 5.48081725947269574051e-02) (10, -1.27661994643097659319e-01) (11, -9.04840009415987800434e-02) (12, -1.83664709777788925926e-01) (13, -3.05166834568506462055e-01) (14, -1.67261248537974305250e-01) (15, -1.84176131214727561991e-01) (16, 6.72686958506283794179e-01) (17, -2.40587535105512007050e-01) (18, 5.49187207063521420913e-01) (19, -2.14966742346981015688e-01) (20, 8.38179459027241891000e-01) (21, 5.24460678371811706011e-02) (22, 4.25196834572647008876e-01) 
