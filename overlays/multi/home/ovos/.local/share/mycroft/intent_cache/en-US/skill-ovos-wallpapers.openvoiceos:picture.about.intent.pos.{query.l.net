FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=16 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (16, 6, 5.00000000000000000000e-01) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.26185468870615546955e+00) (1, 1.45922702800568138137e+00) (2, 1.00434919994803784071e+00) (3, 8.22980871840686550867e-02) (4, -8.54060603583843502840e-01) (5, 8.35048048044369162213e-01) (6, 1.18594413086890071440e+00) (7, 2.29000388050900310910e-01) (8, 7.49189360476810062295e-01) (9, 1.03431242494462449777e+00) (10, 1.22584443177063140418e+00) (11, 2.45512777326771236552e-01) (12, 9.79314651970029981243e-01) (13, 8.87082431593865933239e-02) (14, 1.72202254034859947307e-01) (15, -8.53124845766504602551e-01) (0, -1.02962731498693993437e+00) (1, 1.40567213188942452540e+00) (2, 9.99411314976998421677e-01) (3, 1.87085421926803507908e+00) (4, -7.07160147334129463026e-01) (5, 4.74105125660822246392e-01) (6, 9.04303046317089243011e-01) (7, 5.43491454983578647919e-01) (8, 7.40784101764945912549e-01) (9, 7.05274188803419077587e-01) (10, 1.01496300126392458019e+00) (11, 2.04356997816530716605e-01) (12, 9.04894978586794351827e-01) (13, -1.70838610293534448603e-01) (14, -8.84819566232136200945e-02) (15, -1.02792739051794579375e+00) (0, -3.53212989438410218668e+00) (1, 2.40304152034794160642e+00) (2, 2.08250387319677621178e+00) (3, 3.49405428471429579940e-01) (4, -2.33348908476795813272e+00) (5, 1.72686408866276264185e+00) (6, 1.96054956511126809993e+00) (7, 1.55664423914914751279e-01) (8, 1.76646871268047234160e+00) (9, 2.26782934362249477545e+00) (10, 2.00019219079368859582e+00) (11, 2.37595139612566563780e-01) (12, 2.35296577649752869377e+00) (13, 2.75219397285983047308e-01) (14, 5.57084857754551049380e-02) (15, -2.16895135516817560983e+00) (16, 3.33220432122886567328e+00) (17, 1.65355821030171301622e+00) (18, 3.69455332917332270881e+01) (19, -1.39744435682716550140e+00) 
