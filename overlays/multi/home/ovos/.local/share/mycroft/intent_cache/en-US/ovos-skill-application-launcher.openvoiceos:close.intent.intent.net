FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.31011067886794019266e-01) (1, -4.42833425248021383958e-01) (2, -3.65862803304547457017e-01) (3, -2.86706322574967475969e-01) (4, -3.41885411882752565660e-01) (5, 3.35692565177424462330e-01) (6, 1.43069735573464673628e+00) (7, 4.06046379380202215881e-01) (8, 3.57054996696560489333e-01) (9, 1.71844731726772059766e-01) (10, -5.59971319668219091881e+00) (11, 1.44102264942894842115e+00) (0, 8.06417911188406577594e+00) (1, 3.56297244722601769151e-01) (2, 3.89973142589089272203e-01) (3, 3.85599435711857674303e-01) (4, 4.28334881956336011033e-01) (5, -2.24027793767909200184e+00) (6, -2.58434743058286908735e+00) (7, -1.45500085401446233035e+00) (8, -2.04305114642178597961e+00) (9, -1.69342132411160872785e+00) (10, -2.99471588538070410124e+00) (11, 2.44946947590808106199e+00) (0, 6.72248022099421493891e+00) (1, 2.75631331767451581705e-01) (2, 4.18611966933620016640e-01) (3, 3.85202252234828401711e-01) (4, 3.76740776862513837564e-01) (5, -4.43174798042278084154e+00) (6, -3.19761093627979731124e+00) (7, -4.47108393919140034711e+00) (8, -4.20589924828909911270e+00) (9, -4.52782212373519055149e+00) (10, -5.38820879109644756966e+00) (11, 5.02266751090756624620e+00) (0, -3.14223446341453382935e-01) (1, -4.19616150189427994377e-04) (2, -1.92239577048311550966e-02) (3, 2.63142367727269808897e-02) (4, -1.03297128724385289811e-01) (5, 4.26144609254656003827e+00) (6, -7.94959922134806706850e+00) (7, 3.63783431763639342194e+00) (8, 2.28361997372432234954e+00) (9, 2.88896255053093353737e+00) (10, 2.99498107867778617930e+00) (11, -5.17508089217443734142e-01) (0, 5.96803171863600567804e+00) (1, 3.13355529615647221409e-01) (2, 2.24097156831986388248e-01) (3, 3.79886755654580132724e-01) (4, 3.56714019486672417880e-01) (5, -4.18858696958159892887e+00) (6, -2.88774327226391980261e+00) (7, -3.86573566638126342454e+00) (8, -3.74481159600883861671e+00) (9, -3.96130035061268603869e+00) (10, -5.64655993218717000559e+00) (11, 4.70625034796663754832e+00) (0, 2.74540041718003591242e+00) (1, 3.42647232577099392081e-01) (2, 2.87221119269623348380e-01) (3, 3.69676001831783895835e-01) (4, 3.13845552965893337394e-01) (5, -4.62347598844170093457e+00) (6, 7.03556416650152449677e+00) (7, -2.94801741707942666082e+00) (8, -3.58099495970285053303e+00) (9, -3.18160309001218211122e+00) (10, -8.91929096104193408490e-02) (11, 5.24673971156434104657e-01) (0, -3.00795689614711592164e-01) (1, -4.42500802900197068301e-02) (2, 7.30496180031893621587e-02) (3, -3.80858573343159714786e-02) (4, -1.01161191168010450303e-01) (5, 4.33702716504597418634e+00) (6, -8.06954498775316153569e+00) (7, 3.75924247794865973304e+00) (8, 2.25785995638890746307e+00) (9, 2.77713945127403860624e+00) (10, 2.24040172245166724352e+00) (11, -5.01057568612594983470e-01) (0, -1.89549511162921402452e+00) (1, -2.71512978271492566584e-01) (2, -3.14277399823912340082e-01) (3, -3.02707572028883653559e-01) (4, -2.92101976022967058100e-01) (5, 3.94381381268538300233e+00) (6, -8.48068479343256420577e+00) (7, 5.30094969544958516394e+00) (8, 4.63426336531947669073e+00) (9, 5.18367256800930764626e+00) (10, 4.05412189516382870380e+00) (11, -2.41281051385978573265e+00) (0, -3.51257141979817555377e-01) (1, -5.01292144127242229185e-03) (2, -7.48468147701775027292e-02) (3, -1.06852446861617359289e-03) (4, 2.26677011772467764533e-04) (5, 2.33474224242402517149e+00) (6, -2.33181150725061014928e-01) (7, 2.77043161920218938832e+00) (8, 2.20732405785054330849e+00) (9, 2.49769149504656917671e+00) (10, 7.96520231384201582436e-01) (11, -9.70606881261606324607e-01) (0, 6.65353230534716821865e+00) (1, 2.66038186988589331339e-01) (2, 2.15309873363730530649e-01) (3, 2.80333250901457942117e-01) (4, 3.95523809036967655128e-01) (5, -3.91244376767101220693e+00) (6, -2.54342407193830011281e+00) (7, -3.94874725859138209216e+00) (8, -4.25708900461836581286e+00) (9, -4.19097707848119860330e+00) (10, -5.95776154994408813081e+00) (11, 4.22676242791964806855e+00) (12, -1.22140915494345220216e-01) (13, -1.81087713087622642627e-01) (14, -2.95615446180371499452e-01) (15, -1.45949707768807168673e-01) (16, -2.47055482477215898607e-01) (17, 4.00463136217195370126e-01) (18, -1.41891237828969063450e-01) (19, -4.64395482789666691481e-01) (20, 1.23080086896790930062e+00) (21, -3.24747477084664448732e-01) (22, 7.47934503048986565332e-01) 
