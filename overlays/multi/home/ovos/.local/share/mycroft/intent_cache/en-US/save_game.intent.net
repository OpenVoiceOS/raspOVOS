FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.92424838282304522252e+00) (1, 6.00069318656395456202e-01) (2, 6.56515416447590260951e-01) (3, 5.28594841007660409815e-01) (4, 6.58612650577495961635e-01) (5, -2.26678240032757472022e+00) (6, -2.92612124316899624432e+00) (7, -5.19143993465605579907e-01) (8, 9.64600398798907687770e-01) (0, 1.52505886750327779300e-01) (1, 5.80854599869432067227e-02) (2, 1.00686510598840678332e-02) (3, 2.77807971036615475313e-02) (4, 1.71433169165867788086e-01) (5, -3.56749314955035368158e+00) (6, 1.15644119439620318701e+00) (7, -1.51434160332612643973e-01) (8, 4.18368747611584310131e-02) (0, 1.25465851760443358742e+00) (1, 4.25432024286295118465e-01) (2, 4.62353927777315321102e-01) (3, 3.56361342356706745083e-01) (4, 3.37746316329742557460e-01) (5, 6.96947449089715664883e+00) (6, 3.04637739271994467671e+00) (7, 2.18692971672023422913e-01) (8, 2.76000143795143648706e-01) (0, -1.03692952573911623126e+00) (1, -1.60818399980721497833e-02) (2, -6.20661695749138899586e-03) (3, 2.03505752488913581322e-02) (4, -4.02588995292839993412e-02) (5, 1.26828330411967349356e+00) (6, -1.56660930733818731797e-01) (7, -1.09866867453022307166e-01) (8, -2.86138258415196411466e-01) (0, 1.79741186099158956058e-01) (1, 7.38483775845558652884e-03) (2, 1.41008989107523241557e-01) (3, 6.38768460272887556028e-02) (4, 1.43181638014231060740e-01) (5, -3.87191055582809928737e+00) (6, 6.15431064955348605672e-01) (7, 2.05617249887880770842e-01) (8, 2.39561770951448760325e-01) (0, 1.20619724429186470083e+00) (1, 4.62310395574782984074e-01) (2, 3.56782219743941919621e-01) (3, 3.52064102328036920841e-01) (4, 3.96872512436126367863e-01) (5, 1.27828130281747469610e+01) (6, 1.41028031359410221945e+00) (7, 1.12547726579126095015e-01) (8, 1.50121327819397215597e-01) (0, 2.01659065680610372073e-01) (1, 2.82575126408675381118e-02) (2, 1.97323502194795885600e-01) (3, 4.21068180790932361512e-03) (4, 8.17515041350462823289e-02) (5, -2.90330315755457846194e+00) (6, 8.92336617173327240060e-01) (7, 9.97588121709199332487e-02) (8, -2.40304282437446073417e-02) (0, -1.07869153872744560907e+00) (1, 2.67055032655539557884e-02) (2, -1.50816075702017299287e-01) (3, 1.35579703256430688513e-02) (4, -1.02624150112328536150e-02) (5, 1.35154881076470223533e+00) (6, -1.21251269722833648901e-01) (7, -1.98381836943548467422e-01) (8, -2.86345205741856567716e-01) (0, 1.25688010192450194680e+00) (1, 4.07206078753973188533e-01) (2, 4.51293302462602796687e-01) (3, 4.23021210120226087703e-01) (4, 4.93306917832399549617e-01) (5, 6.92941128106544201870e+00) (6, 7.03372365262568255417e+00) (7, 2.57704079012779363467e-01) (8, 3.68626763652025957185e-01) (0, 3.92730811275678393102e+00) (1, 5.15536988129161710681e-01) (2, 6.24414356400512460255e-01) (3, 4.49634814610027244708e-01) (4, 5.00486949433826322498e-01) (5, -2.08162651320366132168e+00) (6, -2.13833420179480349077e+00) (7, -5.86421301563276875513e-01) (8, 6.42163898617577610928e-01) (9, -2.42898315891616728424e-01) (10, -1.89669112157913127836e-01) (11, 3.90898020254592581946e-01) (12, 5.75382335079191564731e-01) (13, -3.50461138902696311970e-01) (14, 3.99529552349360272956e-01) (15, -1.55583136472467131739e-01) (16, 5.61682306050431567890e-01) (17, 3.51596669541816397864e-01) (18, -3.05783093675964290359e-01) (19, 3.74633334496583203510e-01) 
