FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.24843398852451592518e+00) (1, 6.17464743529003046163e-01) (2, 6.36567994926612756856e-01) (3, 6.64747655366104028829e-01) (4, 6.94078311298530481466e-01) (5, 1.36993058450693894201e+01) (6, -7.50629162586349707453e+00) (7, 1.00051008055886239134e+01) (8, 1.79526826336912681548e+00) (0, 4.55380890075451211230e-02) (1, -1.05152145659416496049e-01) (2, -1.01395741736381828080e-01) (3, -2.85579327294194218467e-03) (4, 7.83371862223780808521e-03) (5, 1.51182225512561080327e-01) (6, -5.01080799343177396565e-01) (7, 3.05670825680263193169e-02) (8, 1.02485044124605839677e+00) (0, 1.85397326301062870257e-01) (1, -1.09016389286011039506e-01) (2, 7.54596229842341599536e-03) (3, -3.87378341312106799776e-02) (4, 6.76452362184826461178e-02) (5, 4.29171459546653644157e-02) (6, -4.44089363755771238118e-01) (7, 1.24567504032469508757e-01) (8, 2.77375153605394719758e-01) (0, 1.70224680277071660495e-01) (1, -4.60719547028239986841e-02) (2, -7.81108966822322281498e-02) (3, -4.42962354774173519556e-02) (4, -4.73908862824138424341e-02) (5, 1.77030852603015181890e-01) (6, -5.58649826290198991963e-01) (7, -3.81317782561155921295e-02) (8, 2.88288197819643376985e-01) (0, -5.05132398579760555357e-01) (1, -1.52891243346596726604e-02) (2, -4.34540177234078589530e-02) (3, -1.35484222555961764112e-01) (4, 1.41368841282461729647e-02) (5, -1.98519191470289228796e-02) (6, 1.95437236567077965432e+00) (7, 2.13379875345888377070e-02) (8, -6.00845041489658449052e-01) (0, -3.06791510279467549704e-01) (1, -4.31849666983513073154e-03) (2, -3.20051968947115614283e-02) (3, -2.70266891375246787188e-02) (4, -2.79466272249880541556e-02) (5, -4.56418224848578135688e-01) (6, 6.24309253031522448651e+00) (7, -1.12196550989672849674e+00) (8, -2.76813359428947303176e-01) (0, -4.48592636022621615854e-01) (1, -3.01437884069586693736e-02) (2, -7.54598587251807118026e-02) (3, -1.53258135864844435847e-01) (4, -7.24970757461691761581e-02) (5, 7.59856958371953883358e-02) (6, 1.93195841186645900223e+00) (7, 1.56555767962419767336e-01) (8, -1.00348157245667812809e+00) (0, -5.10004549298926357359e-01) (1, 1.11919879063901266114e-02) (2, -9.69633222475710515598e-02) (3, -1.41146243467989342818e-02) (4, 2.84663229331311405657e-02) (5, -1.13583107006276634587e-01) (6, 1.98349843238530487710e+00) (7, -2.38104037961784170685e-01) (8, -4.33327652947844865761e-01) (0, 3.15484100088724087052e-02) (1, -3.40891486758884212915e-02) (2, -6.47334072539173469713e-03) (3, -2.88080132360156761229e-02) (4, -5.42004189247783443872e-02) (5, 1.00656083392199682813e-01) (6, -5.37963862957545946308e-01) (7, -6.29447299401137139174e-02) (8, 1.63659408096723801851e-01) (0, 2.37014929708012616061e+01) (1, 3.34716296988495032316e-01) (2, 2.98705007183321158415e-01) (3, 3.66694896715648810392e-01) (4, 4.21890571015842597014e-01) (5, -2.95279132381643050209e+00) (6, -2.34980935374096278068e+00) (7, -4.60289548858184005553e+00) (8, 2.85322612012003640203e+00) (9, 1.09926396144293136992e+00) (10, -1.36581487192371314743e-01) (11, -1.70724622650428342618e-01) (12, -2.33459063328682631111e-01) (13, 4.29931726379260636950e-01) (14, 4.27109211154102719199e-01) (15, 4.71739846517731764575e-01) (16, 3.87379641074410807633e-01) (17, -4.46311636925306592927e-02) (18, -3.10521778779600687859e-01) (19, 2.28899842379070322940e-01) 
