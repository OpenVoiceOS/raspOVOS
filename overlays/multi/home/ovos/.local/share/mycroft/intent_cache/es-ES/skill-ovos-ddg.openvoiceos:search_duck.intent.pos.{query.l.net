FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=17 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (17, 6, 5.00000000000000000000e-01) (17, 6, 5.00000000000000000000e-01) (17, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.21469492010621449296e+00) (1, -2.68645282522992889795e+00) (2, -1.25649811370166220037e+00) (3, 6.49772674039888920028e-01) (4, -6.40136505835943836473e-01) (5, 1.34936050974261192437e+01) (6, 1.60166851949041921799e+00) (7, 4.58047398954470885712e+00) (8, 6.15735508553832566747e+00) (9, 2.91967396725676131553e+00) (10, 2.60413163669726088756e+00) (11, -2.14488473741881202628e+00) (12, -5.98131922629778323142e-01) (13, 1.65690677280270159955e+00) (14, -2.26095733761866846123e+00) (15, 2.64801745090021123374e+00) (16, 1.60699133870668187107e+00) (0, -2.68319199012576126151e+00) (1, 1.44623729725926453149e+00) (2, 2.09536673184681809801e+00) (3, 4.34668541560237930987e-01) (4, 3.22883302612612776983e-01) (5, 2.04440605913998808774e+02) (6, 3.74254594404598250890e+00) (7, -2.32086708155664167563e+00) (8, -4.67965063594543995151e+00) (9, -3.48880212673752632124e-01) (10, -7.00899154253831202510e-02) (11, 1.65647657657330649172e+00) (12, 1.77781336276617718539e+00) (13, -3.87514863264677600352e-01) (14, 1.52086743723235340298e+00) (15, 7.98178112492617941598e-01) (16, -1.76382120624046323520e+00) (0, 2.04930568031815907304e+00) (1, -3.12294946625819491715e+00) (2, -9.44787875098503371341e-01) (3, 5.08064296291160899521e-01) (4, -1.41780773493794209905e+00) (5, 1.34479410551916984673e+01) (6, 1.67159332852905828659e+00) (7, 4.59643819957812560517e+00) (8, 6.16729847394078767309e+00) (9, 2.96726352636478019065e+00) (10, 2.58804825462719634288e+00) (11, -2.34027871034156875751e+00) (12, -1.40392348901499075531e+00) (13, 2.29848707466618762396e+00) (14, -3.81336231853690321714e+00) (15, 2.53466411653293599571e+00) (16, 2.20983266224827268331e+00) (17, -2.42732364551903545546e+00) (18, 9.15468735105780950789e+00) (19, -1.51902372870465596222e+00) (20, -1.18367008710995946785e+00) 
