FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.82198836657774732029e-01) (1, -9.96011627911413954806e-02) (2, -1.60888349830993510059e-01) (3, -1.25068036912764374985e-02) (4, -1.45037083028639636473e-02) (5, 3.29720317989397404546e+00) (6, -1.98035125353275859306e-01) (7, 1.22077831666644387454e+00) (8, 8.09268930679678422102e-01) (9, -1.54360682951453949130e+01) (10, 6.40115887742077199762e-03) (0, 1.06426478111614724043e+01) (1, 1.57363570548149267481e+00) (2, 1.46184299207779067054e+00) (3, 1.42518642238827819568e+00) (4, 1.43089229680153007251e+00) (5, 9.64775901576330308096e-01) (6, 3.67326327156619725223e-01) (7, 1.13617384544010437963e+01) (8, 7.68844711511474976362e+00) (9, 1.67347207813720402214e+01) (10, 9.74459832867977437942e-01) (0, 3.09089877312390974851e+01) (1, 5.85602443275069606266e-01) (2, 6.57522152719115515751e-01) (3, 6.43396135029410620731e-01) (4, 6.70599724707221289677e-01) (5, -2.55341173454337821980e+00) (6, 5.69992483935644722592e-01) (7, -8.36994617969270393587e+00) (8, -7.80651469014718157879e-01) (9, 1.26743899660273151575e+00) (10, 1.28070807929161056826e+00) (0, 1.12829679843349737212e+01) (1, 1.53636822916122595117e+00) (2, 1.41055850751253242237e+00) (3, 1.51648078180404821680e+00) (4, 1.42218276924940223438e+00) (5, 1.13021010561828805230e+00) (6, 4.28881437074737248416e-01) (7, 1.14404552949960507391e+01) (8, 7.70261797039848694624e+00) (9, 1.68170359729985889885e+01) (10, 9.48000220915672597854e-01) (0, 2.89791471356563583583e+01) (1, 5.19483865101618036419e-01) (2, 6.69283592005056382490e-01) (3, 5.13319686849397882611e-01) (4, 5.61869294245523565046e-01) (5, -1.93665473481565175717e+00) (6, 5.12571949181335195789e-01) (7, -8.13447824423234955304e+00) (8, -4.39430731758809589582e-01) (9, 1.21177074209572221974e+00) (10, 1.17463875982992327351e+00) (0, -3.87255666408312493321e-01) (1, -1.40709286749252177051e-01) (2, -4.35360354174032550267e-03) (3, 1.46026404501114950157e-02) (4, -1.28933666467555885227e-01) (5, 3.39283037602711079472e+00) (6, -2.49295805313526713798e-01) (7, 1.22561745667667465476e+00) (8, 7.04504972076534952130e-01) (9, -1.54154125439170623935e+01) (10, -8.16993391482172259810e-02) (0, 2.00856167671772354311e+01) (1, 5.69524946187909608675e-01) (2, 5.85821899150784974886e-01) (3, 6.21226193880017762972e-01) (4, 6.73465485249932660494e-01) (5, -2.43088419538005240383e+00) (6, 7.80398257275893625362e-01) (7, -7.05972997518398948102e+00) (8, -5.52268213045520650617e-01) (9, -6.63554936913594017867e-02) (10, 1.75494211998654425777e+00) (0, -1.74359599403899168113e-01) (1, -8.23519555615494780465e-02) (2, -7.84555850314209990426e-02) (3, -2.05318639962584842396e-01) (4, -1.78256216435344089222e-01) (5, 1.14950216807492777704e+00) (6, -2.82966893343432834840e-01) (7, 8.63450711808404713921e-01) (8, 5.83999652310363770447e-01) (9, 2.70791768225006224124e-01) (10, -7.19368290278682431804e-01) (0, -3.46129675957930371677e-01) (1, -7.20751417874182509493e-02) (2, -9.87701920865858840060e-02) (3, -6.04135600923384613603e-02) (4, -3.75212786792601393770e-02) (5, 3.32822110175896046513e+00) (6, -1.18253801681934916923e-01) (7, 1.31049549977049317739e+00) (8, 7.62358778840422357526e-01) (9, -1.54501791024748111880e+01) (10, -4.64003868319507947748e-02) (0, -1.08275013926070173831e+00) (1, -7.67891426105826030435e-02) (2, -2.59913821239798510654e-02) (3, -8.50047786255209575357e-02) (4, -8.83337129373877177896e-02) (5, 1.16294449299715618729e+00) (6, -2.50010351117199991489e-01) (7, 1.66095674137833793083e+00) (8, 6.09048085040175601890e-01) (9, 2.03322015963384533643e-01) (10, -8.10925960404823453764e-01) (11, -2.99996606142789168370e-01) (12, 4.53515868586062409484e-01) (13, -4.33175052262446236284e-01) (14, 4.89297997158526398742e-01) (15, -3.31097199969992039836e-01) (16, -2.92999593789898149510e-01) (17, -2.54793218152786216102e-01) (18, 5.36911621649573844728e-01) (19, -2.09387321830312722604e-01) (20, 5.49253447806666295072e-01) (21, 4.86620854538439728820e-01) 
