FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.97128457430712644705e-01) (1, 9.13437023982952150947e-02) (2, 3.54876458868930988455e-02) (3, 1.05874443076605609382e-01) (4, 3.36293295249889545584e-02) (5, -5.07946881900167235280e-01) (6, -2.59508268253467955233e+00) (7, -1.25839996638106299542e+00) (8, 9.08111135797894236665e-02) (9, -2.57340757282039783727e-02) (0, -4.19414230562582202033e-01) (1, -4.56127662804354905290e-01) (2, -4.93396219458808293901e-01) (3, -3.90683148648967026872e-01) (4, -5.19690584984053960405e-01) (5, 4.06870726926579384664e-01) (6, 1.76212430588430057909e+00) (7, 7.89606896683260561787e-01) (8, 6.41255808958976825096e-01) (9, 1.28181905623044017917e-01) (0, 5.95068668963285141160e-01) (1, 6.08570577199464279872e-01) (2, 5.73406235868936020594e-01) (3, 6.86181084806924079800e-01) (4, 5.75020910794740158778e-01) (5, 3.12455456920496832396e+00) (6, 7.42476307064000584646e-01) (7, 2.00966295075961731698e+00) (8, 1.20173883793951330468e-01) (9, 2.01515012097094603494e-01) (0, 4.76855623715704357579e+00) (1, 6.17167395324260681377e-01) (2, 7.78792281419784293561e-01) (3, 6.10145193309337585674e-01) (4, 7.06844885618240104108e-01) (5, -2.56023131769114353773e+00) (6, -3.06887069779000531966e+00) (7, -2.46129906669346176784e+00) (8, -9.39540429821829170542e-01) (9, 1.27977321400696203435e-01) (0, 4.75561349974349178993e-01) (1, 3.86979103721554251738e-01) (2, 4.20251787342007132597e-01) (3, 4.16289970911915274687e-01) (4, 3.83381061889107199736e-01) (5, -8.65586421002293715521e-02) (6, -1.58498031000323891249e+00) (7, 3.51885294234197051888e-02) (8, -8.04188335719561997461e-02) (9, 1.72868498199162168305e-01) (0, -3.60178986118353083867e+00) (1, -5.72352985598500119124e-01) (2, -5.73039727963860379134e-01) (3, -6.46595719017441616927e-01) (4, -5.87362448431904660140e-01) (5, 1.38265974547468317724e+00) (6, 3.63488091934577317588e+00) (7, 8.90650190719807222095e-01) (8, 5.63743827695799892830e-01) (9, 1.34354711678798810492e-01) (0, 6.27686759473653599350e-01) (1, 6.16875284905438747707e-01) (2, 6.93615795667176460171e-01) (3, 5.74784436817174393397e-01) (4, 6.30329789216523495021e-01) (5, 2.40477801509419553128e+00) (6, 1.54285635375309282402e+00) (7, 2.61186039126178837222e+00) (8, -1.95727915473250857481e-01) (9, -2.65601306199733433466e-01) (0, 7.31310812773080520799e-01) (1, 6.95884318645005439663e-01) (2, 6.45001532132630783778e-01) (3, 5.98328405613904434901e-01) (4, 5.93944007153516251307e-01) (5, 3.56809139593393886969e+00) (6, 1.53628234886455827812e+00) (7, 2.72246388024351215762e+00) (8, -7.53268063240058127761e-01) (9, -3.49780270118986269523e-01) (0, 6.68055115284295841782e-01) (1, 7.00457842643265937710e-01) (2, 5.19413577015405136805e-01) (3, 5.37636125082974758449e-01) (4, 5.31486773486142483058e-01) (5, 2.19113357354398718968e+00) (6, 1.48458934896517091850e+00) (7, 2.68055136925241566104e+00) (8, -1.60272291196356352072e-02) (9, -2.04281671881381687861e-01) (0, 1.24270682846777269503e+00) (1, 6.58875299130795122338e-01) (2, 5.26426860575793131858e-01) (3, 5.31477352117417201072e-01) (4, 5.32469192032931193381e-01) (5, 2.87334699937355031452e+00) (6, 8.07897582858506657644e-01) (7, 2.71904488331338978213e+00) (8, 1.59303743225348570789e-02) (9, 2.44579613816473945276e-01) (10, 3.86760295167063006261e-01) (11, 6.34082953993334474951e-01) (12, 3.49894735893692243600e-01) (13, -6.99734907109863080166e-01) (14, -1.02650478922631530065e-01) (15, 8.37004076825002329976e-01) (16, 3.71689100211038514487e-01) (17, 3.76683552210702821128e-01) (18, 3.84739850108995418143e-01) (19, 4.12143145149126033377e-01) (20, 1.96484220283199145785e-01) 
