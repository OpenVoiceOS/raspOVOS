FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.93728759524750859811e+00) (1, -1.67582223316707773497e-01) (2, -2.69753100475349616438e-01) (3, -1.77186960479297800353e-01) (4, -2.01450953384914560607e-01) (5, 7.04178064013129767496e-01) (6, 2.33853283226437308473e-01) (7, 2.57694919618091988767e-01) (8, 3.73709234504593590387e-01) (9, -4.96055727657317754170e-03) (0, -1.87025741127657996188e+00) (1, -1.36645386120357814619e-01) (2, -1.62930185100116892150e-01) (3, -2.81833844384231868574e-01) (4, -2.77688948562422099897e-01) (5, 6.07414668121920686694e-01) (6, 2.94758046865410572313e-01) (7, 2.44345855923614879712e-01) (8, 3.07262062331749019606e-01) (9, -3.49855624969555162318e-02) (0, 7.69396786622325912219e-01) (1, 2.23391169049839577454e-01) (2, 7.16788296783967826542e-02) (3, 3.82279989505811546024e-02) (4, 1.95313805081944069642e-01) (5, 1.99629696145904977911e+00) (6, 4.54087912545596772418e-01) (7, -1.15887778461219309589e-01) (8, 4.84911985803676448548e-01) (9, 2.04176212017846303581e-01) (0, 3.16792193909959940434e-01) (1, 1.60737514446330831408e-01) (2, 8.53234938781984170175e-02) (3, 4.42391409974821139817e-02) (4, 1.16537727366042828669e-01) (5, 1.88761650127090474527e+00) (6, 3.45032765970622712359e-01) (7, 2.50572612283216228368e-02) (8, 5.11505712885863883521e-01) (9, 2.68980991939425373438e-01) (0, 8.67558767486925730417e-01) (1, -1.50597540116638953928e-02) (2, 4.91765590929656090657e-02) (3, -7.60499460077614514164e-02) (4, 3.60935779833464684407e-02) (5, -1.26928726967154587718e-02) (6, -7.34719139917832664288e-02) (7, 1.38151171463762628688e-01) (8, -2.84666258495285817709e-01) (9, -7.10887614331037476223e-02) (0, 7.89018754133591015965e-01) (1, 6.59360037459054137976e-01) (2, 5.20484169287600773046e-01) (3, 5.07191271794953602026e-01) (4, 4.65514161897816913793e-01) (5, -1.27527248650658497908e+00) (6, -2.29000332022103236795e+00) (7, -2.27933827342610673128e+00) (8, -8.55314785257073273428e-01) (9, 5.12097870273509281347e-01) (0, -1.95703890559601934029e+00) (1, -1.47040138145961979399e-01) (2, -1.55100742479839542876e-01) (3, -2.00706103941478891661e-01) (4, -3.32317056259193666090e-01) (5, 7.06874499911672171670e-01) (6, 2.83387812673992822710e-01) (7, 2.04875317426643721586e-01) (8, 3.23746147661102878779e-01) (9, -1.36574549310977594319e-01) (0, 1.91825892885999826909e-01) (1, 7.01411397118684998286e-02) (2, 1.16561222161781427586e-01) (3, 1.69927369143497597470e-01) (4, 9.01742384691354009751e-02) (5, 1.75321328325115688429e+00) (6, 2.02485374063817502588e-01) (7, 1.08660807607159886484e-02) (8, 6.03574945155696873655e-01) (9, -7.23519811321454847652e-02) (0, 1.71957854291277079106e-01) (1, 1.14062848772537347997e-01) (2, 8.20456028838273815351e-02) (3, 5.98510236401674569628e-02) (4, 1.55821244503986489072e-01) (5, 1.91036867037666757696e+00) (6, 1.10142408758965998361e-01) (7, 3.72900565860257854345e-02) (8, 4.85786774620013628301e-01) (9, -4.78701332498746578992e-02) (0, 1.81312833091097025395e-01) (1, 1.76042690823627279162e-01) (2, 1.29918329368186674655e-01) (3, 2.23412141154361532092e-01) (4, 1.08323760281158240626e-01) (5, 1.92648108168141640739e+00) (6, 3.26902202771102712298e-01) (7, -1.35798216500525481543e-01) (8, 5.94411091371970345953e-01) (9, 1.95180154950578776951e-01) (10, 5.52667111953339063035e-01) (11, 5.22041798432907655503e-01) (12, 5.39198076773604983991e-01) (13, 5.40231639878996028337e-01) (14, 2.05315109981877297329e-01) (15, -5.41598725011691706221e-01) (16, 5.21676041980824067856e-01) (17, 4.32192613027588767860e-01) (18, 4.75039505180878340873e-01) (19, 5.03783408230023432850e-01) (20, 4.04408840923432766346e-01) 
