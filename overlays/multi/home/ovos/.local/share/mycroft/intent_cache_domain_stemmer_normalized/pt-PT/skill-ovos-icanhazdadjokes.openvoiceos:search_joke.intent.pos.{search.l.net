FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.22376376513701634607e+00) (1, 2.28336522285205090199e+00) (2, 1.87016560702041534370e-01) (3, -5.48397394991604669734e-01) (4, -1.44881589997111848156e+00) (5, -5.95238480581777418266e-01) (6, 1.44329097639633530115e-01) (7, -4.37573815992345072079e-02) (8, -1.57547840017377427380e+00) (9, -1.47853543150722077648e+00) (10, -1.08935858973734783772e-02) (0, -1.07798749914289238028e+00) (1, 5.79321584095682773352e+00) (2, -6.24417062837025804711e-01) (3, -1.07136984875322105459e+00) (4, -7.45904628997529739465e-01) (5, -2.08113948786188629470e+00) (6, -5.93263067293307466699e-01) (7, -7.85144735937799209680e-01) (8, -2.00135864739715252369e+00) (9, -8.42435446446622715477e-01) (10, -5.98279394197604341699e-01) (0, -2.27632256333094806777e+00) (1, 2.48004186068040111124e+00) (2, -1.01087269218250508374e-01) (3, -2.74513839345263521707e-01) (4, -1.71432677555381363099e+00) (5, -7.13289953484075534007e-01) (6, -7.61764988615953875239e-02) (7, -2.26469498526484569467e-01) (8, -1.15524624427511990454e+00) (9, -1.73262393373548095887e+00) (10, -2.90810357947632658338e-01) (11, 9.04617805370101724094e-01) (12, 5.90921074142183933020e+00) (13, 2.31663717631560528432e+00) (14, -8.31069716582441664343e-01) 
