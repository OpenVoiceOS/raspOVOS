FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.54570885220901443891e-01) (1, 2.74232165718126252862e-02) (2, -1.31291733512873459722e-01) (3, -7.90402082896185520511e-02) (4, -8.24622301554632786136e-02) (5, -6.23816966537358519318e-01) (6, 3.80838205716275357560e+00) (7, -2.34442015311580598258e-01) (8, -1.00896898957706718236e-01) (9, -4.39365798394723838793e-03) (10, -3.35284000935681059108e-01) (0, 3.73940069185377643723e-01) (1, 1.47415849776329987986e-01) (2, 2.34732400090756465616e-01) (3, 1.32800209732117646677e-01) (4, 1.02006770135226132457e-01) (5, 1.50000000000000000000e+03) (6, -2.77969583190683389162e+00) (7, 1.63210341414586207476e-01) (8, -1.03575424697977513944e+00) (9, 3.04175759331608286384e-01) (10, -2.12727163770280031097e-03) (0, -3.02684106840982347641e-01) (1, -3.63682318000203147479e-02) (2, 7.66104389460676993284e-02) (3, 9.26454890998000407665e-02) (4, 7.81775791676634634886e-02) (5, -8.21894880275269246184e-01) (6, 1.50000000000000000000e+03) (7, 3.61067580205244112457e-02) (8, 2.29942395142954253417e-01) (9, -1.30249904115738834864e-01) (10, -5.67631373808087161259e-02) (0, 1.03854562751421064526e+00) (1, 7.86589567518753085551e-01) (2, 7.50025850689929884929e-01) (3, 8.12392537451309237895e-01) (4, 7.62714859998744998393e-01) (5, 1.62887794466987023689e+00) (6, 1.39642243546796351872e+00) (7, 2.53108296517714626006e+00) (8, 2.40615542892111600182e+00) (9, -5.94761283482737379558e+00) (10, 4.94916650413784242613e-01) (0, 2.39536560134530462918e+00) (1, 1.54618029864657802186e+00) (2, 1.55947344573367518983e+00) (3, 1.39410740705359836866e+00) (4, 1.42191983955133816053e+00) (5, 2.12227238047812221566e+02) (6, -6.50980501174999837133e+00) (7, 5.88943154309968690541e+02) (8, 6.84943757342519443654e+00) (9, 8.07554817618952469616e+00) (10, 2.29811582245769779886e-01) (0, -3.26314039575784642366e+00) (1, -2.22895826532262697484e-01) (2, -1.39529082312005919819e-01) (3, -1.72161135210412874486e-01) (4, -2.67731036378759279515e-01) (5, -2.05771309826190018644e-01) (6, 4.24895243696135693767e+00) (7, -3.12094380526097447959e-01) (8, -1.57870863745549067092e-01) (9, -1.37323716386507921339e-01) (10, -5.59141670883942620840e-01) (0, -8.63789585638289059144e-02) (1, 7.14606410582316997626e-01) (2, 6.55540301223052401802e-01) (3, 7.25181004722369793036e-01) (4, 6.09746231456054221809e-01) (5, 2.91478588579891129129e+00) (6, 3.59142280620830200988e+00) (7, 2.41255288093510023018e+00) (8, 2.61666700531484108794e+00) (9, -3.48678656969439160207e+00) (10, -1.45612759532351510039e+00) (0, 2.30085531365143625138e+00) (1, 1.55905525954593104920e+00) (2, 1.48677105279792232118e+00) (3, 1.50526813240874690614e+00) (4, 1.44646034957993885328e+00) (5, 3.72532792141726076807e+01) (6, -6.34241404116217299958e+00) (7, 4.35336772391776491986e+01) (8, 1.60258461743052027515e+00) (9, 1.48635890608106784327e+01) (10, 1.27645333671309396673e-01) (0, -3.86696690787190100469e-01) (1, -7.56641241197763825266e-02) (2, -9.81793838029085541574e-02) (3, -7.92235754777781235603e-03) (4, -3.38646086340128535386e-02) (5, 6.60401534928283573400e-01) (6, 2.42314925810680703577e+00) (7, -1.70062607534098658713e-01) (8, -4.24522981689163317331e-02) (9, -5.13999147098959177637e-02) (10, -6.67023329775209838921e-01) (0, 1.23259444721456334904e+00) (1, 6.89972403076029916491e-01) (2, 6.11435907509661924486e-01) (3, 6.26806812908984434252e-01) (4, 6.38906570699549924974e-01) (5, 1.41460068717469567012e+00) (6, 2.13829106174300997978e+00) (7, 3.13353827149881691838e+00) (8, 2.36381201148607900109e+00) (9, -5.33719941091930571986e+00) (10, 3.17673425831660249941e-01) (11, 4.81819152508152548364e-01) (12, 4.59429982520240975941e-01) (13, 6.79293976867121562790e-01) (14, -2.54378733646624610731e-01) (15, 4.63421745710452193112e-01) (16, 4.21713079101843968388e-01) (17, -1.09943100289850381746e-01) (18, 4.27527813725550764890e-01) (19, 4.56285563283362505249e-01) (20, -1.96559448743691689288e-01) (21, 2.81818273011586906129e-01) 
