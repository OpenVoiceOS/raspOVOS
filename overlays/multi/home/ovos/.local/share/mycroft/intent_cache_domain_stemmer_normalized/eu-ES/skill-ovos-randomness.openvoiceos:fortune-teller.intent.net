FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.23835884185956590642e-01) (1, 2.94284571290836349799e-01) (2, 2.79803987921104502234e-01) (3, 3.43644041896686569526e-01) (4, 2.44516674757823959663e-01) (5, 2.54148179250318584366e+00) (6, 1.44607530797659894484e-01) (7, 9.42639185578253324671e-01) (8, 2.17670240392473957058e-01) (9, 1.84868424841480638587e-01) (0, 7.43333018408171786184e-01) (1, 9.41926520303202063911e-02) (2, 1.93898847325177203782e-01) (3, 1.68078197164864495683e-01) (4, 2.46763443572850182939e-01) (5, -1.68689907272263850402e+00) (6, -3.75416620935467709730e-02) (7, -3.08982239720937579275e-01) (8, -4.31337293933577503591e-01) (9, 2.00006148886226725603e-01) (0, 8.13044332119153612126e-01) (1, 3.44213658826196700069e-01) (2, 3.79741886513078719112e-01) (3, 3.73951697604501753780e-01) (4, 2.76425542192304585232e-01) (5, 2.52771671073991832657e+00) (6, 1.00952671731650359122e-01) (7, 9.73140912593033369227e-01) (8, 7.85086685321605276533e-02) (9, 2.72632986017780742927e-01) (0, 7.60209939465872897024e-01) (1, 1.13459279759259248910e-01) (2, 1.76722390575737908769e-01) (3, 1.26884369178147327073e-01) (4, 2.86138629539342048691e-01) (5, -1.67238866467877711486e+00) (6, 4.12008009330678756643e-04) (7, -3.17840726730939715505e-01) (8, -3.32753260384745674916e-01) (9, 2.51512280773662610933e-01) (0, 6.70925643446372621526e-01) (1, 2.50630420029983536079e-01) (2, 3.10015578151569382026e-01) (3, 3.26013718129024521186e-01) (4, 3.27931601882801071479e-01) (5, 2.75691712948754608092e+00) (6, 6.29388558518285817778e-02) (7, 9.94270032734301145716e-01) (8, 1.92543064532467972372e-01) (9, 2.80734017201977215095e-01) (0, 7.78479061112754000540e-01) (1, 1.65784953160614922929e-01) (2, 2.17795213682980492997e-01) (3, 2.28134056551785424638e-01) (4, 1.51814626528353646684e-01) (5, -1.81636431743308390807e+00) (6, -7.58693634833363522718e-02) (7, -9.35397817274664089560e-02) (8, -3.59265548875666973494e-01) (9, 1.99835329424881052995e-01) (0, -1.21355824441241333389e+00) (1, 1.79602972559550662368e-02) (2, -5.84678702659985199963e-02) (3, -1.17450149417676633079e-01) (4, -1.45932359308757420013e-01) (5, 1.15488278030447055755e+00) (6, 7.72250456154706041434e-03) (7, 9.21327189938539903302e-01) (8, 3.81302332754091533040e-01) (9, -3.46823083266438944583e-02) (0, 6.98098397559229510989e+00) (1, 4.55853856604163498734e-01) (2, 3.80954171966378540848e-01) (3, 3.97349275152747483109e-01) (4, 4.10902887086932511185e-01) (5, -3.43660731307765532350e+00) (6, -1.20749888866375543195e+00) (7, -3.61008316201672452284e-01) (8, -2.80396043815077433692e-01) (9, 8.48899374930158101549e-01) (0, 1.12258885649766204651e+00) (1, 1.68432372355517973039e-01) (2, 2.71922620678004767214e-01) (3, 2.32249620103892912004e-01) (4, 3.05789421045836951052e-01) (5, -1.92920183232517938876e+00) (6, -3.32388891262933972026e-01) (7, -2.55307831541913665685e-01) (8, -4.41594649299031083434e-01) (9, 3.33096498496193715866e-01) (0, 7.26435355993436449040e-01) (1, 3.16300962448940292671e-01) (2, 3.09181142927036300971e-01) (3, 1.85042146921978012397e-01) (4, 3.63959241987094894721e-01) (5, 2.55635280864793834610e+00) (6, 7.89824965249891347563e-02) (7, 9.33012133926775510950e-01) (8, 2.15861284127024433133e-01) (9, 3.05155545183735332770e-01) (10, 3.52660707292478170505e-01) (11, -3.63217192200086691489e-01) (12, 3.02223987040441122165e-01) (13, -3.10582899852492821946e-01) (14, 3.37208963093679037204e-01) (15, -3.31070916159846795335e-01) (16, 5.70127474721172089467e-01) (17, -2.29335514536781803763e-01) (18, -1.32818042618056575410e-01) (19, 2.96290434060018148532e-01) (20, 3.15865989088248977357e-01) 
