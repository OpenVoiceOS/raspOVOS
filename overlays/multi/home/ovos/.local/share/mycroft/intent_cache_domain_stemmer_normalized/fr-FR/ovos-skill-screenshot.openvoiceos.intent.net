FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.28437039162056720887e-01) (1, 4.50578312546740022970e-01) (2, 4.52956403762827364279e-01) (3, 3.47654211492071596457e-01) (4, 3.81197768420706240011e-01) (5, 1.08444979302069111071e+00) (6, 1.14384525931426761503e+00) (7, 2.21051746931097720106e-01) (8, 1.85942012778595094913e-01) (9, 8.55950353448098333331e-02) (0, 5.41459244586090515661e-01) (1, -1.67496617277321457884e-01) (2, -1.14057991047558454634e-01) (3, -3.02886174518438647252e-02) (4, -6.50349663097234964582e-02) (5, 2.13914236800993029508e-01) (6, -1.32344842796752715230e+00) (7, 1.13816780920077054162e+00) (8, 9.91618667926747188179e-02) (9, -4.44869206745001147252e-02) (0, -4.94390759523051059876e-01) (1, 5.06405769153603690924e-01) (2, 4.79256360097893796546e-01) (3, 3.62578647448786817176e-01) (4, 4.52666310831078610999e-01) (5, 1.11934941522261066638e+00) (6, 1.07993327743360278959e+00) (7, 1.33126613850480124412e+00) (8, 2.15795151030424875449e-01) (9, 2.02843623902753955601e-01) (0, 6.22270469463924613684e-01) (1, -9.49308977920385599347e-02) (2, -1.16222146292385725141e-01) (3, -1.64485379447397828123e-01) (4, -4.98804406720968554478e-02) (5, 8.23705504738075688920e-01) (6, -1.38731824701259398580e+00) (7, 1.20681876267243115564e+00) (8, -3.10496378388804977755e-02) (9, -2.02301401038822770140e-01) (0, 1.39200643241814109308e-01) (1, -1.23409311147789135799e-01) (2, -2.05435114773372895502e-01) (3, -6.99975889645615689805e-02) (4, -1.46055373223880957667e-01) (5, 5.55892369666085017776e-01) (6, 1.54275396126568864474e+00) (7, 9.07948201093821571916e-01) (8, -2.70670243872618676573e-01) (9, -6.15789073079378246334e-01) (0, -3.97281050588028372683e-01) (1, 4.00084662408361879660e-01) (2, 3.36700822383890596701e-01) (3, 4.10742203862200228048e-01) (4, 4.56028471858034578634e-01) (5, 1.10411096624514026843e+00) (6, -2.05819803742631757260e+00) (7, 1.46927075412295077284e-01) (8, 2.54732187541365839856e-01) (9, 4.97410235707467229815e-02) (0, -3.90626486645322124058e-01) (1, -3.44997928088829841631e-01) (2, -3.81798811799214210527e-01) (3, -3.00119855052159156816e-01) (4, -3.01840723103211250322e-01) (5, 1.25831922176380706091e+00) (6, 1.56073325905263970981e+00) (7, 8.43737428579478310198e-01) (8, -2.40548645425928270258e-01) (9, -3.53074784353145543214e-01) (0, 1.14882935382745882125e-01) (1, 5.29091245200061455201e-01) (2, 6.39085112776183517092e-01) (3, 6.78770116235637099855e-01) (4, 7.10015914108180434816e-01) (5, 5.89173775118307929688e-02) (6, 1.07070526573763169509e+00) (7, 3.42185743004883857754e-01) (8, 9.84086838178290901347e-01) (9, 7.59657578036054603743e-01) (0, 1.34693250596931907159e-01) (1, -1.75617095523203647911e-01) (2, -2.04027820818747318565e-01) (3, -1.90726239674414432823e-01) (4, -2.67478660189236439049e-01) (5, 7.65252759460244402767e-01) (6, 1.58153026583850930820e+00) (7, 8.79269679579882668108e-01) (8, -2.01310598625159320463e-01) (9, -5.84492767720968364742e-01) (0, 1.07399475366285815370e-01) (1, -1.07662553759674206599e-01) (2, -1.23931090208152905330e-01) (3, -1.70815500291446875636e-01) (4, -2.01415735157589204096e-01) (5, 3.99314715483174043076e-01) (6, 1.54690874400795053134e+00) (7, 8.61354713831095741838e-01) (8, -1.90076344980216083158e-01) (9, -4.65718592077047466304e-01) (10, 4.20152384013662782980e-01) (11, -2.35235141420609139562e-01) (12, 4.96300305397043672873e-01) (13, -2.51551976257807397008e-01) (14, 5.31929365064525261353e-01) (15, 4.86524890334139314962e-01) (16, 5.90469003565172512182e-01) (17, -2.06795463247591793099e-01) (18, 5.61893579460243541845e-01) (19, 5.77316357459449314149e-01) (20, 4.67962618143091646505e-01) 
