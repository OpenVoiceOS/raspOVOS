FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.71331062250132948321e-01) (1, 2.30909972720141798419e-01) (2, 2.03132435016627699298e-01) (3, 1.97038076155181318683e-01) (4, 2.16820909910197645587e-01) (5, -6.48585998965797994043e-02) (6, 2.23291120666384179660e-01) (7, 1.27729312773334786613e+01) (8, 2.65823453001971687915e-01) (9, 1.67621328669905089725e-01) (0, 7.57050263546402812942e-01) (1, 6.28157663010056377395e-01) (2, 7.08412687145169139846e-01) (3, 6.98314416073258281692e-01) (4, 7.04056027196343303665e-01) (5, -4.64536158450103708883e-02) (6, 3.09415534308841500000e-01) (7, -5.00105159107673014063e+00) (8, 4.97853865567140452253e-01) (9, 4.59360978419990406696e-01) (0, -2.53295704080436556715e-01) (1, -1.85148529066417488753e-01) (2, -1.63228891147945198714e-01) (3, -2.05429665102336678206e-01) (4, -3.37440355970237526595e-01) (5, 2.18164246564938379969e-01) (6, 2.99067508464886555597e-01) (7, 4.55854097881995556918e+00) (8, 1.58593251478140129240e-01) (9, -2.77330900134320559869e-02) (0, 3.55011887651309008401e-03) (1, 6.20035520921312227616e-02) (2, -5.39151587356962447295e-02) (3, -7.79790961017050032744e-02) (4, -2.56200180222429380050e-02) (5, -2.57317853815349939506e-01) (6, 1.04773416293676924216e-01) (7, -5.76413059397924243399e+00) (8, 3.95020834336839640755e-02) (9, 8.59352342019640003112e-02) (0, 2.33119338088031202716e-01) (1, 1.60168803565497785968e-01) (2, 2.77709334425921883227e-01) (3, 1.41202672653193861407e-01) (4, 2.58153884940143074633e-01) (5, -1.50836742813736074398e-01) (6, 1.07175576675056824505e-01) (7, 1.27441077973234460075e+01) (8, 8.69147547411875109891e-02) (9, 1.80956131953119658817e-01) (0, 8.74951251673654895047e-02) (1, 1.86431131594176680011e-01) (2, 1.85221887462134748858e-01) (3, 2.77078329854007210375e-01) (4, 1.33813544445033461017e-01) (5, -1.31679139430671748867e-01) (6, 1.20694092649340042889e-01) (7, 1.26219464163768098075e+01) (8, 2.71850406460757698657e-01) (9, 1.75312361854433440556e-01) (0, -1.15578304492806774317e-01) (1, -1.34949068986749021182e-01) (2, -1.36431466304635373721e-01) (3, -9.02093159788602411142e-02) (4, -1.33644025289391843447e-01) (5, -2.88059029963358470550e-01) (6, -1.32681075000142423281e-01) (7, 3.44759766461930539094e+00) (8, -5.38715305560582696787e-02) (9, -1.38948443168157090288e-02) (0, 1.16592963777212108023e-01) (1, 1.95546192668107965407e-01) (2, 1.62572359285978296217e-01) (3, 1.09640655658868754752e-01) (4, 2.52087218306688398695e-01) (5, -1.66205253204987579707e-01) (6, 4.52373365169598973257e-01) (7, 4.59294567102420092652e+00) (8, 7.25286133604711502620e-01) (9, 3.17814877613780188970e-01) (0, 2.32773750357623487872e-01) (1, 2.60006248288150276782e-01) (2, 9.91113104748682360867e-02) (3, 1.33333976649041563434e-01) (4, 2.52422913246150459887e-01) (5, -1.84009551401287163586e-01) (6, 2.12663746613382720341e-01) (7, 1.26520692143130109031e+01) (8, 1.58536336653228193683e-01) (9, 1.99852488178133391727e-01) (0, -1.85163251413677010238e-01) (1, 7.44843247476240956362e-03) (2, -1.34003976852267780995e-01) (3, -1.19630570084422641064e-01) (4, -7.77887874549327423823e-02) (5, 2.31090415304734120294e-01) (6, 2.47374218111665600262e-01) (7, 5.17685259435403200001e+00) (8, -7.29027625974992127267e-03) (9, -4.63252612656055023921e-02) (10, 2.26061149768824964923e-01) (11, -1.83677307619426521956e-01) (12, 6.09382356368000865920e-01) (13, -1.02732009974624310944e-01) (14, 2.67449124984736885668e-01) (15, 2.49813928537364449145e-01) (16, 1.56264405866680944346e-01) (17, 8.18761966156918430393e-02) (18, 2.65029325418467964770e-01) (19, 6.20900983773167491897e-01) (20, 9.05563750195459704617e-02) 
