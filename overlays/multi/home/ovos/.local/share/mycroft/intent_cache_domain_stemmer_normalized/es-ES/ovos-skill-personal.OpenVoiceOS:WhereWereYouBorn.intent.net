FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.29358182141549526989e-01) (1, -9.42930415313370934305e-02) (2, -2.59427711408265482262e-02) (3, -1.78843572776444907635e-02) (4, -4.34613079239211646393e-03) (5, 3.90555203700703668090e+00) (6, 8.16084393561321341792e-01) (7, -9.21718196761441288523e-02) (8, 5.27757740929868823798e-01) (9, 1.69083128985913572206e-01) (0, -2.04283860497866343042e-01) (1, -2.22154471747142590043e-01) (2, -1.66975121669036719041e-01) (3, -1.96462578795415732102e-01) (4, -1.39131996504527899461e-01) (5, -6.01794317354991861180e+01) (6, 5.01466746981243827186e-01) (7, 4.73576077873066769719e-01) (8, 3.49225230205707060094e-01) (9, -1.10925519568169983486e-01) (0, 2.59237519925764825501e+00) (1, 3.68462462881912200530e-01) (2, 3.19844213286746836822e-01) (3, 4.14330963949073760588e-01) (4, 3.52268864373077250640e-01) (5, -1.73732625539274998516e+00) (6, -1.14291502701934710728e+00) (7, -1.95489379998446399789e+00) (8, 2.90439964207714507172e-01) (9, 4.06986859808413481421e-01) (0, 1.22929871937158785578e+00) (1, 1.16814605954165762203e-01) (2, 9.77965891985848323475e-02) (3, 1.45866248819108368373e-01) (4, 2.08319366040702280696e-01) (5, -1.97501150509262934918e+00) (6, -4.03336461712192229090e-01) (7, -4.32193911438340072628e-01) (8, -2.93112609704744286887e-01) (9, 1.28238292428267869338e-01) (0, -1.00468991746615698979e+00) (1, -2.71203441670101741412e-01) (2, -2.97706077000063462634e-01) (3, -2.93268540998857962787e-01) (4, -2.22318651279371837237e-01) (5, -6.01446794336274095372e+01) (6, 3.26650629597595776321e-01) (7, -1.01734020691215754084e+01) (8, -1.16634118327259506120e-01) (9, -2.13925848434455195823e-01) (0, 1.40458296287597983465e+00) (1, 9.96388233832630823561e-03) (2, 1.15446795892041098597e-01) (3, 1.98318717252533832651e-01) (4, 1.32554141055863272669e-01) (5, 1.13148258837026749468e+00) (6, 5.02128727030889843164e-01) (7, 1.33607356974498681090e+00) (8, 6.40280475410500149458e-01) (9, -1.09478148412714179627e-01) (0, -5.46444316597790136214e-01) (1, 1.12257296205463444339e-01) (2, 5.39034325489425869549e-02) (3, 6.81951958546066633327e-02) (4, -3.72528191795921323481e-02) (5, -6.02556917881205507115e+01) (6, 2.81289854103285830167e-01) (7, -9.00265494698307827681e-02) (8, 1.12001295170573653137e-01) (9, -3.03776584000009577946e-02) (0, -2.28318507427215044991e-01) (1, -2.37128141991359564500e-01) (2, -8.31120048682515571992e-02) (3, -2.13843401245338238237e-01) (4, -2.12777774504882610795e-01) (5, -6.02132720229759641484e+01) (6, 5.13214017803768851600e-01) (7, 5.34782277101830350041e-01) (8, 3.31537387955836759801e-01) (9, -6.09806798577794198502e-02) (0, 2.58265004581145074525e+00) (1, 2.02102121645563154173e-01) (2, 3.13980077141874425184e-01) (3, 2.29043659502618873747e-01) (4, 1.93830617452018766356e-01) (5, -1.05106502073392027441e+00) (6, -8.13515649308311994403e-01) (7, -1.29055447589887606341e+00) (8, 1.51987562329077036116e-01) (9, 1.74297277524416038830e-01) (0, 2.54205221956900384583e+00) (1, 2.80708600515478301496e-01) (2, 1.52438272470586805296e-01) (3, 1.81762099945896177244e-01) (4, 1.97173197502248792601e-01) (5, -1.04035595110995071622e+00) (6, -8.15066103954660947650e-01) (7, -1.26830811139477717120e+00) (8, 1.63649419695638925765e-01) (9, 2.41504766687099470257e-01) (10, 2.61038862824838902021e-01) (11, -2.90142392219513822749e-01) (12, -4.46033236670507593491e-01) (13, -6.91791351765896345150e-02) (14, -2.77503883154890995666e-01) (15, 8.88840870194462090437e-03) (16, -5.52102478950029729177e-01) (17, -3.01006266327113081172e-01) (18, -3.79437041666879193436e-01) (19, -3.72228150453938977371e-01) (20, 4.88381654227927897161e-01) 
