FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.01072404749309208150e+00) (1, -1.01262779102499311801e-01) (2, -1.58647458412001785000e-02) (3, -1.37040657118732756015e-01) (4, -1.14062459335501020785e-01) (5, 1.56638754731340743009e-02) (6, 1.24692900316405075323e+00) (7, 7.68304519615923053877e-01) (8, 2.41611849489225566368e-01) (9, -2.45135562178960458857e-01) (10, -1.57269232203169045947e-01) (11, -1.13216105224958910047e-01) (0, 9.49470557183369590071e-01) (1, 2.76053589329949056186e-01) (2, 3.53359174475899318058e-01) (3, 2.74688501403561269321e-01) (4, 2.51153786227932551700e-01) (5, -1.22431825709557087767e-01) (6, 1.22682843613019301188e+01) (7, -1.64948405878627551990e-02) (8, -4.52504061617667541206e-01) (9, 3.53375404345276200591e-01) (10, 4.35226128677616730389e-01) (11, 2.40804109822183559642e-01) (0, 6.84223315990275637866e-01) (1, 1.44142053867599206907e-01) (2, 2.42551822061559341215e-01) (3, 2.35325891370793960355e-01) (4, 2.05368172223588607572e-01) (5, 1.72817597249449506069e-01) (6, -2.36674322967712980059e+00) (7, -3.40973326589125325103e-01) (8, -3.08487081553000141998e-01) (9, 2.69389071846176220149e-01) (10, 3.35141494281930574228e-01) (11, 2.46456390261620583715e-01) (0, 4.99580256021327273608e-01) (1, 1.75333152004614772901e-01) (2, 8.99901189292821451771e-02) (3, 2.56349699982539092069e-01) (4, 2.04516860135928069120e-01) (5, 1.72435161317401830505e-01) (6, -2.24253321200261890311e+00) (7, -2.94148169799544390024e-01) (8, -3.07190471912878682037e-01) (9, 3.90177415096927604488e-01) (10, -5.96316343273917692791e-02) (11, 2.30937810154466155455e-01) (0, 8.92214983612641177046e-01) (1, 3.48267641411057093936e-01) (2, 2.25587346152296641666e-01) (3, 2.55765107021561244327e-01) (4, 2.78680880115261708774e-01) (5, 2.62470694651828984068e-01) (6, 1.21572758922865702402e+01) (7, -1.11359082366713255108e-01) (8, -5.79629302480037189582e-01) (9, 2.32364817725899203138e-01) (10, 3.52809132317791596112e-01) (11, 2.59268550804810760102e-01) (0, 8.81747454315766177046e-01) (1, 2.78428134069672261752e-01) (2, 2.72615138933888112582e-01) (3, 2.64618587241402247745e-01) (4, 3.04196071372261622745e-01) (5, 1.74913967421280153181e-01) (6, 1.22404431658377959025e+01) (7, -7.04869480984294666248e-02) (8, -4.22978781618888244331e-01) (9, 3.14720713137873642218e-01) (10, 4.27721225897560730633e-01) (11, 1.87350180099874447093e-01) (0, 3.71213965708384208142e+00) (1, 4.69288542835791078200e-01) (2, 4.10298258035261598220e-01) (3, 3.97901095419008699050e-01) (4, 4.15844812958319154372e-01) (5, 3.38728041222124576226e-01) (6, -4.76572429311886747172e+00) (7, -3.48126984508896897275e-01) (8, -1.13949786012169296257e+00) (9, 5.61430806334674681324e-01) (10, 4.95767994519506538520e-01) (11, 1.28628817984862586776e+00) (0, 5.96872567510909335375e-01) (1, 1.66770438143149318799e-01) (2, 8.83507080758962476397e-02) (3, 2.14908825644389067655e-01) (4, 1.76173070856467189893e-01) (5, 1.49966352279001124970e-01) (6, -2.31898890196929752250e+00) (7, -2.54257052089870094758e-01) (8, -1.63124702230945939352e-01) (9, 4.32977677667308880061e-01) (10, 3.42315623436173083194e-02) (11, 2.63885842175988705183e-01) (0, 5.72444483018225924731e-01) (1, 1.16484532543555216466e-01) (2, 1.06738115140334086095e-01) (3, 1.47131266483202849393e-01) (4, 2.69508885630503569608e-01) (5, 2.43265849197917827240e-01) (6, -2.21795110910783588309e+00) (7, -2.38962798263728709580e-01) (8, -2.88992277637974137594e-01) (9, 2.61671119713951183527e-01) (10, -2.72191500391761459499e-02) (11, 2.39639544399289611265e-01) (0, 1.76244579669238610187e+00) (1, 5.49993740435302580494e-01) (2, 4.56879774149120065907e-01) (3, 4.98239832039535257557e-01) (4, 4.76221626665055963734e-01) (5, 6.44944533149535259575e-01) (6, -4.46643048828679667395e+00) (7, 6.37598181163129495985e-01) (8, 7.26514776203879497629e-01) (9, 4.67046855275606298541e-01) (10, 3.88917126526861667291e-01) (11, 1.10061364945567463636e+00) (12, 5.34766097377134541624e-01) (13, 4.95819096651308244272e-01) (14, -2.63796103202389164988e-01) (15, -3.14005957000540070201e-01) (16, 4.85175629344217484995e-01) (17, 4.82369517173998063608e-01) (18, -2.25464159455474766336e-01) (19, -2.78271266274736694957e-01) (20, -3.20824594252394013072e-01) (21, -1.76128337048424093991e-01) (22, 2.85253864443700211329e-01) 
