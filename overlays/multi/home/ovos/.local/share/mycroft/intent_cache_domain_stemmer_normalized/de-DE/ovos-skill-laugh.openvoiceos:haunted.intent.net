FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.32474357503621065213e+00) (1, 2.60399779974268719140e-01) (2, 2.97450723795937344018e-01) (3, 2.17339719383763202432e-01) (4, 3.23860960750626369897e-01) (5, 2.49520585050771209756e-01) (6, 7.19544779337004780650e-01) (7, 7.50766382336594872982e-01) (8, -5.64879475620193982621e+00) (9, 4.15021849291018651851e-01) (10, -3.32188740505004709291e+00) (11, 6.72867277928513307650e-01) (0, 1.12867164242377027161e-01) (1, 4.15834248696353298014e-02) (2, -1.36133670176479867203e-02) (3, -6.45753159488651889975e-02) (4, 4.54476237927462917154e-02) (5, 5.61441473180745997951e-02) (6, 4.35358236836760684185e-02) (7, 3.84111478923156113296e-01) (8, -1.88805090383441975810e+00) (9, 6.93645154876576242042e-02) (10, -2.38835723231192176286e+00) (11, 5.79042397236676831263e-01) (0, 8.46069522759768377629e-02) (1, 1.19339756891859632981e-01) (2, 1.27450488731993299973e-01) (3, 1.13183848784102092377e-01) (4, -2.19424774490464651044e-02) (5, 7.90182660061534813956e-01) (6, 3.13980754287851437923e-01) (7, 6.69894097474033833883e-01) (8, 1.38156277968683194324e+00) (9, 6.20151457669823935603e-01) (10, 3.69466794913538976175e+00) (11, -1.78309075781793363591e-01) (0, 1.03681900164935159731e-02) (1, 7.41640345206118212218e-02) (2, 5.18085972418642487503e-02) (3, -6.76152913818501843934e-02) (4, -8.42568864919179816297e-03) (5, 8.65206825274642876700e-01) (6, 2.57297426285160224513e-01) (7, 5.82471773739369647060e-01) (8, 1.22132002447365084485e+00) (9, 5.32162243727266837112e-01) (10, 3.79443924760350270731e+00) (11, -4.14493796409810752457e-02) (0, 1.20023861023752220767e+00) (1, 2.36355626867902013366e-01) (2, 2.29985812591206761901e-01) (3, 2.39924648688924047057e-01) (4, 3.31508012400758000915e-01) (5, 6.88911268065091481061e-02) (6, 5.09757263076091593490e-01) (7, 3.84435213042914170067e-01) (8, -4.21535722446869787206e+00) (9, 3.77482085209209783372e-01) (10, -3.22169997475691305411e+00) (11, 5.36832138768295163977e-01) (0, 2.22701224315275975174e-01) (1, 1.00318402682330540254e-02) (2, -2.32474333907578024905e-02) (3, 8.06540162001635890787e-02) (4, -4.59182127679798879338e-02) (5, -4.36532356327081622061e-02) (6, 3.14047660040229006939e-02) (7, 3.59829731283976883560e-01) (8, -1.85499544561656004582e+00) (9, 4.29071461601124720664e-02) (10, -2.47696230838652198258e+00) (11, 6.24925985729547162073e-01) (0, 3.52345448190461485449e-01) (1, -7.69849586363594295957e-02) (2, -1.75750197755889125961e-01) (3, -4.19152918334762952801e-02) (4, -3.45263807733464309080e-03) (5, 8.71083950822034158712e-02) (6, -6.25168639434694195511e-02) (7, 5.00522881213361636732e-02) (8, 2.74856741788736158583e+00) (9, -1.15789110631228098214e-01) (10, 1.72302020234550878897e+00) (11, -7.98134001966278316953e-02) (0, 2.62353996563067237702e-01) (1, -1.19464885090637948362e-01) (2, 4.54451482545845317218e-02) (3, 4.64112501394264506671e-02) (4, -5.79519162063670770918e-03) (5, -1.10176407594015701719e-01) (6, -6.64785478902489568309e-02) (7, 3.11165928839042038589e-01) (8, -2.96844518382845112825e+00) (9, 4.54629752484822166614e-02) (10, -3.60437831386947493684e+00) (11, 6.37234419381471295374e-01) (0, 1.21223672535166318576e-01) (1, 2.91021631111956120830e-02) (2, -7.44769631872319592958e-02) (3, 1.01266028081402809091e-01) (4, 9.77971867670870131928e-02) (5, 9.16560324567970208243e-01) (6, 3.71782988132847047602e-01) (7, 6.28578179295571581875e-01) (8, 1.26016153652785534156e+00) (9, 5.90567367378294516556e-01) (10, 3.76926206683644338113e+00) (11, -1.45451743620797574463e-01) (0, 7.50691551425317737944e-01) (1, -1.24909596099017222715e-01) (2, -2.31273104949353408566e-01) (3, -2.63637030078528511456e-01) (4, -2.06664437009451973370e-01) (5, 1.71532999292198840013e-01) (6, 8.40275765937643637216e-02) (7, 1.51663760614255016534e-01) (8, 5.31744304349039631497e-01) (9, 3.04727254261099811394e-01) (10, 3.07985777952893002851e-01) (11, 3.17636932509246447398e-02) (12, -6.59946440523175026360e-02) (13, -4.26065058557140163842e-01) (14, 1.92846824046638276595e-01) (15, 3.60440643482858646962e-01) (16, -5.52662699287442132912e-02) (17, -3.64980124978172226768e-01) (18, 8.53691033799511611591e-01) (19, -3.83538329152213974815e-01) (20, 4.02802451112864612348e-01) (21, 2.91365474701000604085e-01) (22, 5.03586120563584094256e-01) 
