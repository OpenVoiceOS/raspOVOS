FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.43601964181815624499e+01) (1, 2.83245512332531368394e-01) (2, 1.75602977212282629349e-01) (3, 1.41298578168961047608e-01) (4, 2.10950256373497485596e-01) (5, -9.19903897925006819314e-01) (6, -1.48375876905681458595e+00) (7, -3.47724112928018680435e+00) (8, -4.67332405760197922007e+00) (9, 8.08610908839711095553e-01) (0, 8.40277945143532711825e+00) (1, 1.23814886665430101687e+00) (2, 1.26160958266344103151e+00) (3, 1.28372016406145128542e+00) (4, 1.15709283804979401467e+00) (5, 4.52208949696282613839e-01) (6, 1.05189821157868372836e+01) (7, 1.20653160459314587882e+01) (8, 5.15815995193509557737e+00) (9, -5.36593639259176358181e-02) (0, 3.39797412094450246300e+00) (1, 5.37836623261441104660e-01) (2, 3.64838269422520566909e-01) (3, 5.29840198228825443039e-01) (4, 3.79071061382759977310e-01) (5, 3.91400875522939395434e-01) (6, 9.76296653057898744521e+00) (7, 1.19735094926272633842e+01) (8, 5.14124768532304265989e+00) (9, -7.41465532188253506618e-02) (0, -1.22994397695383916869e+00) (1, -4.20565355915689526034e-02) (2, -7.77572293181086060532e-02) (3, -1.03808728267636346532e-01) (4, -3.83160163063669262362e-02) (5, 2.01701449277724320641e-01) (6, 1.38741590039043694027e+00) (7, 1.76661171374107772714e+00) (8, 4.85530145647242450391e-01) (9, -1.06319833617799314185e-01) (0, 5.30792123921813985277e+00) (1, 3.38861749145092983060e-01) (2, 3.95571999820771236234e-01) (3, 4.39500220688881892972e-01) (4, 3.32801633152070064359e-01) (5, -4.61882581676844705676e-01) (6, -2.10093113994638835962e+00) (7, -2.28860015256155557850e+00) (8, -2.07606801337668755991e+00) (9, 5.08383385983712576817e-01) (0, 2.43456805972908973956e+01) (1, 2.68045985188099356034e-01) (2, 1.50298507001015158036e-01) (3, 1.66948088492962332108e-01) (4, 2.35777893151852158127e-01) (5, -1.00080832956610876749e+00) (6, -1.40990218432905045631e+00) (7, -3.47717621982202640396e+00) (8, -4.67469269945531173960e+00) (9, 8.59694574180849935274e-01) (0, 5.73661995008277969532e-01) (1, 1.57241429508658936420e-01) (2, 5.75234026918140101126e-02) (3, 2.03921527871814417532e-02) (4, 5.27818494746413874319e-02) (5, -8.24798230218818512194e-02) (6, -2.43667406319569801454e+00) (7, -2.17489664275808047833e+00) (8, -3.24835171014708434800e-01) (9, 7.85050713283235029882e-02) (0, 5.35367611893119832445e+00) (1, 3.23741286887755552737e-01) (2, 4.38276275887122424013e-01) (3, 3.27987857057681242434e-01) (4, 4.30593192472090990908e-01) (5, -4.37975933517817606067e-01) (6, -2.25860645482612065749e+00) (7, -2.26857893748034067372e+00) (8, -1.99103472328851061057e+00) (9, 5.44686712471253775547e-01) (0, 1.00141583367880593336e+00) (1, 5.52940589892521733306e-02) (2, 4.80260921227589412941e-02) (3, 1.44264854263033037718e-01) (4, 8.46840774225846443235e-02) (5, -6.97023156066555044097e-02) (6, -1.91703168094798748200e+00) (7, -1.25053396321770393662e+00) (8, 5.45955253786428451601e-02) (9, 1.21272470928972753157e-01) (0, 6.06960353329467849903e-01) (1, 1.31011586011382630268e-01) (2, -5.97486334946482899877e-03) (3, -3.08555799630015614721e-03) (4, 1.58696200073691895405e-01) (5, -4.69369027900627053262e-02) (6, -2.28840499431271515718e+00) (7, -2.05246161688728046002e+00) (8, 5.54358588602504726017e-02) (9, 6.52168267232591247762e-02) (10, -3.06398243870358466534e-01) (11, 4.59046560722117247266e-01) (12, 5.24597297805075468702e-01) (13, 5.62224100132497905946e-01) (14, -1.52968435005343017519e-01) (15, -3.22582767572026252179e-01) (16, -4.30970962901429111014e-01) (17, -9.11612577950087626943e-02) (18, -2.88105357784891186190e-02) (19, -4.46559693475083230307e-01) (20, 4.59147309631080802195e-01) 
