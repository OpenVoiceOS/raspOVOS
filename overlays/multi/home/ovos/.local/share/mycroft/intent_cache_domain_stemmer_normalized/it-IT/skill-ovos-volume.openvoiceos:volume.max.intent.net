FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.05116127207271459199e+00) (1, 4.98212631692601548572e-01) (2, 4.20358177175237046619e-01) (3, 5.03174368192864873706e-01) (4, 4.51133720477534638782e-01) (5, 5.92272317482191668070e-01) (6, 7.09379060530825888975e-01) (7, -2.89352975120891553473e+00) (8, 2.87119680559746293103e-01) (9, 2.32780956114339077079e-01) (10, -4.22192794522783465538e+00) (11, 4.57872161007998823568e-01) (12, 1.17279881453218304266e+00) (0, 5.61513807597750935763e-01) (1, 2.79491462583092598049e-01) (2, 3.26650866145638374416e-01) (3, 3.35762948567418006984e-01) (4, 3.21419537837056068508e-01) (5, 8.33583281776036771893e-02) (6, 4.60215483742772435427e-01) (7, 1.55648588754136063539e-01) (8, 4.66198883782386441776e-01) (9, -7.43009587942957505646e+00) (10, 5.96663655012579854930e-02) (11, 1.00455717428454702200e-01) (12, 2.23920861561958756125e-01) (0, 1.53775839345137566028e+00) (1, 6.48427506533914566056e-01) (2, 6.49689202753358840958e-01) (3, 6.30448152867609024064e-01) (4, 6.31633748856836318986e-01) (5, 1.29417128696107197605e+00) (6, 9.79211884835534562832e-01) (7, 5.31341825523588706659e+00) (8, -6.17212124177272891679e-01) (9, 1.63150327272576305404e+01) (10, 2.08589602643614746569e+00) (11, 8.80926363183970329018e-01) (12, -7.89665227503856537172e-02) (0, 1.29978660498302538429e+01) (1, 3.27687342182416241343e-01) (2, 4.05708510891217510874e-01) (3, 4.57075220063943188364e-01) (4, 4.31185517922658245737e-01) (5, 5.58388094869421092170e-01) (6, 1.19982676118644993046e+00) (7, -2.45961640169129314160e+00) (8, 7.13369418627850748749e-01) (9, -7.51254822366508756559e-01) (10, -7.06942859734885686862e+00) (11, 4.22791289648058177253e-01) (12, 1.41380024884040333966e+00) (0, 1.61402547197024293091e+00) (1, 6.19664972273164749161e-01) (2, 5.35304313150697708146e-01) (3, 6.60837640610986709611e-01) (4, 5.56008947638326533891e-01) (5, 1.38642249091529179417e+00) (6, 3.54743681954076517382e-01) (7, 5.19559354433033515619e+00) (8, -6.69218085714634036698e-01) (9, 1.63330752469462368026e+01) (10, 1.98096355520799871641e+00) (11, 7.32639275505061138283e-01) (12, 6.02559576063074406327e-02) (0, 2.09115591207294082565e+00) (1, 4.79341079500054889628e-01) (2, 3.42094783690309101054e-01) (3, 4.50842415001725727031e-01) (4, 4.80480124261712604472e-01) (5, 6.60938462245522884153e-01) (6, 1.60830352086746497520e+00) (7, -2.77382991637692599696e+00) (8, 5.20465720412348398227e-01) (9, 8.96980561410995358429e-01) (10, -4.27614411404869265709e+00) (11, 4.50869621231008821383e-01) (12, 1.14358641494710600028e+00) (0, 1.61157034306287405556e+00) (1, 2.98736786092124617653e-01) (2, 2.82665116334758437233e-01) (3, 4.47234933818183633125e-01) (4, 4.61857994640670566078e-01) (5, -3.13234166958772930478e-02) (6, 3.90914480603981540074e-01) (7, 9.45584401066531382574e-02) (8, 3.67528513353324537416e-01) (9, -7.17830158635988535565e+00) (10, 3.23177543109051407938e-03) (11, 1.55184178913086084917e-01) (12, 1.94340976969902490268e-01) (0, 2.42779818697569194086e+00) (1, 1.02104499237985757443e-01) (2, 4.47168343238545928919e-02) (3, 1.75894788699598403348e-01) (4, 4.24660139255239113543e-02) (5, -1.20376535631332270970e-01) (6, -3.43157047811318352548e-02) (7, 4.61627546795344012587e-02) (8, 5.24448935378456160272e-01) (9, 5.22637900174641734097e-01) (10, 1.22146327497549261193e-02) (11, 9.48579158367166552779e-02) (12, -9.34543632862820661256e-02) (0, 1.35099888461800397010e+01) (1, 3.57983266332777549934e-01) (2, 4.17559584000738726051e-01) (3, 3.48026194939049293708e-01) (4, 3.60954706886442711067e-01) (5, 7.02776519866345379672e-03) (6, 3.31530831849929097377e-01) (7, 1.19545011317218813351e-01) (8, 2.91601049012793100967e-01) (9, -7.00444327656881959854e+00) (10, -4.06030434718622004753e-02) (11, 1.42964705353862214787e-01) (12, 3.03766653483127146984e-01) (0, -7.37188496354841626967e-01) (1, 2.75492487461928836634e-02) (2, -1.57562124916755669224e-01) (3, -1.00082192012512283252e-01) (4, -6.59626679508324292867e-02) (5, 6.45748026082932080616e-02) (6, 2.10696862610672899785e-02) (7, 8.81124683668483843491e-02) (8, 5.96104574417405275177e-01) (9, 6.94267864976979121039e-01) (10, -1.47685775415565045954e-01) (11, 2.51379650125786779924e-01) (12, -1.71424755580623894291e-01) (13, -1.14039083035198565708e-01) (14, -3.99752943341847855052e-01) (15, 4.98567492001445622396e-01) (16, -8.70335045226756365278e-02) (17, 4.97606858842761901052e-01) (18, -7.84839950468326358335e-02) (19, -3.61103615172832070890e-01) (20, 4.53988746760036143701e-01) (21, -3.91118163799395401892e-01) (22, 9.22388562916223508914e-01) (23, 3.55872276930445985421e-01) 
