FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.15008115452355852426e+00) (1, 1.23462526080359638603e-01) (2, 2.04830048558463290176e-01) (3, 2.29031009552230074844e-01) (4, 4.72002531859771479184e-02) (5, -9.33735729130660552233e-02) (6, -7.22973343458255923721e-01) (7, -1.21835031884832606375e-01) (8, -1.17388760787950419129e+00) (9, -8.06680974815729867622e-01) (10, 1.23510514750910488369e-01) (0, -4.15355270728123482371e+00) (1, -2.24684255213066536028e-01) (2, -3.60519008726402911957e-01) (3, -3.28038459659143966096e-01) (4, -1.88243674129768862047e-01) (5, 9.17089600412528627160e-01) (6, 9.02416593375427344981e-01) (7, 1.45972590141337732472e-01) (8, 1.58637877122305814837e+00) (9, 8.90885936590471883001e-01) (10, -2.06108056689080776369e-02) (0, 9.41798383936096605851e-01) (1, -3.04755451644106341302e-02) (2, -3.50423859918756949727e-02) (3, -2.59515592104631953943e-03) (4, 6.96750027572468899617e-02) (5, -5.07475696829252642672e-01) (6, -1.88330073914479506625e-01) (7, 1.75903868183920966684e-02) (8, -1.54624577999783219262e+00) (9, -9.44473568773823712874e-02) (10, 3.24667410726491301176e-01) (0, 1.24421741654179340841e+00) (1, 1.46996199752382553094e-02) (2, 2.01999514962725029710e-02) (3, 5.80061047936967777439e-02) (4, 9.79320972825578478504e-02) (5, 1.34200489590721350197e+00) (6, 4.20201650982927998879e-01) (7, 2.86259408050811403612e-01) (8, 2.46300181453997080183e+00) (9, 2.82488548647040593753e-01) (10, -1.59987313758094468197e-01) (0, 2.23136885696374154264e+00) (1, 9.83890928072335274601e-02) (2, 1.49979364101350515215e-01) (3, 1.27172064010560720293e-01) (4, 1.09661232654512122431e-01) (5, -4.79809378206099867992e-01) (6, -1.36206480369496230054e-01) (7, -7.33983454097835164021e-02) (8, -1.27927874786382633765e+00) (9, -1.08508422554398117899e-01) (10, 3.97673524088716090485e-01) (0, -1.03253279153954800051e+01) (1, 4.85621472724438563162e-01) (2, 3.57371603973866358572e-01) (3, 3.75173484810353174979e-01) (4, 5.36563267835140744744e-01) (5, -1.06072684531153926812e-01) (6, 3.05589054682303795651e-01) (7, 4.57047976587558191230e-01) (8, 5.54662987848467348151e-01) (9, 2.12434913420916027249e-01) (10, 4.68601843632978187770e+00) (0, 2.26279259705268120939e+00) (1, 6.50350711984040152913e-02) (2, 1.22825290982186988153e-01) (3, 3.42571846885086767065e-02) (4, 1.93321067814290731279e-01) (5, -4.75749122081074504731e-01) (6, -6.97493242775677757539e-02) (7, 3.21669823233918864003e-02) (8, -1.27254594130044895728e+00) (9, -1.34902757821138447047e-01) (10, 3.82667890853738368317e-01) (0, 1.37775358398459202292e+00) (1, 1.06146775698651565922e-01) (2, 1.14060931420315994633e-01) (3, 1.59533195710172021053e-01) (4, 1.61270179367055260800e-01) (5, 1.12477585984661776486e+00) (6, 3.20297270244192910926e-01) (7, 1.72764855378902099092e-01) (8, 3.26154113841685289188e+00) (9, 3.36004891883010137210e-01) (10, -2.74890711616237126691e-01) (0, 1.32323225428364521505e+00) (1, 6.42281740571550158192e-02) (2, -3.10062870715566187008e-02) (3, 6.26020028854898102910e-02) (4, -3.49109277461476796844e-02) (5, 1.38815237278895597939e+00) (6, 4.88166607147287989754e-01) (7, 2.33625407272613161425e-01) (8, 2.39486650457555239058e+00) (9, 4.01781567822570073734e-01) (10, -1.18522746573646198254e-01) (0, 1.35923734148047214987e+00) (1, 1.19326018309582962407e-01) (2, 1.12356938934315933598e-01) (3, -1.98341854811732651309e-03) (4, 4.09065788149731851542e-02) (5, 1.26636808676913004135e+00) (6, 3.65513465529513192909e-01) (7, 2.11450609320438021044e-01) (8, 3.34587945412664877765e+00) (9, 2.85809153209799993167e-01) (10, -2.34554862688739346188e-01) (11, -2.15555649923218906050e-01) (12, 8.81017067713896873116e-01) (13, -1.61904157582316993169e-01) (14, 4.67923769604189687676e-01) (15, -2.08575830941089584991e-01) (16, -3.94403586158644930970e-02) (17, -1.94868580007429376133e-01) (18, 4.35530716430170827813e-01) (19, 4.90619711869408114957e-01) (20, 4.65205633889658742852e-01) (21, 3.53739161021272452423e-01) 
