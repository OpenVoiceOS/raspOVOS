FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.92800221682982986238e-01) (1, 3.71720280299503491594e-01) (2, 3.03461026201564953997e-01) (3, 2.40514192531425585742e-01) (4, 2.33546037028152575488e-01) (5, -6.69255465065894616927e-01) (6, 1.63242205690767638870e-01) (7, 4.00497718184580686618e-01) (0, -5.68124043749074103538e-01) (1, 7.26507085915356204397e-02) (2, -3.40486277286261990183e-02) (3, -5.75158816222400004481e-02) (4, 9.10295921917706057913e-02) (5, 1.08376213614527117102e+00) (6, 3.92294412728023789150e-01) (7, -7.98693692532341792401e-02) (0, -8.95987422378337616813e-01) (1, 5.28734553213863894827e-02) (2, 7.70713764782696292288e-02) (3, -6.26082864050120646571e-02) (4, 9.09643996115475222952e-02) (5, 1.07967431549612413733e+00) (6, 3.91247457142544052822e-01) (7, -1.07457524373845370036e-01) (0, 3.61400483499532854115e-01) (1, 5.83109235086970260908e-03) (2, 1.50797411554246474363e-01) (3, 7.49865544370704184551e-02) (4, -6.38011867484516818905e-03) (5, -1.19819206531531441406e+00) (6, 2.60309798569049233308e-01) (7, 3.79659155390354885462e-01) (0, 3.57316204251246882784e-01) (1, 2.58604880591517150012e-01) (2, 1.89160451462154932667e-01) (3, 2.36185480078344889332e-01) (4, 2.63976816257124602405e-01) (5, -6.34012210910973927902e-01) (6, 1.10427289914514892288e-01) (7, 4.53270608960976484347e-01) (0, 5.97821496215448666689e-01) (1, 2.86375164059085696167e-01) (2, 2.24338202742023373748e-01) (3, 2.67883225348872988647e-01) (4, 1.77404037681503201629e-01) (5, 2.98121591875712521613e+00) (6, 1.02102099127818340962e-01) (7, -2.59484938050857538716e-01) (0, 4.84199941994147842195e-01) (1, 2.35838580677826037402e-01) (2, 3.90668105135280774309e-01) (3, 3.73282681951839612200e-01) (4, 3.22779621730167554094e-01) (5, -5.73889717256484410690e-01) (6, -3.82039724645386741253e-03) (7, 4.57507463573803785373e-01) (0, -6.30431379185418361288e-01) (1, 1.10288717186048587648e-01) (2, -8.56073271874636804180e-02) (3, 4.73478812332897708304e-02) (4, 7.35637578923994256419e-03) (5, 1.00956923965994249670e+00) (6, 4.18975791211796066982e-01) (7, -1.16102567163269988076e-02) (0, 4.81383864622243404230e-02) (1, 2.77905656960887759155e-01) (2, 1.38932350096387879912e-01) (3, 1.40026393351240174834e-01) (4, 1.18520847526474015776e-01) (5, 3.12268056566278540132e+00) (6, 1.90122088558722729390e-01) (7, -5.03931451596320800768e-01) (0, 4.82225195409255569245e-01) (1, 2.94184285948593304827e-01) (2, 2.11223337600547900195e-01) (3, 2.80806492815334485247e-01) (4, 3.44840209732372449114e-01) (5, -6.02274849807677647995e-01) (6, 3.38949234428633644489e-03) (7, 4.77878155588497999240e-01) (8, -2.75010099979954625304e-01) (9, 6.40975911814020915536e-01) (10, 7.16666106778429790047e-01) (11, 3.15974389051945914186e-02) (12, -2.55350536080914403136e-01) (13, 7.98730768618216901977e-01) (14, -2.48576341542321110900e-01) (15, 6.65185306865023417977e-01) (16, 6.57564309636431754136e-01) (17, -2.47537030252533818420e-01) (18, 5.67248028812560423084e-01) 
