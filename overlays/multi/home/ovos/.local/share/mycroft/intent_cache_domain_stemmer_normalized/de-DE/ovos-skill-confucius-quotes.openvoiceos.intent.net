FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.09766936370700074477e-01) (1, 3.12646039841029885209e-03) (2, 9.53834065315578225053e-03) (3, -2.51754640686764862012e-02) (4, -3.92083569515004198847e-02) (5, 1.39698718322989273721e-01) (6, 8.43810662852277765245e-02) (7, 1.22998624402561174129e+00) (8, -9.39504389572069636971e-02) (9, -3.11023790837229863193e-01) (0, 3.07717918686603975065e-01) (1, 1.27511569787989331726e-01) (2, 1.33653046121130658630e-01) (3, 1.20103248884211255554e-01) (4, 9.92993056078059488367e-02) (5, -1.56365184260585365905e+00) (6, 2.17304010980685358145e-01) (7, 4.06805671480543562524e+00) (8, 1.09191158344279032333e-01) (9, 3.13132857077677684288e-01) (0, -3.51009118625491334242e-01) (1, 2.47600407254442989036e-02) (2, -5.55560632694020312128e-02) (3, 2.09754736077532623340e-02) (4, -3.52494387972607722825e-02) (5, 1.11165218635079193765e-01) (6, -3.76005172504434367897e-02) (7, 1.17826186228075013851e+00) (8, 4.59063130509927350142e-02) (9, -3.11735276580752507236e-01) (0, -3.86312837967246247572e-01) (1, 5.93842447650179822149e-02) (2, 4.36540872704729854270e-02) (3, -6.99626549232258698741e-02) (4, -3.25548543679967106179e-02) (5, 1.53015994115349579507e-01) (6, 7.59722294673825879890e-03) (7, 1.18817219245710359310e+00) (8, -1.38596579145185694326e-01) (9, -1.75669026077689222065e-01) (0, 4.56862879132073795851e-01) (1, 3.57526790154320761594e-01) (2, 4.33838825476510092649e-01) (3, 4.02965817404133841428e-01) (4, 4.74295969856125876341e-01) (5, 6.43606575615097264986e-01) (6, 4.42944371265210745658e-01) (7, -3.88693174506508976052e+00) (8, 6.02168382227305065690e-01) (9, 6.19674112437604063253e-01) (0, -4.10281981596320344252e-01) (1, -2.50188454139485504102e-02) (2, 5.17381609332308589622e-02) (3, 4.09738005053744136497e-02) (4, -7.08070068705334565440e-02) (5, 1.65058978481766510660e-01) (6, -1.09999828018094061854e-01) (7, 1.22793846684970842098e+00) (8, 2.17220264566018485264e-02) (9, -1.53409328759612079152e-01) (0, -3.28177678653567506117e-01) (1, -4.13459508764996569452e-02) (2, 5.82378090274081189337e-02) (3, 2.22882510077700470019e-02) (4, 2.19277621161684845019e-02) (5, 1.74253203554627172922e-01) (6, -8.68345945848474493056e-02) (7, 1.16587097305335984920e+00) (8, 4.08265817058160312980e-02) (9, -3.14746983797253743198e-01) (0, -4.54178921201794816298e-01) (1, -3.16101006152774265806e-03) (2, -7.12611346590771577159e-02) (3, 2.01679200780138824511e-02) (4, 6.67373419654116728505e-02) (5, 8.53012657003372198883e-02) (6, 3.68632152901640086640e-02) (7, 1.21092663812913881038e+00) (8, 2.44991260659768450569e-02) (9, -3.14676589352530400312e-01) (0, -1.90047503413156258778e-04) (1, 2.33613615860191296825e-02) (2, -3.65637699137481703149e-02) (3, 8.57103606690613056829e-02) (4, -2.42847669823494961838e-03) (5, 9.43400891404090613523e-02) (6, -1.87254747142667765658e-01) (7, 3.64471103352597414204e-01) (8, 1.47282695442549405040e-01) (9, -2.58320351070583167918e-02) (0, -4.59771874615519715590e-01) (1, 5.67069531333193738165e-02) (2, -5.39457022297635119257e-02) (3, -9.47222306478276154795e-02) (4, 1.22315765273318111106e-02) (5, 1.16552331133362579996e-01) (6, 1.73921361790647759082e-02) (7, 1.26174295801200853084e+00) (8, -3.91755101191923749138e-02) (9, -2.31097091437281659809e-01) (10, 3.48147077723307551977e-01) (11, 5.79823987528386153301e-01) (12, 3.89961270852847041724e-01) (13, 1.14615744459348689599e-01) (14, -4.01784399429894606426e-02) (15, 3.89934985204501094458e-01) (16, 4.13326075537962855933e-01) (17, 7.63280269491117713265e-01) (18, 3.01964341547510728425e-01) (19, 7.45382756727379081063e-01) (20, 4.21764865194857341280e-01) 
