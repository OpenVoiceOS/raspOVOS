FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.44771380718479925065e+00) (1, 3.66287725352552162583e-01) (2, 5.20831549846436980822e-01) (3, 4.36352150820996986802e-01) (4, 4.58925972067620868700e-01) (5, 1.27094250096375205317e+00) (6, 3.18073501083499010633e+00) (7, -1.73981239957806677054e-01) (8, 6.42331404099622904624e+00) (9, 3.15495052035008660685e-01) (10, -1.32631900841580341321e+00) (11, -3.30395573698166578058e-01) (0, -8.15274319329809427082e-01) (1, -2.10239928867857112094e-01) (2, -8.25725241566105522262e-02) (3, -5.52853985691471871977e-02) (4, -1.15654897596876221622e-01) (5, -1.46311643419008929889e-01) (6, -4.75938630766552162044e+00) (7, 2.26711775990663916280e-01) (8, -5.21274470646804477525e+00) (9, 1.56950537595095460097e-02) (10, 5.48200010590283670631e-01) (11, -8.94338692399555268420e-02) (0, -6.50450533905577055194e-01) (1, -1.27442356851141053165e-01) (2, -1.22910652961771088565e-01) (3, -1.67856671568195392474e-01) (4, -1.03347492125074463809e-01) (5, -2.49392500219078397383e-02) (6, -4.03470697862485661034e+00) (7, 2.18735411871431896513e-02) (8, -4.65508389707219194520e+00) (9, -9.11478836337245579280e-03) (10, 1.49518037311296003722e+00) (11, -1.18998192714273920423e-01) (0, -7.23798579254698148944e-01) (1, -1.25684034731428223575e-01) (2, -1.18285570945779877627e-01) (3, -1.74961496796648102725e-01) (4, -1.40256401803533631290e-01) (5, 3.25258934798506316177e-02) (6, -4.08955892783979191307e+00) (7, 2.48009935129641055640e-02) (8, -4.60670797761094164002e+00) (9, 1.00067606677616410815e-01) (10, 1.37390867344598288646e+00) (11, -7.77647350893616584599e-02) (0, -8.02133931496690988361e-01) (1, -1.30310055520574646915e-01) (2, -2.22668294515649928256e-01) (3, -2.16937456932108058139e-01) (4, -2.03146015014688624545e-01) (5, -5.07319968912417623708e-02) (6, -4.75646536714714240901e+00) (7, 2.84134354325472293645e-01) (8, -5.37728171159452106309e+00) (9, 4.55019504395215851345e-02) (10, 4.63290802471368112769e-01) (11, 2.97019203332370661241e-02) (0, -9.48882090785587450910e+00) (1, -3.39634527260731788889e-02) (2, -1.31340067535109461527e-01) (3, -1.65590156609486671702e-02) (4, 3.28709672396708257880e-02) (5, 1.83304451780425259333e-01) (6, 2.40093126312637528130e+00) (7, 4.40089753045916021179e-01) (8, 2.60889964880490188293e+00) (9, -9.95376344789517530920e-02) (10, 5.05440771816551781548e-01) (11, -9.04075468272074189713e-02) (0, -9.48721720018470904279e+00) (1, 8.03670689516552960718e-03) (2, -8.39473937446545553920e-02) (3, -1.66579391508765189966e-01) (4, -1.59464736277531715647e-02) (5, 2.92099754424500868133e-01) (6, 2.81033212680591804045e+00) (7, 5.12936962916731409301e-01) (8, 2.73606002961720529143e+00) (9, -1.29606869612765074340e-01) (10, 5.36312014101326561821e-01) (11, -2.86060613663351004377e-01) (0, 6.61922903508134652384e+00) (1, 1.97620595502483842321e-01) (2, 2.25803567725050446935e-01) (3, 2.22160591441023347326e-01) (4, 3.42800485598671433873e-01) (5, -2.24701974800467357829e-02) (6, -2.44212983920829351803e+00) (7, -4.21468130345843461360e-01) (8, -2.53269545948969199145e+00) (9, 2.81279632448539373968e-01) (10, -1.44610946749138880030e+00) (11, 5.57472772480851613830e-02) (0, 8.60348130297528612687e+00) (1, 4.70178300821092132189e-01) (2, 4.54117568516042457993e-01) (3, 4.94865620815064799487e-01) (4, 3.59496729754712807114e-01) (5, 1.30029474867874839106e+00) (6, 2.50438827472923097872e+00) (7, -1.94722974611518218069e-01) (8, 6.29319387535015284385e+00) (9, 2.13782357585952764722e-01) (10, -1.31187802115665386182e+00) (11, -3.33036163769844739679e-01) (0, 5.88185445959173325292e+00) (1, 2.65385533236052850725e-01) (2, 2.81028220914389947893e-01) (3, 1.42759079597976096254e-01) (4, 1.41534330807711966616e-01) (5, 1.39671822322607414035e-01) (6, -2.93837133604775457840e+00) (7, -1.86990947178068717127e-01) (8, -4.02984294061768189010e+00) (9, 4.06676013514361112122e-01) (10, -1.53922765825676965967e+00) (11, 1.43074349245037285572e-01) (12, 6.06585260869834885789e-01) (13, -5.76134656464934377662e-02) (14, -1.53488141393542422419e-02) (15, -8.86927467679858583249e-02) (16, -2.92645764446139329540e-02) (17, 7.08722963331963273781e-01) (18, 7.10131324230457994240e-01) (19, -1.40863674980449105067e-01) (20, 5.75722303630683884812e-01) (21, -1.83448254296063317792e-01) (22, 4.13376265541645027124e-01) 
