FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.18112253046159199066e-01) (1, -3.16569476681834161003e-02) (2, 1.15855962675923372662e-02) (3, -4.00992452460413872917e-02) (4, -5.54970025378352382894e-02) (5, 3.43275598688327576724e-01) (6, -4.83616531811260352836e-02) (7, 2.58479742592509920129e+00) (8, -3.04659843749180647698e-01) (0, 3.32141468735096700993e-01) (1, 3.19868937975201939050e-01) (2, 2.71970071738992014154e-01) (3, 1.93710484451089237634e-01) (4, 2.93054983860287998620e-01) (5, 2.13383171649920377888e+01) (6, 2.14404628787097789600e-01) (7, -1.41006431835066314839e+00) (8, 2.24942724243850228349e-01) (0, -3.74928458428506417022e-01) (1, 1.63264454048985506451e-02) (2, -1.33759987290490239831e-01) (3, 8.32887298287095755034e-03) (4, -8.10964151579028624806e-02) (5, 2.50946013613946972143e-01) (6, -7.67994091830753872197e-02) (7, 2.55711441373761827478e+00) (8, -1.88052945143357158608e-01) (0, 8.12019450411070486950e-01) (1, 1.62486508045183303262e-01) (2, 2.51466743204580345239e-01) (3, 2.40366674516187761590e-01) (4, 2.26261324737058733270e-01) (5, 5.01007486875199581355e-01) (6, 2.67860647308708710312e+00) (7, 4.54617980558416345804e-01) (8, 2.91232138562867004516e-01) (0, 5.08425793888063637382e-01) (1, -1.89097868788749949587e-02) (2, 9.41801992666213422245e-02) (3, -8.22144139320592519035e-05) (4, 1.51873010159680105202e-01) (5, -1.63362110066309647038e+01) (6, 2.39945600724043611729e-01) (7, 9.70792360296462875091e-01) (8, 1.47381326089927794376e-01) (0, 4.15679350229228028457e-01) (1, 3.19232434874806736413e-01) (2, 3.18578661328587864343e-01) (3, 3.20067257529530857507e-01) (4, 3.26191053634915684167e-01) (5, 2.14785775410282049336e+01) (6, 7.51038279271696584960e-02) (7, -1.39007829981218811177e+00) (8, 2.23312044777620316571e-01) (0, 6.71915145099556188057e-01) (1, 1.40293696136232881599e-01) (2, 1.95276522249933720543e-01) (3, 1.11696289093252645874e-01) (4, 1.12814841032978521729e-01) (5, 9.06404740270604580843e-01) (6, 5.09182874007430008589e-01) (7, 5.82779708940526885996e-01) (8, 2.57971451041554056260e-01) (0, 7.77110004591079706060e-01) (1, 2.13225642064462428404e-01) (2, 8.98554044159753789733e-02) (3, 2.02992604890714412047e-01) (4, 1.98344493130098109557e-01) (5, -6.77120299917136403423e-01) (6, -1.12674043931306777644e+00) (7, -2.76348551647123963360e-01) (8, 3.91529587222150587955e-01) (0, -2.48637115434526073665e-01) (1, -1.36730751898778563058e-01) (2, -2.07356697824491148507e-01) (3, -5.96332018642555805599e-02) (4, -1.73257506397260313546e-01) (5, 1.24641329317280868949e+00) (6, -6.02597093805325723093e-02) (7, 2.01517168502425736420e+00) (8, -1.99583790565753982360e-01) (0, 4.13243598582239246575e-01) (1, -1.91897624616930301267e-03) (2, 8.64504752170531659550e-02) (3, 9.75611088287322431034e-02) (4, 7.64107508074729491199e-02) (5, -1.62432544040575699285e+01) (6, 1.41156922077955965245e-01) (7, 1.09357747404835103922e+00) (8, 1.40359332691261412540e-01) (9, 5.16006000120539209952e-01) (10, 3.99868884479726238723e-01) (11, 4.87307220477957159233e-01) (12, 2.71218368375602050802e-02) (13, -1.66326244051223565146e-01) (14, 3.95969012176717205520e-01) (15, 2.92199203336539620190e-02) (16, -1.07557014410882313682e-02) (17, 4.95116924644666667188e-01) (18, -2.17554670448070280875e-01) (19, 1.28791329496727030568e-01) 
