FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.25664355013144279916e+00) (1, 2.23799013138568425596e-01) (2, 1.14363588929927373350e-01) (3, 1.82410494030272984922e-01) (4, 2.88159363508975530088e-01) (5, 2.98085904795495459929e-01) (6, 3.80337701372611602935e+00) (7, 1.03180806975922423341e+00) (8, 7.83753409970546877084e-01) (9, 6.22449514904671818982e-01) (10, 6.41639703251849824461e-01) (11, -1.76688177932599971287e-01) (0, 1.13437280813229279808e+00) (1, 1.24850770926741946876e-01) (2, 2.30825325942305925597e-01) (3, 1.95389127826957109679e-01) (4, 2.38894945478705766906e-01) (5, 2.51144361432550256019e-01) (6, 3.36498561250842165293e+00) (7, 7.75705769304392611652e-01) (8, 3.60074670717544620402e-01) (9, 9.33530845631535433071e-01) (10, 9.77523260857074860475e-01) (11, -9.34448164597563440958e-02) (0, 1.27810337919366623360e+00) (1, 2.70443432570254826963e-01) (2, 2.16612108588969759504e-01) (3, 2.37010427356517394681e-01) (4, 2.99718447566783452451e-01) (5, 1.38226483892349094607e-01) (6, 5.73340678460762376289e+00) (7, 5.61791267832894680723e-01) (8, 6.84719204891467980723e-01) (9, 1.12635051132110430849e+00) (10, 1.17189544788542132636e+00) (11, -3.29258369926016425389e-01) (0, 2.86968819547200992837e-01) (1, -1.73853554506403273905e-01) (2, -5.96574775172292598446e-02) (3, -1.23473741788965474253e-01) (4, -2.38970599366247378470e-02) (5, 8.14833432155970149857e-01) (6, 5.68423702142898279455e-01) (7, 7.32385676774943705780e-01) (8, 2.04951013080373611874e-01) (9, 6.46840022730366892567e-01) (10, 8.35158271815932939930e-01) (11, -1.77383956967677891559e-01) (0, -9.03897081403502666852e-01) (1, -4.73289021984345985652e-04) (2, -2.79926119537508601154e-02) (3, -1.15079565138971953719e-02) (4, -1.25089941711580901473e-02) (5, 2.15395796046460030748e-01) (6, 1.74186903371923218486e-01) (7, 1.25163587350136751297e+00) (8, 5.14796435054598044978e-02) (9, 7.32413989123399278292e-01) (10, -3.04461136544589672237e-01) (11, -9.87877528064438764632e-02) (0, 4.70990832958399341379e+00) (1, 1.08455981079279145662e-01) (2, 1.95215615395246705477e-01) (3, 2.55643266204534758135e-01) (4, 2.45405766133009184404e-01) (5, -5.92502314656758066747e-01) (6, -1.89474874386149960692e+00) (7, -1.06992690450195460095e+00) (8, -6.07592395764623649512e-01) (9, -1.04115286642735704881e+00) (10, -1.23466940964401450387e+00) (11, 1.24542695525819402391e+00) (0, -3.39556956003179588599e-01) (1, -4.58644399914440586974e-02) (2, 9.03860037651363079636e-02) (3, 2.97863488521877099735e-02) (4, -3.93541673693355992247e-02) (5, 1.84846424633581446484e-01) (6, 1.24340040633040782581e+00) (7, 1.14104580768526076007e+00) (8, 1.64561401579720850696e-01) (9, 7.55930047108209324236e-01) (10, -1.57288468359607608305e-01) (11, -5.76045406000397774982e-02) (0, 1.79671753950254642351e-01) (1, 2.46237022530595511816e-01) (2, 1.69781120222369880102e-01) (3, 1.58220449190894812963e-01) (4, 2.87632761251489399434e-01) (5, 3.09416174243642094766e-01) (6, 5.47231469999170827556e-01) (7, 6.69468682615025900695e-01) (8, 4.83229948081594251619e-01) (9, 4.50760556199808259947e-01) (10, 1.06426665734223835358e+00) (11, -5.85513656550493213904e-02) (0, 1.21389068102110253555e-01) (1, -2.05598562265849521546e-01) (2, -2.05174497570014408021e-01) (3, -1.58922708834624587526e-01) (4, -2.69808403457618029009e-01) (5, 7.49793581384542995316e-01) (6, 7.13297760806743341711e-01) (7, 7.02051040205920573456e-01) (8, 3.32070293478265721188e-01) (9, 8.14149083423154062977e-01) (10, 9.71133945797008291123e-01) (11, -1.86925045095113179228e-01) (0, 1.16774472778309212906e-01) (1, -2.75836146677947313677e-01) (2, -1.45561552847838643343e-01) (3, -2.34131067301249884416e-01) (4, -2.31386821027017020036e-01) (5, 7.85892873722437435013e-01) (6, 7.10449278694601615847e-01) (7, 6.16702027208319347729e-01) (8, 3.29811445551048576519e-01) (9, 8.67135480900835919904e-01) (10, 1.06679734357627120644e+00) (11, -1.64736985109475514433e-01) (12, 4.74225802410406571674e-01) (13, 3.47080847531642588955e-01) (14, 5.04397273588010008893e-01) (15, 5.11829434613038314339e-01) (16, 2.99919308573279530528e-01) (17, -7.25406933953825605599e-01) (18, 3.28250079563234209434e-01) (19, 9.20853731284102389187e-02) (20, 5.22217555621911300179e-01) (21, 5.95252264409968812053e-01) (22, 5.04643090117369186309e-01) 
