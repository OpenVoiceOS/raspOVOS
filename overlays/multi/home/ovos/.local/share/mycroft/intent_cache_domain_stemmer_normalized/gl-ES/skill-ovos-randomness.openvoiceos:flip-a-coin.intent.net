FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.41093425574414621515e-01) (1, -2.60037138937757927870e-01) (2, -3.29684484629677254652e-01) (3, -2.11703121541784722304e-01) (4, -3.14384460328863579726e-01) (5, -1.65054803326321539170e-02) (6, 7.94331856534293556660e-02) (7, 5.12896425566768954241e-01) (8, 3.06140812295898712136e+00) (9, -2.40032179069605611232e-01) (0, 5.67159853997342588983e-01) (1, -2.40624099849508749083e-01) (2, -2.17441677926825005507e-01) (3, -3.16800661264704186415e-01) (4, -3.26342545329378563856e-01) (5, -2.23768954708767758843e-02) (6, 1.92777862446050968215e-01) (7, 5.31855999968147585832e-01) (8, 2.94223438385352409341e+00) (9, -3.25592463624563899227e-01) (0, -6.69502943781876275198e-02) (1, 1.88430170870436036745e-01) (2, 2.01402600265158021609e-01) (3, 2.16105128980291688601e-01) (4, 7.99226531452067734396e-02) (5, -1.11175102473179167328e-02) (6, 5.47476027636280893063e-01) (7, -6.57242591976123086139e-02) (8, -5.95864592921550695337e-01) (9, -5.76444265724102289372e-02) (0, 1.13554301249960271081e-01) (1, 4.70333997357804012296e-01) (2, 4.08087857265192643919e-01) (3, 4.52233176876026765623e-01) (4, 4.44541823316532747068e-01) (5, 1.39013504236038393236e-01) (6, 3.23410267345408120043e-02) (7, 3.14841893923789417631e-01) (8, -1.91286660258904306353e+00) (9, 4.34513512389794742674e-01) (0, -2.01449598374750654672e-01) (1, 1.43222275531900727907e-01) (2, 1.69097300029409730593e-01) (3, 2.07400794482839906374e-01) (4, 2.12332572198522889773e-01) (5, 1.68857800482829709110e-02) (6, 5.58001246778717763242e-01) (7, -5.29112200736003152057e-02) (8, -6.24874732327277637722e-01) (9, -2.97684890509525602875e-02) (0, 8.71949649501964074716e-01) (1, 1.89393785698697109110e-01) (2, 2.56155804647490492609e-01) (3, 2.49702007426306743509e-01) (4, 1.76229202105090160257e-01) (5, 1.92307728547488454574e-01) (6, -2.90215208796567661342e-02) (7, -2.59469542938190689263e-01) (8, -8.49639261418057323283e+00) (9, 3.02982903844749740241e-01) (0, 7.82061523843928796396e-01) (1, 1.87881999443541752859e-01) (2, 2.06099756787787663503e-01) (3, 1.80450686048041569753e-01) (4, 2.82766938935290534918e-01) (5, 3.67622032946693655386e-02) (6, -8.94295394090718898106e-02) (7, -3.61811410921531906304e-01) (8, -8.44833905899001003093e+00) (9, 3.17475274032985976813e-01) (0, -4.56610599891472568324e-01) (1, 1.49924899793279969851e-01) (2, 1.64544935680044496218e-01) (3, 1.79857726550711000124e-01) (4, 1.28055985427511537234e-01) (5, -6.41721186519543101978e-02) (6, 3.57879571234001492286e-01) (7, -8.91938573914910159957e-01) (8, 3.28871687547351498893e+00) (9, -1.31547149020520837137e-01) (0, 6.06736086430661680780e-01) (1, -2.21059620260046441054e-01) (2, -2.89807729302690941786e-01) (3, -3.25369559108065087294e-01) (4, -3.15611243127630669569e-01) (5, -1.32782166435910144869e-02) (6, 8.57395209834388161152e-02) (7, 5.77413744769192049944e-01) (8, 2.93324424135908401468e+00) (9, -2.59673861575213216213e-01) (0, -5.71403086213135430471e-02) (1, 1.19337442672861421267e-01) (2, 2.16904352760923707644e-01) (3, 1.03056836283815705935e-01) (4, 2.13504414415968263308e-01) (5, 3.87822046094863981391e-01) (6, 5.41686784951439737057e-01) (7, -1.65441175877948321027e-01) (8, -7.25516221356208412807e-01) (9, 9.27992935171925020787e-03) (10, 3.09874170981417618176e-01) (11, 2.98981712721358261486e-01) (12, 3.72129562507911904046e-01) (13, 2.33353873020546200012e-02) (14, 4.21370233606144173333e-01) (15, -3.86443783347563241115e-01) (16, -3.22071616356329415432e-01) (17, 3.71354247640415413567e-01) (18, 2.95012810789118729016e-01) (19, 3.66823855053230507561e-01) (20, 3.78394671917286484764e-01) 
