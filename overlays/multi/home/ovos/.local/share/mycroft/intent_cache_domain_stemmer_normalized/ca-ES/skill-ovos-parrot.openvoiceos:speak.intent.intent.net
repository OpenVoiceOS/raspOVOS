FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.74564982359976961224e-01) (1, -6.00515775037837526429e-02) (2, -8.55758659196926146917e-02) (3, -7.40026704622341185980e-02) (4, -2.15150455350978264679e-01) (5, -9.54249812372791744730e-02) (6, 1.53675244982962078133e+00) (7, -1.09805690082911688865e-01) (8, 3.67505358413311500332e-01) (9, -2.06542478080686126019e-01) (10, -2.41094818551361944614e-01) (11, 2.52078099672435751444e+00) (12, -1.53450408160821172299e-01) (0, 1.12201433365674202447e-01) (1, -2.40772400593867591523e-02) (2, 2.54631045663246922961e-02) (3, -3.91260196066012602700e-02) (4, 1.95498320662865314457e-02) (5, 7.58806387636201007396e-01) (6, -1.15528751934981581684e+01) (7, 1.79974018660819301552e-01) (8, 3.43734860839103806285e+00) (9, 2.56999248646598704715e-02) (10, 1.90610050461923474785e+00) (11, 3.90965565232571599097e+00) (12, -3.95312681326908180179e-02) (0, -4.01468251347307569787e-01) (1, -4.72028182867331377870e-02) (2, -2.11246364009694431729e-01) (3, -3.73636411550803057557e-02) (4, -4.74276172045035235292e-02) (5, -1.02091274956201488733e-01) (6, 1.91820665349454744231e+00) (7, -1.83105338295315833719e-01) (8, 2.29878136769386870464e-01) (9, -6.65085883962510948653e-02) (10, -4.01064357184135245049e-01) (11, 2.62305972103713980204e+00) (12, -1.27349549054516925084e-01) (0, 9.07637469498343341101e-01) (1, 1.08594750894908553818e+00) (2, 1.03314526661042860312e+00) (3, 9.56533494430825137478e-01) (4, 1.00163229091767980172e+00) (5, 1.22139171547480493984e+01) (6, -7.91966725120479164701e+00) (7, 1.47522336379390708316e+01) (8, -6.32355474431185893280e-01) (9, 1.28017939714916550997e+00) (10, 1.26883950595034017406e-01) (11, -5.96973533601753558742e+00) (12, 1.16908920313186004414e+00) (0, 1.87987347633706836092e-01) (1, 3.56309192803954788431e-01) (2, 4.51476859477615066751e-01) (3, 2.66484970775699436807e-01) (4, 3.71775942472076126322e-01) (5, 5.85791480614355042356e-01) (6, -8.03193390940655227439e-01) (7, 2.26496619962744838439e-01) (8, 1.83411163772354557366e+00) (9, 1.42687397768855611657e-01) (10, 1.53514251788418509825e+00) (11, 3.13799759694712632196e-01) (12, -2.88942859325359524547e+00) (0, 1.70731244441796592426e+00) (1, 3.93049468948423630366e-01) (2, 3.40566171063959366450e-01) (3, 4.15355657889425522455e-01) (4, 3.21497646822512028741e-01) (5, 1.84289888220495825522e+01) (6, -4.87324398803663783042e+00) (7, 1.23970677970260716450e+01) (8, 1.06401547307382249308e+00) (9, -5.83669834210334581570e-01) (10, 3.73007687416961164484e-01) (11, -2.80456723941466457006e+00) (12, -3.57341719117161338293e-01) (0, -6.62646203298649982827e-01) (1, 7.01653546158080398953e-01) (2, 8.24167905811076573208e-01) (3, 7.15304708544020950711e-01) (4, 7.25914417270427048123e-01) (5, 1.72485191292935780005e+00) (6, 1.68030477647635301253e+01) (7, 3.08145467097326175576e+00) (8, 3.14254627261166108454e+00) (9, 1.07203017708857784029e+00) (10, 2.78796839627468351352e+00) (11, 2.46141916597334597938e+00) (12, -3.81179394983682084952e-01) (0, -1.15674830038610521044e+00) (1, -8.24228416466639413063e-02) (2, -1.84939202227585114402e-01) (3, -2.28299517490856446189e-01) (4, -1.97062131323807038230e-01) (5, -1.88317198105952071652e-01) (6, 1.49127600181059594142e+00) (7, -4.46955985538007027902e-02) (8, 1.69188539322483399996e-01) (9, -6.14991069232197415384e-02) (10, 2.68562064556494284329e-01) (11, 2.33896513507795766884e+00) (12, -2.03372858080103469103e-01) (0, -5.03054916947383023995e-01) (1, -1.10049996455134968532e-01) (2, -1.30100581725062836025e-01) (3, -8.39104465441127822523e-02) (4, -9.53743568853755996351e-02) (5, -1.80445898123881148800e-01) (6, 1.77807805587739764519e+00) (7, -1.76595199783658146631e-01) (8, -4.45234185898469442266e-03) (9, -1.53941821853279342536e-01) (10, 1.10482656155717312574e-01) (11, 2.52504621569751730448e+00) (12, -8.78218657675405300900e-02) (0, -4.67193096964854226449e-01) (1, -1.17235774512393586821e-01) (2, -8.88641349626613646917e-02) (3, -1.05705814774139039702e-01) (4, -8.74206147743297606878e-02) (5, -1.90295669981142806515e-01) (6, 2.01460294321493149639e+00) (7, -2.46174825846336153834e-01) (8, 2.36532542258084232945e-01) (9, -9.30103864603206847983e-02) (10, -2.85205169044696504876e-01) (11, 2.67294389878152838236e+00) (12, -1.63644822627605934784e-01) (13, 4.94107938679871627752e-01) (14, -4.17635342856915614540e-01) (15, 4.73063186230574639346e-01) (16, 8.78104868834531315791e-01) (17, 5.19284951637658531709e-01) (18, 4.49769550416260488479e-01) (19, -1.88665866052396297148e-01) (20, 4.42059795659623833153e-01) (21, 4.57798134771133846677e-01) (22, 5.05992360832606236087e-01) (23, 2.22438980077277914660e-01) 
