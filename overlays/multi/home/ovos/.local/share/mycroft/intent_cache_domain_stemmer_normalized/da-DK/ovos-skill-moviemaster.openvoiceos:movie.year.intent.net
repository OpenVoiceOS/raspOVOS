FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=15 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.42141425165107904149e+00) (1, 5.20817943863821519734e-01) (2, 5.39794397555542482259e-01) (3, 6.17875807933760068380e-01) (4, 6.56087809257460019552e-01) (5, 3.63132529584906937892e-01) (6, 8.08615465784272791083e-01) (7, 1.26303284404814286646e+00) (8, 4.93712219930478479757e-01) (9, 8.00564648910525278325e+00) (10, 3.82448036321361539702e-01) (11, -4.30985868907483027357e+00) (12, 1.12562641188184198171e+00) (13, 1.26118666702871373708e+00) (14, 6.22974589063899797381e-01) (0, -5.92098270581264518597e+00) (1, -2.68444871136585605509e-01) (2, -1.90574129650036228067e-01) (3, -3.46171764263550174601e-01) (4, -2.26461385914722812540e-01) (5, 1.03456133952499820805e-01) (6, 5.08921355037761646845e-02) (7, 1.25372067726479713423e-01) (8, 5.04997549272842016777e-02) (9, 4.30727843093944251507e+00) (10, 1.15170289382848012316e-01) (11, -9.41946365853032624438e-02) (12, -1.89653911910100461680e-02) (13, -2.97936453638235725083e-02) (14, -1.51230585977746058435e-02) (0, -7.69550732410677063022e-01) (1, -3.08924637162771686949e-01) (2, -2.08883083784666523375e-01) (3, -3.77738333666410908140e-01) (4, -1.82512916052427809355e-01) (5, 2.94757426030269997774e-01) (6, -1.79525079165148947202e-02) (7, -2.63957830276789484625e-01) (8, -2.50550541191302711397e-01) (9, 6.22529281065367712245e+00) (10, 1.09438744845312234399e-03) (11, -7.06180348640678481886e-03) (12, -3.08969489972732269667e-01) (13, -1.66368567500444319851e-01) (14, -1.18310356787165199544e-01) (0, 3.48470380667433798916e-01) (1, 1.35970016624289313789e-01) (2, 1.01900724376993934150e-01) (3, 2.27379215564089548485e-01) (4, 1.55520742441969672676e-01) (5, 1.10973309197191685738e-01) (6, 1.58904311289614907921e-01) (7, 9.44467746155414483722e-02) (8, 1.17154175669893806377e-01) (9, -8.06156032548837941931e-01) (10, 2.82923025316319624867e-02) (11, 1.28134081711909174339e-02) (12, 4.29851815556111654937e-02) (13, 4.22224598429863443028e-02) (14, 2.25618426105783087543e-01) (0, -2.21803236609559961678e+00) (1, 1.83949404170368618905e-02) (2, -1.41421957988515006877e-01) (3, -2.39106483051921281380e-02) (4, 2.16787540128086514413e-02) (5, 3.44742484514375724380e-01) (6, -1.38469936070703680819e-01) (7, 1.39931534037503468859e-01) (8, 1.61039772096038591442e-01) (9, 1.47754205537359495359e+00) (10, -2.63728204733022046635e-02) (11, -8.53444206815863748439e-02) (12, -5.27115011156803203729e-02) (13, -4.14361137215618451080e-03) (14, -1.03281698912358521625e+00) (0, 3.73953719530504402613e+00) (1, 4.32460184518969670275e-01) (2, 4.92209445063746586779e-01) (3, 4.79069958750880375842e-01) (4, 3.87592765812552753069e-01) (5, 6.30239605400275904046e-01) (6, 5.04755669509099003101e-01) (7, 4.55405179792447212250e-01) (8, 5.40763012703715184593e-01) (9, -4.56908827463150934989e+00) (10, 1.80716327934612630557e+00) (11, 7.31676650735641409540e+00) (12, 6.70966727452160016654e-01) (13, 2.53880447409751963672e-01) (14, -3.27803881771167204828e-01) (0, 3.04511319439149830135e-01) (1, 6.22735767871832532339e-02) (2, 8.79354737014269582929e-02) (3, 1.43721170654962038249e-01) (4, 2.14696273139188237300e-01) (5, -4.42409425045288962064e-02) (6, 1.04034657688333656567e-01) (7, 1.57537100429018979419e-02) (8, 1.63455195575212375303e-01) (9, -8.42136798088298221820e-01) (10, 1.06101316377978649452e-01) (11, -5.66302750800715265500e-02) (12, 1.17470244359830972014e-01) (13, 1.48445337370572999491e-01) (14, 1.67362371875036997082e-01) (0, 1.65431487651305886288e+00) (1, 4.28125405106215717321e-01) (2, 4.98705097827582488623e-01) (3, 4.08448041770129499639e-01) (4, 4.06938867065577802862e-01) (5, 6.48779408778498267729e-01) (6, 5.14182359492668883405e-01) (7, 4.60321840280099037201e-01) (8, 9.44457180484880143290e-01) (9, -5.00752082504000828322e+00) (10, 1.64957982817741344306e+00) (11, 7.43170193526054312372e+00) (12, 7.13937094228149771169e-01) (13, 2.63166376195015094819e-01) (14, -7.32267922286541938538e-04) (0, -7.32803157604463684116e-01) (1, -3.04249047660913929381e-01) (2, -2.04099334204283222594e-01) (3, -3.46621781015482410826e-01) (4, -2.05764062130537495054e-01) (5, 3.15087292261668650006e-01) (6, -9.06177448068308660778e-02) (7, -2.63024429304954510123e-01) (8, -2.53916333525382453828e-01) (9, 5.56912409139537611935e+00) (10, -3.24296146763075124331e-02) (11, 3.49886326526999413833e-02) (12, -1.69429078440807040495e-01) (13, -2.12376900184603922828e-01) (14, -1.22142515065405105057e-01) (0, 5.78137892269676822998e-01) (1, 4.92325651532032962376e-02) (2, -7.55998091045823310957e-03) (3, -4.07622900718828604094e-02) (4, -4.82773330921312734954e-02) (5, -7.41032243349879216066e-02) (6, -1.08560095045230706884e-02) (7, 1.10908171073715339228e-01) (8, -7.56630184369269098710e-02) (9, -8.39083330085378498175e-01) (10, 6.22682331835002836340e-02) (11, -1.10488794653755009745e-01) (12, 7.30722159116930503053e-02) (13, 2.13909503945901996458e-03) (14, 2.97299305675538638738e-01) (15, -9.01741794647975269950e-02) (16, 4.92960823379529955446e-01) (17, 4.90634512450707938047e-01) (18, 3.94522744594994811962e-01) (19, 2.98603505095639543132e-01) (20, 6.11638530726834273032e-01) (21, 2.07913342671959988639e-01) (22, 6.01754456396504378013e-01) (23, 5.73056277182114937041e-01) (24, -6.59840909438386274966e-02) (25, 1.50402608943338428338e-01) 
