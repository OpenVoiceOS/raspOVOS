FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.59101367652980507650e+00) (1, 2.43211454944537219802e-01) (2, 2.36126921372340287109e-01) (3, 1.45883559482024388609e-01) (4, 8.99291627573234469972e-02) (5, 6.95258420157822465413e-01) (6, 2.89474700029453968497e-01) (7, 9.65290545552332446277e+00) (8, 5.49414852332097414234e-02) (0, 3.97145175317654741676e+00) (1, 3.98109705779608746834e-01) (2, 4.35001628134306927986e-01) (3, 4.31567968461569806404e-01) (4, 2.83803632143792339271e-01) (5, -1.58749857004132843841e+00) (6, 1.23152375174403361235e+00) (7, 9.65272813915569827259e+00) (8, 9.10332712487887524277e-02) (0, 1.43865370661584557332e+00) (1, 1.47576096411390800256e-01) (2, 2.16406251247568570673e-01) (3, 1.75760458167238675653e-01) (4, 2.39528040345354464868e-01) (5, 7.46491356039552189650e-01) (6, 1.07110551715429547226e-01) (7, 9.63149453579742953480e+00) (8, 2.06388576484821312240e-01) (0, -5.73598387064519510403e+00) (1, -1.52781117361470042404e-01) (2, -1.92885767322464762863e-01) (3, -1.11786726516171205925e-01) (4, -1.82178612452431498703e-01) (5, 1.19218071545835280212e+00) (6, 1.38977004340132870297e+00) (7, 1.02600885500706495712e+00) (8, -3.31836375273416694931e-01) (0, 3.88562226424346102149e+00) (1, 4.24499215219077130623e-01) (2, 4.25226347181853314705e-01) (3, 3.31302011046466005073e-01) (4, 3.65934686396178376899e-01) (5, -1.18674559958622194422e+00) (6, 7.58943217885338361484e-01) (7, 9.66585188984234378040e+00) (8, 2.13922622145698737572e-01) (0, -5.77379767568889246121e+00) (1, -2.18398254018708104507e-01) (2, -1.85777660113259135422e-01) (3, -1.32511604231282026367e-01) (4, -2.00155716043396769699e-01) (5, 1.08188837325755571328e+00) (6, 1.30379896722597177217e+00) (7, 1.03390369882382215927e+00) (8, -2.78774659014890791031e-01) (0, 5.75033660142631353196e-01) (1, 2.52730221621636608198e-01) (2, 1.54226132802609716688e-01) (3, 1.81008749775532995496e-01) (4, 1.64693542890195165906e-01) (5, -5.06789853372419063504e+00) (6, -7.68140636657130282394e-02) (7, -3.67068578248122712182e+00) (8, 5.81103775752211726413e-01) (0, -5.84590817215028391018e+00) (1, -1.45700949829502879318e-01) (2, -2.53438274961395926255e-01) (3, -2.05677587192936717209e-01) (4, -9.00949720558364558487e-02) (5, 9.89921876152276003502e-01) (6, 1.27929220460218484590e+00) (7, 9.39345094762218613127e-01) (8, -2.63427297450254560562e-01) (0, 2.44764997922904209426e-01) (1, 2.44581130933670981564e-01) (2, 1.33417134773640672085e-01) (3, 7.26402230977106905252e-02) (4, 1.18730647158532195973e-01) (5, 4.99270271787649100315e-01) (6, -3.58906624980874056074e-01) (7, -1.53893570711363403269e+00) (8, 1.84330335155911628764e-01) (0, 5.24969047292388357739e-01) (1, 1.75413458384588466510e-01) (2, 8.23060262575895512649e-02) (3, 8.58442175761015141555e-02) (4, 2.31930113174036250934e-01) (5, 3.90251586179718445990e-01) (6, -5.35954509040128534991e-01) (7, -1.14025563223036419114e-01) (8, 3.15541816154570553543e-01) (9, 5.21226793754782979917e-01) (10, 5.20024122882223549524e-01) (11, 4.96847450960364422912e-01) (12, 6.10992216973531787616e-01) (13, 4.82812300551619610900e-01) (14, 6.70607758223045413715e-01) (15, -1.23337522618163067389e-01) (16, 5.96595963000286166888e-01) (17, 1.33638494955281746102e-02) (18, 2.96122094721700465647e-02) (19, 1.50457902438225932240e-01) 
