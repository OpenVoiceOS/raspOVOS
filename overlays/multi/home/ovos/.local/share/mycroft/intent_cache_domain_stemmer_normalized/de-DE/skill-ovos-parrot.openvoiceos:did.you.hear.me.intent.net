FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.96065269443249290404e-01) (1, -9.19695045100993660570e-03) (2, -8.16135540162259837116e-02) (3, -5.39009864675348612101e-03) (4, -8.78541603242093821491e-02) (5, 9.57330698849715666654e+00) (6, -5.34455217710219435134e-02) (7, -9.29358112297536287372e-01) (8, -4.93950716045388482645e-02) (9, 1.69922261080881908946e+00) (10, 9.02247551233091409084e-03) (0, -6.94429841505796341394e-01) (1, -1.63202670610333527845e-01) (2, -1.71166193879033146086e-01) (3, -2.51636986828232822599e-01) (4, -3.02875903642560062590e-01) (5, 4.25399035630525113039e-01) (6, -2.30491910229309038272e-01) (7, 1.59659790947274538020e+00) (8, 3.02635639134354483826e-01) (9, 6.25390690904878088219e-01) (10, -2.51916782926562554668e-01) (0, 5.51539066021581647625e-01) (1, 2.09350086587310607600e-01) (2, 1.20330959397197567728e-01) (3, 1.49278420793653360255e-01) (4, 2.71878942685962410319e-01) (5, -3.01320303909717590596e-01) (6, -7.90078436339373968433e-02) (7, -1.41048957616686898575e+00) (8, -1.31902994527815065062e+00) (9, -2.28528681721550941397e-02) (10, 1.77878955240756669864e-01) (0, 1.41080594182395335778e+00) (1, 3.78553946724559442494e-01) (2, 3.24997310748721734974e-01) (3, 3.56341128459598199818e-01) (4, 3.97541110625888483021e-01) (5, 7.12399346735093086380e+00) (6, 7.72082309313721015798e-01) (7, -3.80500624272812482118e+00) (8, -9.75305789384877219739e-01) (9, 6.58409738821995649261e+00) (10, -5.62236339309448940327e-01) (0, -6.95717985188237131311e-01) (1, -2.28541827249179069215e-01) (2, -2.25245451974520921601e-01) (3, -3.08364240872512185287e-01) (4, -2.43079772638926688844e-01) (5, 4.74976638416304941526e-01) (6, -1.38680895969710338278e-01) (7, 1.62888234237151441341e+00) (8, 4.88399345030941067769e-01) (9, 5.62064747751538362763e-01) (10, -2.36331688606762402305e-01) (0, -1.34336542060945945964e-01) (1, -1.99570182935692674864e-01) (2, -9.43815358112038219063e-03) (3, -1.94125037865139848936e-01) (4, -1.75494957940079576719e-01) (5, -4.03125504915606125422e+00) (6, 1.24372659045731345784e-01) (7, -5.56288585984396544148e+00) (8, 1.30457691953154908404e+00) (9, 2.35928293070726224911e+00) (10, -1.09464127935680624604e-01) (0, 4.59188480373497931453e+00) (1, 6.93943220373871016982e-01) (2, 5.10688591000320490920e-01) (3, 6.56393873688461249039e-01) (4, 6.89940947291137640640e-01) (5, 5.50563789053756114100e+00) (6, -9.87463262567716992812e-01) (7, -4.16790195241315242214e+00) (8, 3.54285251060341899176e+00) (9, 4.16648604600108019014e+00) (10, 6.72849962232453524535e-02) (0, -3.56495989559324311102e+00) (1, -1.77041204743340313543e-01) (2, -3.49847169690087167471e-01) (3, -2.26428197793915514380e-01) (4, -2.76734540336087075918e-01) (5, 5.85247039011748126924e-01) (6, -1.11247117492445628945e-02) (7, 2.03439368859981684068e+00) (8, 9.91983206324747790461e-01) (9, 6.65441481313995719660e-01) (10, -2.06215030865308707186e-01) (0, -3.47630940077932404364e+00) (1, -1.82795133369126117096e-01) (2, -2.45755705909886157379e-01) (3, -1.75822537319817340240e-01) (4, -2.47664984243073260650e-01) (5, 5.57696514246763030975e-01) (6, -4.13333064214583406626e-02) (7, 1.66519041487889585262e+00) (8, 1.22270824908409481147e+00) (9, 5.98346013363625917059e-01) (10, -1.17139669978526247962e-01) (0, -7.19441669439545350428e-01) (1, -2.10400795983920335663e-01) (2, -2.72637656378398263168e-01) (3, -2.30107015418658439332e-01) (4, -3.82501049387107217026e-01) (5, 4.23054354666663467999e-01) (6, -1.85338290587506282492e-01) (7, 1.72224191183258934501e+00) (8, 5.07161772547483069573e-01) (9, 5.88561631648099825576e-01) (10, -1.57427659456364221757e-01) (11, -3.12455632061490740092e-01) (12, 4.78356062523131342346e-01) (13, -5.78645998654309726139e-02) (14, 1.00539131145471904993e+00) (15, 4.89344164240824441858e-01) (16, -3.07376624107005613773e-01) (17, 5.76537059082730674042e-01) (18, 4.40416556928622082712e-01) (19, 5.04696576944594466063e-01) (20, 5.12660115114455416929e-01) (21, 4.44437168283304984140e-01) 
