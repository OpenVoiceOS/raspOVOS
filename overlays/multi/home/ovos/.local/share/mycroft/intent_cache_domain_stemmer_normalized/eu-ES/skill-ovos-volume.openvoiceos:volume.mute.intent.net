FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.08055470744985981923e-01) (1, 3.37647949766000862737e-02) (2, 9.35882380712834902048e-03) (3, 6.97294925760111178326e-02) (4, 8.47817366432031815915e-02) (5, -3.30838294959147471985e+00) (6, 1.35344327568907185633e-01) (7, 3.16820853183275685794e-01) (8, 9.94349070607049648207e-03) (0, 3.88106644448686965987e+00) (1, 4.97719116578092368730e-01) (2, 4.49194535682191642412e-01) (3, 5.03186352620115129319e-01) (4, 3.62082764575471727220e-01) (5, 1.55448357145299063120e+01) (6, 4.67921514740944011201e-01) (7, 2.59099301929633707431e+00) (8, 3.71893643099615034409e-01) (0, 1.48756506916937709661e+01) (1, 2.67436878844196035399e-01) (2, 4.27868390544349386229e-01) (3, 4.20664453967506124510e-01) (4, 3.65035908385211660399e-01) (5, -2.27652656704208977700e+00) (6, -1.31260245022980481799e+00) (7, -2.73278146719922609975e+00) (8, 4.64857409093100693021e-01) (0, 6.71501676254034318703e+00) (1, 5.31389124036633075931e-01) (2, 4.89381789506279529789e-01) (3, 4.80919434965454639652e-01) (4, 5.06843096853100361088e-01) (5, 1.55367953310717687998e+01) (6, 5.04323570046190883254e-01) (7, 2.93909077420663145119e+00) (8, 2.60530850392502122403e-01) (0, 6.10332061211485532581e-01) (1, -5.70858860899129891275e-02) (2, 3.76369109857884907508e-03) (3, 4.29362287234148001791e-02) (4, -6.74248435985239438772e-03) (5, -3.40287677085478801331e+00) (6, 2.80800748224346530257e-01) (7, 6.75269802720388501172e-01) (8, -6.46855137528556077553e-03) (0, 3.84551644992877372786e+00) (1, 4.28797841141214164384e-01) (2, 5.15814922819127774645e-01) (3, 5.51849223742475247789e-01) (4, 3.90624478528489971207e-01) (5, 1.56981332953085050974e+01) (6, 5.65379571846485129427e-01) (7, 1.15937509706485331051e+00) (8, 2.81970559317418989487e-01) (0, -5.16988815400302659242e+00) (1, -7.92973465222265583296e-02) (2, 9.28275520621276058197e-03) (3, -4.56213182705786368665e-02) (4, -6.75295120972540241500e-02) (5, 2.22530891277593179112e+00) (6, -6.37312969523400919825e-03) (7, 3.15779455424781640982e-01) (8, -1.35034867843606604110e-01) (0, 5.97916011373419431507e-01) (1, -5.59822241355100655436e-02) (2, 9.71830790351709550290e-02) (3, -3.59533573080221130480e-02) (4, 2.17483421276888008733e-02) (5, -3.24881854540188808045e+00) (6, 1.71924139912216722426e-01) (7, 6.58954342515310376172e-01) (8, -5.79174063386100022865e-03) (0, -5.11976878378093491762e+00) (1, -1.25476484478973492054e-03) (2, -1.70213652302637408198e-01) (3, -8.19254866737272602339e-02) (4, 1.35386460524652002535e-02) (5, 2.24003906933075347396e+00) (6, -6.37608385044068949610e-03) (7, 4.70126570782997688092e-01) (8, -1.13605008741834295760e-01) (0, -1.38387067300698376471e+01) (1, -6.08432745292586119046e-02) (2, -1.02837145860473599956e-01) (3, -9.90607743814391761283e-02) (4, -2.48819147899550438541e-02) (5, 2.08521362670463128453e+00) (6, 4.27994654480841965616e-02) (7, 6.94930707861701302264e-01) (8, -1.99356785868723601629e-01) (9, -3.54347469035702022921e-01) (10, 5.28561614522924161363e-01) (11, -4.27717264288063780953e-01) (12, 4.94062773952474387773e-01) (13, -1.07928346195393501383e-01) (14, 5.48840423554602718781e-01) (15, 5.11066503364998592218e-01) (16, -3.78011541585801733034e-02) (17, 4.37532595832306692163e-01) (18, 4.78810656718596461268e-01) (19, 3.64960151298101831419e-01) 
