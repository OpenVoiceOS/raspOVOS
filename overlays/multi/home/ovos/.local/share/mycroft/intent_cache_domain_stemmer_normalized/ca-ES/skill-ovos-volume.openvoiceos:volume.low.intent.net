FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.89752153167992293481e-01) (1, 6.39635570513555629102e-02) (2, 6.76697515117475612012e-02) (3, 8.85006062852689845410e-02) (4, 2.42700467275316467131e-01) (5, 9.66525133956662313439e-02) (6, -8.16043000798271217500e-02) (7, 2.03364236917846025188e-01) (8, 1.14607605916836524651e-01) (9, -4.32073566283418308842e+00) (10, 1.76610304875728818530e-01) (0, 1.37094704050402693696e+00) (1, 4.92348722077589007196e-01) (2, 5.37858269072752026574e-01) (3, 5.62713405944089917199e-01) (4, 6.14255568839292553918e-01) (5, 2.17853214228871661096e-01) (6, 2.47839923491124852761e-01) (7, 2.69075633088470178578e+00) (8, 2.36636521064960608784e-01) (9, -2.35445151519919093630e+00) (10, 2.50327084181372949701e-01) (0, 6.45619922917332900170e+00) (1, 5.78652641849360160897e-01) (2, 5.87031311468920291574e-01) (3, 4.40850741343340513101e-01) (4, 5.36129630284151725839e-01) (5, -1.35169297667786669770e+00) (6, -5.68939053026478624986e-01) (7, -2.69412470459571284920e+00) (8, 3.12209104404487181039e-01) (9, -1.45805666384043530748e+00) (10, 4.93058998784181523600e-01) (0, 6.43824223469939482811e+00) (1, 4.24284061956757996281e-01) (2, 3.65063442457074671665e-01) (3, 4.69207352567071411809e-01) (4, 3.72403873670453522404e-01) (5, -1.00458560544613240140e+00) (6, -5.54816177249912029223e-02) (7, -1.63004304579224834626e+00) (8, 4.41338327889961634654e-01) (9, -2.14763324140352196423e+00) (10, 4.81605548771418534582e-01) (0, 4.30921654169897916375e-01) (1, 2.23543573320571981045e-01) (2, 2.16658555120889745327e-01) (3, 3.41071389765207511058e-01) (4, 2.13186636716787447643e-01) (5, 4.33419038145025248276e-01) (6, 2.10930448551330446127e-01) (7, 1.36914715380012597112e-01) (8, 1.31477477111916520036e-02) (9, -5.33313131263464423881e+00) (10, 2.29390926478430373647e-01) (0, 7.42615875318720641829e-01) (1, 3.01519634618526100045e-01) (2, 2.39444958462482093697e-01) (3, 2.42291147305732396111e-01) (4, 1.78127678527598976022e-01) (5, 1.90090208857678771848e-01) (6, 2.08822271953725019378e-01) (7, 1.90788078450204379166e+00) (8, 1.70051545961342420732e-01) (9, -2.07356104592855761126e+00) (10, 1.76779818290678403248e-01) (0, 1.64430541395843982100e-01) (1, 1.09108606190947990400e-01) (2, 1.93357521505622437230e-01) (3, 1.71973125846652558080e-01) (4, 1.58626245172290375463e-01) (5, 6.40758012197403283017e-03) (6, -7.08492112752422964483e-02) (7, 2.27102515838383978153e-01) (8, 1.86844819388173100094e-01) (9, -4.93581157566342021425e+00) (10, 7.30959621774555090568e-02) (0, 2.38805314004124191740e-01) (1, 8.28769022603925015202e-02) (2, 1.71977836825459834413e-01) (3, 1.02546181716531112360e-01) (4, 1.65106240846722956972e-01) (5, 1.38355734344387720780e-01) (6, -2.99210251045903402600e-02) (7, 5.25577456286727487389e-02) (8, 6.06081548309653495021e-02) (9, -4.44700357283784519780e+00) (10, 2.30539248904398474949e-01) (0, 1.48001253966074042268e+00) (1, 3.28716616126538241360e-01) (2, 3.93127630445004483395e-01) (3, 2.73534807356835385495e-01) (4, 2.37326535376549713208e-01) (5, 1.34670480697774319623e-01) (6, 2.74958196869126092476e-01) (7, 2.67722703019500452015e+00) (8, 2.11201542182407941972e-01) (9, -1.97339336231121142973e+00) (10, 6.53840755373762960723e-02) (0, 7.44153806061518929837e-01) (1, 3.35822610502894025597e-01) (2, 4.16320963149721723351e-01) (3, 5.02422048097307838432e-01) (4, 3.45719462578947644982e-01) (5, 1.51191010598183961378e-01) (6, 7.56305660648542432689e-02) (7, 8.95917950233046517239e-02) (8, 1.73822815851579132174e-01) (9, -5.24036134290681587800e+00) (10, 1.33975138103774482623e-01) (11, -2.07055364194176694248e-01) (12, 4.33714968806979128679e-01) (13, -6.59059960418935109061e-01) (14, -2.23899133623330415244e-01) (15, -3.81374554056924885970e-01) (16, 6.35768337512358616692e-01) (17, -1.74722341901186600799e-01) (18, -1.71630853867653504485e-01) (19, 6.03353245520934056145e-01) (20, -4.30411278986349010722e-01) (21, 2.50700545013253839333e-01) 
