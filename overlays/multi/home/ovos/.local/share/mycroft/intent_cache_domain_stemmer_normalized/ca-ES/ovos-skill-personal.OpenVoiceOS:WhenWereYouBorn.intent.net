FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.25979797019765271671e+00) (1, 3.30025370838212206426e-01) (2, 4.56481221737431719365e-01) (3, 3.27890935959386065068e-01) (4, 4.62671342911290361943e-01) (5, -2.00034929707116049258e+00) (6, 4.24292719156197428720e-01) (7, -2.21476571635614050138e+00) (8, 2.68218895744370966483e-01) (9, 3.53489497887929104980e-01) (10, -3.63184283293811471793e+00) (11, 6.67730324306579747784e-01) (0, 1.24945669804956027704e+00) (1, 4.41858248273261366990e-01) (2, 4.33708222071059523728e-01) (3, 4.29594473401435195115e-01) (4, 4.41640288988478957322e-01) (5, -2.90630505306945741140e+00) (6, 4.51507182496406589411e-01) (7, 6.26871421840081843868e+00) (8, -9.65662180865303532151e-01) (9, 2.98699329979693728454e-01) (10, 5.67903476455426670100e+00) (11, 1.66483402491420628966e-01) (0, 3.32796988090592726905e+00) (1, 3.23426476717997679611e-01) (2, 4.10374476612616723159e-01) (3, 3.45255388916541283706e-01) (4, 4.28233622611571496108e-01) (5, -3.18133025027306093335e+00) (6, 5.20681138543194310664e-01) (7, -2.11025916685084080626e+00) (8, 9.58241826044281819197e-02) (9, 2.12472710911431938996e-01) (10, -2.16917675479713656372e+00) (11, 6.50202961271749479977e-01) (0, 1.97653189538094076205e-01) (1, 2.16368180188898744098e-02) (2, -5.21583441164448144423e-03) (3, 9.91292711767916279175e-02) (4, 5.49484756264452881003e-02) (5, -9.09018016535720185800e+00) (6, 7.79391249340354086428e-01) (7, 6.77243714537185792501e-01) (8, 3.58761104408035491620e-03) (9, 6.37540899880980171943e-01) (10, 2.17884624315287922514e+00) (11, 3.86428282359398134194e-02) (0, 1.26085686122323581415e+00) (1, 3.28576424578555403855e-01) (2, 4.44152222434409438279e-01) (3, 4.40985651174910842087e-01) (4, 3.71716463426478682663e-01) (5, -5.27449085852022747645e+00) (6, 4.52720442491390262507e-01) (7, 6.38533131645344553817e+00) (8, -8.04776764894024387864e-01) (9, 3.94902120716845828063e-01) (10, 5.76307053138368807765e+00) (11, 2.51779908390009798946e-01) (0, -1.07456099392554715877e+00) (1, -8.96118789461037013044e-02) (2, -1.12170642569341325046e-01) (3, -1.12186869933881425143e-01) (4, -2.37165307953633941462e-01) (5, 2.24463447757854961395e+00) (6, -5.73261459621766555905e-01) (7, 1.17532571868687552019e+00) (8, 3.83935565485085950055e-01) (9, -8.96410225517968971276e-03) (10, 6.75642392646234157816e-01) (11, -3.28415122590727359686e-01) (0, 8.80882493078515071971e-01) (1, 1.75253332924344779054e-01) (2, 1.47613593708970786134e-01) (3, 1.09554876905181716729e-01) (4, 7.28700546140458732536e-02) (5, -1.66428584773079890624e+00) (6, 1.47760807613983913278e-01) (7, -5.00657320273372841157e-01) (8, -5.24555115051193010522e-01) (9, -3.57401783520236049352e-01) (10, -2.73279896915843978356e-01) (11, 1.96451041729149594728e-01) (0, -1.06116372497460798030e+00) (1, -1.54285257657508140250e-01) (2, -2.07741385301093317572e-01) (3, -3.07441702087859369819e-01) (4, -2.14942438503245569770e-01) (5, 2.24217201598778270721e+00) (6, -3.74021978099287000230e-01) (7, 1.06279195951065141834e+00) (8, 4.38352020813550402600e-01) (9, 1.76069106748994903822e-02) (10, 5.48350720714490535990e-01) (11, -1.97984826527304175192e-01) (0, 2.34457072107168762454e-01) (1, -8.16466990377857568251e-03) (2, 6.98239472183947162964e-02) (3, 3.97968035611872411605e-02) (4, 7.26094659838442402222e-02) (5, -9.05280431289157228036e+00) (6, 7.74192703586398245363e-01) (7, 7.20964794363540772970e-01) (8, -2.99238487833427407869e-02) (9, 5.41965321370218910957e-01) (10, 2.29824531389262531889e+00) (11, 3.20787139931476839028e-02) (0, 2.30554259791180982120e+00) (1, 3.77040895204313053490e-01) (2, 3.27722868453033222558e-01) (3, 4.38935017715461506249e-01) (4, 4.54413248728282703759e-01) (5, -1.99825288250512023147e+00) (6, 3.97430138827017664926e-01) (7, -2.21250734964895645618e+00) (8, 2.17125146042394134849e-01) (9, 4.57172000992139004882e-01) (10, -3.47127257652608545158e+00) (11, 5.43595999815555730450e-01) (12, -1.65434406877376510847e-01) (13, 4.46079543160791902601e-01) (14, -1.26009503186561455657e-01) (15, -3.25472061118976530025e-01) (16, 5.07618202196951417982e-01) (17, 4.84721452773869299069e-01) (18, -3.59750935361465573603e-02) (19, 4.89704736353218816891e-01) (20, -1.01503832962380288740e-01) (21, -1.54940368414737544844e-01) (22, 3.69730727464118780201e-01) 
