FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.07535166893278311129e+00) (1, 3.75747143369317748718e-01) (2, 4.28723364215493840668e-01) (3, 3.50522927086949986908e-01) (4, 4.24955039363504094574e-01) (5, -2.74610813826462241138e-01) (6, -1.19368773342526601766e+00) (7, -2.92745456362764298885e-02) (8, 2.72664843947108659350e-01) (9, 2.43424017436175033069e+00) (10, 2.83672846300132841524e-01) (0, 1.08297978196417044039e+00) (1, 4.25557776432634038422e-01) (2, 3.87648179274202142608e-01) (3, 3.62507573407293004486e-01) (4, 3.30737597387433746032e-01) (5, -2.28987898796936234502e-01) (6, -1.10785567776716398214e+00) (7, 4.77737671452793111193e-02) (8, 1.30523682522952544360e-01) (9, 1.78904516453565753942e+00) (10, 3.36449695626823197525e-01) (0, -3.63597096890642734746e-01) (1, -3.13400033177875791957e-01) (2, -3.43835677268051365107e-01) (3, -2.98281918527626366267e-01) (4, -2.69404511215233288812e-01) (5, 1.08450140763383232057e-01) (6, -5.88699946745495750200e-01) (7, -5.50050598604052587426e-01) (8, -9.33645469690572382682e-01) (9, 3.57160264538709248949e-02) (10, -2.70327016659888563765e-01) (0, 1.62024306487617830719e+00) (1, 6.58066530171072749944e-01) (2, 6.68700132909453182073e-01) (3, 7.67888907733595416083e-01) (4, 7.01121654751932887883e-01) (5, 6.53805199356709776382e-01) (6, -2.10604655830874787359e-01) (7, 3.77363310145248753713e+00) (8, 1.19971208142255258977e+00) (9, -5.68759346666329612674e+00) (10, 1.25297780979296180526e+00) (0, 9.50991938572351314107e-01) (1, 6.24965117238485690088e-01) (2, 4.91080098710978074639e-01) (3, 5.77128791175806399316e-01) (4, 5.53852298222506145287e-01) (5, 5.17175670059358050246e-01) (6, 6.14260868590635888964e-01) (7, 7.99509167472653992093e+00) (8, 7.17592050428197292256e-01) (9, -5.85615953083214524355e+00) (10, 1.40753125450684124509e+00) (0, 2.18406350311731101144e+00) (1, 1.11629241205835816331e+00) (2, 1.07707116998816032627e+00) (3, 1.09439604975367088535e+00) (4, 1.02677355952644866477e+00) (5, -1.34301119156528225851e+00) (6, -4.15234785219210067453e+00) (7, 2.22278989306866092690e+00) (8, 7.58248810462437905500e+00) (9, 4.75955847686652777639e+00) (10, 4.71247331867370861103e-02) (0, 1.15378330623094260687e+00) (1, 2.54620830323405267226e-01) (2, 2.38266776110835049041e-01) (3, 2.93695191647715514449e-01) (4, 2.66386191155619678206e-01) (5, 4.67855957965163243850e-02) (6, -6.77631589804463252413e-01) (7, -1.47388915817151244791e-01) (8, 3.83423752040084275805e-01) (9, 1.22471709125488437131e+00) (10, 2.69773078958122136672e-01) (0, -3.48217795050873890617e+00) (1, -3.09313053879074428831e-01) (2, -2.88359488043121781065e-01) (3, -4.16756610068611588193e-01) (4, -3.33901974055103634154e-01) (5, -2.00081294153043792727e-01) (6, 8.87270565853981096893e+00) (7, -6.47649685971153243891e-01) (8, -5.94697024181570221835e-01) (9, 2.16616619151093453555e-01) (10, -2.67814841865644581720e-01) (0, 1.52478501743612380182e+01) (1, 6.58646079796504912984e-01) (2, 6.47176864641857085836e-01) (3, 6.50195556777667937887e-01) (4, 6.35615709322643218648e-01) (5, -5.76663433412575865411e-01) (6, -3.90545856980182248819e+00) (7, 1.99823725304644272960e+00) (8, 6.91551455099480127942e-01) (9, 7.44957106172225103080e+00) (10, 1.39538296695754931998e-02) (0, -6.93642149315388767405e+00) (1, -4.21116301180914753832e-01) (2, -3.22989226641253290850e-01) (3, -3.19348545136050043780e-01) (4, -2.93100715937212930040e-01) (5, 1.51898150940407394849e+00) (6, 6.93323887600185617686e+00) (7, -1.38504047110590677860e+00) (8, -5.89544187706889100120e-01) (9, 1.27520707563488655545e+00) (10, -1.45002439930754040143e-01) (11, 3.62894793399708426307e-01) (12, 4.01133661517040884803e-01) (13, 6.31342868433453885402e-01) (14, -2.10285688218212196698e-01) (15, -1.83170492228603432050e-01) (16, 5.52971546984695749849e-01) (17, 3.42491021601026457422e-01) (18, 6.99150445617687354982e-01) (19, 4.61262454725288928437e-01) (20, 6.44482503331128442348e-01) (21, 2.40299021929752443238e-01) 
