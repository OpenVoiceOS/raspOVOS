FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.00609307991454444142e+00) (1, 1.87527864839648311657e-01) (2, 2.96871587302302508693e-01) (3, 1.94436691369628017467e-01) (4, 3.17572585906600146632e-01) (5, -1.32512198545908832514e+00) (6, 2.90822610880671572620e-01) (7, 4.09859667459656490385e-02) (8, -6.43839463037294557068e+00) (9, 2.51981045957108573674e-01) (10, 3.95909953497339039963e-01) (0, 2.16536731365171791763e-01) (1, 1.68211721507844025325e-01) (2, 3.06562044350441986751e-01) (3, 1.77360907820996338558e-01) (4, 2.52256632475194031429e-01) (5, -1.45194063910153570163e+00) (6, 2.04031734283774190963e-01) (7, -3.11541995883827205205e+00) (8, 8.74264341509110254336e-01) (9, -2.56829526015088482893e+00) (10, 2.98396049118659467680e-01) (0, 1.12006816438704088768e+01) (1, 2.57664355099649189373e-01) (2, 3.47879918873758187114e-01) (3, 3.60207165241689553081e-01) (4, 3.52058740914315937420e-01) (5, -3.48471103988355945802e+00) (6, 2.39919732104705768494e-01) (7, 2.28851464299665741109e-01) (8, -3.29061808981946146702e+00) (9, -2.66755625895235992662e-01) (10, 3.13552541022408703952e-01) (0, -8.08848916686668917286e-01) (1, -4.71776486748042775399e-02) (2, 7.06140710598644333329e-02) (3, -5.00815225775868861496e-03) (4, 7.79991461521801071610e-02) (5, 5.41225009071519380655e+00) (6, -1.86146095956304780117e+00) (7, 4.88167194557841133129e-01) (8, -3.81113106428151160454e-01) (9, 3.08000461242491141434e-01) (10, -2.18159800943591081213e-01) (0, 1.85415104483112780365e+00) (1, 2.89848823152279277959e-01) (2, 2.50493023596500774541e-01) (3, 3.64907618664001731634e-01) (4, 2.92432416282390972295e-01) (5, -2.21559815680469140986e+00) (6, 3.43933122771238442006e-01) (7, 4.58962495998630759519e-01) (8, -4.53636149451388170917e+00) (9, -1.51038221884925681626e-02) (10, -4.17917346730759253770e-02) (0, 1.12201913467913225730e+01) (1, 1.67693577607782695615e-01) (2, 2.77696192165525879147e-01) (3, 1.99644774099500987852e-01) (4, 1.73497341474207256162e-01) (5, -3.60965110611417738795e+00) (6, -2.51780746208867145519e-01) (7, -7.30333071500799757558e+00) (8, 8.19944721706212220624e+00) (9, -4.02335182505601096636e+00) (10, 1.48652867212920480888e+00) (0, -1.03855192171523413869e+00) (1, 2.15008381891091365778e-01) (2, 3.08507096159298943583e-01) (3, 1.87426868963082332575e-01) (4, 1.86965111780007381403e-01) (5, -1.12488969519978443401e+00) (6, 6.87130106461908279902e-02) (7, 3.55374988089097232358e-01) (8, 1.05158370322703582644e+01) (9, 1.63512827425781215318e-01) (10, 2.49762537447638155452e-01) (0, 1.91800412926993280038e+00) (1, 5.33836689898868899107e-01) (2, 4.92183690080543856382e-01) (3, 5.57874751398464541197e-01) (4, 4.60897480258842695555e-01) (5, 8.00336389569906891950e+00) (6, 4.71276135666961604187e+00) (7, 1.13477959021967667042e+00) (8, -1.27540730188240813980e+00) (9, 5.08725246083046145351e-01) (10, -3.53411568988123148127e-01) (0, -1.48617013650111755296e-02) (1, 3.18200320367412192724e-01) (2, 2.47462377314166648290e-01) (3, 2.47276172403888327977e-01) (4, 2.58649222914771659276e-01) (5, -1.10255013130400272847e-01) (6, -1.52451943082410812380e+00) (7, 6.62351279287258565276e-01) (8, -9.63456036540016569347e+00) (9, 3.22511292063506593841e-01) (10, 3.58643331027439393743e-01) (0, -8.05676168895855471241e-01) (1, -2.07785133359879373161e-02) (2, -4.92865059612244346687e-02) (3, 9.50102618952094156446e-03) (4, 1.51434700848609073848e-02) (5, 5.58253975617578035440e+00) (6, -2.02154840345123520962e+00) (7, 1.37586758034582812282e-01) (8, 8.69888188309389659425e-02) (9, 2.19275228011452050225e-01) (10, -4.46734566790041656703e-02) (11, -2.06307974872827426527e-01) (12, -1.71018548810015130757e-01) (13, -2.10468883799079187202e-01) (14, 6.77557517581211965485e-01) (15, -1.43718076091866459043e-01) (16, -1.39154956227478976416e-01) (17, -1.73104137711267813682e-01) (18, 9.18100381766839723774e-01) (19, -6.55942367279070959185e-01) (20, 4.52868307850857687580e-01) (21, 5.25734954329918013904e-01) 
