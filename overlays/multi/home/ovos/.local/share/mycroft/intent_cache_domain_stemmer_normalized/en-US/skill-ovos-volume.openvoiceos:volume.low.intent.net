FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.00947286425957272193e-01) (1, -6.67716804054559447817e-03) (2, -2.14670324614363895732e-02) (3, -1.09716078816922218975e-01) (4, -9.90580083718614889943e-02) (5, -3.83166377015226600200e-01) (6, 4.73686784369931834782e-01) (7, 3.37182283144658756502e-01) (8, 2.06501064878418932880e-01) (9, 2.54834500040225175876e-01) (0, 5.37988510229818306385e-01) (1, 4.15705144059156303515e-02) (2, 1.59924671019265579597e-01) (3, 1.44228711689660449302e-01) (4, 1.54377087916085620201e-01) (5, -1.97286570019828788602e+00) (6, 1.99702387539775587377e-02) (7, -2.11212022007995631201e-02) (8, 1.79216944775731634731e-01) (9, 6.72929617075550684513e-02) (0, -1.30827148669756199162e+00) (1, -8.68023170426337475902e-02) (2, -1.71219839051215613757e-02) (3, -1.29993556280419142457e-01) (4, -3.40024961426703825618e-02) (5, 3.37122333827812470375e+00) (6, -1.34268557990711773220e-01) (7, -1.98375660690059102409e-01) (8, -3.57746602612694752921e-01) (9, -4.05458438641442056594e-02) (0, 7.14862749918274031913e-01) (1, 8.14611768990392282053e-02) (2, 1.13093041506373392924e-01) (3, 1.52964696910941055918e-01) (4, 1.27625421312415082697e-01) (5, -3.72424063913600500442e-01) (6, -1.08743159264474476000e-01) (7, -1.01020844924511785101e-01) (8, 2.27051830470284932151e-01) (9, 4.20544395280165114737e-02) (0, 6.84937232941565099509e+00) (1, 5.44001819778582196285e-01) (2, 3.98446241606375317623e-01) (3, 4.07422835219999890377e-01) (4, 4.59901573349138836910e-01) (5, 6.29564496364388159755e-02) (6, -3.41093932929662946307e+00) (7, 2.00067924206769220952e-01) (8, 8.56712887351194551933e-01) (9, 1.42365859934719424240e-01) (0, 7.52925934134850316504e-01) (1, 1.30928847579254870742e-02) (2, 5.88681865124001182932e-02) (3, 6.41377586511864133945e-02) (4, 1.00033538380075892604e-01) (5, -1.14697206512898031150e+00) (6, 5.83523216400204436383e-01) (7, 5.26687399063222594364e-01) (8, 5.21252170345374188365e-01) (9, 3.28487043573812087516e-01) (0, 6.22895461882403522758e-01) (1, 1.56919270719239639655e-01) (2, 1.74503490294167923347e-01) (3, 1.50662831927487750328e-01) (4, 4.62254285466169242969e-02) (5, -2.10292267747032113334e+00) (6, -1.43691862678271581322e-01) (7, -1.08073982717716246538e-01) (8, 1.87233948311955999966e-01) (9, 1.46808098485909727104e-01) (0, 1.11360661262452698139e+01) (1, 4.90130801908945812340e-01) (2, 4.80245609991526323235e-01) (3, 4.32974127345061021721e-01) (4, 5.20222609155153947746e-01) (5, -6.65371419297787625169e+00) (6, 1.07897316364731050697e+01) (7, 5.84194996631134966236e+00) (8, 1.02272997162547368832e-01) (9, -7.60539065628683563780e-01) (0, 7.58740322529206090429e-01) (1, -1.72788937147507620784e-01) (2, 9.62712937985899311344e-03) (3, -1.01188380773911373867e-01) (4, -3.25887543519830583105e-02) (5, 2.39429709363621040508e-01) (6, 4.85648341228571700512e-01) (7, 4.27286274509151242640e-01) (8, 1.34961718552831955176e-01) (9, 3.59987333099089534816e-01) (0, 1.45900298871174118887e+01) (1, 2.82728967348899629108e-01) (2, 3.70400232354965164294e-01) (3, 2.92374764661159358692e-01) (4, 4.05062836686935379138e-01) (5, -4.13193961076629923124e-01) (6, -3.13309806005079716229e+00) (7, -4.36499933938127929189e-02) (8, -1.18665527713602547699e+00) (9, 4.65989799807186633185e-01) (10, 4.38460123684381697373e-01) (11, -2.70884805927820992988e-01) (12, 1.06687695774964286244e+00) (13, -8.15811484482479726266e-02) (14, -2.04599105235154787863e-01) (15, 5.47240345860966148628e-01) (16, -4.96440546964382223294e-01) (17, 8.58215831355036318229e-01) (18, 4.18755686959255857271e-01) (19, -5.41442304806071139645e-01) (20, 2.34834373319683514802e-01) 
