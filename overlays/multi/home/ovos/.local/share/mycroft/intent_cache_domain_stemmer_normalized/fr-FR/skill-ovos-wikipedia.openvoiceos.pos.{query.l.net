FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=17 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (17, 6, 5.00000000000000000000e-01) (17, 6, 5.00000000000000000000e-01) (17, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.37313099238623781417e-01) (1, 1.29167776785061683142e+00) (2, 1.34001467238398763726e+00) (3, -3.45592008993366728298e-01) (4, 2.27473200089799565404e+00) (5, 1.35964539470156964285e+00) (6, -3.66568147576677461075e+00) (7, 1.59228454251868378755e+00) (8, -3.78957768745313527958e+00) (9, 2.11914710963704333579e+00) (10, -1.27287498668945819880e+00) (11, -4.14524465444718703822e+00) (12, 2.25136603715657357405e-01) (13, -2.02802261082534496239e+00) (14, 1.93548140854357275664e+00) (15, 1.75334948893771414014e+00) (16, -1.56172592194895032414e+00) (0, 2.48892036742370710567e-02) (1, 1.24593468122738304515e+00) (2, 6.25384090023950900417e-01) (3, -2.31594518302800839171e-01) (4, 1.36428531054586743565e+00) (5, 5.86794973761328608752e-01) (6, -2.90275234788126201835e+00) (7, 8.50708938027467609366e-01) (8, -2.35823655153877176360e+00) (9, 9.38631783467400282461e-01) (10, 1.02369318860494398771e-02) (11, -1.69143046835628729774e+00) (12, 3.77557706334138043491e-01) (13, -5.89903015723027612793e-01) (14, 5.44621748309521369613e-01) (15, 3.62002886846534699394e-01) (16, -6.58843631828923692595e-01) (0, 1.62373982603315214490e+00) (1, -1.78699619494061567870e+00) (2, -2.74964607423937912323e-01) (3, 1.12781705748277527590e+00) (4, -1.67017034126751662271e+00) (5, -1.59475300331059455239e+00) (6, 4.39426413257951420377e+00) (7, -1.04925032731164402655e+00) (8, 5.21876217998956981603e+00) (9, -2.61435026668785885917e+00) (10, 1.96894799874995474198e+00) (11, 3.49771242831313822208e+00) (12, 3.83111276940926059886e-01) (13, 2.84909281369016564867e+00) (14, -4.10279793972400219637e-01) (15, -1.03442933629744926449e+00) (16, 1.66536384251559232972e+00) (17, 3.27487700090708457878e+01) (18, 4.35395277485097409453e+00) (19, -6.01349074340745559653e+00) (20, -1.32871436373753981641e+00) 
