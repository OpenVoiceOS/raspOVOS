FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.79330968935426204175e-03) (1, -3.49769234735901931449e-03) (2, 1.87440080932861977137e-02) (3, 3.90653288356548888949e-02) (4, 3.02528193585163730772e-02) (5, 4.29987184579900608150e-02) (6, -1.13339815567851198708e+00) (7, -3.99794066610615506097e-01) (8, -5.05688839580106686000e-01) (0, -9.14093388512668303392e-01) (1, -4.78579572606880401797e-02) (2, -3.86902413535911773868e-02) (3, -1.45243982153018147407e-01) (4, -3.21227631736595367618e-02) (5, 1.58502393630694360382e+00) (6, 1.06849439394337247800e-01) (7, -3.15863646748467952197e-02) (8, 9.61353871497158118942e-02) (0, 3.45049364324012119987e-01) (1, 2.21139015066076999316e-01) (2, 2.19061785745074039111e-01) (3, 2.96203405963827881564e-01) (4, 1.60787889170100034564e-01) (5, -2.11889948992019849783e+00) (6, 3.53944138268641961265e-01) (7, 4.16320773862090598438e-01) (8, 1.22826023293508806988e-01) (0, 3.97370768508978011724e-01) (1, 5.36110435647491168076e-01) (2, 3.93826258403781492845e-01) (3, 4.14928537828448851243e-01) (4, 5.61428253573898028428e-01) (5, -3.18098663740636578012e+00) (6, 1.29945252896229962447e-01) (7, 3.13563964418855201099e-01) (8, 1.27098618341459551617e-01) (0, 9.36538697164022992947e-03) (1, 3.76234982995268182893e-02) (2, 8.04990527121302035241e-02) (3, 1.84562317737745923418e-01) (4, 1.51077367076086682696e-01) (5, 3.99415366086573309090e+00) (6, 4.38936668884118197376e-01) (7, 6.41525574459833602958e-01) (8, 4.69772044073899386341e-01) (0, 2.03928325062907950249e-01) (1, 1.27530850180792465487e-01) (2, 1.62580303558516187090e-01) (3, 1.11937053212332396357e-01) (4, 1.88407373515840845246e-02) (5, 4.01422445583553066939e+00) (6, 5.74905827123407431323e-01) (7, 6.19728915824694137626e-01) (8, 3.51746052008231391284e-01) (0, 2.49622765666164175835e-01) (1, 9.47481018392321017174e-02) (2, 1.88434667596029920000e-01) (3, 2.46914622275110559602e-02) (4, 1.78123645195173901934e-01) (5, 5.11440498686898870062e+00) (6, 4.34445525932792786517e-01) (7, 4.69757751061720185692e-01) (8, 4.37253791343529818469e-01) (0, 2.01027329748786703911e-01) (1, 9.42408886639353182701e-02) (2, 1.71185604938673657793e-01) (3, 1.80368639239477795977e-01) (4, 1.14157437988924650996e-01) (5, 4.99201762236226720404e+00) (6, 4.70144107419733170428e-01) (7, 5.68773955538076858574e-01) (8, 4.97864175092537997180e-01) (0, -1.80775748251758905383e-01) (1, 3.98723421156330692927e-01) (2, 5.30402557462378299036e-01) (3, 4.11088117867632496516e-01) (4, 4.88538028210325825373e-01) (5, 2.76700033237766618299e+00) (6, 1.63916551089056922175e-01) (7, 2.34671674487188612612e-02) (8, 2.15049238828087185826e-01) (0, 2.54284210074655736555e-01) (1, 2.06287210243393720477e-01) (2, 2.77182721900393280734e-01) (3, 2.77622797893931183566e-01) (4, 3.41796250450064453830e-01) (5, -2.24001315532213407522e+00) (6, 3.41212235967330468345e-01) (7, 2.84977319739547263477e-01) (8, 3.94309147129195264325e-02) (9, 1.66248925148814424846e-01) (10, 9.51276977205758655920e-01) (11, -7.88105406846874578797e-02) (12, -4.81083114572091352645e-01) (13, 1.28053702878305697421e-01) (14, 1.14584468769380845576e-01) (15, 2.04006212015071075605e-01) (16, 1.63576217551150426832e-01) (17, 1.00839055695552470837e+00) (18, -4.55224923233562117630e-01) (19, 1.19999700245943072274e-01) 
