FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.50946848796819610428e-01) (1, -1.69483732489276485433e-02) (2, -4.69075255667451927050e-03) (3, -1.70569279423110564675e-01) (4, -4.83394425419497522634e-02) (5, -1.26960198573598415095e-01) (6, 2.77749827895730172500e+00) (7, -8.01066708222192974675e-02) (8, 3.20470186677462143265e+00) (9, -6.65559130609908122800e-01) (10, -6.00113725615294552052e-02) (0, 8.60237824842826737104e-01) (1, 8.49784154052954793235e-02) (2, 2.26568023448727673408e-01) (3, 1.82349527960560864326e-01) (4, 1.45859281307004068351e-01) (5, 3.96867542800285466598e-01) (6, -3.18988452620794760151e+00) (7, 2.18876698039791289796e-01) (8, -1.47470236338194204961e+00) (9, 2.82101066252734122841e-01) (10, 1.73884033159280915193e-01) (0, 9.36767779546064005558e+00) (1, 3.06562746471011393634e-01) (2, 3.26650778359019511310e-01) (3, 2.74307342773520645984e-01) (4, 2.19600054031455355075e-01) (5, 1.55861013333985387597e-01) (6, -3.37227636828847643358e+00) (7, -8.81291552114123015460e-03) (8, -2.41624292976624355234e+00) (9, 2.63277367494196057329e-01) (10, 1.62597395997959165426e-01) (0, 1.23601515102845960214e+00) (1, 3.74752929660206179907e-01) (2, 3.84049182983761172583e-01) (3, 3.12784252914314608862e-01) (4, 2.46249681564693678748e-01) (5, -9.03303265703350177773e-01) (6, -1.20500924715239055018e+00) (7, 3.86705322786368155263e+00) (8, 1.92338849199970312043e+01) (9, 6.35193304911315870243e+00) (10, -2.81501789977564864653e-01) (0, 1.79313865281125330853e+01) (1, 3.04296162921253776634e-01) (2, 3.04468800324265098656e-01) (3, 4.37837311077181434715e-01) (4, 4.40058880496088600243e-01) (5, 3.22707670368047683240e+00) (6, 4.58360144620140097516e+00) (7, -2.48124848303869027788e+00) (8, -7.03291165873318480095e+00) (9, 7.86990843456328525996e-01) (10, 9.76078036097690393547e-01) (0, 7.45159737421454471118e-01) (1, 1.39979071448345870898e-01) (2, 4.19807764690120627238e-02) (3, 1.12565974693496530235e-02) (4, 3.52303637077406315084e-03) (5, 1.47031174532325253912e-01) (6, -3.26211743643726181929e+00) (7, 3.09955793973178794776e-01) (8, -1.48960060394819571172e+00) (9, 3.67290446004416293313e-01) (10, 1.20124446892678704568e-01) (0, 3.28890478188670065673e-01) (1, -3.33385602088298940715e-02) (2, 2.54253237991008719521e-02) (3, 9.36533376125964905912e-02) (4, -4.68722865434017185726e-02) (5, -5.03859323206995934896e+00) (6, 6.91530436947814464155e-01) (7, 1.55941708903729797653e-01) (8, -8.75112510589035608177e-01) (9, 3.29366870452461213414e-01) (10, 1.68050245045731544424e-01) (0, -2.32717848349624473192e-01) (1, -1.15788945363586026627e-01) (2, -1.13356243235353607024e-03) (3, -3.82484806643176369900e-02) (4, -1.43485827313113607773e-02) (5, 5.56162923330709504932e-02) (6, 2.74434658803452702358e+00) (7, -1.53436137355625307199e-01) (8, 2.51341911075750168436e+00) (9, -3.08430938528253262287e-01) (10, -4.56740415049346204501e-02) (0, -2.03558578299497555664e-01) (1, -1.09637529955928403336e-01) (2, -6.42117987734560149993e-03) (3, -1.87243651015047297276e-03) (4, -1.68070210085559425262e-02) (5, 3.81660468437931181887e-03) (6, 2.43235962031313146525e+00) (7, -8.92192400775586869077e-02) (8, 3.19715726925876397857e+00) (9, -6.37493486405291576169e-01) (10, -6.21238354614561533174e-02) (0, 1.26303966600162320688e+00) (1, 2.90091072220850287877e-01) (2, 3.78224511642504035436e-01) (3, 2.91569110949087439977e-01) (4, 3.17494017083692847692e-01) (5, 3.93005683568133312722e-01) (6, -5.32131999694794632916e-01) (7, 1.06439681792370000046e+00) (8, 1.92667210964520521088e+01) (9, 3.89904693939364976885e+00) (10, -1.08352524908201020004e-01) (11, 5.54431449679243737449e-01) (12, -1.98508723652650875824e-01) (13, -2.45269190047281704370e-01) (14, 4.36635426538841409094e-01) (15, -1.74962737895563713586e-01) (16, -1.37792879489968267404e-01) (17, -1.59997365188599721675e-01) (18, 4.69657588085544197565e-01) (19, 5.14688923650265972576e-01) (20, 4.00026588312991038254e-01) (21, 3.33753592888516081860e-01) 
