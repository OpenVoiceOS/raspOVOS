FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.37689038792238882536e+00) (1, 4.03087083344272734120e-01) (2, 4.23138883058838011220e-01) (3, 3.52666471247486124074e-01) (4, 4.14681535308174253895e-01) (5, -2.76496711383325877165e+00) (6, 3.37828438823036203420e-01) (7, -2.59803257147533717131e+00) (8, 3.82089168713594662385e-02) (9, 4.97565657492283319741e-01) (0, 2.83791646091588398160e-02) (1, 2.92295499930240232356e-01) (2, 3.22984068879939634211e-01) (3, 2.54109098801471366968e-01) (4, 3.64770858774043638117e-01) (5, 4.70791322071256956860e+00) (6, 2.74078958809234107807e-01) (7, 4.67003006566467604443e+00) (8, -6.32781943184183015561e-02) (9, 1.70808767109967785114e-01) (0, -7.54225217075698006752e-02) (1, 1.32972571617995194426e-01) (2, 1.14406291014586380950e-01) (3, 9.57596931523427286059e-02) (4, 1.30552466577921799651e-01) (5, 4.72766858417692503735e+00) (6, 3.00283738553382362202e-01) (7, 4.72841267366113982007e+00) (8, 1.91660625284840846483e-01) (9, 1.81761785635806749628e-01) (0, 1.35151504406319311613e+00) (1, 3.05022914056591099019e-01) (2, 4.07891158108524443104e-01) (3, 4.92629159335903177297e-01) (4, 3.53677854035905847585e-01) (5, -2.75524763772947611784e+00) (6, 4.97459326033405313527e-01) (7, -2.68631403158171000456e+00) (8, 2.09525823681166317725e-01) (9, 3.12456738297752445455e-01) (0, -8.20809330012477800231e-01) (1, -1.43318591764115543796e-01) (2, -1.67259318878792972995e-01) (3, -2.90552659084939268741e-01) (4, -2.66167199363850859317e-01) (5, 1.78347142435982797259e+00) (6, 1.09365024036548325048e-02) (7, 1.84134880848601434344e+00) (8, -9.49598135412430821578e-02) (9, -1.74853093558170608057e-02) (0, -1.22228503254210196793e-01) (1, 8.66315025753126299879e-02) (2, 5.24527873760805285475e-02) (3, 1.25208023554716996184e-01) (4, 1.74492749936018903822e-01) (5, 4.72770921964350065991e+00) (6, 2.13957824885703612461e-01) (7, 4.69789835889044127271e+00) (8, 2.20635001903702943071e-01) (9, 3.67580740938045102961e-01) (0, 1.42422634044275930876e+00) (1, 3.08621924464515751119e-01) (2, 4.95645944123081216848e-01) (3, 3.50092724059633264577e-01) (4, 4.97239563708118448293e-01) (5, -2.72849652553660693144e+00) (6, 3.64642363135627756154e-01) (7, -2.58312144140465083098e+00) (8, 1.47995479492952941580e-01) (9, 3.73530738647583460121e-01) (0, 6.20907917348988772077e-02) (1, 3.56205015668727476008e-01) (2, 3.71626614818431455500e-01) (3, 2.95861742684699613459e-01) (4, 3.56694667825557309992e-01) (5, 4.58004490364494643018e+00) (6, 1.59980730295039730304e-01) (7, 4.68813985664549193189e+00) (8, -4.58388587337777986264e-02) (9, 1.81106058090783672565e-01) (0, -8.28153445537961885314e-01) (1, -9.12230295444957928197e-02) (2, -1.60683764269494266941e-01) (3, -1.99368788054131718113e-01) (4, -1.73913462212228031589e-01) (5, 1.76882813521102066900e+00) (6, -7.80836492412903121485e-02) (7, 1.67348140873387452032e+00) (8, -8.17348020137047548417e-02) (9, -9.70403236652843670385e-02) (0, 5.91989233820088625593e-02) (1, 3.53509619126178342707e-01) (2, 3.75570117721416074641e-01) (3, 3.60821305999614316828e-01) (4, 1.99590808937408159540e-01) (5, 4.75234131593408903882e+00) (6, 1.54644885241843776935e-01) (7, 4.64376480210724196240e+00) (8, -5.63401540619180574154e-02) (9, 2.79428878009177650288e-01) (10, -1.60833237817429752781e-01) (11, 3.50594996700145322688e-01) (12, 3.06153326520778257258e-01) (13, -1.66164336850785465671e-01) (14, 7.57704916593847643824e-01) (15, 2.85890302846290189631e-01) (16, -1.46620301654481144382e-01) (17, 2.99999199101783353694e-01) (18, 7.01735171673117275049e-01) (19, 3.10397281536914426692e-01) (20, 3.51624711642123777278e-01) 
