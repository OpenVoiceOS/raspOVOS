FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=15 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.05596541434610857735e+00) (1, 1.29290821797237964752e+00) (2, 2.25682750206492421796e+00) (3, 2.05069629405139619571e-01) (4, 1.76028702947214998886e+00) (5, 1.59354842409740604658e+00) (6, 1.37799541335123953978e+00) (7, 1.02724972105060796679e+00) (8, 9.90434408781393549326e-01) (9, 1.80749095577356833076e+00) (10, -6.52562552396090622686e-01) (11, -6.50116826843744499698e-01) (12, 2.36715043361594146276e+00) (13, -2.69644512724176499407e-01) (14, -1.92105665341540898794e+00) (0, 2.01663112099052543869e+00) (1, -5.46256504718923530106e+00) (2, -2.08413729278456871796e+00) (3, 1.98890192684873318152e-01) (4, -1.80285588900278659352e+00) (5, -3.35246898528098213887e+00) (6, -5.93586318872952989345e-01) (7, -2.18949988626425584570e+00) (8, 1.97005163413133077555e+00) (9, -1.10139537739834994512e-01) (10, 1.39985221060792741632e+00) (11, 1.79491880460870723013e+00) (12, 1.05210932917358626071e+01) (13, 4.53841752546328636164e-01) (14, 2.36855232513935742844e+00) (0, 1.99747442718425816111e+00) (1, -1.86580941670345978878e+00) (2, -2.22350045993902245556e+00) (3, 2.33473197483043432010e-01) (4, -1.74314974669232425342e+00) (5, -2.24595993434676932665e+00) (6, 1.19284608745941628216e-01) (7, -3.35434541081585146927e+00) (8, 1.40352066823626531189e+00) (9, -5.10699627652257959198e-01) (10, 1.38496238252701320270e+00) (11, 1.73329027755551301482e+00) (12, 2.09973688248143997015e+00) (13, 1.01159012339442022643e-01) (14, 2.43283272407472006549e+00) (15, 2.06116781732231544311e+01) (16, -3.15128806812628292633e+00) (17, -4.25657361804868905608e+00) (18, -1.24741846162624336891e+00) 
