FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.13460535920302318935e-01) (1, -2.69130285609399562408e-02) (2, -1.23768885039154175054e-01) (3, -1.05827118981515633928e-02) (4, -1.49527054630581218708e-01) (5, -6.54465516820228576655e-01) (6, 7.22610470236226709595e-01) (7, 4.27455847965598711991e-01) (8, 2.21566242431114057698e-01) (9, 4.29532642837209432951e-01) (10, 4.82221677250164848516e-01) (11, 2.41639166037715985569e-01) (12, -2.84110652271163555138e-01) (0, 1.53777800835166122972e-01) (1, -7.13178757140485453103e-03) (2, -1.07528301510308593736e-01) (3, -3.27446931929334453248e-02) (4, 6.73878168730989157709e-02) (5, 4.29178474959823308410e+00) (6, -5.83816124650289647313e-01) (7, 7.65748199807136820105e-01) (8, 9.12153591071526194389e-03) (9, -2.62472899960156158539e-01) (10, -4.20497218034273090304e-02) (11, -8.15173278867880185539e-02) (12, 1.83401481554667566964e-01) (0, -6.27079524523495135391e-01) (1, 2.13400552255771326290e-03) (2, -8.98047397078785836211e-02) (3, 3.62256271599020601704e-02) (4, 2.52223415134634788848e-02) (5, -1.65636942739229679755e-02) (6, 9.50864724431621621825e-01) (7, 4.66414404907387891708e-01) (8, 1.23749124627259815545e-01) (9, 4.48314254359677366590e-01) (10, 6.70921227886589921496e-01) (11, 9.80886097617816449246e-02) (12, -1.06696659155746123582e-01) (0, 5.18471550022220828424e+00) (1, 5.33290431246506990703e-01) (2, 6.86485227540480691388e-01) (3, 6.13242861226546365216e-01) (4, 4.96476728812205836405e-01) (5, -1.33299570616250995236e+00) (6, -2.48627820647551234234e-01) (7, 1.50398574039416310644e-01) (8, 1.22981229848010054084e+00) (9, 1.26186499253518213948e+00) (10, 8.00450646937849286111e-01) (11, 1.08925085335831117739e+00) (12, -2.15863880516582229419e+00) (0, 1.79748555528858988684e-01) (1, 6.01692742789380688451e-02) (2, -9.19580736076241744836e-02) (3, -8.62590425526505721887e-02) (4, 4.58481854880445141576e-02) (5, 8.35581806214853628489e+00) (6, -1.25633722854319773710e+00) (7, 7.63242015472364920825e-01) (8, -6.37270858451230576280e-02) (9, -3.43354048536892608734e-01) (10, -8.65840738967604828247e-01) (11, -8.71583114683309873039e-02) (12, 1.31922544286410425851e-01) (0, -8.71730312324206280117e-01) (1, -3.21345017855017012209e-02) (2, -1.10222576708063318973e-01) (3, -1.02187460810407831913e-01) (4, -3.78706143801061934084e-02) (5, -9.23317052595448162222e-02) (6, 6.64299733711918416468e-01) (7, 3.34292571720528675083e-01) (8, 1.91801579889385453992e-01) (9, 3.81100706637255537412e-01) (10, 4.70220349536907777921e-01) (11, 2.37871699687610599350e-01) (12, -2.80209394160163494103e-01) (0, 2.66959339715037602403e-01) (1, -1.44517967433675925681e-02) (2, -4.12552306384786418580e-02) (3, 5.49774890809312313800e-02) (4, -3.31162312955602458620e-02) (5, 5.56644545345229513345e+00) (6, -3.73372580857185831782e-01) (7, 7.59723599991171338885e-01) (8, 1.41666046643366492358e-02) (9, -3.53967214332695678802e-01) (10, 1.27575673265842931547e-01) (11, -1.89151633840767469108e-01) (12, 9.06862777926130542161e-02) (0, -6.53975900686262545669e-01) (1, 6.55202967880453845950e-02) (2, -1.17341157996824735354e-01) (3, -9.77463992478165566435e-02) (4, -2.79744172266505920776e-04) (5, -1.02369885241482772020e-01) (6, 1.24016741254217932600e+00) (7, 5.40594011080727909757e-01) (8, 1.49887616555837266397e-01) (9, 1.78121099982712000065e-01) (10, 6.60755596115502275012e-01) (11, 1.03873650319166135891e-01) (12, -1.79981605537791855554e-01) (0, 2.78702393508944767930e-01) (1, -8.47530091137631558240e-02) (2, 3.98839240937486280703e-02) (3, -2.97803530425771526002e-02) (4, 8.23345458178773859093e-02) (5, 4.05937506449740492798e+00) (6, -3.29784344882874114191e-01) (7, 7.28844378134577253192e-01) (8, -6.91773872221548846717e-03) (9, -3.86376219199772552582e-01) (10, 1.21096084374760812330e-01) (11, -2.23499678385225858390e-01) (12, 1.63387717054049530496e-01) (0, 1.36030292247409589912e+00) (1, 4.27969643475111682918e-01) (2, 4.34702286125715930964e-01) (3, 4.69330006839331348445e-01) (4, 3.20933328570422005122e-01) (5, 9.81532118532956521229e-01) (6, -4.44230043207497649060e-01) (7, 1.93454232601283276916e-01) (8, 2.80691446787052656386e-01) (9, 1.55190675117390708415e-01) (10, -8.75247352976349590747e-01) (11, 8.25814138989386159473e-01) (12, -7.00466794607201626022e-01) (13, 3.01683634163775860060e-01) (14, 2.47697759356051178115e-01) (15, 4.57406188828526072410e-01) (16, 7.76268194391931121157e-02) (17, 3.35583647291213482688e-01) (18, 3.66527123229346440958e-01) (19, 3.10834298966940980602e-01) (20, 4.43771204742827329870e-01) (21, 3.37713341353949592083e-01) (22, 3.79645442481103989607e-01) (23, 1.99547016775617369611e-01) 
