FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.42922007987113075522e-01) (1, 1.82047314256574166436e-01) (2, 2.27389327496434701104e-01) (3, 2.00780037105227959771e-01) (4, 2.64739505261327279229e-01) (5, -2.57795503990694818697e+00) (6, 2.40236748728621968274e-01) (7, 3.16955605290355268977e-01) (8, 5.44319937647071670772e-04) (0, 6.34917432019324379233e-01) (1, 1.73238641828443062920e-01) (2, 3.33339839488412337243e-01) (3, 2.81871616155053572594e-01) (4, 3.50559278637315285820e-01) (5, -1.91520342087293116151e+00) (6, 2.01833863530028773114e-01) (7, 1.28102249725131345226e-01) (8, -1.00994978321978332025e-01) (0, 5.93150410192229554651e-02) (1, 2.77316140948674960676e-01) (2, 2.66208085237882419172e-01) (3, 1.78942139266870192671e-01) (4, 1.16891863762281139616e-01) (5, 6.69796039351233662984e+00) (6, 2.20470326785350639875e-01) (7, 1.55549923077682533679e-01) (8, 4.52738793035827646882e-01) (0, -1.28748634696447039616e+00) (1, -5.90914074293793882553e-03) (2, -5.85150826346081398555e-02) (3, -5.53634721409481805887e-02) (4, -9.12388745657624102015e-03) (5, 1.97134948485729433187e+00) (6, -2.14321909515050507133e-01) (7, -3.67231989800160585347e-01) (8, -1.59309034907869323527e-01) (0, 1.09845862104199165632e-01) (1, 9.82084234692697510827e-02) (2, 2.64445949111188072234e-01) (3, 2.88956124100888334105e-01) (4, 2.86989096317494474242e-01) (5, 6.82318902947911443135e+00) (6, 3.10814629141593634643e-01) (7, 2.65331143632987931369e-01) (8, 2.50255080367914328754e-01) (0, 2.07621209635041048536e-01) (1, 1.38966649536097525131e-01) (2, 2.92916867647374234984e-01) (3, 2.89025861535275541137e-01) (4, 1.85618247602188979339e-01) (5, 6.81513042190083684346e+00) (6, 2.63730554877684042481e-01) (7, -4.14140180662527918054e-02) (8, 2.67922046090951992969e-01) (0, 5.01216663477692314643e+00) (1, 3.84435239307798160002e-01) (2, 3.34167572729505313323e-01) (3, 3.39770193271554721282e-01) (4, 3.79408142589248431609e-01) (5, -3.82575637784146493914e+00) (6, 2.77034892468217053274e-01) (7, 4.20543250324496353798e-01) (8, 7.43294104527193799647e-01) (0, 5.11150123236450859565e+00) (1, 3.46230874829210055754e-01) (2, 3.65707698337949527190e-01) (3, 5.29270137720025846129e-01) (4, 4.43413290254987491057e-01) (5, -3.84947887202381444638e+00) (6, 2.91452406673195996145e-01) (7, 3.57513504121321157303e-01) (8, 5.78977852653223767909e-01) (0, -6.64265000786278370093e-01) (1, -1.29827577210585465295e-01) (2, -5.80138224732082985469e-02) (3, -7.68411416184109352656e-02) (4, -1.34869832135359607461e-01) (5, 1.99483623319503999838e+00) (6, -8.77829484370981349972e-02) (7, -3.38665949701493440571e-01) (8, -1.20002526379744400842e-01) (0, 1.21781371862617771029e+00) (1, 8.90367718444370209729e-02) (2, 1.17491448114921945289e-01) (3, 1.59873621355106798614e-01) (4, 1.10840124826242822365e-01) (5, -1.45374925912708130582e+00) (6, 1.83088249382190509928e-01) (7, 3.23300191499260425321e-01) (8, 2.13715368698646934753e-01) (9, -1.83182969508775411738e-01) (10, -2.73617170570501111460e-01) (11, 4.15864930888496409089e-01) (12, 6.96204223960782964120e-01) (13, 3.97298531075798044832e-01) (14, 4.28286076923690806062e-01) (15, -9.55777830703799513579e-02) (16, -8.05793884765308998652e-02) (17, 4.11531714545301241515e-01) (18, -3.78495566045425405055e-02) (19, 3.59378488203369150789e-01) 
