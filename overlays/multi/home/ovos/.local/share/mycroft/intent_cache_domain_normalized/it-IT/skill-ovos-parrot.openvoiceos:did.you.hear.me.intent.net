FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.12650404731694442351e-01) (1, 1.33399200523182270839e-01) (2, 3.64988864305461624404e-02) (3, 2.09404800916000721767e-01) (4, 1.80843491936012623622e-01) (5, 9.51655254605258682510e-02) (6, 2.07148805625886445192e-01) (7, 6.36655253793922248917e+00) (8, 1.79866050267502186610e-01) (0, 1.47939385334912520964e-01) (1, 1.36895370567127583339e-01) (2, 9.04616014006580093643e-02) (3, 1.68626730227753041103e-01) (4, 6.74355634394134262344e-02) (5, 1.96980376625343678310e-01) (6, 2.29637353780716646501e-01) (7, 6.39537628617015663224e+00) (8, 1.37023848378940937831e-01) (0, 1.55512826005879623015e-01) (1, 1.91666190409942982509e-01) (2, 4.37626809719051101943e-02) (3, 1.31353181684299824550e-01) (4, 1.68574591064735768153e-01) (5, 2.28424583459183094813e-01) (6, 1.59235202141255860475e-01) (7, 6.42273250844207588273e+00) (8, 2.38251104119271028825e-01) (0, 1.55761097354214853028e-02) (1, 2.24296794993912251837e-01) (2, 2.49048778576885732061e-01) (3, 1.68772080702816518194e-01) (4, 2.22514511806999715215e-01) (5, 1.53489863289629491216e-01) (6, 1.76312865479027303106e-01) (7, -2.36818600458375705387e+00) (8, 1.05375246865784186201e-01) (0, 1.56134174625340682585e-01) (1, 1.97743912124916432216e-01) (2, 1.45506185376926777675e-01) (3, 1.21567522073074710254e-01) (4, 1.31250594640060780360e-01) (5, 5.34434513094867447158e-02) (6, 2.94618286557645325807e-01) (7, 6.29652197908488098221e+00) (8, 1.59404172661751497575e-01) (0, 3.93822021636790364774e-01) (1, 1.74879613283112911315e-01) (2, 3.50072509332028866669e-03) (3, 2.99234641222509492597e-02) (4, 1.15959736469224389266e-01) (5, 1.16960810265972464661e-01) (6, -4.51997131900563897666e-03) (7, -3.85025808796627311281e+00) (8, 1.05825300279096035094e-01) (0, -1.84935291270548862741e-01) (1, -1.81425005703294839332e-01) (2, -1.44512750714147597542e-01) (3, -3.25054009846096475522e-02) (4, -1.14735030143583327522e-01) (5, 3.69578495195178657884e-01) (6, 3.06337803175716072435e-01) (7, 1.84388067968562219257e+00) (8, -9.93390907934551675718e-02) (0, 9.67998880150179430437e-01) (1, 4.76638279285466037738e-01) (2, 4.50729280140435062396e-01) (3, 6.20878017869030740528e-01) (4, 6.18339754071270730762e-01) (5, 6.19515083160435464649e-01) (6, 4.15418748052062580811e-01) (7, -1.29856060484954838330e+00) (8, 5.21807573165928628711e-01) (0, 1.47205309431020003874e-01) (1, 6.48813367727245071670e-02) (2, 1.63587932372375843837e-01) (3, 2.24693511510177967860e-01) (4, 1.87016536379143116786e-01) (5, 1.38745029354378102138e-01) (6, 2.95954986575096834489e-01) (7, 6.44282025720802131730e+00) (8, 5.49822495224918106338e-02) (0, 1.14886038450650540543e-01) (1, 1.34083719713722737676e-01) (2, 1.45475273741518529302e-01) (3, 1.72921525104080708868e-01) (4, 1.78555728657280476934e-01) (5, 1.82837420864140065557e-01) (6, 2.47195938391720326788e-01) (7, -2.40630971652738345767e+00) (8, 2.86889547271763245551e-01) (9, 2.84634866185636048463e-01) (10, 3.39035727448911194948e-01) (11, 2.98581488795728211549e-01) (12, -2.75083050635797188299e-01) (13, 3.26218463845700745729e-01) (14, -3.33085060623628248511e-01) (15, 6.85174827890223658855e-01) (16, -1.47088515888443738255e-01) (17, 3.35281826920957093385e-01) (18, -2.63116382566434547918e-01) (19, 1.82180873218029726335e-01) 
