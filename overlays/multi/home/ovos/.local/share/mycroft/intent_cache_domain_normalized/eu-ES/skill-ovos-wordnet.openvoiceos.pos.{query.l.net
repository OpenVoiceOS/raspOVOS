FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=30 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (30, 6, 5.00000000000000000000e-01) (30, 6, 5.00000000000000000000e-01) (30, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.79806239914008569869e-01) (1, -4.40185063138304485619e+02) (2, 5.38661852979325658453e+02) (3, -9.19092726741712340299e+01) (4, -3.78639499312534777431e+00) (5, 3.45372203823497670783e+02) (6, 8.42974173297859238119e+02) (7, 7.91787416758001794115e-01) (8, 4.97533580835158792399e-02) (9, -9.50000000000000000000e+02) (10, 5.43224310245690844567e+02) (11, -9.50000000000000000000e+02) (12, -1.41523999557971933427e+03) (13, 4.61201571173640786583e+02) (14, -1.40785657487323373971e+03) (15, -9.50000000000000000000e+02) (16, 1.36383673380221239313e+03) (17, 3.32209150287950990332e+02) (18, 2.18289903781159644325e+01) (19, 2.18821867255857938517e+02) (20, -9.50000000000000000000e+02) (21, -9.50000000000000000000e+02) (22, -9.50000000000000000000e+02) (23, 6.41485269863861446993e+01) (24, -9.50000000000000000000e+02) (25, -9.50000000000000000000e+02) (26, -9.50000000000000000000e+02) (27, -9.50000000000000000000e+02) (28, -9.50000000000000000000e+02) (29, 1.73005146377853163964e-01) (0, -3.22720934411603508352e+01) (1, 1.90275110814078161070e+01) (2, 1.83583786618269462210e+00) (3, 1.62001588667249620812e+01) (4, 3.07670024338276659748e+00) (5, 1.84754833969609251199e+01) (6, 2.98798061547960251971e+01) (7, 2.37737439879270917586e+00) (8, 1.36239909212838106178e+00) (9, 1.50000000000000000000e+03) (10, 3.93384108834028722868e+01) (11, 1.50000000000000000000e+03) (12, -6.89122935147580051307e-01) (13, 2.57508860190087247588e+01) (14, 1.64874889041866303785e+01) (15, 1.50000000000000000000e+03) (16, 2.29663727621828570591e+01) (17, 1.52989182631769118359e+01) (18, 2.22329547539694800662e+01) (19, 2.21340121573052250881e+01) (20, 1.50000000000000000000e+03) (21, 1.50000000000000000000e+03) (22, 1.50000000000000000000e+03) (23, 2.23143041741782610643e+01) (24, 1.50000000000000000000e+03) (25, 1.50000000000000000000e+03) (26, 1.50000000000000000000e+03) (27, 1.50000000000000000000e+03) (28, 1.50000000000000000000e+03) (29, -2.57861220159158257559e+01) (0, -1.45851647300080493608e+01) (1, 3.48662717697746682433e+00) (2, 8.59813057642934985836e+00) (3, 6.75650416967455225148e+00) (4, 4.50225927340092901829e+00) (5, -2.97036468750205440159e+00) (6, -3.47043736670067026751e+00) (7, 6.34585577210186979613e+00) (8, 5.67999820123251342174e-01) (9, 1.50000000000000000000e+03) (10, 8.74149396336616888448e+01) (11, 1.50000000000000000000e+03) (12, -6.94922606141164010296e+02) (13, 5.96337077601136034133e+00) (14, -7.70787269996159920993e+02) (15, 1.50000000000000000000e+03) (16, 1.44742641352963255486e+03) (17, 2.13387909566555919127e+02) (18, 5.53614663689608406116e+01) (19, 2.35501306166765047578e+01) (20, 1.50000000000000000000e+03) (21, 1.50000000000000000000e+03) (22, 1.50000000000000000000e+03) (23, -4.92242189086687318422e+01) (24, 1.50000000000000000000e+03) (25, 1.50000000000000000000e+03) (26, 1.50000000000000000000e+03) (27, 1.50000000000000000000e+03) (28, 1.50000000000000000000e+03) (29, -3.25786688376153188429e+00) (30, -3.11047203659099325002e-01) (31, 5.29811186993884497554e+00) (32, 4.94975476027972671744e+00) (33, -5.04095400216595912468e+00) 
