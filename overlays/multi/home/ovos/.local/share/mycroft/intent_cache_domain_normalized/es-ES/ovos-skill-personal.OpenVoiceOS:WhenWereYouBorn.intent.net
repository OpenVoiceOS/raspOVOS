FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.94314856750786013606e+00) (1, -1.28038361184357296629e-01) (2, -1.11465811245201745772e-01) (3, -1.08385636918305078291e-01) (4, -2.39488042406796192152e-01) (5, 1.40488709860175742250e+00) (6, -2.71347889610510824288e-02) (7, 2.08130444764716343586e-01) (8, 2.61189206756645253549e-01) (9, -3.73431612713212235377e-01) (0, 1.33050693372720774121e+00) (1, 7.88465006880594732053e-01) (2, 6.48535824053122045285e-01) (3, 6.85227433823181630856e-01) (4, 6.99786348872019292600e-01) (5, -3.50074022473297707947e+00) (6, 6.04906664701442609022e-01) (7, 3.11187943791937549065e+00) (8, 1.00206254056587180656e+01) (9, 4.89060596550296364238e-02) (0, 2.81284743913635004731e-01) (1, -2.24973985712540597293e-01) (2, -1.54233881990921944949e-01) (3, -1.70607061843884438845e-01) (4, -6.56277106809740606863e-02) (5, -9.32382598711588883589e+00) (6, 1.07187598966273361922e-01) (7, 4.98226549361444615016e+00) (8, 1.91802646777404128819e+00) (9, 1.22597740222540815824e-01) (0, 8.96390529939066538212e-01) (1, 1.71605776226345291269e-01) (2, 1.06221127486053681932e-01) (3, 2.25081677710834732187e-01) (4, 1.28720599388900985849e-01) (5, 1.20080963287306885512e-01) (6, 2.85679471760042838491e-02) (7, -2.13181306684982696531e-01) (8, 1.22579821253245596635e-01) (9, 4.57458103996025045035e-01) (0, -1.94035907013237185481e+00) (1, -1.98090569666408783389e-01) (2, -2.03982585660003906680e-01) (3, -2.63849662235760007434e-01) (4, -1.35609106710933929874e-01) (5, 1.49752959214776648622e+00) (6, 2.14384860932064769123e-01) (7, 1.21591968800644642523e-01) (8, 3.30696052835547371629e-01) (9, -4.08065479450394785754e-01) (0, 1.29145593742364939160e+00) (1, 8.04409979514910222775e-01) (2, 7.18526943259073735959e-01) (3, 7.20852217309309484250e-01) (4, 6.79226542495323659665e-01) (5, -2.76255814044966063747e+00) (6, 6.37069256516437421034e-01) (7, 1.56402123626169009540e+00) (8, 1.75853326399737461827e+01) (9, 7.76521243540078121015e-02) (0, 1.12761839634358783380e-02) (1, -2.08354377906334847781e-01) (2, -1.50186324279320687625e-01) (3, -1.51700103442681283328e-01) (4, -6.19082169342165464232e-02) (5, -9.19667545898297333906e+00) (6, 1.34975314162882858993e-01) (7, 4.82297174517608784328e+00) (8, 2.64943652280906194463e+00) (9, 3.29276378810916675599e-02) (0, -8.98276999066166981223e-01) (1, -8.37523683092886439550e-02) (2, -1.02806341566830314327e-01) (3, -1.71876360394745547611e-01) (4, -4.81917380473906378779e-02) (5, 1.39285622887939108949e+00) (6, 6.86192516539298053013e-02) (7, 1.31223167166529430805e-01) (8, 1.50925842184809005930e-01) (9, -2.53905625058287731655e-01) (0, -1.75458704603731319160e+00) (1, -1.48387059679202792939e-01) (2, -1.28008559456042947389e-01) (3, -1.79691210498981263077e-01) (4, -2.50280819943122678772e-01) (5, 1.38833764708661067111e+00) (6, 2.19682193934155223225e-01) (7, 1.48023958191691173969e-01) (8, 2.77134151292346420092e-01) (9, -4.03689616335505707667e-01) (0, 8.43258383342157968876e-01) (1, 1.08144584123475454018e-01) (2, 1.15132926974875829385e-01) (3, 1.01021870051009557412e-01) (4, 2.01868123386485409654e-01) (5, 9.86260218059550192171e-02) (6, 1.74038135435009372332e-01) (7, -2.98451212311756530760e-01) (8, 1.14091866155497184687e-01) (9, 3.33416491689587590752e-01) (10, 6.25200820699739034936e-01) (11, 6.96429585255728400561e-01) (12, -1.51681049101675680113e-01) (13, -2.07500789661989835932e-03) (14, 5.56192172304200704858e-01) (15, 6.89774935282812751147e-01) (16, -2.58435022809927306131e-01) (17, 5.27146833515715229623e-01) (18, 6.34825480714845236108e-01) (19, -1.85688350011883884783e-02) (20, 4.07015793634838085602e-01) 
