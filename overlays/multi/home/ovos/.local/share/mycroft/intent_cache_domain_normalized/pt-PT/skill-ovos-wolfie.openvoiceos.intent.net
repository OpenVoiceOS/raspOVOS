FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.72985304738309075834e-01) (1, -7.45221472100691534335e-02) (2, -1.79728365258650588099e-02) (3, -1.23144539328046309645e-01) (4, -4.73100042657331881779e-02) (5, 5.62546517188361877571e-02) (6, -3.00339499765403250553e-01) (7, 1.90603877490348266877e-01) (8, 1.81134240239714761067e+00) (9, -2.00405111579609829242e-01) (0, 5.79590856103968210533e-01) (1, 2.49798751223757553586e-01) (2, 2.19203552950098912167e-01) (3, 1.36536060620024629619e-01) (4, 1.51283441830351805812e-01) (5, 1.72615266636701925052e+01) (6, 1.13058474846132805958e+00) (7, 1.41471455921561806157e+00) (8, -5.54419975084143157318e+00) (9, -4.68090895821495212026e-02) (0, 1.56455473444223946977e-01) (1, 1.55275340997560101775e-01) (2, 8.87566766375136179112e-02) (3, 1.23180966698510627189e-01) (4, 1.68449815236909467009e-01) (5, -1.16436045461496018305e+00) (6, -1.47636512645602985261e-01) (7, -4.44350671290460574880e+00) (8, 1.58463021419895948583e+01) (9, 1.37032299942693586159e-01) (0, 4.67183276873684716346e-01) (1, 1.85653439353283211677e-01) (2, 2.08666248808677956550e-01) (3, 1.42372156123693777152e-01) (4, 2.72553368101890958197e-01) (5, 1.71710784916994327887e+01) (6, 1.32869449091702618304e+00) (7, 1.26960933713424406477e+00) (8, -5.49619354409056182220e+00) (9, 1.21900130110693977192e-01) (0, -7.57746232159608679169e-01) (1, -8.74990655005394996069e-02) (2, -1.46451478999894690869e-01) (3, -2.45018853050511964398e-01) (4, -2.32484696608823426800e-01) (5, 4.74693546217663187026e-01) (6, -1.42188783289443154700e+00) (7, 6.32446866219064651737e-01) (8, 3.21032761270632827078e+00) (9, -3.08260756396786794742e-01) (0, 4.68403922935567929020e-01) (1, 2.73478032914823365740e-01) (2, 1.42749095229333711199e-01) (3, 1.77676731614297700457e-01) (4, 1.49265022842115235857e-01) (5, 5.98365838388330573139e+00) (6, 1.61004222650065975664e+00) (7, 1.73348884863802427114e-01) (8, -3.14981475109341468865e+00) (9, 1.60935099133584530451e-01) (0, 4.63912710865562079310e-03) (1, 3.68926798882928466683e-02) (2, 6.89941359641995238805e-02) (3, 1.19708196628376478676e-01) (4, 8.79871932747807311559e-02) (5, 1.74153704431039035860e+00) (6, 5.38097377115187303076e+00) (7, -4.80484087902004752824e-01) (8, -4.78978024997440854360e-01) (9, 1.36108768116697670392e-01) (0, 4.74196039760944376695e-01) (1, 2.17033279747179425057e-01) (2, 1.98345986813715347008e-01) (3, 2.35828367680719769295e-01) (4, 2.24298407942465222176e-01) (5, 6.74567955253089568401e+00) (6, 1.57058553863301830766e+00) (7, -3.60856559702078638630e-01) (8, -2.32641392052693296577e+00) (9, 1.09615933081141106453e-01) (0, -6.07506847741531075258e-01) (1, 3.16758776290048782442e-01) (2, 4.03266394717325449282e-01) (3, 4.32403857094873667055e-01) (4, 3.84410524947275400454e-01) (5, -6.20953791244340091993e+00) (6, 6.87724857728895511144e+00) (7, 5.65318287670629882058e+00) (8, 3.77661088364166586118e+00) (9, 6.22459277507032449073e-01) (0, -5.09716897004522273562e-01) (1, -2.51879441414069593641e-02) (2, -8.95209955845069349500e-02) (3, -1.24671948221702549864e-01) (4, -9.55762537989806593153e-02) (5, -1.21205645084585006410e-01) (6, -3.53134229004089916781e-01) (7, 3.91204080683722865697e-01) (8, 1.75089939916216175142e+00) (9, -7.54517925883550766297e-02) (10, 6.48562642942142941749e-01) (11, 3.45796462564550322050e-01) (12, 2.98246912962094767874e-01) (13, 3.98448802724610584569e-01) (14, 6.25472657344901650234e-01) (15, 3.90076101870800828753e-01) (16, 8.71568057453614951358e-03) (17, 3.27336167647576503636e-01) (18, -4.19756714473540071264e-01) (19, 6.27793657789898373878e-01) (20, 2.01407830238413937396e-01) 
