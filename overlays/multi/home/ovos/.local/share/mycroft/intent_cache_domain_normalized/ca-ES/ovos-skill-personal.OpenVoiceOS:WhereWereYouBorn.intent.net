FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.75922908182609782912e-01) (1, -1.78082717763102138520e-01) (2, -1.85985801921999538422e-01) (3, -2.12151048885500459473e-01) (4, -2.22574560152208889008e-01) (5, 1.49857410548606972966e+00) (6, 7.07180287290075426654e-01) (7, 1.11624659119497933457e-02) (8, 6.01474343077087802989e-01) (9, -6.39868208772387259131e-01) (10, 8.92714354217391425905e-01) (11, -1.19496767527420680310e-01) (0, 2.90124891295624953713e+00) (1, 5.51685829468704369560e-01) (2, 5.64176727839447167412e-01) (3, 5.48888628192878869072e-01) (4, 5.34790855654216912285e-01) (5, -1.90579058716908855686e+00) (6, 1.91936806113021052322e-01) (7, 5.30551884318925970341e-01) (8, -6.17480127709779136325e+00) (9, 7.52164320967146693420e-01) (10, -3.88693157893939345016e+00) (11, 9.87978053761740637739e-01) (0, 3.07108024069540075374e+00) (1, 4.79830738538162937523e-01) (2, 3.25075500094549885155e-01) (3, 4.10152074330704441429e-01) (4, 4.04639017218010654808e-01) (5, -3.47568450998464095747e+00) (6, -7.57082237947117819843e-01) (7, 8.53126438593440283853e-01) (8, 4.58226841101870974171e+00) (9, 9.75109412923886420543e-01) (10, 4.96424174295422382386e+00) (11, 1.37960151333773289872e-01) (0, 2.98159387304974776711e+00) (1, 8.48482602841907018743e-01) (2, 7.74944731600337499700e-01) (3, 8.85900677747779363713e-01) (4, 8.72429797060542577825e-01) (5, 1.18446868444738839798e+00) (6, 4.92510073867981235107e-01) (7, 6.37049103102633407225e-01) (8, -3.83258084518237440719e+00) (9, 2.04047058736479369756e+00) (10, -4.84646220832034479997e+00) (11, 7.84416957383694990469e-01) (0, 2.93510085651151708674e+00) (1, 3.87981195585874516496e-01) (2, 4.44528211491254765519e-01) (3, 4.00188554661420781144e-01) (4, 3.32320038812307316789e-01) (5, -2.84356498828705683835e+00) (6, -3.13492888414355352911e-01) (7, 5.78634876301710621149e-01) (8, 3.01347507375146017594e+00) (9, 1.04600433225972855311e+00) (10, 4.24213681463378655678e+00) (11, 9.11523779224993613290e-02) (0, -1.67653627837658980582e+00) (1, -3.07096517490398568384e-01) (2, -1.86599301951181434367e-01) (3, -3.25883804666053822352e-01) (4, -2.41289551215421671504e-01) (5, 2.93408762475790618751e+00) (6, 6.69523507332406619952e-01) (7, 1.83822865828181497561e-01) (8, 5.43380698398495232126e-01) (9, -1.97829257558805871042e-01) (10, 8.81570320770444393332e-01) (11, -1.38603504839731550558e-01) (0, 9.68630383697071994931e-01) (1, 3.27818821316634922969e-01) (2, 2.09025326317226256556e-01) (3, 2.46746293401395672129e-01) (4, 3.05402244573509007441e-01) (5, 1.79444880827958369585e-01) (6, -2.86310277679248936789e-01) (7, 1.18409397200893121149e-01) (8, -1.43440648582985352810e+00) (9, 6.87392768091744765790e-01) (10, -9.87539811675678835812e-01) (11, 2.40406691075656320233e-01) (0, -1.55400484199286559317e+00) (1, -2.17143687265169194056e-01) (2, -2.55598897891294529749e-01) (3, -2.56048711793672612025e-01) (4, -2.80441786008131077601e-01) (5, 2.80750253981294273231e+00) (6, 4.92550827538571933673e-01) (7, 3.74063537536512835668e-02) (8, 5.86757792369270725352e-01) (9, -1.08046716561149142022e-02) (10, 8.55253505528312141237e-01) (11, -2.83404473307920790059e-01) (0, 1.02885962548546894268e+00) (1, 2.43186712935490018106e-01) (2, 2.82370739355606414911e-01) (3, 1.64544929489416541513e-01) (4, 2.45170020237488156534e-01) (5, -4.45574116348579074565e-02) (6, -4.44885909357353226401e-01) (7, 9.29605980675922843881e-02) (8, -1.32868790472946263215e+00) (9, 3.67342447459619247940e-01) (10, 7.50866541197275916275e-02) (11, 2.14297767081603640626e-01) (0, 3.06035770782701543880e+00) (1, 4.08416446679489841820e-01) (2, 4.46089651816742649437e-01) (3, 4.62128814690964451195e-01) (4, 3.56934551530735721947e-01) (5, -3.00509292742785305563e+00) (6, -7.95961222696434878010e-01) (7, 5.66665123691980854304e-01) (8, 3.67974824281750523269e+00) (9, 7.98492551534897065935e-01) (10, 4.20984625164645898110e+00) (11, -2.88790488028965175449e-02) (12, 6.41155350349231323293e-01) (13, -2.15572683321154145997e-01) (14, 6.01295120802045390818e-01) (15, -1.91450683580553615570e-01) (16, 4.08213392762071580755e-01) (17, 6.75747278473659118703e-01) (18, -2.18068493479025640736e-02) (19, 6.88309933386131111988e-01) (20, 1.93437843884640848363e-03) (21, 6.00317410912633464548e-01) (22, 3.14096577697437484566e-01) 
