FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.54910467476055074831e-02) (1, 3.13273861385375725075e-03) (2, 9.40305371520617633285e-02) (3, -1.21310795905491628638e-02) (4, 3.84447951552966196709e-02) (5, -5.49762832094565889740e-01) (6, -1.12640514214057518849e-01) (7, -2.25942727917135405269e-02) (8, -5.30376683458084613454e-02) (9, -1.11277828339798912083e+00) (10, 1.51654721886112647811e-01) (11, 4.75225566577461788764e-01) (12, 1.08881979871523634773e-01) (0, 2.20228062790344625288e-01) (1, 2.72228910969353921079e-01) (2, 4.22983675645447976255e-01) (3, 2.49851673291779763364e-01) (4, 2.51837580846406228208e-01) (5, 6.62159713469892552418e-01) (6, 1.89752456448685213886e+00) (7, 2.23316823754075910458e-01) (8, 2.17350914691520458177e-01) (9, 2.74626369773909584371e-02) (10, 2.52979355729297195055e-01) (11, 4.48137066442355891382e+00) (12, 1.49893607169051312766e+00) (0, -1.83047147195938370023e-01) (1, -6.83887539404409161570e-02) (2, 3.84073542458040761982e-02) (3, 3.03357379538042419564e-02) (4, -1.59712446826474931127e-02) (5, -7.40504415060443954566e-01) (6, -6.40564676248340347797e-01) (7, -3.43709185968464780991e-01) (8, -5.16507774243482598031e-01) (9, -7.35038886139371960837e-01) (10, -3.56968999926395302857e-01) (11, 1.74089708163352234749e+01) (12, 3.51007205887904835673e-02) (0, -1.00413157318066464940e-01) (1, 4.76979372323386718868e-02) (2, -8.60983389533278632190e-04) (3, 3.14327833474509696354e-02) (4, -6.07509481488830993534e-02) (5, -3.39850743515286601859e-01) (6, -1.38750646539169325555e-01) (7, -3.27665746795997747665e-01) (8, -2.41801990819307283109e-01) (9, -1.42008507227399594086e+00) (10, -4.11558361213789969391e-01) (11, 1.24029685369146775997e+01) (12, -1.78956851197026700628e-01) (0, 5.79842859127360499283e-02) (1, 2.47371071262699644688e-02) (2, 6.62186243815762048959e-02) (3, 1.18482890097652115990e-01) (4, 1.13933789102588334252e-01) (5, -3.92749876108946460729e-01) (6, -1.08172855539966000782e-01) (7, 4.23071246412561538519e-02) (8, 8.58450790913563473172e-03) (9, -5.90557076672256542338e-01) (10, -7.54111533436715025802e-02) (11, -3.15021060447081779898e-01) (12, 6.12097457365838662491e-02) (0, 4.15572741492846287059e-01) (1, -8.98855097029921112917e-02) (2, -1.80629021618199103738e-01) (3, -2.10336878094506019021e-01) (4, -1.27375430557560620493e-01) (5, -2.66048275434535186346e-01) (6, -1.05887151586037370210e-01) (7, -3.25680674283356716425e-02) (8, -1.26567210546352504341e-01) (9, -5.73754288390902755790e-03) (10, 3.65182908020488736223e-02) (11, -3.57260918199759780478e+00) (12, -7.38833997782180063041e-01) (0, 2.55808131017523955608e-02) (1, 4.36104410572391923417e-02) (2, 1.20229372067791571987e-02) (3, 5.57058328075748857011e-02) (4, 1.04418004421744980981e-01) (5, -2.42056237997054085609e-01) (6, -1.75432630020860777509e-02) (7, -7.91166041228010125108e-02) (8, -3.89393370780183462054e-02) (9, -7.09741660097778392924e-01) (10, 3.22417194571555515425e-02) (11, -3.47995445172175621451e-01) (12, 2.14230813117488982922e-01) (0, -1.38177927794096599978e-01) (1, -3.89815026107897977248e-01) (2, -2.46459161076417104796e-01) (3, -3.13463200960030663467e-01) (4, -3.57194994721284131423e-01) (5, -1.23509282244598561640e-01) (6, -6.99303059970625362496e-01) (7, 1.04527437468121500719e-01) (8, 6.17049672830203080331e-02) (9, 2.57521671613888253338e-02) (10, -9.36758847607671862878e-02) (11, -2.65538838166803170537e+00) (12, 2.09967330627508136365e-01) (0, 2.02108086133800352036e-01) (1, 2.61258187415351395000e-01) (2, 2.16573687913169277142e-01) (3, 1.52034344794501674603e-01) (4, 2.84086602451552872051e-01) (5, 3.63488900373651335762e-01) (6, 1.38251553912892766185e+00) (7, 3.52779249280989470883e-01) (8, 4.36254681948681943826e-01) (9, 1.62160501647084909216e+00) (10, 4.90331919745056021842e-01) (11, -3.05215631761041450432e+00) (12, -6.91898930960139074697e-02) (0, 1.69842050335629574098e-01) (1, 1.08182150990940167956e-02) (2, 1.65274033334968178943e-01) (3, 5.53776938588596209789e-02) (4, -3.54070028949011929992e-03) (5, -3.02359678176226276403e-01) (6, -2.29758914077914707524e-03) (7, -7.97669056984617180772e-02) (8, 3.85049294498727920355e-02) (9, -7.52716154495418621195e-01) (10, 1.95197264280379499668e-02) (11, -3.82348015944346641959e-01) (12, 2.22737170787319305187e-01) (13, -2.89945206590504156452e-01) (14, -7.27691707965521811935e-03) (15, 5.83138914304783262388e-01) (16, 6.82392528676157739120e-01) (17, -3.07165184336750940464e-01) (18, 2.86655208926008875370e-01) (19, -4.16177658443252718179e-01) (20, 2.40045682424639306163e-01) (21, 1.11625259984745817121e+00) (22, -8.58603703003057661114e-01) (23, 2.79309348863640616312e-01) 
