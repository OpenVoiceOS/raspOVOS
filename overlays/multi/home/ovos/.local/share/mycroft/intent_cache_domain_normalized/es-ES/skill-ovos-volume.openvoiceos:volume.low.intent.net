FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.30491816890888134850e+00) (1, -4.79013420283962917945e-02) (2, 5.00095613658259954826e-02) (3, -2.21239611149002569912e-02) (4, 3.26293684899638600228e-02) (5, 4.52776039736846949713e-02) (6, 6.45720455301699164385e-02) (7, 7.66444747052749814076e-02) (8, -4.34098247955117366725e-01) (9, 6.04574616159726851983e-01) (10, 1.49456907966598384618e-01) (0, 1.19360135261928945738e+01) (1, -6.11806599983027304956e-03) (2, -3.71597999204044959765e-02) (3, 1.13790445638811063556e-01) (4, 1.12866260720407438067e-01) (5, -1.92833829416351118513e-02) (6, -3.54484365537680451430e-02) (7, -2.29158013308355563986e-02) (8, -7.82627046760705269435e-01) (9, 5.74169080652756180783e-01) (10, 1.36566492122781379948e-01) (0, -3.31780933154082058323e+00) (1, -5.25082015331504864397e-02) (2, -1.47689927452397007368e-01) (3, -7.22648912008522631423e-02) (4, -3.86217051084754986467e-02) (5, -1.57032591864548792815e-01) (6, -2.91494432206232112481e-01) (7, 2.38855404887003297532e-01) (8, 4.28755183862274069639e+00) (9, -1.25575794254315931120e+00) (10, -2.88351550317167415471e-01) (0, 4.93399455314797119598e+00) (1, 4.12420577930323439819e-01) (2, 2.67406429724804495240e-01) (3, 3.87371398137919265015e-01) (4, 3.78722570465914565307e-01) (5, -8.23201438375043559326e-02) (6, -1.67246884422150889071e-02) (7, 7.85013514988620642043e+00) (8, -5.59349956990892316355e+00) (9, -1.88638369565419627971e-01) (10, -2.46936582296956197435e-01) (0, -1.80290821931572047276e+01) (1, -1.09454016107918383760e-01) (2, -1.23909051436783393396e-01) (3, -2.01772618014217752780e-01) (4, -2.48681436199547190036e-01) (5, 1.03055448659988453664e-02) (6, -1.36440113603919638274e-01) (7, 6.20263392601904994805e-01) (8, 3.49145587469292006944e+00) (9, -1.50048230390639969478e-01) (10, 5.30823922916677237716e-02) (0, 5.53439359928162577518e+00) (1, 6.76987855410110639376e-01) (2, 6.51138043677341515902e-01) (3, 6.19901566481124932650e-01) (4, 7.13362893735897229952e-01) (5, -2.55550810558580962506e-02) (6, -6.70236262269841676087e-01) (7, 4.87321830631014396573e+00) (8, -4.55019948750253089287e+00) (9, 1.10992343999643944263e-02) (10, -1.44148920893124921072e-01) (0, 6.38853484285526196373e+00) (1, 2.98088030965536036898e-02) (2, -4.72469715325624858848e-02) (3, 3.46145840437620047614e-02) (4, 1.90747218282430602843e-02) (5, 7.57569859764788688938e-02) (6, 7.57196527717995254703e-03) (7, 6.50592540107330363774e-02) (8, -7.68655383193137975439e-01) (9, 5.86149375047018028617e-01) (10, 1.22807865002616756200e-01) (0, 5.00684978935469482408e-01) (1, -3.05984794336341819898e-02) (2, 2.87103996438003786218e-02) (3, 1.16343621985337875024e-01) (4, 7.21652255219437099854e-02) (5, 8.19158295859632734626e-02) (6, 8.18124670286851235490e-02) (7, 4.63648937413690953591e-02) (8, -1.12126517105345979708e+00) (9, 5.21074455436338124237e-01) (10, -5.23249375773440217330e-02) (0, -2.13101845521156985086e+00) (1, -1.76882280125749830058e-01) (2, -6.93377760197050607704e-02) (3, -1.83000868275297351451e-01) (4, -1.31190037443769697001e-01) (5, -4.58336421401266402853e-02) (6, -6.27473489676701134954e-01) (7, 2.32311233051994747711e-01) (8, 4.71094282558427135399e+00) (9, -9.91194214749472002346e-01) (10, -1.85084299313137634613e-01) (0, 4.28799724408191451630e+00) (1, 6.97805883610861599209e-01) (2, 6.57841766501086055996e-01) (3, 7.09757143879549912135e-01) (4, 6.05334440494196601712e-01) (5, 1.09950766577027209125e-01) (6, -6.91482557692157273621e-01) (7, 4.60726716515545753339e+00) (8, -4.83704753916230600908e+00) (9, -5.02570195220212734277e-02) (10, 1.37894133572136451393e-01) (11, -4.73906001195313134056e-02) (12, -1.28072768900106576107e-01) (13, 6.72918629365301224077e-01) (14, 7.00242042637842065922e-01) (15, 6.64209331682775849792e-01) (16, 4.63742125318749198737e-01) (17, -2.54813088966731222940e-02) (18, 4.76604573503560724479e-01) (19, 5.98278390672054571908e-01) (20, 4.10590517805321464362e-01) (21, 2.22222755838653890370e-01) 
