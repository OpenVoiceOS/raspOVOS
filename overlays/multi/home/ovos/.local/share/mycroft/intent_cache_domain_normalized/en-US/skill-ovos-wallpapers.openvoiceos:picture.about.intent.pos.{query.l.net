FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=16 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (16, 6, 5.00000000000000000000e-01) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.33146420199453956457e+01) (1, 7.23630787330512781352e+00) (2, 7.14810220412212871111e+00) (3, -1.73215228792480080422e+00) (4, 2.09703672834361798394e+00) (5, 7.48529577637390453049e+00) (6, 7.03747365138727687395e+00) (7, -2.83520245735276965604e+00) (8, -2.79019155536521745731e+00) (9, 7.00429743283171823975e+00) (10, 7.14199943355518840349e+00) (11, 2.16011843987430340874e+00) (12, -2.33047117177053886294e+00) (13, -1.95135234632506726626e+00) (14, -2.83582300592244873627e+00) (15, -5.56637459581579996382e+00) (0, -5.75846491533744053726e+00) (1, 7.21764017539863367290e+00) (2, 4.63044507636696067721e+00) (3, -2.13271326311403308651e+00) (4, 2.26747142517318556187e+00) (5, 7.01741216063795913982e+00) (6, 4.69921177460819450289e+00) (7, -1.21066335522661039370e+00) (8, -1.33725721323022628262e+00) (9, 7.19711835953269041255e+00) (10, 4.64697878642946449190e+00) (11, 2.20701992643604727462e+00) (12, -3.48665808675158617191e+00) (13, -3.44222829279769104716e+00) (14, -2.88068943101251173644e+00) (15, -5.77977648157107548599e+00) (0, -1.08160813232968724407e+01) (1, 1.45216845919825776612e+00) (2, 4.85917783123007573920e+00) (3, -1.64146624904228111141e+00) (4, 1.99508579815263509261e+00) (5, 1.55249205200514195369e+00) (6, 4.89948260895422027517e+00) (7, -4.89312957573107332188e-01) (8, -3.21084830510786622959e-01) (9, 1.91298215382674463569e+00) (10, 4.88453723601511047292e+00) (11, 2.05203486228818654524e+00) (12, 4.20373545321732677849e+00) (13, 4.14830650121448485379e+00) (14, 5.43328470510167083063e-02) (15, -2.04062764056298001636e-01) (16, 4.54550192632525540404e+00) (17, 3.07020200921931030180e+00) (18, 2.48867523046112459895e+00) (19, -1.36524897796062050226e+00) 
