FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.88423925635344113871e-01) (1, 3.03242421781892868005e-01) (2, 3.19054032748813720666e-01) (3, 2.84231252109880538903e-01) (4, 4.18447881078596262139e-01) (5, -1.64273236353710649915e+00) (6, -1.29178056969393301179e-01) (7, 7.15921938141999281147e-02) (0, 1.01247490122771166554e+00) (1, 3.71345631711458790125e-01) (2, 3.62801842324709522547e-01) (3, 3.17098639838671314539e-01) (4, 2.88953840665793049158e-01) (5, 3.51153677916650641677e+00) (6, 4.90479774546949826020e-02) (7, 1.50585884946160597497e-01) (0, 4.20736911144978187327e-01) (1, 3.26208348458881469689e-01) (2, 3.13625599330539794884e-01) (3, 4.50887768602247329675e-01) (4, 4.00463222598905710381e-01) (5, -2.52094171994025639805e+00) (6, -8.50757011315713407296e-02) (7, 2.00852212282103093077e-01) (0, -1.40353414296091738578e+00) (1, -1.49104325541063148508e-01) (2, -1.22911720045610253771e-01) (3, -1.32841511138482887278e-01) (4, -2.14508830078645545969e-01) (5, 1.21989399309312762654e+00) (6, 1.74762231810505874741e-01) (7, -1.10923936530519282040e-01) (0, 1.61466577431457336544e+00) (1, 2.76764016985601324361e-01) (2, 2.83514846503442663472e-01) (3, 3.85249954104131597798e-01) (4, 3.51342242598241705220e-01) (5, -3.43293455245331058379e+00) (6, 1.91663285555678353234e-01) (7, 4.68844229766212761135e-01) (0, 9.11606057731865870863e-01) (1, 3.46172206037020313563e-01) (2, 3.62306497924303638758e-01) (3, 2.95813344352221119227e-01) (4, 3.06972272627329456629e-01) (5, 3.50381210661058295486e+00) (6, -1.65725119638116674681e-02) (7, 3.12701227861218622461e-01) (0, -1.69220497607482545099e+00) (1, -2.92719979201498614607e-01) (2, -3.03597662960234271345e-01) (3, -3.07465035830679522810e-01) (4, -2.57886518155279742537e-01) (5, 2.53964668417432815062e+00) (6, 2.41425452335293749817e-01) (7, -2.49369675571561033589e-01) (0, 1.07853125543842787160e+00) (1, 5.35603998220120502971e-02) (2, 1.74238206259027555989e-01) (3, 1.32255413941160276936e-01) (4, 4.35771135604535037045e-02) (5, 1.29415760987548311700e-01) (6, -5.99083192469938852209e-02) (7, 9.89837052538948269920e-02) (0, 1.04416363821874136342e+00) (1, 5.74883012092267109416e-02) (2, 3.80636019623433186077e-02) (3, 1.88626171461359098958e-01) (4, 7.85603238260899616741e-02) (5, 1.72635005891594556227e-01) (6, -1.39104611995085284543e-02) (7, 1.17727153213317892178e-01) (0, 1.05224284455037020436e+00) (1, 3.61588768594240772547e-01) (2, 3.46681408517336475672e-01) (3, 2.54468560152029732446e-01) (4, 3.14664177529787647547e-01) (5, 3.42256652033452857253e+00) (6, 1.06374091312921276176e-01) (7, 2.88364412980847528711e-01) (8, -2.18644293257192479096e-01) (9, 5.61283757021612483840e-01) (10, -2.38980110457056221795e-01) (11, 6.34308743268560237816e-01) (12, -2.04276966494746803349e-01) (13, 5.44839506080335933547e-01) (14, 6.45586694568704433372e-01) (15, -1.20357846145856747788e-01) (16, -1.07572813754308591050e-01) (17, 5.52484248807615596633e-01) (18, 2.12389229583316130334e-01) 
