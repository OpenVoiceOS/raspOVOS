FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.16732052961093746291e+00) (1, 1.57997938839252727306e+00) (2, 1.06692379717217167290e+00) (3, -2.00707604751812507260e+00) (4, 1.52075022998712072742e+00) (5, 5.88648546136841588350e+01) (6, 2.19227715586868487918e+00) (7, 1.48512847411769066674e+00) (8, -1.85525130232219392923e+00) (9, -4.85029851258541278014e+00) (10, 1.17808026265796006449e+00) (11, 2.01812049154911843374e+00) (12, 9.98396949067541172873e-01) (13, 2.15818463278596855970e-02) (14, -4.99534580315181053756e-01) (15, 1.35322181808257879787e+00) (16, -6.92594738521666974940e-01) (17, 5.89577863834724240633e+01) (18, 1.01788170823795942610e+00) (19, -6.03177836400144329332e-01) (20, 5.90955938455736262682e+00) (21, 5.89060429580435567232e+01) (22, 5.90224588833675198885e+01) (23, -2.36189940021556049610e-01) (0, -9.87188736687154566596e-01) (1, 3.93518515194427487280e-01) (2, 4.61981472820946481583e-01) (3, -1.95913427107018645046e-01) (4, 4.90834960879282911073e-01) (5, 1.03413771416265465319e+01) (6, 5.07181476396716957034e-01) (7, 4.48167563272595770307e-01) (8, -2.29311328637466532721e-01) (9, -7.94087597145663126597e-01) (10, 4.00403412893712229437e-01) (11, 4.29541882561523813422e-01) (12, 5.97240709730726293536e-01) (13, -1.76649173563069375459e-02) (14, -2.36062033835959042549e-02) (15, 8.28761772731247181589e-01) (16, 7.68648990068193233016e-02) (17, 1.03075643505174614489e+01) (18, 5.71339049407583288165e-01) (19, 6.38763616719122850895e-01) (20, 6.33214146623896190214e-01) (21, 1.01829299803096748889e+01) (22, 1.01886574725825287402e+01) (23, -9.17497757119058177100e-02) (0, -2.93827308260138408968e+00) (1, 1.28629546702503372302e+00) (2, 1.38596649222876799890e+00) (3, -1.03774842385541576917e+00) (4, 9.26757620286563388312e-01) (5, 2.46750436598117133258e+01) (6, 9.22195037730194400183e-01) (7, 8.74896769808825913728e-01) (8, -6.97307416337881069701e-01) (9, -2.04284258138214402933e+00) (10, 7.88916268131668485530e-01) (11, 9.61039175676402512849e-01) (12, 1.36917225574325818194e+00) (13, -5.96072521995499760017e-01) (14, -3.36776284119577995479e-01) (15, 1.22709698142696033152e+00) (16, -3.25671081510163107353e-01) (17, 2.46237634146268149493e+01) (18, 1.37684663688015240801e+00) (19, -4.38391447232490349961e-01) (20, -2.37135898368637298983e-01) (21, 2.46142832921499987719e+01) (22, 2.46860521087105055926e+01) (23, -3.42572868585001688579e-01) (24, 1.24645082622112184367e+01) (25, 3.05511995608835817961e+00) (26, 3.23648557942078198835e+01) (27, -4.56654013811957082414e-01) 
