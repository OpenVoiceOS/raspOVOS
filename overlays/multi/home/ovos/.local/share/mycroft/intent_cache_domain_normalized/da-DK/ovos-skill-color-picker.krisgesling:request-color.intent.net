FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.24738069265936912799e+00) (1, 4.21080126164803891786e-01) (2, 3.66049407719025943209e-01) (3, 4.41451905964265034488e-01) (4, 3.94742852745900540956e-01) (5, 2.37277428592341799174e+00) (6, 4.19763580215007592322e-01) (7, 4.39460020115020721931e+00) (8, -5.97526608194787822725e+00) (9, 3.99154796804477074446e-01) (0, 1.16882119711441426202e-01) (1, -1.08441146989321168803e-01) (2, 9.86118833566256621642e-04) (3, -5.90903376834148938435e-02) (4, 5.33073367877250348101e-02) (5, -1.03076958428423029468e-01) (6, -1.17271328843645675222e-01) (7, 1.57513526491461136603e-01) (8, -4.17477890643155657990e-01) (9, 2.83168277141532476193e-01) (0, 2.21739013979121368791e+00) (1, 1.48717099958568632623e+00) (2, 1.38967895293146193048e+00) (3, 1.37372165703683912774e+00) (4, 1.39087433898359358331e+00) (5, 2.19513474308670269997e-01) (6, 8.73650022151004623794e-02) (7, 8.11494101361191377819e-01) (8, 7.32292959962694695042e-02) (9, 1.43453966285490386312e+00) (0, 3.18852152799041499431e-01) (1, 1.57421802690207501829e-01) (2, 5.38826003279085988251e-02) (3, 1.49187646414633522107e-02) (4, 9.87068466450568005044e-02) (5, 7.05509680883610545976e-01) (6, 5.93426805278797542265e-01) (7, 1.14017609604867264927e+00) (8, -2.43139573985480528240e-01) (9, -3.04036565109566836451e-01) (0, -4.41883577626564938434e-01) (1, -4.98697333054419766896e-02) (2, -5.76087407784339200489e-02) (3, -1.83833057435023372594e-01) (4, -1.96195299180018545293e-01) (5, -2.23661608524504818950e-04) (6, 2.88237032919123559171e-01) (7, -2.29175734526534863322e-01) (8, 2.10108357557681957317e+00) (9, -8.60434501685954700179e-01) (0, -9.73002046700123107703e-02) (1, 1.43565350024158155939e+00) (2, 1.45216960830742514155e+00) (3, 1.57565504310781157038e+00) (4, 1.44023119656497633478e+00) (5, -9.01303562406152725117e-02) (6, 7.17553535834042244268e-01) (7, 5.83218342680461465655e-01) (8, 3.98259658611043487753e+00) (9, -2.01641345079905542903e+00) (0, -1.64465181418632054589e-02) (1, -6.07024198071712817182e-02) (2, 1.67096080584769914046e-02) (3, 1.28400894208198258772e-02) (4, -4.61009172396416311290e-02) (5, -1.72324844966928653056e-01) (6, -1.86439494169764019560e-01) (7, -1.83062498986611948970e-01) (8, -2.75170224984942146662e-01) (9, 1.87357193228682855635e-01) (0, -1.13619003975091892311e-01) (1, -9.28262236844247246026e-02) (2, -1.86489513827437614069e-01) (3, -2.37031160606021196191e-01) (4, -4.75560191403572932178e-02) (5, -1.97892615105107583240e-01) (6, 2.52366671840417000627e-01) (7, -6.58700617265876808837e-01) (8, 3.15261869818290696443e+00) (9, -6.38145197125245866587e-01) (0, -7.73520729322960121088e-03) (1, -1.08395951767420228862e-01) (2, 7.61683406634574844407e-02) (3, -1.57194239692444205636e-02) (4, 5.61582418484931622515e-02) (5, -1.26915449970787519440e-01) (6, -9.82881529125465142060e-02) (7, 1.32415537945566624822e-01) (8, -4.35811488102934019295e-01) (9, 1.78159272667846063642e-01) (0, -2.82704267539553924515e-02) (1, -7.77875614024547412662e-02) (2, 7.97221989856684333520e-03) (3, 5.76377305530163044911e-02) (4, 4.78172990821453328114e-02) (5, 4.15469309513112339260e-02) (6, -9.26552822896563495203e-03) (7, 2.08028428486912608797e-01) (8, -8.64774368315501584803e-01) (9, 1.21514385935744664846e-01) (10, 1.23705725358377360834e+00) (11, -3.27301637454915139713e-01) (12, -2.67849032718942448028e-01) (13, 5.71519562026340022243e-01) (14, 8.55496594588519898572e-01) (15, -5.17046347373861792107e-01) (16, -2.92745049449943783859e-01) (17, 1.25990594957978929713e+00) (18, -3.25897828861165139713e-01) (19, -4.79360399883400456478e-01) (20, 4.58705500915768948911e-01) 
