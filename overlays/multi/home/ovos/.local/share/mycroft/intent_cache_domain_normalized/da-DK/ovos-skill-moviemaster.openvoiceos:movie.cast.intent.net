FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.59778306981807816101e+00) (1, 1.34237533056333985249e-01) (2, 1.96279545867041077534e-01) (3, 1.63799618923262085834e-01) (4, 1.32538882636621918598e-01) (5, 2.34820965020975130910e-01) (6, 1.88675269308997717310e+00) (7, 5.12863598160947731230e-01) (8, 4.37600022041401715001e+00) (9, -4.35347816313248792142e+00) (10, 5.48837432626590171481e+00) (11, -1.52301072896963013426e-01) (0, 6.98882756845249364375e-01) (1, 8.82493608117006778091e-02) (2, 9.46949698448084353775e-02) (3, 4.05872703015707353424e-02) (4, 1.94426329475631626265e-01) (5, -4.94694271269526308910e-01) (6, 9.52804458283965927112e-02) (7, -3.18363164262147058103e-01) (8, -5.45776757408142632055e-02) (9, -1.77729669352799790616e+00) (10, 2.03612527769419737744e-01) (11, 3.55515092698430401619e-01) (0, 4.04784932778709527490e-01) (1, 3.36099148300587555194e-02) (2, 9.46325019505917519602e-02) (3, 8.48773897198140114817e-02) (4, 1.40349286845058124351e-01) (5, 6.98345486447270680230e-01) (6, 5.44191364666783763959e-02) (7, 6.43534031137879658502e-01) (8, -1.40156442198102904051e+00) (9, 7.23292826609410188787e-02) (10, -2.03896102265632928052e+00) (11, 2.64549935979566108735e-01) (0, -8.22871936625667932397e-01) (1, -1.46026219766007075984e-01) (2, -7.65821817921262665285e-02) (3, 1.53502118183511757771e-02) (4, -1.47223431275945639690e-02) (5, 4.88785079141261402658e-01) (6, -1.28307898150054090769e-02) (7, 2.28621565108487051488e-01) (8, 1.19885141212066351213e-01) (9, 1.18646939579729493452e+00) (10, 3.80871005233960946423e-01) (11, -1.75116077182662338574e-01) (0, -3.82656227107111757135e+00) (1, 4.61805166630025965002e-01) (2, 4.99794440297361419745e-01) (3, 4.67981969891067606238e-01) (4, 5.16725959209676677375e-01) (5, 2.29519704130369150974e+00) (6, 3.07758991175058616019e-01) (7, 1.68863530417897789171e+00) (8, -1.82507448335090294300e+00) (9, 5.41027260405249599273e+00) (10, -1.38903636198938240653e+00) (11, -3.18660112765687064673e-01) (0, 7.69222265830522644592e+00) (1, 2.22844979440534746162e-01) (2, 2.66271962498987380119e-01) (3, 2.63920529460275832268e-01) (4, 1.60213305329645366859e-01) (5, 1.56204244262531460885e-01) (6, 1.86204326349808302332e+00) (7, 4.55103374414648265134e-01) (8, 4.01392546684432183213e+00) (9, -4.67289135537447286595e+00) (10, 5.59578311804637351656e+00) (11, -1.93790092886930304106e-01) (0, 7.66110893107048496198e-01) (1, 8.29384901046656131118e-02) (2, 8.55409741818808078140e-02) (3, 6.78791046559713839859e-02) (4, 6.56421125352285861343e-02) (5, -1.12735030894315957362e+00) (6, 9.80310497403116959392e-02) (7, -2.54246886964421325850e-01) (8, -1.49658648196460269952e-01) (9, -5.47716974945287926602e-01) (10, 1.15327139695608940628e-01) (11, 3.26691100852807780885e-01) (0, -3.92022583688561265802e+00) (1, 4.39227601254452870716e-01) (2, 4.52457045877446339954e-01) (3, 4.55854305738677190174e-01) (4, 5.44472081327905033099e-01) (5, 2.22372172581260452162e+00) (6, 6.30683939888116773531e-01) (7, 1.19142223393368840156e+00) (8, -1.44640703903198697411e+00) (9, 5.43426535857148174102e+00) (10, -1.50614095937908043510e+00) (11, -3.31803994921105460669e-01) (0, 7.30051083580745885371e-01) (1, 1.16349847656478738722e-01) (2, 1.01485350769748544630e-01) (3, 1.97128401738395603315e-01) (4, 6.19368195950888156265e-02) (5, -6.09027800009346753640e-01) (6, 4.94918477845999182918e-02) (7, -3.36120761739688522773e-01) (8, -1.70239815387727283502e-01) (9, -1.49538668589237522255e+00) (10, 1.97041288575010437034e-01) (11, 2.63956628826951367195e-01) (0, -7.82115017955049562914e-01) (1, -8.55880189345937791856e-02) (2, -1.45910296182499538142e-01) (3, 1.18243735624689091240e-02) (4, -3.77457249568563454889e-02) (5, 4.06147642453315305122e-01) (6, 1.41999016894730385741e-02) (7, 1.91086935565592003217e-01) (8, 8.51533411062890543963e-02) (9, 1.18860875550989564253e+00) (10, 2.19389483210283148251e-01) (11, -1.22036352870833780804e-01) (12, 5.93229952956349171345e-01) (13, -6.98065207969993939408e-01) (14, 1.80102918818724699879e-01) (15, 9.84329351845067868076e-01) (16, -3.32756498366695130375e-01) (17, 5.30396286154896645648e-01) (18, -3.46661149381975064454e-01) (19, -3.00924540966849951573e-01) (20, -6.94857762825340619095e-01) (21, 1.12032251196067234034e+00) (22, 3.06006396381847067811e-01) 
