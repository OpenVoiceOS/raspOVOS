FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.45653737120376680636e+00) (1, 1.24654383266072060765e-01) (2, 1.77939695173601669653e-01) (3, 1.43423952961067774359e-01) (4, 1.86380070501665634497e-01) (5, -2.21362899207288332804e+00) (6, 7.01021138416295763740e-01) (7, 1.68098846218251751772e+00) (8, 2.30565413345726416550e-01) (9, 4.51292783113213857860e+00) (10, 4.19625644964794375369e-01) (0, 1.49176212269131869270e+00) (1, 3.46979685734890130888e-01) (2, 2.29627751421116022001e-01) (3, 3.33837308596752313505e-01) (4, 2.32552886616371301542e-01) (5, -2.30535385500857126218e+00) (6, 1.20432513632341064991e+00) (7, 8.16036366368274590499e-01) (8, 3.42296970493757346521e-01) (9, -8.55530860731428610677e+00) (10, 7.05156253533954363588e-02) (0, 1.14555681004837481396e+02) (1, 1.66486110628586594373e+01) (2, 1.66423887700777832777e+01) (3, 1.66655549944382492811e+01) (4, 1.66294360400181595594e+01) (5, 1.84335017296813816756e+01) (6, 2.49720833050812540677e+00) (7, 1.50938632017567329058e+01) (8, 2.28431460135866348793e+00) (9, 1.99868956758109952432e+01) (10, 7.26425397847248022209e-01) (0, -2.29262799886613848344e+01) (1, -9.26441671955822304563e-03) (2, -4.55918458353304772990e-02) (3, -3.37668803583407312052e-02) (4, -5.61789420496248831371e-02) (5, -8.03567570253909714550e-03) (6, 1.79745780884419864565e-01) (7, 2.18502606072332072884e+00) (8, 1.54169772408966854194e+00) (9, -6.39977715095599308803e-03) (10, -1.30572383730179319983e+00) (0, 1.99280392981204546032e+00) (1, 1.95239009127081725170e-01) (2, 9.49680747241392064772e-02) (3, 1.02530920669497510600e-01) (4, 2.30936215981901976635e-01) (5, -2.21367155496379597324e+00) (6, 6.17794536493579404812e-01) (7, 1.68867909981066421921e+00) (8, 3.60388427629124596940e-01) (9, 4.52488050452116041811e+00) (10, 6.05260064088389504455e-01) (0, 1.18020667225738140615e+00) (1, 7.51217612376957194487e-02) (2, 1.77821741377427899877e-01) (3, 1.31487780188634773015e-01) (4, 2.62958072995260250249e-01) (5, -1.57882710385630287142e+00) (6, 2.66352400425752644519e-01) (7, -1.24845344132773927726e+00) (8, -1.67058298867312549074e-01) (9, 5.84090692212924356141e+00) (10, 1.24214305972702845904e-01) (0, -1.51303349134754117067e+00) (1, 4.89160384359411601340e-02) (2, -1.53628472862191809561e-02) (3, -1.21396686571592915538e-01) (4, 4.14593036594442729270e-02) (5, 1.69002635600096623447e-01) (6, 3.61821420154348136200e-02) (7, 5.73249165087251211226e-01) (8, 3.97740192007729927159e-03) (9, -4.42670353183195253166e-01) (10, -3.60921505569057055052e-01) (0, 5.80019427858988412261e-01) (1, 2.10014610780975080617e-01) (2, 5.48262440102306874978e-02) (3, 7.86121182577816240977e-02) (4, 5.96461363570896657693e-02) (5, -8.34092890988944901665e-01) (6, 5.79797062077762381804e-01) (7, 1.54626376837931078789e+00) (8, 1.85387623291679881632e+00) (9, -9.71651311020903385440e+00) (10, 1.07928647055092072349e-01) (0, -1.26336322924107857801e+00) (1, -5.28797546483744662638e-02) (2, -1.24822784409688886109e-01) (3, 1.68880110524426418905e-02) (4, -3.62112784840334656078e-02) (5, -3.93934308496357507567e-02) (6, -6.37770619096428986738e-02) (7, 5.25099173353731213387e-02) (8, -1.17074171879181537781e-01) (9, 3.45214265761524563558e+00) (10, -1.50731536411593064484e-01) (0, 7.45267613776430337680e+00) (1, 2.65559981635517972087e-01) (2, 3.61087243131108182048e-01) (3, 3.84669835737652676677e-01) (4, 2.24012198916382493374e-01) (5, 8.13664318592072222103e-01) (6, -1.03344989765575023810e+00) (7, 3.06090155451027490230e+00) (8, -4.48608973518299158911e+00) (9, 2.00798962815133954507e+01) (10, -2.75131737736864168120e-01) (11, -1.53035045465247741131e-02) (12, -1.86974229748656795014e-01) (13, 4.46241494428330942590e-01) (14, 7.37994813159444706940e-01) (15, -2.73180128634545708877e-02) (16, 2.57945072805013164707e-01) (17, 4.39498405595213637032e-01) (18, -1.79512266790339186651e-01) (19, 5.13787798357715375097e-01) (20, 5.98113142746360182400e-01) (21, 3.83369258838062998418e-01) 
