FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.72865959334827995475e-02) (1, -5.52134175551954251016e-02) (2, 3.65375916706499048736e-02) (3, 1.44592414843019469173e-02) (4, 1.41876752721246703060e-02) (5, 2.68108099078025174933e+00) (6, -7.49801328289878199485e+00) (7, -3.62237751860969986462e-02) (8, -4.96399141527117393480e+01) (9, 8.42482878970018667086e-02) (0, -1.25607594180561672748e-02) (1, 2.40585322724756293933e-02) (2, -1.02277581347051602090e-02) (3, -3.55296924243602482013e-03) (4, -4.80607494245204654865e-03) (5, 3.37042175251916242829e+00) (6, -7.62511454034221003440e+00) (7, -7.06415608902328934215e-02) (8, -2.22355122691960538361e+01) (9, 3.98707746671549193018e-02) (0, 6.96209393067038107006e+00) (1, 1.66901769852571635333e+00) (2, 1.60292353099517970172e+00) (3, 1.62718367195062785235e+00) (4, 1.65224732077055125323e+00) (5, 7.47379897324152242533e+00) (6, 4.79721464198175517879e+00) (7, 9.36468849121975388528e+00) (8, 5.55394346623932335660e+01) (9, 7.20697992139440746229e-02) (0, -5.02202796268748219433e+00) (1, -1.41793040703612260867e-01) (2, -6.59627822745617459210e-02) (3, -9.49726311076458801219e-02) (4, -4.50000671256359854877e-02) (5, 1.04338120696414815569e+00) (6, 8.06066224926818786223e-01) (7, 1.17296854070039668905e+00) (8, 3.39771068822535271536e+00) (9, -2.49670567335556259358e-01) (0, -1.23137724332854900378e-01) (1, -1.48536150110784512246e-02) (2, -1.10401098383489590371e-02) (3, 1.40106122242387755306e-02) (4, 6.39271552907404033705e-02) (5, 2.63168307517852184674e+00) (6, -7.50393387186896632102e+00) (7, 3.36145698647147966875e-02) (8, -4.96850592769087455736e+01) (9, -1.61708981586583706858e-02) (0, -5.15560082796501095714e+00) (1, -8.93991803126183287587e-02) (2, 9.76104388667670998248e-03) (3, -2.40656053023186392026e-02) (4, -1.51655941207870570420e-01) (5, 1.10731422270048129874e+00) (6, 8.01108042353500304777e-01) (7, 1.15542973241420665609e+00) (8, 3.39215313624533409964e+00) (9, -3.26728726150463333333e-01) (0, 3.16697544666915886680e+00) (1, 1.59842238193683772174e+00) (2, 1.63120926535062937823e+00) (3, 1.61207789546184687701e+00) (4, 1.49916842943363293195e+00) (5, 7.43406434891529332987e+00) (6, 4.89007804896775333248e+00) (7, 1.79597770905587026391e+01) (8, 5.53458707838570092008e+01) (9, 5.10137729936224193494e-02) (0, 1.39726968106860134355e+01) (1, 2.39925761162796735704e-01) (2, 3.64474799871006782670e-01) (3, 3.60303353905239875932e-01) (4, 3.36270105480709902146e-01) (5, -6.88552671192943677170e+00) (6, 1.18165303956149525533e+00) (7, -5.65730141399076735809e+00) (8, -5.86757073701335318816e+00) (9, 8.76438067244033058856e-01) (0, 1.42375525091166235114e+01) (1, 3.24999752808052433384e-01) (2, 2.16103378105598903369e-01) (3, 2.88798074591595066440e-01) (4, 2.86784741449791324985e-01) (5, -5.47825710776825847148e+00) (6, 1.31682639147077051867e+00) (7, -5.55366169957092559173e+00) (8, -5.80372457356168158782e+00) (9, 9.31109913574198921893e-01) (0, 1.89111097546561701677e+00) (1, 2.51563150331720275510e-01) (2, 2.01443295821889800656e-01) (3, 1.28541346535428924192e-01) (4, 1.74200620398267669309e-01) (5, 6.14935381238130229775e+00) (6, -2.30231148635424043292e+00) (7, 1.30505128680375093175e+00) (8, 1.38577163613050551305e+01) (9, -2.08081728561013201695e-01) (10, -1.15492965635650146616e-01) (11, -1.11082248106435826918e-01) (12, 5.83436457427401133913e-01) (13, 5.14216740567403851614e-01) (14, -1.81840512511126983775e-01) (15, 5.27128783006387768850e-01) (16, 5.16369842097139430948e-01) (17, -4.77961404778511567137e-01) (18, -2.21582537886631819601e-01) (19, 2.47298755519172047679e-01) (20, 2.85964692423112676334e-01) 
