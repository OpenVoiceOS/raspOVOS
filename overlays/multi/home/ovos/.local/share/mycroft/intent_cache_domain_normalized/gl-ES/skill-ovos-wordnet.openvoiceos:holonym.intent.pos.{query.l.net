FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.71349443630122255655e+00) (1, 2.63422230635767551377e+00) (2, 1.88619340548592884232e+00) (3, -6.99460770355409988674e-01) (4, -9.65495714600039134368e-01) (5, -1.05003576880211868527e+00) (6, 3.05216549045421725594e+00) (7, -2.44126087867894275840e-01) (8, -1.25444441149107666078e+00) (9, -2.03060458390034836995e+00) (10, -9.09193705972348276134e-01) (11, -1.17447640607229941700e+00) (12, -1.66991564733991859626e+00) (0, -1.83139385509331642510e+00) (1, 2.20993790998325029262e-01) (2, 2.86478864614302697333e+00) (3, 1.67173572582932014607e-02) (4, -6.46215512650279572116e-02) (5, -2.73340217070846235037e-02) (6, 1.60498481237030823365e+01) (7, 3.50405717802825672491e-02) (8, 2.31459355079502368535e-02) (9, -6.24097771499430242770e-01) (10, -5.05635979539448884162e-03) (11, -2.69374856627612874194e-02) (12, -1.09559888076045164329e-01) (0, -2.40176307242583986223e+00) (1, 1.75061471751847719247e+00) (2, 2.45545560631058989998e+00) (3, -7.10501927303022751126e-01) (4, -1.05928647300119438412e+00) (5, -1.06883892571444549802e+00) (6, 1.82788490029911843138e+00) (7, -3.18739860200562608039e-01) (8, -7.49910039593857491447e-01) (9, -1.93455415008582343184e+00) (10, -6.64008577549529133144e-01) (11, -1.07151327234752713480e+00) (12, -1.00877890688427052091e+00) (13, 8.20633018457931306955e+00) (14, 2.53823642499100887715e-01) (15, 8.20681056076329973337e+00) (16, -9.35246625578926904510e-01) 
