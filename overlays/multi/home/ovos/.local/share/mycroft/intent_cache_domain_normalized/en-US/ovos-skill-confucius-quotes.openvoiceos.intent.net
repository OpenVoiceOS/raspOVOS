FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.11071965247223247708e-01) (1, 1.90672487399055790025e-01) (2, 3.04258019110634214677e-01) (3, 2.32642643532230686265e-01) (4, 2.13570997497513126451e-01) (5, 7.71159445319089531523e-01) (6, 2.07711558418183506181e-01) (7, -3.67337337038043143522e+00) (8, 7.64351187237229390270e-02) (9, 5.31947110562253980270e-02) (0, -1.78176694895973042332e-01) (1, 2.94972336367851029060e-01) (2, 2.37318141834026052894e-01) (3, 1.66667325870280935707e-01) (4, 1.41324243025069934410e-01) (5, -1.39269837877389668357e-01) (6, 2.43081103012194682522e-01) (7, 1.02628668228294337439e+01) (8, 2.94109652683367805981e-01) (9, 3.25916057596521258066e-01) (0, -1.02092513229598821911e-01) (1, 2.37977749184852316322e-01) (2, 3.11657822207694779060e-01) (3, 1.59466555790191366615e-01) (4, 2.60766005591636373939e-01) (5, -8.74830947729319241546e-02) (6, 2.47988636538615275784e-01) (7, 1.03530728796627009558e+01) (8, 1.58852002516617907268e-01) (9, 2.36674411366300435633e-01) (0, -1.69636619946859426578e-02) (1, 2.09815977589374258461e-01) (2, 2.94612383918052445075e-01) (3, 2.84432089404350052497e-01) (4, 3.06297680811172257087e-01) (5, -2.00543695828553886207e-01) (6, 1.80238949999442232830e-01) (7, 1.03629125783349955725e+01) (8, 2.86657403156390266918e-01) (9, 2.97251572976426958750e-01) (0, 1.88959267115200002518e-01) (1, 6.70191962607294688947e-02) (2, 1.90651634741583503319e-01) (3, 8.03477783091456065900e-02) (4, 9.80806593187243114240e-02) (5, 8.37290864593633887836e-02) (6, -2.22246371570422596164e-01) (7, -2.72104745700621819537e-01) (8, 1.56616627188786522451e-01) (9, 1.19413657995327979200e-01) (0, -7.98296680717539182404e-03) (1, 4.38201239149710153331e-01) (2, 4.07769841890474771251e-01) (3, 5.44200448136469061566e-01) (4, 4.62061928402325128307e-01) (5, 2.04657163931696167714e-01) (6, 6.16366218223405315513e-01) (7, -5.46133084653698830380e+00) (8, 5.40881912370194228856e-01) (9, 6.57294678647984298436e-01) (0, 9.57075844540172804287e-01) (1, 1.33618163319447674775e-01) (2, 1.43511863799908850892e-01) (3, 1.90324189515927472138e-01) (4, 2.82444397362092258774e-01) (5, 2.61657793415580930407e-01) (6, 8.60052479394402547008e-02) (7, -5.00762422296315712344e+00) (8, 8.11273230203118367321e-02) (9, 4.62610844709131080466e-02) (0, 2.41170997354500198095e-02) (1, 4.12145754139563058605e-01) (2, 4.86697388630052907299e-01) (3, 5.24687131683965857221e-01) (4, 4.26280481557985757579e-01) (5, 1.90292153968183747059e-01) (6, 5.77532704367471061424e-01) (7, -5.52790838538491158261e+00) (8, 5.98278763850201400487e-01) (9, 7.02746930678356918065e-01) (0, 4.89132598057607337338e-01) (1, 1.18340861238691152230e-02) (2, -1.36449958942678507834e-02) (3, 1.98217967526643969872e-03) (4, 1.51203994844124056662e-01) (5, 1.00627351486133886915e-02) (6, 2.63449835349912897531e-01) (7, -3.60022190860248736399e+00) (8, 2.14399569115116428453e-01) (9, 3.26961115381195432938e-01) (0, -1.80510484959831074558e-01) (1, 3.18192085699325333259e-01) (2, 3.33054116443877945564e-01) (3, 1.69329999462848379554e-01) (4, 1.81546198652272894325e-01) (5, -8.40376929851740506194e-02) (6, 1.26325118288626803142e-01) (7, 1.04009644219781840491e+01) (8, 2.88635860130419807934e-01) (9, 2.48029945562200371256e-01) (10, -4.78572306555261395289e-01) (11, 3.14292332605605850837e-01) (12, 2.58771582023387625160e-01) (13, 2.44244425074344351234e-01) (14, 7.61368299268059059437e-03) (15, -9.41537189910558319772e-02) (16, -4.82971010130395672633e-01) (17, -9.02127641866353607858e-02) (18, -4.27453284483899798030e-01) (19, 2.41294650809055044594e-01) (20, 2.68519988427476763437e-01) 
