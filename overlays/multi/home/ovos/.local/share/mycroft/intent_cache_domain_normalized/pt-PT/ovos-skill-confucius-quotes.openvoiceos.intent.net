FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.05514017851248548263e-02) (1, 2.65830765733535812068e-01) (2, 1.08329247007186907359e-01) (3, 7.55378261898117242534e-02) (4, 2.40493442187126232890e-01) (5, -2.00081479607669421306e-01) (6, -1.93257214459546189378e-01) (7, 9.42216274926227193021e+00) (8, -5.09356903623557899508e-01) (9, -5.22781247984386299166e-01) (0, -1.78306606625775132535e-01) (1, -2.35451399268712738277e-02) (2, -1.74076794566716853974e-02) (3, -4.94159151931667164903e-03) (4, -1.05369695919951419927e-01) (5, 1.53309451976173821697e-01) (6, -1.03353123036260485801e-01) (7, 2.65764949728317390054e+00) (8, 5.24417368285125390370e-02) (9, -7.68751088591880099576e-02) (0, -1.41311523532131971814e-01) (1, -1.08470649916132907964e-01) (2, -3.13076763333883303919e-02) (3, 1.43697322426233255882e-02) (4, -1.27280098843773809003e-01) (5, -2.47409697497510093489e-03) (6, -3.36631562980364493209e-02) (7, 2.73030042905874381631e+00) (8, 7.96789137236541267217e-02) (9, 6.60127202061352724716e-02) (0, -3.03589438115815013486e-01) (1, -9.49138301810259921859e-04) (2, -1.02820695835551242925e-01) (3, -1.11302861470183353521e-01) (4, -2.08386677702899082015e-04) (5, 2.27427655843434398109e-02) (6, 1.60294506228456394223e-03) (7, 2.56795894612140784830e+00) (8, 3.33847982398933346149e-02) (9, -1.14759403845912849595e-01) (0, 1.66539566642947134412e+00) (1, 3.63673657591314591908e-01) (2, 3.94305069411964692616e-01) (3, 4.24052089865179338002e-01) (4, 3.36581103916139878773e-01) (5, 1.09116202393880673549e-01) (6, 4.50572071969892851140e-01) (7, -5.46413455669527436953e+00) (8, 3.96445097689849257350e-01) (9, 1.57481215310208155778e+00) (0, 9.26671537162717995351e-01) (1, 2.36623436532400949206e-01) (2, 2.09429584763430459704e-01) (3, 3.71095903537653815096e-01) (4, 2.28842217795037133898e-01) (5, 2.48934850477250529943e-02) (6, 2.02764188617129942349e-01) (7, -2.88149405763192456575e+00) (8, 8.92246567171517401817e-02) (9, 4.09132872992710117099e-01) (0, -1.20492578656569392093e-02) (1, 1.76123949954326702860e-01) (2, 1.71361911365802838114e-01) (3, 2.36335139045532299784e-01) (4, 2.42670129308517529276e-01) (5, -2.54099902568904467692e-01) (6, -1.22864464962826797079e-01) (7, 9.55293238201898198270e+00) (8, -5.15799867700553749117e-01) (9, -5.46948375891662452730e-01) (0, 2.25639487928367382663e-01) (1, 1.27360652914778632594e-01) (2, 1.96275073817507639262e-01) (3, 2.21911210349337473247e-01) (4, 2.18634146979586496684e-01) (5, 6.85657653350026818906e-01) (6, 2.21171777075744396823e-01) (7, -3.32718432657194718161e+00) (8, 7.62232682828517971174e-01) (9, 5.14755450444621676098e-01) (0, 1.03284819662755378289e+00) (1, 2.43890044957061374875e-01) (2, 3.73682250946422156446e-01) (3, 3.70490064590831336133e-01) (4, 2.29154793291946018430e-01) (5, -3.45721765972105479769e-02) (6, 2.44657439857383335324e-01) (7, -2.85607332483573239656e+00) (8, 3.81285749834481130227e-02) (9, 1.72446619504645598520e-01) (0, 1.68216427094645393225e+00) (1, 4.36505102033586778187e-01) (2, 3.45084175879926957631e-01) (3, 3.76944169814558305287e-01) (4, 3.98043170983763017201e-01) (5, 1.55289000073781824351e-01) (6, 6.76890135875480303262e-01) (7, -5.49022373323088075381e+00) (8, 4.83766502057534575343e-01) (9, 1.26702144967401286735e+00) (10, 3.93221206220751406946e-01) (11, 5.38312941607010264633e-01) (12, 5.86847647841942210434e-01) (13, 5.73769837435257334946e-01) (14, -6.26706111483726902023e-02) (15, -3.82983949505796535465e-03) (16, 4.23853919428388181689e-01) (17, -1.27724982423647354102e-01) (18, -1.31498303683947517090e-02) (19, -4.58722788148079180237e-02) (20, 3.81208903345232608117e-01) 
