FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.52155375437537920824e-01) (1, -7.86652935205114089978e-02) (2, -1.18409596150935977898e-01) (3, -6.48336557207715713513e-02) (4, -7.84185004888189041150e-02) (5, 3.45323502199568477256e-01) (6, -1.06612512754180088770e+00) (7, 1.01389120139183375180e+00) (8, -3.53075881762053345181e-01) (9, 3.54456613921754093433e-01) (0, -4.74866558691535919912e-03) (1, -8.08953461988958788531e-02) (2, -9.72832707508596850055e-02) (3, 6.67232593454981405545e-03) (4, -1.22574315015891499581e-01) (5, 2.67499830470931843074e-01) (6, 1.47263779211827983140e+00) (7, 7.09791049887519287509e-02) (8, -2.70089794051010800846e-01) (9, -7.14614761675653048512e-02) (0, 6.05687060049121261951e-02) (1, -4.68226293061551196439e-02) (2, -3.75697234605130298002e-02) (3, -5.88607409928616487349e-02) (4, -7.99737069352235950548e-03) (5, -2.94477229620305702706e-01) (6, 1.97921007045474794950e+00) (7, 3.14702627027546699701e-01) (8, -2.13901407367737189658e-01) (9, -2.04619321804477671822e-01) (0, 5.91585333494578868851e-01) (1, 3.44681924719647259092e-01) (2, 4.02402857829169180448e-01) (3, 4.40044085074499990995e-01) (4, 4.36532432724074270780e-01) (5, 6.10899326618690263757e+00) (6, -1.13940884344139470308e+00) (7, -3.27671164513307910937e-01) (8, -4.55697600607402775186e-01) (9, -9.53589621426951250527e-02) (0, 2.05585975448827618095e-01) (1, 1.99114800917871953567e-01) (2, 3.67428132819899000427e-01) (3, 3.56933602618940748474e-01) (4, 3.87018093395002760193e-01) (5, 1.39070804606548703575e+00) (6, -9.37760649662989109743e-01) (7, 1.06561589123187028250e-01) (8, -8.23708795054692577420e-02) (9, -8.37876013734694530255e-02) (0, 7.86741020884516828460e+00) (1, 2.56264228978701213979e-01) (2, 2.84025055029936412954e-01) (3, 3.86596967139788416645e-01) (4, 3.75859577813692835591e-01) (5, -4.68390904642579997130e+00) (6, -3.25192540553749187549e-01) (7, -2.89789028015502481139e+00) (8, 6.76547942225081522238e-01) (9, 1.67353056352299556231e+00) (0, 2.48560432906994865920e-01) (1, 5.60155684476572490738e-01) (2, 6.40365163212496368850e-01) (3, 7.33370052998739918593e-01) (4, 6.98570313280302612746e-01) (5, 2.50664148365062722235e+00) (6, -1.44802829605377159083e+00) (7, 1.19747549652297191614e+00) (8, 3.08205051492688120174e-01) (9, 4.67929701578858159294e-01) (0, -2.02327928258558054075e-01) (1, 1.67602996059855707811e-01) (2, 2.05676528343161774126e-01) (3, 1.45443181225261009004e-01) (4, 1.35287607737979209688e-01) (5, 1.51324493439236618109e+00) (6, -1.09944287951209163090e+00) (7, 3.30430431603683072428e-01) (8, 4.04006907805142034817e-01) (9, 3.51898404289333055495e-01) (0, 6.72617182121966472597e-02) (1, -2.42012966547601182654e-02) (2, -1.11573405948697745860e-01) (3, -9.49407596264473796488e-02) (4, -8.95680341992966533304e-02) (5, -1.33204949386480919760e-01) (6, 2.04459439234796613860e+00) (7, 3.21131762826954658685e-01) (8, -1.97226742896830203877e-01) (9, -1.88788853158144559474e-02) (0, 1.38403483538920152318e-01) (1, -5.47698209021863086088e-02) (2, 1.82195534969988789942e-02) (3, -1.44079863462286822395e-01) (4, -7.71418804262455348741e-02) (5, -2.37681483532277859627e-01) (6, 1.90290820890036327384e+00) (7, -7.23529843202747394160e-03) (8, -4.62435979908003974570e-02) (9, -1.23498395787635301124e-01) (10, -2.94230861748085548157e-01) (11, 4.49355518281974675165e-01) (12, 3.56777390555091944435e-01) (13, 8.91772866094985156016e-02) (14, 1.11046803429021290199e-01) (15, -6.68713259850508445759e-01) (16, 3.51830595483365454745e-02) (17, 7.23709613242142779654e-01) (18, 3.97568603945853360493e-01) (19, 4.29305555267216809590e-01) (20, 4.95138687080578621114e-01) 
