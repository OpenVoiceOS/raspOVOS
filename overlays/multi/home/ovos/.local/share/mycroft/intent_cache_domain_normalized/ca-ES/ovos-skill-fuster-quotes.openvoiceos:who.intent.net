FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=14 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (14, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.08003964087183923493e-01) (1, -1.88867958908014749175e-01) (2, -2.05543848400049661285e-01) (3, -2.50546927277975561843e-01) (4, -3.22146828000479168441e-01) (5, 3.97972171819495623701e-01) (6, 1.87211157233456965132e-01) (7, 2.77744741589764976286e-01) (8, 2.41928111522713562564e+00) (9, 3.23065783031312836471e-01) (10, 2.36778122199094859246e-02) (11, -1.27534743498491920377e-02) (12, 2.56426317662131753039e-01) (13, -2.90665853645654281845e-01) (0, 9.30038451521288528356e-02) (1, -3.84467250419746843157e-03) (2, 4.11110802857767368423e-02) (3, 8.16286414234529966727e-02) (4, -1.89451590807546282891e-02) (5, 1.98371489802855793805e-01) (6, 3.46445100559057028722e-01) (7, 3.34733432335914404820e-01) (8, 3.50438655167242529842e+00) (9, 3.00460299654067786168e-01) (10, 3.29456770969690115880e-01) (11, 4.40378669620255236428e-01) (12, 4.60914177997173102330e-01) (13, 2.19443255444205396684e-03) (0, 8.34395720927607054129e-02) (1, 4.23407986132990146744e-02) (2, 1.19719272789229086440e-01) (3, -1.99672893316854144219e-02) (4, -3.26202965093742814837e-03) (5, 2.27762782285470311017e-01) (6, 3.87784419758380682897e-01) (7, 3.32889778716625006627e-01) (8, 3.53809090703150275203e+00) (9, 3.96251386208595068883e-01) (10, 4.31890322072566779088e-01) (11, 4.44032359839180712502e-01) (12, 3.63604052169383795690e-01) (13, -4.69441896895729862682e-03) (0, -2.40377204053806636797e-01) (1, -2.49999778990679294433e-01) (2, -1.43811675434046298827e-01) (3, -2.27323467557363961822e-01) (4, -2.26918319885664437896e-01) (5, 3.57240488446044335280e-01) (6, 2.03240634352902765913e-01) (7, 3.03071984500626945280e-01) (8, 2.43065403907814880924e+00) (9, 3.21491828233134713244e-01) (10, 1.84500986040881914674e-01) (11, -2.37322103332209266568e-02) (12, 3.33844771653544869494e-01) (13, -3.23902405675502380600e-01) (0, 3.92321228134714261593e-01) (1, 1.12773710083958006445e-01) (2, 2.17885554921623564306e-01) (3, 1.36524745416637699469e-01) (4, 1.82040647757049839361e-01) (5, 3.27939030886914145713e-02) (6, -4.30767349714962666241e-01) (7, -3.68546195144383137432e-01) (8, 7.61706539570841556497e+00) (9, -5.74902540871759237806e-02) (10, -2.50163736088003629821e-01) (11, -1.22557760828480508120e-01) (12, -1.49346241993631861922e-01) (13, -2.27515397394889462568e-01) (0, -2.55646495433064613323e-01) (1, -1.61243545536928628570e-01) (2, -2.39861125771933109130e-01) (3, -2.46864351158075839843e-01) (4, -2.67978201334410137679e-01) (5, -5.79191719126252724248e-03) (6, 1.91086628885011072798e-01) (7, 7.43819826509255599412e-01) (8, 2.47853612660685440616e+00) (9, 2.75496533185374703478e-01) (10, 2.71674665756551636520e-01) (11, -1.22687470267939247037e-02) (12, 3.58330717355143990588e-01) (13, -2.49290265019984857986e-01) (0, 1.87407379552899405750e-01) (1, 2.81025893540964959161e-02) (2, 1.12461080357609807812e-01) (3, 1.68786635205327079090e-01) (4, 9.60965282769785517081e-02) (5, 2.42552356435567717519e-01) (6, 1.64668906116178181964e-01) (7, 1.37494682901790260532e-01) (8, -3.76740231113219659065e+00) (9, 2.60669288292694201203e-01) (10, 2.95716223374176134797e-01) (11, 3.22414895150001101776e-02) (12, 2.59050157919693102571e-01) (13, 3.47082236011669098552e-01) (0, 4.06459555136828576405e-01) (1, 2.05478758385662624297e-01) (2, 2.90817671289925250289e-01) (3, 2.47869469991211482940e-01) (4, 1.87500328591351100860e-01) (5, -5.52765016033588407751e-02) (6, -5.15600367977545118170e-02) (7, -1.33043020923368726649e-01) (8, 3.96400130580237863853e+00) (9, -9.23375853087813336373e-02) (10, 2.11990027445587814192e-01) (11, 1.43859752216468073094e-01) (12, -5.54986999120623339388e-02) (13, 1.62417984004148779897e-01) (0, -4.98935580810721368561e-01) (1, -2.25911037411403947672e-01) (2, -2.81737723734093059580e-01) (3, -2.04629198994350725016e-01) (4, -2.11050869312000566325e-01) (5, 2.91686435854720427230e-01) (6, 3.14114907235841178679e-01) (7, 6.08444997336167636703e-01) (8, 2.38244905828753372745e+00) (9, 4.21317560643088784289e-01) (10, 2.32087011583177460494e-01) (11, -3.87462627242731796895e-02) (12, 3.67310566872489419055e-01) (13, -2.78791840996594986191e-01) (0, 3.56040432422052716133e-02) (1, 4.61006372539888645279e-02) (2, 1.72350204853903114788e-02) (3, 2.85044185190092384807e-02) (4, 9.69994052617441787634e-02) (5, 3.23794954726952854962e-01) (6, 4.36827404601634772252e-01) (7, 4.44953261120380194615e-01) (8, 5.29386078920754155064e+00) (9, 4.26517648799480231236e-01) (10, 3.53160521192611487340e-01) (11, 5.02889852941731274605e-01) (12, 4.28550346000255377721e-01) (13, 6.28609770317710078724e-03) (14, 2.10571342802495620194e-01) (15, 3.24903564104443320915e-01) (16, 3.39936953232460759011e-01) (17, 2.16232867634744307939e-01) (18, 5.66843249441448371329e-01) (19, 2.18599045372457168046e-01) (20, -3.18089225617172233207e-01) (21, 6.16739959608772272959e-02) (22, 2.20535682237596175614e-01) (23, 3.55485927508049748269e-01) (24, 2.55722259315520061840e-01) 
