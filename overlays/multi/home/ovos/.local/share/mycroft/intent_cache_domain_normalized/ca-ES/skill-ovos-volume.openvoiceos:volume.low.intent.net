FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.27033378777005800941e-01) (1, -3.00448532989455903419e-02) (2, -3.74485513476866069965e-03) (3, -1.89812332003398143154e-01) (4, -5.71847405126525709651e-02) (5, -8.54084189977844937536e-02) (6, -8.23697765162430262098e-02) (7, 1.65165681468492731021e+00) (8, 9.93411593339860871099e-02) (9, -6.73157901821294646361e-02) (10, -3.47442071407212615952e-01) (0, -5.52832099538040910858e-01) (1, 1.97567764596683695388e-02) (2, -2.79056605024592882525e-02) (3, -2.84141626281993395220e-02) (4, -2.98378344698207349783e-02) (5, -1.62187683498696888496e-01) (6, -1.82109515206307470692e-01) (7, 1.43647075800806267587e+00) (8, -3.44510902315820488617e-02) (9, 3.29842189765640475541e-02) (10, -1.73267770080937660859e-01) (0, -5.42798376654897607452e-01) (1, 9.81189577845320744232e-03) (2, -3.18964693042875502282e-02) (3, -2.89477977249265952531e-02) (4, -3.28014317247511122400e-02) (5, -1.26191838747100382179e-01) (6, -2.12758394948613982489e-01) (7, 1.60436226783901436654e+00) (8, 1.14280316754080457642e-01) (9, -1.14140004434519243270e-01) (10, -3.21775746246417360119e-01) (0, -1.22706355833568303559e+00) (1, -6.88735505213613152797e-01) (2, -6.25217383375043511684e-01) (3, -7.07078879346723199184e-01) (4, -5.70109812190408238308e-01) (5, -7.63361350329673005177e+00) (6, 1.41040496872299137010e+00) (7, 5.94699448925726059656e+00) (8, -2.22282005665593995758e+00) (9, 1.10947522850389154736e-01) (10, 3.38526598026417033238e-02) (0, -6.73515962657430300453e-01) (1, -1.62803907995248756113e-02) (2, -4.23858096008325330173e-02) (3, -1.46674640954020163441e-01) (4, 1.10812703962301223326e-02) (5, -4.46920610128207843048e-02) (6, -2.25667683473105312730e-01) (7, 1.66036589381861499071e+00) (8, 6.53182899195925842362e-02) (9, -3.49793662809661579094e-02) (10, -3.20836973091204957775e-01) (0, -1.43315670161952701811e+00) (1, -1.38410513970950305174e-01) (2, -8.95954759157687880000e-02) (3, -1.57215238846332081013e-02) (4, -5.66110850609332499905e-02) (5, -1.92807794218100014838e-03) (6, -5.19986072203074550790e-02) (7, 1.68348656578352029456e+00) (8, -9.00574399249765705777e-02) (9, 1.70126626706787291432e-02) (10, -2.22198072820427083851e-01) (0, -7.38315062818029055336e-01) (1, -2.64580478076959467459e-02) (2, -6.40847687726045500689e-02) (3, -2.48575587873483584700e-02) (4, -4.87859030370736829196e-02) (5, -9.66018355546756357644e-02) (6, -9.63889612475755941379e-02) (7, 1.54331587587413476825e+00) (8, 1.99615841347948672069e-02) (9, 5.57468304849335002937e-02) (10, -3.57520599564154939465e-01) (0, -2.71438225703758595486e+00) (1, -1.28897742814670168698e+00) (2, -1.20596267915616595090e+00) (3, -1.31363406664977633298e+00) (4, -1.24064860380540453733e+00) (5, -4.01201212609299595613e+00) (6, 2.70010024283644567422e-01) (7, 6.25355590558843310589e+00) (8, -5.34246423420296867590e+00) (9, 2.43110063501677142739e+00) (10, 1.44193698327008457127e-01) (0, -3.92962251848496624262e+00) (1, -6.95916501452798486049e-01) (2, -5.52265373637551681973e-01) (3, -6.98714097609395623500e-01) (4, -5.27278555204743648588e-01) (5, -7.29891550202490790866e+00) (6, 1.44467370316564291954e+00) (7, 4.98753717689853193207e+00) (8, -1.89402864549366700686e+00) (9, 5.75507535090197142047e-01) (10, 6.42797360837364384345e-01) (0, -1.42321083798731287118e+01) (1, -8.48989860202639251563e-02) (2, -1.97608724334415786217e-01) (3, -1.05352491238292947373e-01) (4, -8.67301301147310882422e-02) (5, 1.37984039371575939459e-01) (6, -1.84105506051279843582e-01) (7, 1.95697025264245905163e+00) (8, 1.12408920455072235817e-02) (9, -6.89761296579976812549e-02) (10, -2.86896725771564609087e-01) (11, 4.06963470224770806905e-01) (12, 4.27844151672540862208e-01) (13, 3.91839580525264241651e-01) (14, -3.15772737451416041221e-01) (15, 3.96415346216134112378e-01) (16, 4.09610914830598138447e-01) (17, 4.49264229642959145306e-01) (18, -5.83594282294613631024e-01) (19, -3.27206011151968900741e-01) (20, 4.25156431019777458769e-01) (21, 4.82442792082601212833e-01) 
