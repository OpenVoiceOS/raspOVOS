FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.82294454221826196516e+00) (1, 5.41066890017187773765e-01) (2, 5.40328641788160979331e-01) (3, 5.11454587237036628622e-01) (4, 4.94931591109431190390e-01) (5, -1.99490095912428455627e+00) (6, 1.14637563727169400352e+01) (7, 6.72933815381340050266e+00) (8, 3.09864074438687220336e+00) (9, 5.40446157321507225646e+00) (10, -1.75189091749317782387e+00) (0, 4.16272286086674214722e-01) (1, 2.43720841031665663712e-01) (2, 3.09553888064021953674e-01) (3, 3.58529772978420147034e-01) (4, 3.06268375735874065491e-01) (5, 2.66744556380284381092e-01) (6, -1.78157187272119155175e+00) (7, -1.55411178462488952512e+00) (8, -6.51106660569459733123e-02) (9, -6.34884541929961687678e-01) (10, 1.70640958449336660463e-01) (0, -3.47669045792880992973e-01) (1, -1.61127056586190392506e-01) (2, -1.34109906511946846974e-01) (3, -8.17484740490161537751e-02) (4, -1.17703962730809338910e-01) (5, 4.18138648877724339314e-01) (6, -2.45698831066515310795e+00) (7, -6.34884557610341637712e+00) (8, -3.10478243453566848942e+00) (9, -4.37593544683361646008e+00) (10, -2.85892323137453052695e-01) (0, -3.06918286178823995769e+00) (1, -3.50537453932292797365e-02) (2, -7.02048395914562362030e-02) (3, -1.38024725501013495466e-01) (4, -1.21029496674013956059e-01) (5, 4.84655383623313340546e-01) (6, 7.17608861409800402598e-01) (7, 1.70415932555645771584e-01) (8, 4.99750088454459950871e-01) (9, 6.18429528654472870919e-01) (10, -1.51365407662810997486e-02) (0, 9.47759672313881140759e-01) (1, 9.09770086265425381722e-02) (2, 9.57347184277395901741e-02) (3, 1.62189352498135958003e-01) (4, 1.15509878084741085535e-01) (5, -6.44139072741796603339e-01) (6, -2.96630627518008527232e+00) (7, 5.24680730229096448092e-01) (8, -2.06761456402922982889e+00) (9, 1.25586992256364560205e+00) (10, -6.22158755292174014961e-01) (0, 3.67358166485424519898e-01) (1, 2.97658797722453960510e-01) (2, 3.16557180505390056702e-01) (3, 1.96247350793476021957e-01) (4, 3.07204213362331279846e-01) (5, 1.34630682421696568074e-01) (6, -1.61656274035950131562e+00) (7, -1.48084784142954650754e+00) (8, -1.36828330656364599571e-01) (9, -6.31789534127971563748e-01) (10, 1.67283334514066156506e-01) (0, -2.02202010259336351083e+00) (1, -2.77276938173008746791e-01) (2, -3.12139300021363086390e-01) (3, -2.52391239020062274623e-01) (4, -3.15191165867281741786e-01) (5, 6.78815692665754255586e-01) (6, 1.32253578533375359960e+00) (7, 3.05927716678710936993e-01) (8, 5.82920236147119297243e-01) (9, -9.50113244162733155962e-02) (10, 1.33337799314451055377e-01) (0, -2.08765312388843415903e+00) (1, -2.78543901952935046840e-01) (2, -2.81879415127468890834e-01) (3, -2.59342727574539966273e-01) (4, -2.24040207776261185435e-01) (5, 6.43000220533922806077e-01) (6, 1.28169208993160821386e+00) (7, 3.34941693133445739239e-01) (8, 8.52499038269317610528e-01) (9, -5.25938279734785157915e-02) (10, 2.07537075914858426540e-02) (0, 8.91975897601059442010e-02) (1, -1.77355069326802422536e-01) (2, -1.78055833684846093190e-01) (3, -2.84728367203914423111e-02) (4, -1.39850943940325878057e-01) (5, 4.55870594392403460926e-01) (6, -2.46187259092953070194e+00) (7, -6.36963158955761521440e+00) (8, -3.08897606902464882950e+00) (9, -4.70619135137519695178e+00) (10, -1.80933192850282642539e-01) (0, -3.13279204581685843944e-01) (1, -1.11807771508169992436e-01) (2, -3.12794749779231884279e-02) (3, -1.02405347411108807454e-01) (4, -1.53476536755038001081e-01) (5, 4.69678546882342728974e-01) (6, 8.98758365357168798049e-01) (7, 1.83649391419025448391e-01) (8, 8.45502288770104248883e-01) (9, 1.40818800518174591652e+00) (10, -6.94509727896256839896e-02) (11, 8.16718394740536646204e-01) (12, -2.74998997492320908231e-02) (13, -3.66946001953311673471e-01) (14, 8.74243531456870504037e-01) (15, 2.72738715088726879632e-01) (16, -1.04498142528351420366e-01) (17, 5.15049213615409895439e-01) (18, 5.09761007574550562005e-01) (19, -3.38259601450391522715e-01) (20, 4.27336972287389316172e-01) (21, 6.74319909036104725431e-01) 
