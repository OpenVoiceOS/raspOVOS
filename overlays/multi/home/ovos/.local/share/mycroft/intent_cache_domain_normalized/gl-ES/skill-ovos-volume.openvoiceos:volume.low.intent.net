FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.97986700833694340140e-01) (1, 5.51585992056164431396e-01) (2, 6.38169226425919111634e-01) (3, 6.04210254925522383118e-01) (4, 4.78782718259129269622e-01) (5, -8.52929644536194186966e-02) (6, -5.20197371290633703289e-01) (7, 4.78797472363336851231e+00) (8, 4.99973602962719587683e-01) (9, -2.84036117229991535993e+00) (10, 1.76860705906141529864e-01) (0, 2.48525007086877725015e+00) (1, 1.74131304026986977185e+00) (2, 1.74999754132177254284e+00) (3, 1.66198983044769188488e+00) (4, 1.56353694946910759533e+00) (5, 2.16917394122583431226e+01) (6, -6.63845287372326897657e-02) (7, 6.36191133760035931743e+00) (8, 1.24329165382156037190e+00) (9, -5.28987578042459194450e+00) (10, -3.53072474822451298770e-01) (0, 9.97178730686572034614e-01) (1, 3.41250216531617300841e-01) (2, 3.36814230251176072173e-01) (3, 3.23520852196080455077e-01) (4, 2.86957262027127457671e-01) (5, 2.55097884034955191268e+00) (6, 8.93048840037853230989e-01) (7, -1.15428522382506626442e+00) (8, 2.98579131383287910140e+00) (9, 4.66742756737523212252e+00) (10, 3.19426972692715416269e-01) (0, 1.48698684343104314820e+00) (1, 2.91485041845402248484e-01) (2, 3.57464030850491221170e-01) (3, 3.42658065724930460672e-01) (4, 2.81727076042255886179e-01) (5, 1.09298637079346061540e+00) (6, 4.01642013859965951728e-01) (7, -2.76536111671517426114e-01) (8, 1.05443792344003872685e+00) (9, 8.47048589828214293362e-01) (10, 2.01251512161547269075e-01) (0, 6.79508487725202448004e-01) (1, 2.16898726285697895921e-01) (2, 2.48051227988006495195e-01) (3, 3.05996032418014374255e-01) (4, 3.55926850796939697741e-01) (5, 2.06113494243862466204e-01) (6, 4.81019524790370217593e-02) (7, 1.62463938336656260608e-01) (8, 3.93254139263581270480e-01) (9, -5.04093957936435632661e+00) (10, 1.70314894345995615499e-01) (0, -1.06525771641169031412e+00) (1, -2.47277218250246851039e-02) (2, -3.91628790048571262528e-02) (3, -7.69033479837389483125e-02) (4, -1.13672142043492366281e-01) (5, 3.86026809947341287277e-01) (6, 3.12146920335883426567e-01) (7, 1.16251367821027712379e-01) (8, 8.35639475719396340736e-02) (9, 5.94381520277730945878e-01) (10, -2.48288497715174666380e-01) (0, 3.43572114871792677615e-02) (1, 2.88610288349068266900e-01) (2, 3.28728327003395548456e-01) (3, 2.95498759892857176812e-01) (4, 3.51772093621170511835e-01) (5, -1.32966535603295687995e-01) (6, -2.27500935711771967718e+00) (7, -2.16696572220603025927e-02) (8, -1.24214437165484081760e+00) (9, 8.63299543896510890306e+00) (10, 2.66147135848561477989e-01) (0, 6.63935679294098690661e+00) (1, 3.37780295234923588765e-01) (2, 3.36403591853385197652e-01) (3, 4.96245330494647585162e-01) (4, 5.00140404623752199420e-01) (5, -5.69999975122044366671e-01) (6, 2.91524505663542828071e-02) (7, -1.46921384683629724366e-01) (8, 1.38430823663303753657e-01) (9, -4.02687148443557507704e+00) (10, 4.54903440862807539879e-01) (0, 3.21401672697188045547e+00) (1, 2.20454557956258817564e-01) (2, 3.87604816974203292279e-01) (3, 3.47843199194471541791e-01) (4, 2.86717935622732233991e-01) (5, -9.38310603199826620546e-01) (6, -2.25696905758528520991e-01) (7, -5.25691452612979337466e-01) (8, -1.09799748919493941890e-01) (9, -1.96941625644495599268e+00) (10, 4.20026013450989943454e-01) (0, 1.00897653818215560229e+00) (1, 7.43120117684900938215e-01) (2, 6.90621553560793577375e-01) (3, 5.80715282460749548932e-01) (4, 5.69364099403918300091e-01) (5, -1.13185672237512940930e-01) (6, -8.05083677016809717841e-01) (7, 5.56275595873467842978e+00) (8, 1.56687749157811850864e+01) (9, -3.75772073223704783373e+00) (10, 7.55725794530901634483e-02) (11, 3.77380136422882372926e-01) (12, 4.85312458710550065355e-01) (13, -1.33658633568842583061e-01) (14, -1.29547931796911236502e-01) (15, -1.02079390843474526740e+00) (16, 7.47410572460585842514e-01) (17, 3.24704409297638996179e-01) (18, -2.09618331072718183661e-01) (19, -2.28816045382458449486e-01) (20, 4.70591098069966351503e-01) (21, 2.72480986003236003157e-01) 
