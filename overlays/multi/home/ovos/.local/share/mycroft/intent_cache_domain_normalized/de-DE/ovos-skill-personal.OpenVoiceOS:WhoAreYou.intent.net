FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.91144059001509525331e-01) (1, -5.08891694139727499002e-03) (2, -7.84224919866807756996e-03) (3, 9.12723787236919929799e-03) (4, 3.29454699914526055737e-02) (5, 3.66400589542425270118e-01) (6, 2.30417325003938522343e-01) (7, 5.58474956990749560326e-01) (8, -2.28651243848468008202e-02) (0, 1.11486527908224819505e+00) (1, 9.67100359883128340988e-02) (2, 1.76539587267857706054e-01) (3, 1.53624849804860269531e-01) (4, 2.88003670462590399826e-01) (5, 2.26425460113738985513e-01) (6, 2.46744255931035827434e-01) (7, 3.20983120884390793481e-02) (8, 4.30595070291375114913e-01) (0, 4.54319632142481921733e+00) (1, 3.61072031883549193765e-01) (2, 3.72411063043426970864e-01) (3, 3.89092525569748381997e-01) (4, 3.78067931262802581216e-01) (5, -1.80647102748044829923e+00) (6, 2.47791535695658104999e+00) (7, 5.46723234137828639767e-01) (8, 5.34773320623984194100e-01) (0, 1.76613901101043282438e+01) (1, 5.05318639681475278991e-01) (2, 4.15201639638083042083e-01) (3, 5.53623555109636900085e-01) (4, 5.29269097254412290710e-01) (5, -4.74990445560411878034e+00) (6, 4.91553457991781250769e+00) (7, 8.28790410035930347199e-01) (8, 9.33550185941956905955e-02) (0, 3.30707399144975600080e+00) (1, 3.64056477227500008276e-01) (2, 2.45060967185786321432e-01) (3, 2.67033414819529524298e-01) (4, 3.18717421868136452368e-01) (5, -7.47585796525895962539e-01) (6, 3.23033495990667951503e+00) (7, 2.45750239524753694154e-01) (8, 5.92645363166411587308e-01) (0, 1.96855266061381795062e+00) (1, 6.07863528062174807154e-01) (2, 6.65170704354117625634e-01) (3, 6.15941954184840434472e-01) (4, 5.91864523817370424830e-01) (5, -4.52429809194688736795e+00) (6, -2.99757452852182026959e+00) (7, 4.80064757942494646503e-01) (8, 8.81310347604475907701e-01) (0, 6.73379452717983539856e+00) (1, 2.65263593559745658457e-01) (2, 3.10426584249023251871e-01) (3, 3.05785990124229245524e-01) (4, 3.84179069464687161783e-01) (5, -2.87169265511662619161e+00) (6, -1.87056427624690813083e+00) (7, 2.59358641078813789704e-01) (8, 7.44525802426649341292e-01) (0, -3.94449229155212499620e+00) (1, -7.42194146476317651029e-02) (2, -4.18727636895705537801e-02) (3, -1.04518109615855406269e-01) (4, -1.57687375005297669706e-01) (5, 1.04381077083938333949e+00) (6, 5.95173527170839933298e-01) (7, -5.92187879716868370572e-02) (8, -3.87389175456863632530e-01) (0, 1.98288264372385447665e+00) (1, 2.72858042824332625020e-01) (2, 4.19564635115926232167e-01) (3, 2.41960332351987245092e-01) (4, 3.52065548855130638906e-01) (5, -6.09453553028689198889e-01) (6, 3.82544676466003874538e-01) (7, 3.84314345406004509442e-01) (8, 6.37593270726760974476e-01) (0, -6.69699027487224718413e+00) (1, -5.02815091033913738605e-02) (2, -1.64538751633975688371e-01) (3, -1.16665548922631909234e-01) (4, -2.98302316089608422767e-02) (5, 1.02279974056174283170e+00) (6, 7.08062108474615925502e-01) (7, -1.04797575184985683472e-01) (8, -3.82850669187408676475e-01) (9, 4.54151378241413161696e-01) (10, 7.31642983511519989781e-02) (11, 6.04930065229964605833e-02) (12, 7.69491014309209298005e-01) (13, 5.41734240606856834455e-02) (14, -7.72380117249617081931e-01) (15, -1.62347265442404853353e-01) (16, 4.32561177514563521829e-01) (17, 4.93682701346125907271e-02) (18, 4.14658039562474212136e-01) (19, 4.30367236252342910685e-01) 
