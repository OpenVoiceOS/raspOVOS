FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.17949198032189384033e-01) (1, -4.23651874029977188602e-03) (2, -1.30566129084859587628e-02) (3, 1.22266268733705781024e-02) (4, 1.02217799428667328876e-02) (5, 3.37030471407105647330e+00) (6, 6.08042338588753034090e-02) (7, -5.61716347897393570437e-03) (8, -8.83950602928801898450e-02) (0, -3.97061405921746324310e-01) (1, 3.08935350183214448017e-02) (2, 4.42758804563249813713e-02) (3, -5.48288220163618000846e-02) (4, -1.03214747607353773962e-01) (5, 3.34036078594853602652e+00) (6, -8.55482608468563499038e-03) (7, 7.36059850457872477669e-02) (8, -4.90591984907790476522e-02) (0, 2.98092249959915178703e-01) (1, 1.50001072968710569278e-01) (2, 1.11796462620962766543e-01) (3, 2.11299763705004334247e-01) (4, 2.20557259108294129168e-01) (5, -5.62929001138158646711e+00) (6, 2.91590911809378960928e-01) (7, 1.36770872111786512271e-01) (8, 3.90460061444771411310e-01) (0, 4.00953593919057493800e-01) (1, 3.75049459446876176649e-01) (2, 3.00305391360728868300e-01) (3, 4.07054039348571428114e-01) (4, 2.53924245645015311812e-01) (5, 8.22413805794056429477e+00) (6, -1.43327380585721142481e-01) (7, -2.01170757779810305266e-01) (8, 3.48517392742510728754e-02) (0, 2.56305691033809679436e-01) (1, 1.54541277970541623965e-01) (2, 1.36751128073204664126e-01) (3, 8.93901751296412028225e-02) (4, 2.54303859259356113132e-01) (5, -5.80631445780940858015e+00) (6, 4.01737859014445641836e-01) (7, 1.22314424897898343936e-01) (8, 3.95592826022637011896e-01) (0, 5.64681386928016060267e-01) (1, 2.48353370338561668662e-01) (2, 1.69856415003421412635e-01) (3, 2.34193601518752680946e-01) (4, 1.63441547065856562782e-01) (5, -3.52671225517264730343e+00) (6, 2.99950349098199842146e-01) (7, 3.28701580828184125593e-01) (8, 3.52354842860483241651e-01) (0, 5.47433291614936701208e-01) (1, -4.41975325762794090528e-03) (2, 6.76400196510596601884e-02) (3, 1.08928887243871244661e-01) (4, 1.36392189260129498285e-01) (5, -6.55605369256207048956e-01) (6, 7.36859884578655310872e-02) (7, 1.26979662175778912347e-01) (8, 1.20340175611755959006e-01) (0, 4.54663668812202548253e-01) (1, 2.73498949366851248910e-02) (2, 3.62042468744559683969e-02) (3, 1.30712254043225811762e-01) (4, 1.00651523168687376253e-01) (5, -5.75108774946400225225e-01) (6, 2.64355636807150629064e-01) (7, 1.06015650625829252474e-01) (8, 2.39360793331633736614e-01) (0, 1.83038491934745695122e-01) (1, 1.72660166110266327655e-01) (2, 2.09450827624071717059e-01) (3, 1.10143111731279996768e-01) (4, 8.81270111458193339260e-02) (5, -5.78632270977445450910e+00) (6, 2.77903543327027713339e-01) (7, 1.74992227639425873553e-01) (8, 4.12073078169357898126e-01) (0, 5.86362680773192979089e-01) (1, 1.52930208355071622917e-01) (2, 3.33278165072086074439e-01) (3, 3.09510812967899062720e-01) (4, 2.51048297494533223517e-01) (5, -3.42354621886483556636e+00) (6, 9.41166001234295668265e-02) (7, 2.08102579182142338743e-01) (8, 5.71224796429646075602e-01) (9, 6.56306042174042980619e-01) (10, 6.05677216151894959317e-01) (11, -8.93343586359328506452e-02) (12, 4.95303763091919202477e-01) (13, -1.33610327902824344015e-01) (14, -1.69857536364239447568e-01) (15, 3.35656930984540476104e-03) (16, -6.77837164311250600646e-02) (17, -1.41054791573078097677e-01) (18, -1.69320580471199744199e-01) (19, 3.50805305373031672822e-01) 
