FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.57968715909967505340e-01) (1, 4.99513638209221233488e-01) (2, 4.84443855475303997160e-01) (3, 3.69760622273800243498e-01) (4, 4.51256033967850078703e-01) (5, -1.87137650278718559171e+00) (6, -1.54905555178535947469e+00) (7, 4.82034271078270737387e-01) (0, 6.67763949429989978057e+00) (1, 5.91906396348810925900e-01) (2, 4.76357055504656068390e-01) (3, 5.44618991811609887144e-01) (4, 4.80376412768697969025e-01) (5, -1.60295488674388586503e+00) (6, 1.75920039678269413130e+00) (7, 2.32512017992891645290e-01) (0, 1.59550268990685051307e+00) (1, 3.82292727247346308950e-01) (2, 4.20049349084962275747e-01) (3, 3.90197159961331752065e-01) (4, 4.30765303090680506948e-01) (5, -2.88781791065696991083e+00) (6, -3.69336213502627352945e-01) (7, 4.12597619213919741821e-01) (0, 6.52809337398410960418e+00) (1, 5.16606574157526421409e-01) (2, 3.78709082702448074365e-01) (3, 4.56962240139295705621e-01) (4, 4.82500587800790914361e-01) (5, 1.13087111095316839027e+00) (6, -3.33294652963306570204e-01) (7, 1.64317385560799084088e-01) (0, 6.61395957565308734161e+00) (1, 4.77918796768932507835e-01) (2, 5.32220840981751042165e-01) (3, 4.02924553087501802207e-01) (4, 5.16907886198311405934e-01) (5, 1.12468140277456019049e+00) (6, -2.87705769174348924277e-01) (7, -5.15974595536289673547e-02) (0, -9.27338768931214696423e-01) (1, -5.04929237459525934173e-02) (2, -1.60104390272937768813e-01) (3, -2.24325824568115228530e-01) (4, -6.23420440052375735007e-02) (5, 3.11584879109439827349e-01) (6, 3.35504754741952682107e-01) (7, -1.34916380383551276489e-01) (0, -1.16450085667068492512e+00) (1, -1.99211420916292729355e-02) (2, -6.65813269518587547147e-02) (3, -1.32801461448547569733e-01) (4, -1.82834576299068657379e-01) (5, 2.15959001729068705844e-01) (6, 2.08833324145573873132e-01) (7, -9.05821885155681794100e-02) (0, 6.63654715812207385284e+00) (1, 5.43899730895346156245e-01) (2, 5.45330898021048060542e-01) (3, 4.47220542584245983608e-01) (4, 5.24467663024252406245e-01) (5, -1.65853368479953511283e+00) (6, 2.46807843857286313138e+00) (7, 1.93413854807947094283e-01) (0, -1.29448188644940387348e+00) (1, -5.05012007855150449331e-02) (2, -1.13342064847824330887e-01) (3, -3.00022693775865885446e-02) (4, -8.34391745232316850434e-02) (5, 2.25851264247474620150e-01) (6, 3.67218188305661941140e-01) (7, -1.39810726382315314575e-01) (0, -1.14014467028076182942e+00) (1, -2.54859956406328531930e-02) (2, -1.43123205234882561188e-01) (3, -5.86771848105165846898e-02) (4, -1.20669152071354132683e-01) (5, 3.24910312528544575894e-01) (6, 2.40546777034453734823e-01) (7, -1.47436775602877295777e-01) (8, -5.27084722026593066602e-01) (9, 4.81917224071700844856e-01) (10, -5.41107280954129077344e-01) (11, 4.93041864774902138802e-01) (12, 4.91108185790260109993e-01) (13, 6.12462185113633927891e-01) (14, 5.81765219359601792881e-01) (15, 4.43954802296836648079e-01) (16, 5.71537632285560426304e-01) (17, 5.42271837382520494053e-01) (18, 2.18597475241840200066e-01) 
