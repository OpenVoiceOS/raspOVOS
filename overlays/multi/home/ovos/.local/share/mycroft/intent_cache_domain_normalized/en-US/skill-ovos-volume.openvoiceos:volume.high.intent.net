FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.26384810509894651709e-01) (1, 2.31217631789434677203e-02) (2, -7.29166118708859667397e-02) (3, -3.44907677081834687649e-02) (4, -2.62865012792360026872e-02) (5, 1.35209305857857259303e-01) (6, -2.72816142156977137212e-01) (7, 1.79303472916778794399e+00) (8, -1.32177370456660975284e-01) (9, 1.59071419817499976057e-01) (0, 2.58773570659373508551e-01) (1, 9.45213825428370922610e-03) (2, 6.13564738723028427203e-02) (3, -6.28621762899171099281e-02) (4, -1.13948624422908872944e-01) (5, 1.37166334962090047389e-01) (6, -3.70804278269667109136e-01) (7, 1.83387660448876310681e+00) (8, -2.40442017880881958591e-01) (9, 1.27034862023882727522e-01) (0, 2.14768646064017493247e-01) (1, 6.58901819678533867686e-02) (2, 4.41898146363485719301e-02) (3, -8.04552806822072252846e-02) (4, -1.25773351481319600742e-01) (5, 1.35702962701757939845e-01) (6, -3.47284266814846476201e-01) (7, 1.70186552691386205893e+00) (8, -1.31279858616794337101e-01) (9, 1.21334862393431511252e-01) (0, 2.61572016182158695319e-01) (1, 3.06100288125265330985e-02) (2, 5.22212722989309693911e-02) (3, 5.29883542748678590395e-02) (4, -7.63917414752255663490e-02) (5, 2.69311463814420337659e-01) (6, 6.96555846072867274055e-02) (7, 3.92744444510241486057e-01) (8, 1.43407684901081772244e-01) (9, 4.88027268613849957157e-02) (0, -6.61259923325840492936e-01) (1, -9.98242837946310412889e-02) (2, -1.27339814380873744826e-01) (3, -2.36388769523371816694e-01) (4, -2.35197451488246084272e-01) (5, 3.53067285840286682053e-01) (6, -5.54495460562993008891e-02) (7, 1.74619808613593452407e+00) (8, -1.04687917616907641416e-02) (9, -1.25785597603754295548e-01) (0, 5.61461248809840718366e+00) (1, 7.40669472068715473156e-01) (2, 7.39139242023396758619e-01) (3, 6.63339918404984740796e-01) (4, 7.87703199237752227369e-01) (5, 1.36413222988234505983e+00) (6, -1.40497187094465170176e+00) (7, -3.16496359666418625167e+00) (8, 2.87187682362813556658e-01) (9, 2.21908559791019838192e-01) (0, -6.68595795077457477618e+00) (1, -1.34038195909596868916e-01) (2, -2.30382044763900312168e-01) (3, -2.29576536418534787876e-01) (4, -1.53560833038426824970e-01) (5, 6.46354765864002089870e-01) (6, -4.63666878664924994591e-02) (7, 1.28834430571226765672e+00) (8, 5.39971378547491193123e-02) (9, -1.22978172766606247412e-01) (0, 3.48708147826495240551e+00) (1, 8.31323187328807278185e-01) (2, 8.56493722177974259324e-01) (3, 8.21145262099734707384e-01) (4, 8.64113475657931839891e-01) (5, 1.54871116334067471243e+00) (6, -1.46213905827775869639e+00) (7, -3.59699700899534136056e+00) (8, 3.47787605914475883573e-01) (9, 2.59529800415841727101e-01) (0, -6.75852434081211139727e+00) (1, -1.38157219196932079530e-01) (2, -1.98392950500623943544e-01) (3, -1.35458156968729259706e-01) (4, -2.69673921670095628755e-01) (5, 7.29528713717926491356e-01) (6, -8.92752669775918050732e-02) (7, 1.25861838157801320115e+00) (8, 9.29043081504644235880e-02) (9, -1.89301892685334149924e-01) (0, 5.55000708068158488118e+00) (1, 1.00673332661074721450e+00) (2, 8.76511624452296134180e-01) (3, 8.98329755660715933985e-01) (4, 8.59933065619889247522e-01) (5, 1.41012455959902749392e+00) (6, -1.34380100981965933116e+00) (7, -4.19585319740618611917e+00) (8, 5.37618624586824078726e-01) (9, 1.96298388532570339260e-01) (10, 3.20892650975415749670e-01) (11, 2.92370949281880898596e-01) (12, 3.30949492240314890878e-01) (13, 1.77985446119968637735e-01) (14, 5.23771099528375194687e-01) (15, 4.89321478180385627255e-01) (16, 9.80375272526565755271e-01) (17, 4.55018200449443965816e-01) (18, 5.91400837984399463387e-01) (19, 4.40810009888523202104e-01) (20, 2.34338207970883949383e-01) 
