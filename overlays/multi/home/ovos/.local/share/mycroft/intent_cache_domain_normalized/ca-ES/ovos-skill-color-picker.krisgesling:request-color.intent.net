FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.47037140967047041951e-01) (1, 2.91205694718012775279e-01) (2, 2.82767137331614459850e-01) (3, 3.23360448522219623424e-01) (4, 2.32590688211569779353e-01) (5, 6.73663721193919151631e-01) (6, 3.53948743494265249954e-01) (7, 9.44505672293989739785e-01) (8, -1.70546579674253417913e+00) (9, -9.72844547380500995759e-02) (0, 8.78314383527263764506e-01) (1, 4.54761163642951826702e-01) (2, 3.89689044406959284039e-01) (3, 3.28331099203178267132e-01) (4, 3.71239037564346063824e-01) (5, 1.45969087671133168627e+00) (6, 1.71565500840871387744e+00) (7, 1.41810800591949970340e+00) (8, -3.71250973053881816455e+00) (9, 2.96889513104225052920e-02) (0, 5.28404982787873511718e-01) (1, 1.35520956338909370764e+00) (2, 1.28831994207170708044e+00) (3, 1.35939538152483208044e+00) (4, 1.32259455741909248694e+00) (5, 5.10371709370169623909e-01) (6, 7.53486272463126716126e-01) (7, 4.85814103802818308964e-01) (8, 2.45624408478367195485e+00) (9, -7.18264306880042502357e-01) (0, -2.58846834887857035756e-01) (1, 4.77424720346912134783e-01) (2, 3.97485720038398493426e-01) (3, 3.73814562380298365252e-01) (4, 4.56679174721225489275e-01) (5, 1.10241926227986830611e+00) (6, 3.47056198496977663659e-01) (7, 3.32131010222309730473e-01) (8, -7.82602052900010836112e+00) (9, 1.79048718417160884764e-01) (0, -3.93164522440307862006e-01) (1, -9.39843212985539411264e-02) (2, -1.81071758809044330851e-01) (3, -9.16713481568837140756e-02) (4, -2.27424167635395441112e-01) (5, 2.43112529330501564440e-01) (6, 3.95940645724794149096e-01) (7, 5.23322417763963154691e-01) (8, 1.05044888965834082306e+00) (9, -1.06230950973595450471e+00) (0, 4.63176756748213902526e-01) (1, 3.73300575962611902447e-01) (2, 3.93428818634101618024e-01) (3, 4.14562599113532770367e-01) (4, 4.48592321327277998577e-01) (5, 1.49456701468320996007e+00) (6, 8.92185764436774442210e-01) (7, 1.39108632507793661404e+00) (8, -3.22404792183401323058e+00) (9, -9.87415687956921250823e-02) (0, -2.97555055680784608096e-01) (1, -2.42506204370858402530e-01) (2, -5.53382171434185152203e-02) (3, -7.47354759019634995454e-02) (4, -2.31870925251843662540e-01) (5, 6.06901155534348979437e-01) (6, 3.54084926390833443222e-01) (7, 4.54673544155620057428e-01) (8, 1.00698444590324465153e+00) (9, -9.38398888927353125311e-01) (0, -1.02641961285101190882e+00) (1, 1.20974675105142859266e+00) (2, 1.32185337976742056654e+00) (3, 1.29630578593540457533e+00) (4, 1.35657844976711539076e+00) (5, 7.99094875958048400655e-01) (6, 1.25154694979009395439e+00) (7, 3.06400694606356660543e-01) (8, 1.83793066795313331241e+00) (9, -3.10951624560353023785e-01) (0, 7.61196342986533713848e-01) (1, 1.23434478250217805062e+00) (2, 1.30661637914252648507e+00) (3, 1.22784724664760003243e+00) (4, 1.38713645768237481271e+00) (5, 6.87539709725741854385e-01) (6, 8.57374338294753846057e-01) (7, 5.21318832358497519230e-01) (8, 2.16328900733203033369e+00) (9, -1.84133339847265542488e-01) (0, 2.08044442480617181035e-01) (1, 5.10681511506109880871e-02) (2, 1.03930474971201947110e-01) (3, 2.42040248259573868850e-02) (4, 2.18353995725184373000e-02) (5, 4.06341376238321394521e-01) (6, 4.02986203768537665226e-01) (7, -9.38810157911869502811e-01) (8, 6.14520418176109584074e-01) (9, -6.00085694632514349278e-02) (10, 5.41060398936105690915e-01) (11, 4.81670267145362929195e-01) (12, -1.40269077723220642051e-01) (13, -1.12209821138763676807e+00) (14, 5.31225584640904968659e-01) (15, 5.41659929257533256930e-01) (16, 4.50721353317948936201e-01) (17, -1.44080377524093444785e-01) (18, -1.30408908675757995166e-01) (19, 4.27149839373779705021e-01) (20, 5.03817086730531049632e-01) 
