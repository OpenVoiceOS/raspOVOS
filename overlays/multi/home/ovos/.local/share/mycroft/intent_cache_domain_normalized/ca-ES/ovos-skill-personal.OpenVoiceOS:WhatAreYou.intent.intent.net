FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.39333336493293469260e+00) (1, 4.16912739745183613671e-01) (2, 3.63922213784261372460e-01) (3, 3.29688688388867889856e-01) (4, 4.02741899362607624902e-01) (5, -2.26799637777659013338e+00) (6, -4.25507405790653603361e-01) (7, 8.88812258618896511297e-02) (0, 1.10822833554056865424e+00) (1, 9.46988357865387875290e-02) (2, 5.95134018623406021997e-02) (3, 8.49900289141709286422e-02) (4, 1.36841189738469842796e-01) (5, -7.18219097072108336732e+00) (6, 4.12124619696795058132e+00) (7, 1.35871068784766763082e-01) (0, 3.87005831026169921927e-01) (1, 2.47504279456729536779e-01) (2, 3.25968705556983706639e-01) (3, 2.16240752927655877080e-01) (4, 2.42265023730392103918e-01) (5, -7.10203354284968502164e-01) (6, -2.32422501402437919893e+00) (7, 6.55939950115949188536e-01) (0, 6.90215644095330427277e-01) (1, 2.48166338744588765852e-01) (2, 3.12290773930974985273e-01) (3, 2.37165228667684468977e-01) (4, 1.44973554852434127760e-01) (5, 2.88282349471054022416e-01) (6, 7.57756303414781996253e+02) (7, -1.60710115719674036250e-02) (0, 1.07914894369936487095e+00) (1, 6.50718237541613037100e-02) (2, 8.33957593224940035848e-02) (3, 2.49917032875865474661e-01) (4, 2.43018868126719966849e-01) (5, -6.44401283675969871467e+00) (6, 3.45469863627216833279e+00) (7, 1.17187238911565627664e-01) (0, 4.80278047254597884042e-01) (1, 2.22545578583016878671e-01) (2, 2.71429694696202761239e-01) (3, 2.24397655083671099252e-01) (4, 2.03467472894921841409e-01) (5, 9.58331619452142263738e-02) (6, -3.52622758236658784270e+00) (7, 5.27995195861322041964e-01) (0, 1.85375408355423090256e+01) (1, 5.93767151744849952522e-01) (2, 6.09017998488433631721e-01) (3, 5.14920630069263474127e-01) (4, 6.26634650440700324836e-01) (5, -5.07480412958847360017e+00) (6, -1.70047691539188505772e+00) (7, 1.00667779102697596549e+00) (0, 7.21255828295140455353e-01) (1, 2.66213686409421945722e-01) (2, 2.63006554189153696210e-01) (3, 2.84952090325780893476e-01) (4, 2.83838228526540781171e-01) (5, 3.82625594500503485307e-01) (6, 7.57776110291560598853e+02) (7, 4.35326124738814462800e-02) (0, 6.14511843422350212407e-01) (1, 8.07142858235812554746e-02) (2, 1.39589779528853957791e-01) (3, 1.74572661968944109478e-01) (4, 2.11739927980182263134e-01) (5, -3.36477423363668570744e+00) (6, 7.56506550053116844090e-01) (7, 6.85361078599617673524e-02) (0, 6.92810374936098982701e-01) (1, 2.53144883058662062414e-01) (2, 3.44396926901931577092e-01) (3, 1.78526290200347631520e-01) (4, 3.18599753521079775975e-01) (5, -7.03556695798784215157e-01) (6, -1.88842459440354448752e+00) (7, 5.88729722864896332091e-01) (8, -2.35474297104633573455e-03) (9, -7.47661670059463351334e-02) (10, -4.21968128694603428208e-01) (11, 6.90654833472696960683e-01) (12, -3.59134437580452547945e-02) (13, -4.99914743742297218443e-01) (14, -1.59960468477177264468e-01) (15, 5.07576265089829226085e-01) (16, -1.75777527732579215425e-02) (17, -3.72590930330046032903e-01) (18, 3.74130163549017957791e-01) 
