FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.02701986855484506123e+00) (1, 2.85529627046515910305e-01) (2, 3.63898588857581639644e-01) (3, 3.11108755460908492640e-01) (4, 3.46382877371242070552e-01) (5, 6.99872059725874406944e-01) (6, 6.80183906313263308974e-01) (7, 1.17827947414728106956e+00) (8, -7.68026834788039813873e+00) (9, 2.48739121300482757260e-01) (0, 1.32595330856964910282e+00) (1, 3.37179575903221673272e-01) (2, 3.81266844315334862969e-01) (3, 4.25592047018810704095e-01) (4, 2.63288368327423638604e-01) (5, 7.22699742205223927272e+00) (6, 7.67792524574754331468e-01) (7, 2.51197776066306888154e-01) (8, -7.46839083386254731778e+00) (9, 2.12697628325527121618e+00) (0, 3.53300742285078950289e+00) (1, 4.96746543440225507560e-01) (2, 4.24996588024499799552e-01) (3, 5.16808706912401105704e-01) (4, 5.13178977760675336661e-01) (5, 1.40506473237573237256e+00) (6, 2.45711610620607068256e+00) (7, 1.30331583949001905687e+00) (8, -4.64437930705757651140e+00) (9, -2.25246323960674689132e-03) (0, 1.02463773449371464697e-01) (1, 2.06225183071724361972e-02) (2, -1.59876901445754650288e-02) (3, 4.70029082359901817512e-02) (4, 6.17171343626610260924e-02) (5, 4.59413953985023798543e-02) (6, 2.03961344341785644207e-01) (7, 4.15518202205253039949e-01) (8, 1.10955877086338042248e-01) (9, -6.25018101689041927216e-01) (0, 9.72556719662947322114e-01) (1, 8.33856822835181248077e-03) (2, 1.29595906901228186126e-01) (3, 1.06860236692297230765e-01) (4, 6.63767518388006915603e-03) (5, 1.43933346741583728656e-01) (6, -7.27509468236476608549e-02) (7, 4.14340945252650652564e-02) (8, 3.11578562656729174396e-01) (9, 3.13200336170183224471e-01) (0, 1.82607657249904659080e-01) (1, 4.85334363045326691588e-02) (2, -5.00776167748340911290e-02) (3, -6.24981183348068750072e-02) (4, 4.25215032162300568541e-02) (5, 5.54486140755182238538e-02) (6, 1.59278849045784182126e-01) (7, 5.51631503189241256813e-01) (8, 8.35390964953269948845e-02) (9, -6.52556091303634233647e-01) (0, 1.23693404167313600328e-01) (1, 3.94417199710116794797e-01) (2, 2.59929637828574533476e-01) (3, 3.37956796804175785276e-01) (4, 3.41291266897426059934e-01) (5, 2.06585361317022764283e+00) (6, 5.20708247013735747721e-01) (7, 2.68634541020897188446e+00) (8, -3.95970013804828768755e+00) (9, 1.05836330255163035829e-01) (0, 5.47198305970022058631e-01) (1, 3.92059973022868712977e-01) (2, 2.96401775023868052639e-01) (3, 3.37711131713321233150e-01) (4, 3.32102725795438369349e-01) (5, 7.13779171630229081202e-01) (6, 2.78113950720428881880e-01) (7, 1.76241955504708291969e+00) (8, -8.06413451118421953367e+00) (9, 2.40400944204465477627e-01) (0, 1.03680940401893173508e+00) (1, 4.37680971327996715114e-01) (2, 4.26316552314734809048e-01) (3, 3.99006121311164252408e-01) (4, 4.75053996298289649136e-01) (5, 1.60492773224681384292e+00) (6, 3.73719311954211208526e-01) (7, 1.67844660152496549799e+00) (8, -9.82518676908382815327e+00) (9, 3.16197798053610201752e-01) (0, 3.42379432909137415564e+00) (1, 3.03729531789176721013e-01) (2, 2.70244394863002557194e-01) (3, 2.76807693267219268041e-01) (4, 2.00592925274722833073e-01) (5, 6.70651953939983425101e+00) (6, 7.06663024384982962900e-01) (7, 1.49868587790144197625e-01) (8, -4.97674364410301794948e+00) (9, 1.00637582239522446748e-01) (10, -3.85646811462266148052e-01) (11, 3.88169604987297689469e-01) (12, 4.47310657931149047162e-01) (13, 5.93388019098745056468e-01) (14, -1.07079191678987217795e-01) (15, 4.39272641654201656536e-01) (16, 3.52724000888634092732e-01) (17, -4.41969774578255869546e-01) (18, -5.55708776157110118099e-01) (19, 9.74530123308489509837e-02) (20, 1.65638855979037241672e-01) 
