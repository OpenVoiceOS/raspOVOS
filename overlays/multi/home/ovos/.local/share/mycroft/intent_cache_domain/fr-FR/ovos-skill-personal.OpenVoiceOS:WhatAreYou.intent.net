FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.15129247146296731508e-01) (1, 3.85863499846217761213e-01) (2, 3.79333989825008044416e-01) (3, 3.55375902857539782698e-01) (4, 2.54341246690509337203e-01) (5, -1.74334559880832884460e+00) (6, -3.26580840163734342774e-01) (7, 1.20842022828068476059e+01) (8, 2.23345620918488529938e-01) (9, 9.71169896201866666985e-02) (10, 3.24640462668964180359e-02) (11, 2.19189203493340478701e-01) (0, 3.42821425382860006659e-02) (1, 6.66338344045598773846e-01) (2, 7.44534199067075519451e-01) (3, 6.34342477597911846843e-01) (4, 7.51057838030774860272e-01) (5, 3.77208484772178775923e-01) (6, 5.02963734419318853064e-01) (7, -6.68956586033125244484e+00) (8, 6.10568848476224168564e-01) (9, 6.54573580515150355019e-01) (10, 5.95296672565333140348e-01) (11, 1.45468276224142822883e+00) (0, 9.67126811879325365418e-01) (1, 3.79903378095386157209e-01) (2, 3.24952567126510272200e-01) (3, 4.06098621096370349104e-01) (4, 2.64812657739875390028e-01) (5, -1.80638229393104765563e+00) (6, -3.02459913306739713867e-01) (7, 1.21661182797755937912e+01) (8, 2.87933072436070469635e-01) (9, 3.31565044598358116268e-02) (10, -2.57884314932144489974e-03) (11, 3.07510900460227054598e-01) (0, 1.49359155050205627546e+00) (1, 3.31009306580050816082e-02) (2, 1.12650037378295101581e-02) (3, 1.09247432705782229756e-01) (4, 2.05079258054717203374e-02) (5, -1.90459875330806447380e+01) (6, 2.28659602878145129523e-01) (7, 9.92640167653906724254e-01) (8, 5.82249644900261348335e-02) (9, 1.24121760208319803498e-01) (10, 1.29443956464302345477e-01) (11, 1.80673910828184014488e-01) (0, 4.43136191551454297621e-02) (1, 6.43077542015035641398e-01) (2, 6.25285223998744976726e-01) (3, 6.99955386050660877117e-01) (4, 6.60049741097409992108e-01) (5, 3.32087929692071570642e-01) (6, 6.17000078411075070228e-01) (7, -5.79067320273593644231e+00) (8, 6.38794240579419358994e-01) (9, 7.52870448257174307294e-01) (10, 2.35797201494652552967e-01) (11, 1.48885478681928407063e+00) (0, 1.44304393149376997130e+00) (1, 5.55633863386047199828e-02) (2, 1.13931733923806038922e-01) (3, 1.50742981391800756619e-01) (4, 1.79009888130082006619e-01) (5, -3.04139205438034343487e+00) (6, -1.95705144794246999052e-01) (7, 7.19761501622903504538e-02) (8, 2.82535045558469019578e-02) (9, 8.22074778659088040156e-02) (10, 6.96722348309808947597e-02) (11, 1.93580988375180201855e-01) (0, 5.89797901604997010239e-01) (1, -2.19135455242874643833e-01) (2, -1.31289846650841313114e-01) (3, -2.32004515282394963016e-01) (4, -2.81166873327972965946e-01) (5, 4.54595280157075898320e-01) (6, 4.73078887901120848092e-01) (7, 2.05488770486799854353e+00) (8, -2.84972019352357941457e-01) (9, -2.35048027975903822684e-01) (10, -2.36834165798995049945e-01) (11, -2.89938600816028013707e-01) (0, -2.59488092179529540593e-02) (1, 6.49659712739904193768e-01) (2, 5.80661562212427151408e-01) (3, 6.57918360956628589520e-01) (4, 7.44927172490079669842e-01) (5, 2.46949026796552811858e-01) (6, 3.69101432445218924361e-01) (7, -6.52057644784469925270e+00) (8, 6.32304386075930868749e-01) (9, 6.69649253082677309301e-01) (10, 6.33010188654406058539e-01) (11, 1.57765863693362939912e+00) (0, 5.71670649488474458266e-01) (1, 3.07896253248571394323e-01) (2, 4.04202264329313276647e-01) (3, 2.33711932381509890355e-01) (4, 3.62632673760770796179e-01) (5, -3.53575549170111536057e+00) (6, -3.71534484439399625977e-01) (7, 1.21837656653728227951e+01) (8, 2.52131773519730539856e-01) (9, -7.36167507602998247296e-03) (10, -3.31316327182224756864e-02) (11, 2.67715574973018677341e-01) (0, -3.62875667479775065871e-02) (1, 6.05306577809770596232e-01) (2, 6.50447484978158740887e-01) (3, 7.32495506235082416424e-01) (4, 5.97258512803037655559e-01) (5, 3.64409087661239750044e-01) (6, 5.50727245957824185218e-01) (7, -2.89229759065825753339e+00) (8, 6.52257290706448777939e-01) (9, 7.54565364014867845377e-01) (10, 3.32527208622965975149e-01) (11, 1.26869337987679364765e+00) (12, 5.40271751480893791530e-01) (13, -2.09106322640033759352e-01) (14, 5.59671558338002861355e-01) (15, -7.75340551481675799295e-01) (16, -1.80244531744571778731e-01) (17, -7.38309720502328681313e-01) (18, 5.63641444820937365101e-01) (19, -1.74962457531543824629e-01) (20, 7.49213402301768471858e-01) (21, -1.36189501994701422927e-01) (22, 3.83820442689358609645e-01) 
