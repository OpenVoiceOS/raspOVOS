FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.31631897256141749963e+00) (1, 6.57866863475466689959e-02) (2, -2.49723898305272140608e-02) (3, -3.41191100015019455061e-02) (4, 7.77009544835711163380e-02) (5, -8.41296777267055290173e-02) (6, 1.10857913104280281225e+00) (7, -1.59220050662558593180e-01) (8, -1.35159234552208989966e-01) (9, -1.07997969979724967038e-01) (10, -2.46780433710009433623e-01) (0, -3.84912070043392873231e+00) (1, -8.44075997647065756624e-02) (2, 9.21410674873571478027e-02) (3, -9.50675924595613119905e-02) (4, 5.49270565334540258884e-02) (5, 1.32068306069774623474e-02) (6, 1.16818198767885017553e+00) (7, -1.98460202306311589426e-01) (8, -1.47375718319359250152e-01) (9, -6.35722605579285282573e-02) (10, 6.58610116551184773814e-03) (0, 2.67617748595113411625e+01) (1, 4.43077157515956387979e-01) (2, 5.70035892803146149177e-01) (3, 5.47658863741828705329e-01) (4, 4.89344927746726554574e-01) (5, -7.08484477367080334176e+00) (6, -1.64356795116953402491e+00) (7, 7.29645931209868869871e-01) (8, 2.08519850583709542846e+00) (9, 5.15862520666185209173e-01) (10, 6.23224712323363738697e-01) (0, 3.77677405895845996753e+00) (1, 7.88493195504471056090e-01) (2, 8.09966871470733873473e-01) (3, 7.29601809710785143004e-01) (4, 7.09067905277534715758e-01) (5, 5.40719892009572422609e+00) (6, -4.84593499080961809256e+00) (7, 7.66653420215857139830e-01) (8, -2.51798389713744852347e-01) (9, -2.49728564961235743880e-01) (10, -5.63511301705714173771e-01) (0, -2.35950387135511485681e+00) (1, 9.88036195671374711802e-03) (2, 1.24424601618033127404e-02) (3, 1.05367283049803452111e-02) (4, -9.94205673301402741149e-03) (5, -2.84966231771277252530e-03) (6, 1.00018536505683708349e+00) (7, -6.86546299753599958970e-02) (8, -1.38139905203377183485e-01) (9, -1.27404857538306104381e-01) (10, -2.29481344129235126372e-01) (0, -1.56955948120859090089e+00) (1, 8.60738330134644263891e-02) (2, 4.11758892783417873584e-02) (3, 3.98153536566987209522e-02) (4, 2.54811816462769645530e-02) (5, -6.06665029008852333542e-04) (6, 1.06017533895953941503e+00) (7, -2.35992069929640807535e-01) (8, -2.46700383530790781639e-02) (9, -5.85425319183384210153e-02) (10, -1.22199936419717450353e-01) (0, -2.29324358567958874744e+00) (1, 8.86205552087450665333e-02) (2, -1.80583702458714523420e-02) (3, -2.45137693418835678205e-02) (4, -9.79273425473546066389e-02) (5, -1.64412149800737317218e-01) (6, 1.18583347109540748754e+00) (7, -1.53562631100218810465e-01) (8, -6.31088147971262947156e-02) (9, -3.96973316318608437925e-02) (10, -9.08225089326734902340e-02) (0, -2.04637149229982773235e+00) (1, 2.54087431836644062066e-01) (2, 3.42023699093380872949e-01) (3, 2.99935518312970106347e-01) (4, 2.66268397230425779565e-01) (5, 1.90827168640155764301e+00) (6, 6.61975139682479785108e+00) (7, 9.28635083012321560503e-01) (8, 1.61467887735342152666e+00) (9, 1.00933718360427859828e+00) (10, 4.10998765817538080913e-01) (0, 1.12277760365977723467e+01) (1, 6.56269021112086403669e-01) (2, 8.38646642643572914899e-01) (3, 7.35003724474074693340e-01) (4, 7.28439956683280320782e-01) (5, -4.69632153118863371333e+00) (6, -4.17836277177623893753e-01) (7, 4.12833883681621507944e-02) (8, 5.61023094462704596808e-01) (9, 5.70217521189767095890e-01) (10, 3.97734688035322914157e-01) (0, 1.33801653519921859292e+00) (1, 7.97676135503543742855e-02) (2, 9.27005250655902335311e-02) (3, 5.29491592847599057414e-02) (4, 7.75966782771839030941e-02) (5, -5.50416642862161409333e-01) (6, 7.05701588063007534402e+00) (7, -4.72789439679450140819e-01) (8, -5.08334628073057515074e-01) (9, -9.19442546045119102338e-01) (10, -2.52185353609385876084e-01) (11, 3.90750007976343627369e-01) (12, 4.12861470267290531222e-01) (13, -1.91001651885648493501e-01) (14, 1.33692411601996519188e+00) (15, 4.33169324522873488981e-01) (16, 4.09300179847949863188e-01) (17, 4.23415325497797812027e-01) (18, -1.59740368878881933146e-01) (19, -5.44948532943115626637e-01) (20, 5.33639587864880970969e-01) (21, 6.44563695285250704003e-01) 
