FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.08870570811852240833e-01) (1, 1.75769090111014381073e-01) (2, 2.63936079497096076629e-01) (3, 3.43829973990675830109e-01) (4, 2.02284998650309522095e-01) (5, -2.43537017761096619139e+00) (6, 5.46273417607250760808e-02) (7, 1.42067139488332189190e-01) (8, -6.44810398546807550524e-01) (9, 9.55569877465610506562e-01) (10, -8.94369324076978555738e-01) (11, 1.56482229710662723576e-01) (0, 5.94639542217349270636e-01) (1, 5.55213616405180632185e-01) (2, 4.51051988814524407179e-01) (3, 5.33519798134020506453e-01) (4, 5.45351416979483305525e-01) (5, -4.58857777469309535689e+00) (6, 7.64023308694564140531e-02) (7, 1.44457752892292190516e+00) (8, 3.54061931482001135407e+00) (9, 3.79147397211808856454e+00) (10, 3.56379835599036098870e+00) (11, -1.58285063740753809136e-02) (0, -5.33953714848586891151e-01) (1, -1.51280726804675191843e-01) (2, -2.25629839443579754965e-02) (3, -9.21469214701071959173e-02) (4, -1.25405568196715444529e-01) (5, 1.26732138085090428881e+00) (6, 1.41421788519255270389e-01) (7, -7.61579352148247457066e-01) (8, 4.63478786376312013040e-01) (9, -4.77521027090220373523e-01) (10, 3.66077169715042394227e-01) (11, -1.03145728617540843874e-01) (0, 3.22815955135449250690e-01) (1, 2.42668360779986796993e-01) (2, 1.49185464094386488476e-01) (3, 2.46852979372249065060e-01) (4, 1.99135456542477967679e-01) (5, -2.33533968834504745971e+00) (6, 2.04043107546452995305e-02) (7, 3.94778314314116682282e-02) (8, -5.75893827226987009560e-01) (9, 9.22217450281028749970e-01) (10, -9.27898665297834490673e-01) (11, 2.80805095864410603212e-01) (0, 6.93040345932992574163e-01) (1, 4.47174898038969759195e-01) (2, 3.08145790051089163430e-01) (3, 3.06023752938376303323e-01) (4, 4.14838394771681551187e-01) (5, -5.91784369001715937486e+00) (6, -6.57674170945781288999e-01) (7, 1.05056889036604661491e+00) (8, 1.04009844668762116981e+01) (9, 4.42682165839181962497e+00) (10, 5.83598873459841183120e+00) (11, -2.47513161345257082235e-01) (0, 5.50587954635714749152e-01) (1, 5.69965065632513701033e-01) (2, 5.72405339394262968611e-01) (3, 5.16108461831263243269e-01) (4, 6.10744432721785246443e-01) (5, -4.46618764486569563843e+00) (6, 2.25576836652690210228e-01) (7, 1.03549618508732788058e+00) (8, 1.86320512763709067450e+00) (9, 3.60514430599338675520e+00) (10, 3.44792970661036246582e+00) (11, 6.17507499734212955689e-02) (0, 7.13800046330458015653e-01) (1, 6.53669173024995775467e-02) (2, 1.30080518325458249773e-01) (3, 1.19028200408111378694e-01) (4, 1.88481588860641230410e-01) (5, -5.80909572772323579137e-01) (6, 1.01017295552785643653e-01) (7, 2.16771829056344678133e-01) (8, 1.85359953946877831221e+00) (9, -6.67999744049758481523e-01) (10, 7.95796508469725383250e-01) (11, 1.19910052785773088568e-01) (0, 2.94379547688588094623e-01) (1, 1.67448035831210151336e-01) (2, 3.44565405900236987335e-01) (3, 1.89626056159493461273e-01) (4, 2.83666833693739794953e-01) (5, -2.44824395386800430785e+00) (6, 5.29731752790097015771e-02) (7, -1.24418118289924800601e-01) (8, -3.95121461897372794336e-01) (9, 8.76139647503738405732e-01) (10, -8.42443781648819944863e-01) (11, 2.39843840179432915560e-01) (0, -6.83480240776865533014e-01) (1, -1.80374677791537374461e-01) (2, -5.82522335791007053740e-02) (3, -8.94232797765151243841e-02) (4, -3.88116124414817006971e-02) (5, 1.34238956823367994176e+00) (6, 7.65926066394963384054e-02) (7, -4.20120648904332205653e-01) (8, 4.19194561866119252969e-01) (9, -9.58692556535097550885e-01) (10, 7.36699558802691778503e-01) (11, -2.84246418472446811532e-02) (0, 4.73587646045636689873e-01) (1, 1.48538894409892041626e-01) (2, 3.40654774958845996125e-01) (3, 2.89949073846098803742e-01) (4, 2.37887419218775764129e-01) (5, -2.36603995470628403197e+00) (6, -3.38833240352983885990e-02) (7, -1.69124689616928919333e-02) (8, -5.02638124373784189736e-01) (9, 8.53164783855323571871e-01) (10, -8.77260265996834154301e-01) (11, 2.07093558044279008046e-01) (12, -3.44216304888565027831e-01) (13, 4.83306991599565083373e-01) (14, 7.88402002094932052856e-01) (15, -4.00645832588512273986e-01) (16, 5.60343879006867884307e-01) (17, 5.43461071990495203643e-01) (18, 4.17051910560030714148e-01) (19, -3.67608743777114832518e-01) (20, 7.21868950663753006225e-01) (21, -3.27775466313201868651e-01) (22, 1.69967148152752128842e-01) 
