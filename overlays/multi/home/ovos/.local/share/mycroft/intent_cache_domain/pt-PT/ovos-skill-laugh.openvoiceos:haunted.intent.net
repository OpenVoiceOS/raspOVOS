FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -7.56160676836624467967e-01) (1, 1.62516630816265175707e-02) (2, -1.12386994433597599274e-02) (3, 4.68053914236827919848e-02) (4, 6.95996206281623754769e-03) (5, 1.63565420281709360262e-02) (6, 1.55931116646793777036e+00) (7, 6.58579195621779855951e-02) (8, 6.18957465305905868425e-02) (9, 6.50871508629372597099e-02) (10, 1.55936854259236135078e+00) (11, 1.73440186718394273591e+00) (12, -5.13558757947899166552e-02) (0, 2.01448769846034014819e+00) (1, 2.89585881253992649675e-01) (2, 2.10679918846403746446e-01) (3, 2.18089133819853453478e-01) (4, 2.86063403209959599138e-01) (5, 4.21745622273671683100e-01) (6, 1.33347892139874719675e+01) (7, 1.26212843214962000538e+00) (8, 3.28257196932383088495e-01) (9, 7.37236764149186707407e-02) (10, -6.65720071553447145796e-01) (11, 7.52295851772685253422e+00) (12, -1.40480901899649651687e-01) (0, 2.05294832882701311361e-01) (1, 3.16646305908387493133e-01) (2, 1.65177950699752135177e-01) (3, 2.53103671659653972625e-01) (4, 2.10337517847245497604e-01) (5, 9.92533487035923561725e-02) (6, -1.77830985602338120799e+00) (7, 2.71603184609828574025e-01) (8, 1.34069278129121643994e-01) (9, 2.64849046732291093509e-01) (10, 4.12186332519551967835e+00) (11, -1.44558244411955372222e+00) (12, 1.76648420455459420619e-01) (0, 1.01189963467266119679e+00) (1, 1.26786245440533767992e-01) (2, 1.54231070016911664400e-01) (3, 1.47938451205781112963e-01) (4, 2.00009128486207166109e-01) (5, 4.87839699377653646106e-01) (6, 6.47073579111081542692e+00) (7, 5.88079334302720635463e-01) (8, -4.87224578962265966742e-03) (9, 1.76035669356108676054e-01) (10, 1.20054997069459523651e+00) (11, 5.40714495725995192288e+00) (12, -1.50559060586239273904e-01) (0, 8.82528185321350466808e-01) (1, -5.27826647271087134872e-02) (2, 5.88660587559769188370e-02) (3, 5.76424946080277000870e-02) (4, 4.92964138279984032120e-02) (5, 5.86923499337216547644e-01) (6, 6.56779149823767127714e+00) (7, 9.18690156007186731202e-01) (8, -3.98635179240802384193e-01) (9, -5.76822548702973447732e-01) (10, 3.31383188594851940678e+00) (11, 5.28599612511759886502e+00) (12, -1.62354412801517869469e-02) (0, 3.32446902559714319025e-02) (1, -2.07049338169790070330e-01) (2, -1.92148858704067032610e-01) (3, -1.78030686475730753893e-01) (4, -1.61533257015443659776e-01) (5, 1.34834536516761527292e-01) (6, 9.14073856953614205523e-01) (7, 9.44028437069127535075e-01) (8, 9.32287558897194390539e-01) (9, 9.71469365647143923148e-01) (10, -3.46829919576639389422e-01) (11, 8.75687024713190487191e-01) (12, -5.63830534197427499232e-02) (0, -7.44404878824606264232e-01) (1, 4.02881424901924047738e-03) (2, -3.03746290874675750615e-02) (3, -5.58486372602180550229e-02) (4, 6.83971292900844574092e-02) (5, 4.24464859735787861106e-02) (6, 1.30815267718282535192e+00) (7, 1.85142169750019708330e-01) (8, 1.55510692463658228846e-01) (9, 2.26754757182237448587e-01) (10, 9.68152849549044458577e-01) (11, 1.67719941241813352839e+00) (12, 6.19693549824737247023e-02) (0, -6.85357477439964335453e-01) (1, 9.63122166512593441690e-02) (2, -5.27215570392028098912e-02) (3, 1.10027260897740224166e-02) (4, 9.50041778205022030557e-02) (5, 1.18169812829369696994e-01) (6, 1.69663549664399782024e+00) (7, 1.14021773222258808456e-02) (8, 1.53644244301574001144e-01) (9, -6.60351866682476612569e-02) (10, 1.61203577418513632757e+00) (11, 1.77954468054675096766e+00) (12, -1.19477353756330145762e-01) (0, 1.76749983290811063519e+00) (1, 1.31758602500008481506e-01) (2, 1.77467866033362259293e-01) (3, 1.62942132145213053329e-01) (4, 2.60028472334193072601e-01) (5, 2.66805205586226223957e-01) (6, -2.09542615748274085874e+00) (7, -7.63884388124069890758e-01) (8, -1.82692134942469636139e-01) (9, 5.94504246952515663649e-02) (10, -1.87809125009719690702e+00) (11, -2.13911202610842776650e+00) (12, 9.00685552771456565679e-01) (0, 4.10961082738674932102e-01) (1, 2.00087273891583844465e-01) (2, 1.97387742276803418440e-01) (3, 2.67939361210481119535e-01) (4, 1.86635392184869214338e-01) (5, 1.38960070605485985773e-01) (6, -1.67567265075046822886e+00) (7, -4.47709320653151721103e-01) (8, -1.12432939185590830000e-01) (9, -5.75957630811982590480e-01) (10, -3.05178458187282453107e-01) (11, -1.45109383230219379790e+00) (12, 3.00266016048684025730e-01) (13, 2.63018996321740139432e-01) (14, 2.49306832599582750554e-01) (15, -1.57841410583287794500e-01) (16, 7.85697659156435412875e-01) (17, 6.05990161563059293037e-01) (18, 5.78060952869039024193e-01) (19, 2.25007920231896113572e-01) (20, 3.18198915170501084315e-01) (21, -6.97012939383170659902e-01) (22, -1.43701706177026350408e-01) (23, 3.54326967551558180691e-01) 
