FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.56663965431792240324e+00) (1, -2.24365877540800756629e-01) (2, -2.10640857549402843452e-01) (3, -1.83352808089945501502e-01) (4, -2.73586603434775033072e-01) (5, 3.19264929783330764224e+00) (6, 1.59402264197517729016e+00) (7, -9.88034207400771968821e-02) (8, -2.55151544610204839003e-01) (9, 3.09447717410585798614e-01) (10, -1.50760559535862315172e+00) (0, 7.54559495301985294624e-01) (1, 5.73079794380178864088e-01) (2, 5.58261200520506317702e-01) (3, 6.41406610342970306959e-01) (4, 5.85436410936823303786e-01) (5, 4.30844018822213181696e-01) (6, 5.39212231138404352038e+00) (7, 8.29235550174004520940e-01) (8, 6.70843437205842274551e-01) (9, -3.01727994939167132316e+00) (10, 7.23430442726346378812e-01) (0, 1.49411730867472525297e+00) (1, 5.79280481773478350682e-01) (2, 5.78931153851610980077e-01) (3, 4.80067008274657480715e-01) (4, 4.81043391960723154543e-01) (5, -1.04842651314537405050e+00) (6, 9.80548792000794264823e+01) (7, 3.18332067901664927945e+00) (8, 9.63481059689702057369e+00) (9, 6.78358863721375193734e+00) (10, 5.54081500083121292199e-01) (0, 1.58850657215084539731e-01) (1, -1.17159372818436038899e-01) (2, -2.78689923405307550530e-02) (3, -1.17156057310070407795e-01) (4, -8.05545809387821082348e-02) (5, -9.57112740939689047082e+02) (6, 5.72345207451308013447e+00) (7, -1.99732300618175456774e-01) (8, -2.71069315702557600556e-02) (9, -1.28057945134679662669e-01) (10, 2.14524982016980501551e-03) (0, 6.04541720245743569029e-02) (1, 4.12578038946321210001e-02) (2, 1.60384528413942059610e-02) (3, -2.78621017182562914771e-03) (4, -2.26051159128019679700e-02) (5, 2.91902181130200100156e+00) (6, -4.76957562437842668146e+01) (7, 1.50610379621756829138e-01) (8, 1.74880477131069134167e-01) (9, 1.12705806858918677893e-01) (10, 2.94906576573374969163e-02) (0, 7.02931593959799982940e-01) (1, 5.79925525274341602255e-01) (2, 5.31772393074100513388e-01) (3, 6.91132138755386149498e-01) (4, 7.01451788928573405357e-01) (5, 3.42390684981101978135e-01) (6, 3.04399136556262250863e+00) (7, 6.24615365516083542730e-01) (8, 7.69399571023381301238e-01) (9, -3.14229669978469150493e+00) (10, 8.03183186299739282354e-01) (0, 6.64646785563058450919e-01) (1, 5.70523672621895627799e-01) (2, 6.62648730796028706536e-01) (3, 6.17119409959961728873e-01) (4, 6.39732413809944944205e-01) (5, 4.11282102232476243220e-01) (6, 3.99192581032534921093e+00) (7, 6.47130492607497997959e-01) (8, 7.83189044676245615939e-01) (9, -3.14719293742334160768e+00) (10, 6.58756205984381670859e-01) (0, 1.07265899690395065391e-02) (1, 6.98288029849713220987e-02) (2, -1.07573771059329137412e-02) (3, 6.78735769212429618236e-02) (4, -1.62527167379672259073e-02) (5, 3.16695005844471744183e+00) (6, -2.43757250184509466351e+01) (7, 1.60254374542369959489e-01) (8, 1.08716803134143655263e-01) (9, -1.11956125100830944374e-01) (10, -2.68427826839324305819e-02) (0, 5.48876860791009946183e-01) (1, 5.88249471997264961054e-01) (2, 5.98376077627185920527e-01) (3, 6.11232251887563804438e-01) (4, 6.03173629408125022699e-01) (5, 7.46133169719747191273e-01) (6, 4.11914621913288847566e+00) (7, 5.86313606205671189464e-01) (8, 7.30759010992468760470e-01) (9, -2.90300072478678528043e+00) (10, 5.20230287858275519675e-01) (0, 1.81092675699701621816e+00) (1, 5.49503759580714290500e-01) (2, 5.49141601759059017063e-01) (3, 5.78151361185175738377e-01) (4, 5.08948222833735530735e-01) (5, -1.00979776732127524141e+00) (6, 9.80874403905057761222e+01) (7, 3.22959020758444026455e+00) (8, 9.62725063060106300838e+00) (9, 6.73627666438703265328e+00) (10, 5.74980070563119283200e-01) (11, 6.09158721809014092052e-01) (12, -2.41757844361060347804e-01) (13, 4.32793950408095928761e-01) (14, -7.90789737621441446436e-01) (15, -7.86484215238666961589e-01) (16, -2.50903730067008168270e-01) (17, -2.05132480141608869451e-01) (18, -2.60646433805918786852e-01) (19, -1.85982030602687198328e-01) (20, 4.50324823825950237843e-01) (21, 4.37524486592360151160e-01) 
