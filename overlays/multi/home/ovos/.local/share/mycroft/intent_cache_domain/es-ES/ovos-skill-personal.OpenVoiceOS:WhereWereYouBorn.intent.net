FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.11960187708062380851e-01) (1, 4.48445636465884395205e-02) (2, -5.99769618675374260874e-02) (3, 5.06299841835833736026e-02) (4, -4.84367426798009009792e-02) (5, -6.75042098147392799490e+00) (6, 1.05265991730526797809e+00) (7, 1.39092255397944397632e-01) (8, 2.23890980601820643869e+00) (9, 2.12118011939276367162e-02) (0, -6.54447570701854552944e-01) (1, -5.58214171788176255484e-02) (2, 2.63814196923295510300e-02) (3, -3.13952176830252296935e-02) (4, 7.45227650740662855844e-02) (5, 1.36444199248198660968e+00) (6, 2.35704937928086277754e-01) (7, 5.31643445889764670875e-02) (8, -3.19539594406644533731e-01) (9, -2.25310225860069796022e-01) (0, -5.69677993913905944545e-01) (1, -6.67497090062578873892e-02) (2, 1.95360348561326516159e-02) (3, -1.10282307769962131805e-01) (4, -2.94348209163626355067e-02) (5, 1.44289175262028956936e+00) (6, 1.05184646301632891974e-01) (7, 5.07922734420114402321e-02) (8, -2.10312264914075619515e-01) (9, -1.62125927285145271517e-01) (0, 4.08592299355427290841e-01) (1, -1.82511836867254931271e-02) (2, -4.20974039118212350896e-02) (3, 9.78282287139970174739e-02) (4, -8.69187817554396280340e-02) (5, -6.01692538169714241647e-01) (6, -6.79093851975925005826e-02) (7, -1.32585294895705113616e-01) (8, 3.05498622934264107975e-01) (9, 1.30777049252297633553e-01) (0, -6.97614348162194186642e+00) (1, -2.83813167526635379279e-01) (2, -2.31316808774384680136e-01) (3, -3.42279952182683200324e-01) (4, -3.93938686861905196235e-01) (5, 1.75421715643173348198e+00) (6, 9.89113259448655357531e-01) (7, 1.12168649250479535162e-01) (8, 7.74840696262051875642e-01) (9, -1.53834770047021451855e-01) (0, 1.23048085603052270720e+00) (1, 1.45035022719868278429e+00) (2, 1.56931258215674018786e+00) (3, 1.39586027934321021959e+00) (4, 1.46133761330612754747e+00) (5, -6.71245965132440236545e+00) (6, 7.52551021010373322184e+00) (7, 3.98803611134737989730e+00) (8, 3.66983664885424643032e+00) (9, -2.30142002537373213666e-01) (0, 2.24230147565313314706e-01) (1, -9.87241075019758829168e-02) (2, -4.55960214714926370672e-02) (3, 3.06586667318421574047e-02) (4, -9.88863289933127054265e-02) (5, -5.32733638713442925194e-01) (6, -2.48190675676986854947e-01) (7, -3.99815965228642045126e-02) (8, 2.06575391164842775416e-01) (9, 7.26718739676177477582e-02) (0, -9.02906241477970716858e-01) (1, -1.41042915940911284256e-01) (2, 4.13579365008763522038e-02) (3, 4.05051281445912569890e-02) (4, -8.47233737117357860180e-02) (5, 1.45811439146573329495e+00) (6, -7.64835897123265356923e-02) (7, 3.22637632921114886342e-02) (8, -2.02873292321721798714e-01) (9, -1.32529939049669642781e-01) (0, 2.19702524389285502870e-01) (1, -4.11095873098295816472e-02) (2, 2.79861583728867741039e-02) (3, -7.27006152849119791082e-02) (4, -3.10689539294165331662e-02) (5, -6.88356693295332222604e-01) (6, -7.91297807626254595670e-02) (7, -9.95923060708607532643e-02) (8, 4.00085289607686023228e-01) (9, 1.27317792277306329751e-01) (0, 2.05911320890445198595e-01) (1, -8.53489444236677774480e-02) (2, 3.00857617874222965648e-02) (3, -1.35711983423155487655e-02) (4, 4.73192825336533756664e-02) (5, -5.58651823011728443369e-01) (6, -1.00056558974683088015e-01) (7, 1.52129229373370658540e-02) (8, 1.49714757816662741297e-01) (9, 5.63315958785712694867e-02) (10, -2.32974446989362898863e-01) (11, 4.38726484484361134442e-01) (12, 4.31698876240669160431e-01) (13, -1.91280788079056740525e-01) (14, 9.33667984066376854813e-01) (15, 1.25581407410724654738e+00) (16, -1.51678483026981392179e-01) (17, 3.81609531858383088654e-01) (18, -1.65100570514901373587e-01) (19, -1.68018215789517783021e-01) (20, 3.22971162653304610934e-01) 
