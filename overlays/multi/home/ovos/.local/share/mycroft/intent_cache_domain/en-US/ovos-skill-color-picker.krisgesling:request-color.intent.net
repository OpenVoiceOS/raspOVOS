FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.54127204482740187697e-01) (1, -9.87010472212916240009e-02) (2, -7.46736102496271675344e-02) (3, -2.01271018454897893113e-01) (4, -1.10616954485047422341e-01) (5, 2.16262608776382841969e-01) (6, 8.37118999642570138509e-02) (7, -1.04461469523858568875e-01) (8, 3.49815196118694027305e+00) (9, -2.56239868994380726175e-01) (10, -3.81187327791067953608e-01) (0, 1.80960632727806297604e-01) (1, -2.48633791159696068696e-02) (2, -8.58320240329809303059e-02) (3, 3.41858472276621583319e-02) (4, -9.35904179166860694661e-02) (5, -5.47067025507346274549e-02) (6, 8.57631144265837003227e-02) (7, 6.09400270843026559131e-02) (8, -4.51504804593011010994e-01) (9, -6.98828748997405296839e-02) (10, 2.81679872762889749183e-01) (0, 9.24985232126296075261e-02) (1, 5.26501668269968650660e-02) (2, -6.99763687674665041394e-02) (3, -5.98243050023550184541e-03) (4, -9.89077411338323830847e-03) (5, -6.33520023728267184238e-02) (6, -4.46049061557160925195e-02) (7, -1.79677944699172635612e-02) (8, -4.01105064279920597858e-01) (9, -2.07678794204004701918e-01) (10, 2.92836510681934281131e-01) (0, 1.40568230311008290911e+00) (1, 1.01732873943920232307e+00) (2, 9.73806232486917333624e-01) (3, 9.64147948001577215216e-01) (4, 1.14085174379224851826e+00) (5, 4.60958752149357220418e+00) (6, 1.29286389996029482674e+00) (7, 8.30724104491696313524e-01) (8, 3.26924984418043385048e+00) (9, 6.76925028546010665309e-01) (10, -3.46743752533555549267e-01) (0, 6.07505779360025810476e-01) (1, 4.94476203215610976560e-01) (2, 4.33919936758768554075e-01) (3, 5.18885638905060120329e-01) (4, 4.77001954210293288572e-01) (5, 5.17780843810256796722e-01) (6, 9.72260912255650810998e-01) (7, 6.13241136967111910572e-01) (8, -4.42258468137220273064e+00) (9, 7.23058257692344108492e-01) (10, 1.77202542780811073131e-01) (0, -1.88783515755979069972e-01) (1, -2.70063316052944979440e-01) (2, -2.05124599462540524453e-01) (3, -2.49154788976700625192e-01) (4, -2.19262940412552731484e-01) (5, 1.94819871974495351097e-01) (6, 9.59035624003862496867e-02) (7, 2.01153888020978388607e-01) (8, 3.42427078723154876272e+00) (9, 2.75625610147583244292e-01) (10, -5.12333091301632959080e-01) (0, 5.30021306204674913509e-01) (1, -7.45326515633154967899e-02) (2, -8.50915696817923783435e-02) (3, 2.88713562887620289743e-02) (4, -5.85319299596835027066e-02) (5, 8.28510035162273728027e-02) (6, 1.37411551350668736937e-01) (7, -5.03759771866324410072e-02) (8, -4.25364369027643351995e-01) (9, 3.02791602742246646063e-01) (10, 3.23825194550259598536e-01) (0, 1.44898236552806691790e+00) (1, 9.64420654152585821173e-01) (2, 9.86673683201028661749e-01) (3, 1.01659899977321721565e+00) (4, 1.11827770647878721455e+00) (5, 3.50692277500825877468e+00) (6, 1.38657821167923578365e+00) (7, 8.48003178087696873888e-01) (8, 3.40353009420100027782e+00) (9, 6.98667655570661239040e-01) (10, -3.89676952586696156988e-01) (0, 5.58322880063742310597e-01) (1, 5.15287866989255882721e-01) (2, 4.44133548239351527709e-01) (3, 5.21845420995832642852e-01) (4, 5.10381600061536988555e-01) (5, 5.91114523929112789524e-01) (6, 1.26977943042905594417e+00) (7, 3.71372103813297549380e-01) (8, -4.50372698328172305082e+00) (9, 3.33001485202552793830e-01) (10, 2.64489188628251992164e-01) (0, 2.82934269445504656126e-02) (1, -3.88681486822485058874e-02) (2, -7.61781827188848792431e-02) (3, -2.63452500678419132552e-02) (4, -4.68813486970781415075e-02) (5, -6.73541794496989865149e-02) (6, -5.54276421611979985826e-02) (7, 5.69824516924289301012e-02) (8, -4.11835700313666341899e-01) (9, 6.57459442193514403963e-02) (10, 3.47105604170791559593e-01) (11, 9.42541018354869364337e-01) (12, -2.98066633440567330116e-01) (13, -2.32800988033588063253e-01) (14, -2.84724347838257230148e-01) (15, 8.10810878028035086906e-01) (16, 9.35711161792810774962e-01) (17, -3.47121603529166877777e-01) (18, -3.04695209363306906969e-01) (19, 7.72676698386596028101e-01) (20, -6.45674943291710046189e-01) (21, 3.47271053112942318375e-01) 
