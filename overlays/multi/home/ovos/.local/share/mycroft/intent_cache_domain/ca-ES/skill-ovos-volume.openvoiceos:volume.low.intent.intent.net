FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.80140550545424671380e-01) (1, 8.00510074613011574085e-02) (2, 7.58023883817113136585e-02) (3, 6.43017400478489847826e-03) (4, -2.59484920981012945340e-02) (5, -4.22090689368412493032e-03) (6, 3.06514215549820237539e-02) (7, 1.17958117108410379115e-01) (8, 3.08462931519505392797e-02) (9, -9.32884398267687722783e-03) (10, -1.27598585388627533410e-01) (0, 2.15178032834006538465e+00) (1, 3.38702904872017540594e-01) (2, 3.49992818079310041846e-01) (3, 4.01604159615355171820e-01) (4, 4.69210601291971840521e-01) (5, -9.57406497466665840079e-01) (6, 6.40295757596744508078e-01) (7, -2.78641443428755075651e-01) (8, 5.20588894413876679401e-01) (9, -6.57579766457053871420e+00) (10, 1.83765722795438485315e-01) (0, 1.16281523671520385932e+01) (1, 3.75091674213168912999e-01) (2, 3.65247937326190763585e-01) (3, 4.49995154921768003575e-01) (4, 3.51032602076289945714e-01) (5, 3.97976149083253760708e+00) (6, -4.50146361831710237200e-02) (7, 1.50564437550461978077e+01) (8, -3.28777248610773398241e-01) (9, -8.11187164967281049144e+00) (10, 1.12107482132961261412e-01) (0, 2.48208108109912739536e+00) (1, 3.61996912070326748445e-01) (2, 3.30057629056982937410e-01) (3, 4.54131290920786800935e-01) (4, 4.98636291035227718904e-01) (5, -1.08939083541896186702e+00) (6, 5.85738699309672261606e-01) (7, -5.66540978172132558832e-01) (8, 5.53084844903109384973e-01) (9, -6.47553079818460197714e+00) (10, 1.67592878345733470313e-01) (0, 3.11202723807146277579e+01) (1, 3.62794574193827989994e-01) (2, 4.41859457485549333988e-01) (3, 3.63009776763789537846e-01) (4, 4.14196658723227861820e-01) (5, -2.04281534333851366725e+00) (6, 5.53744533613493183921e-01) (7, -6.59573970202859705125e+00) (8, 4.13394284732418959560e-01) (9, -4.45854012903602603402e-01) (10, 1.14760947848247418790e+00) (0, 2.14810011777950515821e+00) (1, 2.59045251852908997581e-01) (2, 4.02026058382430884208e-01) (3, 2.83503395713010641899e-01) (4, 4.41344754046836706962e-01) (5, -4.93395684839698644986e-01) (6, 5.95128115653662970175e-01) (7, -5.54814501920053659845e-01) (8, 4.98244286984529105577e-01) (9, -6.54127018252396474907e+00) (10, 1.74872302192125100850e-01) (0, 4.84668111839239024174e-01) (1, 4.45312933693269685786e-01) (2, 4.24452917347291902583e-01) (3, 3.13709729979375850917e-01) (4, 3.48374711046556428951e-01) (5, -9.64290767650619717877e-01) (6, 4.82528513720471730064e-01) (7, -4.52826472497262155770e-01) (8, 5.49936377139168874884e-01) (9, -6.45259724820049296312e+00) (10, 7.62412811017083164034e-02) (0, -6.55341937647004102452e-01) (1, -7.57832864807913980654e-02) (2, 5.36097024990250664578e-02) (3, -3.12009104955892615715e-03) (4, -6.48469219492743415012e-02) (5, -1.26593276210934281567e-02) (6, -7.16404816825194495911e-02) (7, -1.02226403096688997496e-02) (8, -1.89609506289693086067e-01) (9, 1.76362554250830361191e+00) (10, -7.30995180225043061917e-02) (0, 5.12623920317026193771e+00) (1, 1.38730904563743884239e+00) (2, 1.33864434912283236656e+00) (3, 1.30967669292766863975e+00) (4, 1.42753447696049029503e+00) (5, 3.26569220826012696079e+00) (6, -4.57816038037155426110e-01) (7, 1.49395640012777537464e+01) (8, -1.40743667830744628722e-01) (9, 3.77957773396843910163e+00) (10, 4.96975238806229638322e-02) (0, -5.90717845631800964057e-01) (1, 2.69302139245893926156e-02) (2, -9.40911536849114993331e-02) (3, 3.74447861873533627275e-02) (4, -9.71843218243692019698e-02) (5, -1.12784289307326479612e-01) (6, 1.83515348713593588748e-02) (7, -8.82447179893030286824e-02) (8, -1.06820331077309760293e-01) (9, 1.75801335542076775376e+00) (10, -7.67905183629486592922e-02) (11, 5.87732975422120995646e-01) (12, -1.66588262156800392955e-01) (13, 4.39725774844530736818e-01) (14, -1.59276318238333824961e-01) (15, -4.05735093059555129713e-01) (16, -1.59913376406983498423e-01) (17, -1.34881259006850967586e-01) (18, 3.68986230811597426538e-01) (19, 4.52359001225122736578e-01) (20, 3.90289627483607626246e-01) (21, 2.73519829426480232115e-01) 
