FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=8 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (8, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.76899294573744736425e-01) (1, 1.94394381306419616884e-01) (2, 2.98808464370021953371e-01) (3, 2.17220404706249481386e-01) (4, 2.26660394630680328554e-01) (5, -1.38360126130838523295e+00) (6, -5.34707433220876993119e-01) (7, 2.59078961834335180781e-02) (0, 1.02690143118381249643e+00) (1, 4.36829784073821253410e-02) (2, 9.11235147275916146370e-02) (3, 3.79229941525450892081e-02) (4, 7.48967834868422693839e-02) (5, -2.39826019260420575385e-01) (6, -3.46509833458199634215e-01) (7, 2.06650920910124102914e-01) (0, 2.10526468232908348099e+00) (1, 3.82714449260895317462e-01) (2, 4.06423448417847221759e-01) (3, 4.48114349339668815997e-01) (4, 3.37708516810600878344e-01) (5, 4.53692652043175925769e+00) (6, -9.59706952029118487424e-02) (7, -1.64348909276158028359e-01) (0, -5.51358761156464094455e-01) (1, -9.37363467065441269277e-02) (2, -1.30969639763032108526e-01) (3, -2.32293438061867890676e-01) (4, -1.70458365127240302206e-01) (5, 1.24672154602198959061e+00) (6, 2.98335393946147997557e-01) (7, -7.40763457580119050183e-02) (0, 2.08923431486525634782e+00) (1, 4.07708073846330287804e-01) (2, 4.18034757367601039757e-01) (3, 4.28838881544103267540e-01) (4, 3.80786138466825130333e-01) (5, 4.63849772270989646472e+00) (6, 4.91895104593386076064e-02) (7, -1.12767858573915497056e-01) (0, 8.37259188064293446985e-01) (1, 6.99082137205592202278e-02) (2, 4.11231302776328272452e-02) (3, 8.03244606711855935188e-02) (4, 1.18883163587092513525e-01) (5, -1.79841286841168152000e-01) (6, -4.12353497567906457366e-01) (7, 1.99900858802084246957e-01) (0, 1.74094399713490921577e+00) (1, 4.02852806700207399793e-01) (2, 3.75923800719715761609e-01) (3, 3.52708223713375734754e-01) (4, 2.81480911625363094952e-01) (5, 4.72546824422722444581e+00) (6, -1.50850996912113211046e+00) (7, -4.28542584301073115061e-01) (0, 1.69811246082190558937e+00) (1, 2.58455099936425014562e-01) (2, 3.15509030993878225591e-01) (3, 2.84938516493737081792e-01) (4, 4.31748548921047914373e-01) (5, -2.98208173948887012017e+00) (6, -7.26172706158291769718e-02) (7, 3.53128112409843486486e-01) (0, -1.49570710393927375215e+00) (1, -7.81176812457484298635e-02) (2, -1.19139415721837907403e-01) (3, -2.68131492237989266236e-01) (4, -9.79183889436167770315e-02) (5, 1.33257625159304127216e+00) (6, 3.92216861146318207521e-01) (7, -9.50906373724750425547e-02) (0, 8.56037884656916103765e-01) (1, 1.66463465950737243837e-01) (2, 1.78105445168266540712e-01) (3, 2.20253744683513885683e-01) (4, 2.75423148236522863375e-01) (5, -1.33067215737619970461e+00) (6, -5.56238851186766081192e-01) (7, 1.58954862229528370854e-01) (8, -4.57067599647667355267e-01) (9, -4.46514128099377710646e-02) (10, 3.47426753074484895301e-01) (11, 7.25770945193986660726e-01) (12, 4.09192803830462525916e-01) (13, -3.99738191018994548642e-02) (14, 3.89478334765098910264e-01) (15, -1.44868295535241248251e-01) (16, 5.86940306804429101639e-01) (17, -3.32078712429015376895e-01) (18, 3.73700730730096686294e-01) 
