FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.34411560582842598555e-01) (1, 3.33764850520816558355e-01) (2, 4.09325099909034484380e-01) (3, 3.32584149563041442388e-01) (4, 3.06043311381068938726e-01) (5, -1.34185781235533552191e+00) (6, -1.28998117799597578070e+00) (7, 1.26252160515177056510e+01) (8, -1.25281387473183469794e+00) (9, -1.61169702151376048604e+00) (0, 2.45993675004463063782e-01) (1, 2.01567211722960722142e-02) (2, 9.23034274553885675241e-02) (3, 5.92987263178458498536e-02) (4, -8.08504358176085832777e-03) (5, -9.88295942306786079357e-02) (6, 8.09327045858999616357e-02) (7, -7.61239010312050368157e+00) (8, 9.73998846889635450097e-02) (9, 1.56756879615893018887e-01) (0, -4.79648952175914189411e-01) (1, -3.78931636574600036460e-02) (2, -1.48300031817230948405e-01) (3, -1.45405436551842459636e-01) (4, -2.20536376035485037761e-01) (5, 2.46418505641336112177e-02) (6, 7.05667692658573514342e-02) (7, 4.59739437827550290194e+00) (8, -9.83905470642407187221e-04) (9, 9.05562448737293607115e-02) (0, 1.10641646536348092766e+00) (1, 5.34606038666714744600e-01) (2, 3.88699448741425646059e-01) (3, 5.49952223039616883149e-01) (4, 4.45476397014607561342e-01) (5, 2.45028955436695478065e-01) (6, 2.21887838240762025332e-01) (7, -5.10445890698659265894e+00) (8, 2.85983041074176214114e-01) (9, 2.56789481066684144306e-01) (0, 1.04495804162976968499e+00) (1, 4.09614737219561708681e-01) (2, 4.51507813371171129457e-01) (3, 4.40492241717328203432e-01) (4, 5.16219808794011192354e-01) (5, 2.90140435244937322512e-01) (6, 2.95752622332473180666e-01) (7, -3.78890761892427363478e+00) (8, 1.99111640598674144442e-01) (9, 2.45164347611884436695e-01) (0, -4.82346673299609562946e-01) (1, 9.62145921143313723189e-03) (2, 2.05757647410275516797e-02) (3, -1.50984448228752426990e-01) (4, -1.13497734849130907375e-01) (5, 8.30126940938348267807e-02) (6, 1.31546143018928196611e-01) (7, 4.63107046613179562655e+00) (8, 8.25805846092373257994e-02) (9, 1.48848462426391270341e-01) (0, 5.93785983851776499876e-01) (1, 2.01102965130428801288e-01) (2, 2.39635967268566618671e-01) (3, 1.79223433687309807727e-01) (4, 1.83249250604729241321e-01) (5, -1.10693589733024774779e-01) (6, 7.92892478321331334312e-02) (7, -9.18659145445487324011e-01) (8, -1.08622179315468012084e-01) (9, -1.94496140734976008524e-03) (0, -4.77349539090930363727e-01) (1, -7.55330050947997794220e-02) (2, -8.29663152458999381134e-02) (3, -1.90126861131462820964e-01) (4, -2.02846693492207297282e-01) (5, -2.00101569560652246815e-02) (6, 1.36796343648162510576e-01) (7, 4.63525910803758023349e+00) (8, 7.74726006624370938658e-02) (9, 1.68690729462829258622e-01) (0, 2.02205855085750396682e-01) (1, -8.41939499743579872204e-02) (2, 4.16162894896865837024e-02) (3, 1.81822465590835632976e-02) (4, -6.67473873265384681774e-02) (5, 4.12842499495645956498e-02) (6, -2.23266303301125103309e-02) (7, -1.28051751922356888969e+01) (8, 9.07032492158121178560e-03) (9, -1.21459816372421314234e-01) (0, 2.96583459984283259736e-01) (1, -3.09286391759285295144e-02) (2, 8.13142681097617364694e-02) (3, 6.02612593745818422852e-02) (4, 4.25936230992903924752e-02) (5, -1.48509946441677143092e-01) (6, 1.40494415390600813076e-01) (7, -7.65271603532522703972e+00) (8, 1.59708918857683790371e-01) (9, 1.54171081113924635098e-01) (10, 4.41725400473202023388e-01) (11, -4.62428700506851003693e-02) (12, 4.68047819326375069693e-01) (13, -1.16809959209236868816e-01) (14, -1.03281999624047063358e-01) (15, 4.43629208915651773726e-01) (16, -2.90761614802215392905e-02) (17, 4.18673705273092722212e-01) (18, -7.63959190018772132946e-02) (19, -8.35911524721665022408e-02) (20, 5.65176851760812892778e-01) 
