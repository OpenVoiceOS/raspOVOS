FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.68218323299037619822e-01) (1, -2.59574745730667827415e-02) (2, 8.99989707905954165745e-03) (3, 5.94492684169501475755e-02) (4, -6.11003060774117229270e-02) (5, 3.56795322393782532444e-01) (6, -6.57750586019103256064e+00) (7, -7.93376401012736015561e-02) (8, 3.78807871743909452267e-02) (9, 2.37349758874073751835e-01) (10, 3.10105794085519526071e-01) (11, 2.62281855078520476088e-01) (12, 6.22757085666457710360e-01) (0, -8.62952949612496311715e+00) (1, 5.40984339629925425896e-01) (2, 4.46161508178031851468e-01) (3, 5.54164446508206065545e-01) (4, 4.35957356905258108792e-01) (5, 1.05713653341797875207e+00) (6, 4.60857566861356993115e+00) (7, 2.26418310179086024192e+00) (8, 3.89304708329145565671e+00) (9, 7.13426515646145786853e-01) (10, -6.69359176152207524524e-01) (11, 5.04660398265802179196e+00) (12, -1.47063197592460670471e+00) (0, 4.50818103262530966990e-01) (1, -3.11605827372365843178e-03) (2, -2.11398658291607546844e-02) (3, 7.00285564227790258141e-02) (4, 3.70943899317473652077e-02) (5, 2.50940483307249717626e-01) (6, -6.69454133854453292685e+00) (7, -1.20030122244914133622e-01) (8, 8.80621729440102668507e-02) (9, -1.70227426471267873076e-01) (10, 3.01605486546992540564e-01) (11, 3.51805915566267723982e-01) (12, 5.86278470692877085035e-01) (0, -7.00258880404005412679e-01) (1, 1.43808183017312286173e-03) (2, 1.48277268379359755679e-01) (3, 1.01203248470454865160e-01) (4, 1.15654051869540863695e-01) (5, 4.11593276670253860328e-01) (6, 4.80815200006605714123e+00) (7, 2.98322436286468761768e-01) (8, 1.03641622740615335641e-01) (9, -2.54222740696692428575e-01) (10, 2.08669985729980828060e-01) (11, 7.45245443292121501067e-01) (12, 2.93329361371775121370e-01) (0, 1.92077090102578851294e+00) (1, 1.62572977664163342837e-01) (2, 1.48790193321397534731e-01) (3, 1.53858704092195264224e-01) (4, 1.27566657683160222803e-02) (5, 1.38495910212571593512e+00) (6, -1.63109803043308554393e+00) (7, 4.56870242864460485155e-01) (8, 4.72422292541311794611e-01) (9, 9.94110078271807418027e-01) (10, 2.41704814369641773908e+01) (11, 1.64277885952306101913e+00) (12, 3.82879639020259482374e-02) (0, 5.50745105281936875308e-01) (1, 6.63201663010806047316e-02) (2, 8.33407569044322671381e-02) (3, -6.66521458690459613766e-03) (4, 1.39779903303930197467e-01) (5, -1.54929104849031190616e-01) (6, 1.33750290830949442045e-01) (7, 8.60403048550639759640e-01) (8, 8.79959994485511654005e-01) (9, -4.72949859925351871748e-03) (10, -2.96838056184316884112e-02) (11, 3.97081396976447120739e-01) (12, -2.67778790606398552077e-02) (0, -7.05102499008258831736e+00) (1, 4.66053840626055371210e-01) (2, 3.99572518575960433651e-01) (3, 4.59681500602537485012e-01) (4, 5.59150052178675083248e-01) (5, 1.06413133382160340901e+00) (6, 4.47223551181251366415e+00) (7, 2.53062599018140144125e+00) (8, 3.86142302769815071173e+00) (9, 4.83565039853060929520e-01) (10, -1.05895303510680349746e+00) (11, 1.54904790090157629123e+00) (12, -3.74751593272729388584e-01) (0, 1.15909258307623086459e+00) (1, 2.28981921508004448995e-01) (2, 1.87125938071896757986e-01) (3, 1.42791735067059721853e-01) (4, 1.89914265706231322195e-01) (5, 1.49405276952111032429e+00) (6, -2.51436382417261761191e+00) (7, 8.43752987727716563526e-01) (8, 1.37432565391004429811e-01) (9, 3.84678204452236105482e-01) (10, 2.41989698163949498166e+01) (11, 5.76348013606855502644e+00) (12, -1.52755162461046846423e-02) (0, -1.25339782966157486932e+00) (1, -2.58767496469191449204e-01) (2, -2.40550856712035021623e-01) (3, -3.48698634329012768784e-01) (4, -2.63448912325075945695e-01) (5, 1.07901666044286770330e+00) (6, 7.92303052212698144530e-01) (7, 6.13664463939366577883e-01) (8, 1.19593931913578366277e+00) (9, 6.04482845800615176124e-01) (10, 1.02918313691490511536e-02) (11, 9.06575139474719349231e-01) (12, -7.11016015915995613916e-01) (0, 5.42701824076465610958e-01) (1, -5.46794365764709522360e-02) (2, 3.16199157713798403857e-02) (3, -7.93545748711678017306e-02) (4, 8.99927709578421941572e-02) (5, 1.14780373515856459754e-01) (6, -9.95846030366588252924e-01) (7, -1.29285168114324222621e-01) (8, -2.62654221908088847393e-01) (9, -4.89130453966413358824e-01) (10, -1.22859722155560180390e-01) (11, -1.95919146336242300244e-01) (12, 7.32552802749990572551e-01) (13, -4.57042957978028796528e-01) (14, -1.90042971894209961059e-01) (15, -5.70745635201105883105e-01) (16, -1.78828006677714847206e-02) (17, 5.08718259944275441597e-01) (18, 3.52872022653118511126e-01) (19, -2.07985475101236549911e-01) (20, 7.06538749157766710063e-01) (21, 1.27396976930953287344e+00) (22, -5.65825748165642017362e-01) (23, 4.10912495024736423854e-01) 
