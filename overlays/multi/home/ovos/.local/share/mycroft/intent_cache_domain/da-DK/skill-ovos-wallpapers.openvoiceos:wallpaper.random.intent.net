FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 5.85796646487085670429e+00) (1, 6.71410916446004923941e-01) (2, 6.49769885538374003531e-01) (3, 5.86832152752433833243e-01) (4, 6.29039591251169150077e-01) (5, -5.56916647063788738947e-01) (6, -4.39092079906413434998e+00) (7, -1.20117104838960964130e+00) (8, -1.76129799438489653696e+00) (9, 2.39260413657368414819e-01) (0, 4.07605287989737874454e+00) (1, 7.49570433946162628658e-01) (2, 6.84305150957614349849e-01) (3, 6.83696371467620300777e-01) (4, 7.23968197556048798091e-01) (5, -1.33208741595378932221e-01) (6, 7.74059895412873011367e-01) (7, 1.92243097061839440798e+00) (8, 4.14035720709653531912e+00) (9, -1.04925791553005698376e+00) (0, 7.10242138641341291816e+00) (1, 6.44908460011290873837e-01) (2, 6.37951130201625193905e-01) (3, 5.41528666546153392147e-01) (4, 6.89104037513541434201e-01) (5, -4.65422936188277514002e-01) (6, -4.38141574694464086548e+00) (7, -1.20007438253038722920e+00) (8, -2.11571559881763793243e+00) (9, 2.46147275830078199332e-01) (0, -5.11130814191912996591e+00) (1, -5.25155579720334886318e-01) (2, -5.29669305358724473720e-01) (3, -4.50079066727952614713e-01) (4, -4.77783052299813992825e-01) (5, 5.05403709466418327168e-01) (6, 3.70820459799465984574e+00) (7, 5.29315415228433172601e-01) (8, 8.27846473037949337481e-01) (9, 5.67984597288580250751e-03) (0, -3.77221652311181010475e+00) (1, -1.79531529559005154084e+00) (2, -1.78614702833999050569e+00) (3, -1.75535538060773266267e+00) (4, -1.67689384533275021028e+00) (5, -1.72855055148709635393e-01) (6, -1.53976324315188151104e-01) (7, -1.73928088179806161762e+00) (8, -3.82699646274843485738e-01) (9, 2.05411255970883097066e-02) (0, -6.08641540365476174657e+00) (1, -5.29047390495138047939e-01) (2, -5.35283876632051347499e-01) (3, -6.13809859429197191005e-01) (4, -5.17368977938489793544e-01) (5, 3.69462956542929765735e-01) (6, 3.83596751914915889969e+00) (7, 4.99234560335702237666e-01) (8, 8.93002381503334774493e-01) (9, 1.30964659317364395807e-01) (0, -3.80584069532250346413e+00) (1, -4.02213583914259042995e-01) (2, -4.67741708485105545101e-01) (3, -5.35107511309602768002e-01) (4, -4.20834834901311960476e-01) (5, -2.54011799746889699314e-01) (6, -1.09377777261038389156e+00) (7, 8.88493147548601536201e-01) (8, -4.25673894803324071034e-01) (9, -2.59927959346909154270e-01) (0, 4.09795581361415273136e+00) (1, 7.57865493150264191158e-01) (2, 6.45478104205638336666e-01) (3, 6.48574990184813904293e-01) (4, 6.35817808063537048824e-01) (5, -1.78236608554950687333e-01) (6, 7.31000732617329340712e-01) (7, 1.88178228671279290651e+00) (8, 4.23890723013947212650e+00) (9, -9.04381167206616654042e-01) (0, -3.91988274645899714699e+00) (1, -1.79851653440106762361e+00) (2, -1.76510050160992992829e+00) (3, -1.72587791843522442292e+00) (4, -1.78086859373558414887e+00) (5, 3.58701664675403807461e-03) (6, -1.50716069455263834698e-01) (7, -1.81579070023277688861e+00) (8, -3.21585677783289225484e-01) (9, -8.83428187486431926168e-02) (0, 1.87998925778321024360e+00) (1, 8.97092596940098685465e-01) (2, 8.45787615827618299846e-01) (3, 9.28757378212509809856e-01) (4, 9.24178996435700117473e-01) (5, -4.96106424014724767257e-01) (6, 7.38731537503031665537e-01) (7, 1.73041573903563739023e+00) (8, 3.67814112515454150198e+00) (9, -8.49942603793537143630e-01) (10, -4.17191119351743466837e-01) (11, 4.58573135283048216593e-01) (12, -2.80932642530321907692e-01) (13, 6.61982957420969242435e-01) (14, -7.17344069612525225832e-02) (15, 6.70621428785944218021e-01) (16, -1.92460312857237192397e-01) (17, 4.31027251031453673136e-01) (18, -5.77473619501824991795e-02) (19, 2.30111480691124609121e-01) (20, 5.47222851672171994863e-01) 
