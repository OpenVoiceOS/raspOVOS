FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.84662549702689582354e-01) (1, -2.00443182721849577632e-01) (2, -2.34944768831249373164e-01) (3, -2.82108005717512211330e-01) (4, -1.23758022323366287387e-01) (5, -2.53507951124625119377e+00) (6, 1.52105766954746313147e-01) (7, 7.01395405604891775120e-01) (8, -1.51402882425134444055e-01) (0, -2.69306898120806437191e-01) (1, -1.65710985157798695866e-01) (2, -2.53475844357322621647e-01) (3, -2.37056686971496510807e-01) (4, -1.52859605346034876927e-01) (5, 1.11981659485926710040e+00) (6, 2.83260980319237909431e-02) (7, 2.08893086658998056171e-01) (8, -9.27975917795409305233e-02) (0, 1.22784263734571830184e+00) (1, 2.94883897433301789270e-01) (2, 2.85632150152942521082e-01) (3, 2.81202910373231751429e-01) (4, 3.51381750682613236414e-01) (5, -1.05580809948915343988e+00) (6, 2.28640696624981848428e-01) (7, 1.09719314305577186897e-01) (8, 6.46478336250978224964e-02) (0, 1.28078112845175162704e+00) (1, 1.72684267966006388395e-01) (2, 1.60357409028266062467e-01) (3, 4.76130031625968119791e-02) (4, 1.10320732800219645231e-01) (5, -8.84665539656841137806e-01) (6, 1.28423197786080328653e-01) (7, 2.75475476853674128286e-01) (8, 1.27805362263937516420e-01) (0, 3.26363196364597429877e-01) (1, 7.24852109307670411376e-01) (2, 6.16949582452201661376e-01) (3, 6.17917934412383851317e-01) (4, 7.21006298417472657469e-01) (5, 3.94109615474936614277e+00) (6, 1.62956004870757897862e+00) (7, 1.01815675869114510843e-01) (8, -3.71102067500906462882e-01) (0, 3.26902186266140093451e-01) (1, 6.63608039504766433758e-01) (2, 5.19159029013395167951e-01) (3, 4.66679612881421790327e-01) (4, 5.75041840559720962567e-01) (5, 3.87906791806218276264e+00) (6, 7.90942392939348759562e-01) (7, 2.49278245046265251039e-01) (8, -4.22446961373644347404e-01) (0, 1.19975122903339759262e+00) (1, 3.54823993424198014246e-01) (2, 3.57610525468608719812e-01) (3, 2.35990257838985195704e-01) (4, 3.19196285585185868250e-01) (5, -1.03262975675934653985e+00) (6, 1.83225071648823678583e-01) (7, 7.53633224702162096698e-02) (8, 6.22071649825769179554e-02) (0, -6.46099027681847903892e-01) (1, -3.21431789446260718357e-01) (2, -2.77285221863176611912e-01) (3, -3.61743803966429022800e-01) (4, -2.88227949190523413669e-01) (5, 1.52692363268790276543e+00) (6, 1.08516266763344151891e-02) (7, 2.89248977413183949725e-01) (8, -8.61151958444823367733e-02) (0, -4.30137342039627224022e-01) (1, 7.09600207678613356665e-04) (2, 2.52967396949451417409e-02) (3, -1.01090189608462513449e-01) (4, 3.44524154637973756277e-02) (5, 1.16124180807700239093e+00) (6, -1.17526301011884048986e-01) (7, -9.54750287347165271790e-02) (8, -1.66819266472171712223e-01) (0, 1.14550919924728766830e+00) (1, 2.83334156403562409388e-01) (2, 2.85003607997915131556e-01) (3, 2.96545157114288193689e-01) (4, 3.66676563302299363123e-01) (5, -9.10794551055372658688e-01) (6, 2.53335482100712772180e-01) (7, 1.23523257050542345503e-01) (8, 4.15562774721025374181e-01) (9, -2.86966756773545772496e-01) (10, 8.06893385114771599653e-01) (11, -2.05143521932087236070e-01) (12, -2.36022641682480022185e-01) (13, 6.89053257745629310627e-01) (14, 6.06185814184075355548e-01) (15, -2.00029219892940812731e-01) (16, 8.47652188601595635298e-01) (17, 8.97896077900859457266e-01) (18, -6.94277044885288491249e-02) (19, 5.95861701113110542316e-01) 
