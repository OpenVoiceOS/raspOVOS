FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=13 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (13, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.13633513338180003327e-01) (1, 2.97336951720026221313e-01) (2, 2.77144000756052222290e-01) (3, 2.94770085143354620971e-01) (4, 2.76732650476005759277e-01) (5, -8.55269134511885797956e-01) (6, 1.54664714344991321981e-01) (7, -2.84151586107423748118e-01) (8, -1.25366437937553465432e+00) (9, -1.43787887639453337840e+00) (10, -6.10030978869847695378e-02) (11, 1.27931772362371243279e-01) (12, 3.90335780810524834994e-01) (0, 1.20805483558138937461e+00) (1, -8.09079845765555971671e-02) (2, -3.28176905730689777441e-02) (3, -4.29808562019790424413e-02) (4, -3.06466509917701461496e-02) (5, 2.94362538059265599344e-01) (6, 3.96695094180402163531e-01) (7, 3.28408919889591199848e-01) (8, 4.84223587558269330522e-01) (9, 4.84605423894902798132e-01) (10, 2.84990218469761691367e-01) (11, 2.55531960436318705820e-01) (12, 1.09169751064372752558e-01) (0, 3.11981974013861229622e+00) (1, 3.92488500001030415909e-01) (2, 4.43287080051498860733e-01) (3, 4.38791973414020985977e-01) (4, 4.23523308606939763443e-01) (5, 8.25252668691647817134e-02) (6, -8.03573054914392403969e-02) (7, 1.46340830557471102136e-01) (8, 9.84856349325866742284e-01) (9, 1.51745045709447734517e+00) (10, 3.18630662517046473609e-03) (11, 2.85528589639931162925e-01) (12, 1.70564301060931067244e-01) (0, 5.89250164783136742841e-01) (1, 2.83139416447287184386e-01) (2, 3.06829699745779616027e-01) (3, 3.52799126377707106261e-01) (4, 2.86147498956328016906e-01) (5, -1.08600027800724285854e+00) (6, -2.38771879463730796189e-01) (7, -2.53747025839498430155e-01) (8, -1.19458774979646698000e+00) (9, -1.50446359760215209178e+00) (10, -2.40134412045424405768e-01) (11, -2.42154468070575112915e-01) (12, 5.47158926855033977965e-01) (0, -5.49415378322745229234e-01) (1, 1.69977557560053921248e-01) (2, 1.46877583762255764510e-01) (3, 3.56320372723017558814e-02) (4, 1.55793723364916897323e-01) (5, 3.31867997623940313989e-01) (6, 2.50151872938672303892e-01) (7, 2.57987106437888802368e-01) (8, 6.46314988636115028697e-01) (9, 7.40203740414032917982e-01) (10, 2.01651789673448156304e-01) (11, -4.19986625487995396400e-02) (12, 7.27608776231567361270e-02) (0, 6.63908329623803528108e-01) (1, -1.49621436973851967833e-01) (2, -1.57287868341249276183e-01) (3, -8.68388886058748393770e-02) (4, -4.12388319576204170902e-02) (5, 1.81664933906582004575e-01) (6, 1.17709482968909082135e-01) (7, 1.88481801755853051183e-01) (8, 3.89811401628803178010e-01) (9, 2.56464788722166159296e-01) (10, 3.82649325776718507441e-01) (11, 1.79825305249023792431e-01) (12, -1.29409078657540227431e-01) (0, -7.71676160566964308707e-01) (1, 1.80617448588458157088e-01) (2, 4.43155548475657329321e-02) (3, 3.38949530325804576636e-02) (4, 1.35747980972376974806e-01) (5, 3.53271734990139807397e-01) (6, 2.51202759422322119409e-01) (7, 3.45724943310412480280e-01) (8, 5.99960354367305659373e-01) (9, 6.18053076067973994334e-01) (10, 2.37195854297761715701e-01) (11, -1.11744307475824325437e-01) (12, -1.09361844644947747707e-01) (0, -4.54533977856779902726e-01) (1, 1.14080098172274685409e-01) (2, 1.72518190642443752791e-01) (3, 5.23885308705244884253e-02) (4, 1.11391354998198605086e-01) (5, 3.93022966660519446069e-01) (6, 3.78991675652523840601e-01) (7, 2.46097210079821521189e-01) (8, 6.02155859374144508678e-01) (9, 6.55078800235088354320e-01) (10, 2.80661617628221338183e-01) (11, 2.63255785153388181460e-03) (12, -8.31788317720134479094e-02) (0, 5.20861606932393028657e-01) (1, 1.55433678342894954216e-01) (2, 1.30729847862319475960e-01) (3, 3.06462289108829000206e-01) (4, 2.00728000416354579460e-01) (5, -1.94541462300407946850e-01) (6, -4.91644353911303455540e-01) (7, 3.83679296099666777842e-01) (8, 4.44021105362300705366e+00) (9, 4.38102423095379922557e+00) (10, 1.77836564614835490605e-01) (11, -1.50418323147896187963e-01) (12, -5.30690047574003953557e-02) (0, 2.89632810599317780387e-01) (1, -5.38977156565213708084e-02) (2, -2.05013975052597524629e-01) (3, -1.78082026092770101533e-01) (4, -2.38709181098701955781e-01) (5, -1.85125390923317345582e+00) (6, -4.73817194334843427850e-01) (7, -5.05820011501855071323e-01) (8, 5.69676243487779476737e+00) (9, 4.76230337771935641200e+00) (10, -6.56883403359917572573e-01) (11, -2.58045665261155021675e-01) (12, 2.96982649839789801527e-02) (13, -1.52222826219604007170e-01) (14, 1.70683647346031086567e-01) (15, 2.98211546661453552609e-01) (16, -1.29588064346308229347e+00) (17, 4.05489571818079319598e-01) (18, 3.21907131970405158139e-01) (19, 3.92838129089529530802e-01) (20, 3.66176606403047888438e-01) (21, 6.48788151636081833473e-01) (22, 6.29620783893663382713e-01) (23, 4.90729550673561276675e-01) 
