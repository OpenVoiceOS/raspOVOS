FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 7.61908842842296762932e-01) (1, 2.15330257474047326305e-01) (2, 2.06864941327435158946e-01) (3, 2.88259345500333108436e-01) (4, 2.25522774665218972423e-01) (5, 5.11681896646578149301e-01) (6, 1.82169114364029244291e-01) (7, -1.09892997301854620673e+03) (8, 3.29381081274692066874e-01) (9, 3.00733250788629336014e-01) (0, -9.54270338402631868036e-01) (1, 2.44268639140095444873e-01) (2, 3.23182946197952791767e-01) (3, 3.15258389465775057392e-01) (4, 2.98206811897720913684e-01) (5, 1.04688180271573538782e+00) (6, -9.83972128193243006367e-02) (7, 1.28436186254524227479e+03) (8, -2.05476644345337564057e-02) (9, -1.87720662641566254925e-01) (0, 9.05903152960941815408e-01) (1, 3.09635979526570626064e-01) (2, 1.78439011269142716598e-01) (3, 2.45515210025837565810e-01) (4, 1.87314090722134202194e-01) (5, 5.54929460129331642015e-01) (6, 1.35691810441942589671e-01) (7, -1.09892997301854620673e+03) (8, 1.16277029286753749715e-01) (9, 2.00214485217862531163e-01) (0, 3.46271430081465658724e-01) (1, 3.62864292680152522586e-01) (2, 3.50969247042068110964e-01) (3, 3.31230423866637813113e-01) (4, 2.90554955123790370486e-01) (5, 1.27547670371237220621e+00) (6, -2.20932269363630667813e-01) (7, 1.28436186254524227479e+03) (8, -1.19816052072927878291e-01) (9, -3.31658996721224674786e-01) (0, 6.81956634343362733119e-01) (1, 2.11750804840189599254e-01) (2, 3.52368164269788008980e-01) (3, 2.07523479519945763805e-01) (4, 1.96473698525292062023e-01) (5, 5.09978669297799891424e-01) (6, 6.01263667519348135593e-02) (7, -1.09892997301854620673e+03) (8, 2.15148972829901641290e-01) (9, 2.37133706446718134364e-01) (0, 7.52375363593993595757e-01) (1, 2.03496116607052468517e-01) (2, 2.47102524547440249858e-01) (3, 3.00333294479710799507e-01) (4, 2.89783480970723372749e-01) (5, 4.65127954793081110907e-01) (6, 1.25245159315945764344e-01) (7, -1.09892997301854620673e+03) (8, 2.49110984898002013610e-01) (9, 2.64786343959039716101e-01) (0, 8.36924712754030020179e-01) (1, 2.00304750256735442093e-01) (2, 2.74800456963975148206e-01) (3, 2.79478907488782235546e-01) (4, 3.26634429298836959088e-01) (5, 5.63791344604085975512e-01) (6, 1.24389266419293556543e-01) (7, -1.09892997301854620673e+03) (8, 2.04869880340043553080e-01) (9, 1.56486734175008246339e-01) (0, -6.23448569713937472692e-01) (1, 2.33667181685094316190e-01) (2, 2.08605082585935130979e-01) (3, 2.43664370730046764280e-01) (4, 2.80621977403287370390e-01) (5, 2.19838834274255567891e+00) (6, -1.01249554685321652148e-01) (7, -3.10840649125394197227e+00) (8, 1.59966653115529267026e-01) (9, -1.26313715191712555574e-01) (0, -1.10421596571352043092e+00) (1, 1.62911092064151746817e-01) (2, 1.95200984499225543845e-01) (3, 2.34653401587105354953e-02) (4, 1.02675703487167327421e-01) (5, 7.91472294999775782820e-01) (6, -4.78830018126190706806e-02) (7, 1.28436186254524227479e+03) (8, 1.14753698240658619234e-01) (9, -1.55988003552733456303e-01) (0, 1.51545048488557387856e+00) (1, 3.96010812869627970567e-01) (2, 3.54742687693198222032e-01) (3, 3.20623737326224345079e-01) (4, 3.14361829808314341417e-01) (5, 1.00917052431299403281e+00) (6, 3.64396907961245908325e-01) (7, 1.28436186254524227479e+03) (8, 1.40247231066277522338e+00) (9, -1.90561051004019044175e-01) (10, -1.19099168853134984580e-01) (11, 2.26405587526759127792e-01) (12, -2.48553506081353597912e-01) (13, 4.64878789504983624958e-01) (14, -1.62122344875584079027e-01) (15, -2.84979916160355839505e-01) (16, -2.44305818324338508418e-01) (17, -4.39562289791397220462e-01) (18, 2.01802849729474237384e-01) (19, 4.22985191670843363454e-01) (20, 2.33665291486410769961e-01) 
