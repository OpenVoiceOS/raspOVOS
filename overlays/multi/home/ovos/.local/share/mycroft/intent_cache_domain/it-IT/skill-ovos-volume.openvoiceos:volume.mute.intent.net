FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.76854374073633069386e+00) (1, 3.45197101537310202524e-01) (2, 3.49600633088671286508e-01) (3, 3.77450750623070319101e-01) (4, 4.13664226833902914926e-01) (5, -9.08260554153297317015e-01) (6, -7.53984905857417953001e-01) (7, -7.83816389817569625365e-01) (8, 4.76974096601916086602e-01) (0, -9.75990044588502136946e-01) (1, -3.74757961308709378057e-02) (2, -1.08714366046165605839e-01) (3, -5.30765370404473538213e-02) (4, -6.75653384005776569410e-02) (5, 7.62027639083131091979e-01) (6, 9.26195463649500672076e-01) (7, 7.35705631903870838073e-01) (8, -1.35142123873111863475e-01) (0, -8.68349904829915364424e-01) (1, -2.36322001492730374150e-02) (2, -8.98266822969666645093e-02) (3, -4.64080587899438137822e-02) (4, -1.37506270495628524220e-01) (5, 7.31460447541936176208e-01) (6, 9.91714125982989136432e-01) (7, 6.60519789091809528259e-01) (8, -8.45617838063941196225e-02) (0, -3.38189448889829435974e-01) (1, -1.50112205830787825978e-01) (2, -5.22543505704156155400e-02) (3, -1.47252389875625777638e-01) (4, -7.95793251073113605543e-02) (5, 8.19469097189172046569e-01) (6, 9.96357745043505493854e-01) (7, 8.24397760562165515807e-01) (8, -1.85936670736382980706e-01) (0, 1.98196870075654729693e-01) (1, 4.38475962432648358469e-01) (2, 2.92768560054327775521e-01) (3, 3.02541441919829179330e-01) (4, 2.66748081597115327401e-01) (5, 3.71730738883297329167e+00) (6, 3.85584171121399288396e+00) (7, 3.87568619852344875554e+00) (8, 5.88213106566850829626e-02) (0, 1.40389819430303375292e-01) (1, 4.47399239691521344309e-01) (2, 3.11525039079214749460e-01) (3, 3.99248432072426495676e-01) (4, 3.83311506065155682688e-01) (5, 3.74990747874061947087e+00) (6, 3.77143637841026668767e+00) (7, 3.79891808336059932927e+00) (8, 2.14804610186998534704e-02) (0, 2.25417298065614446489e-01) (1, 4.36149801763321576242e-01) (2, 3.98998345884110150461e-01) (3, 3.87733053120400128488e-01) (4, 3.24736240955616650705e-01) (5, 3.71090077613870983342e+00) (6, 3.79749334608595257023e+00) (7, 3.83949849014561062077e+00) (8, 4.04006889039461303259e-02) (0, 2.59140742622748387891e-01) (1, 3.01621528101651270592e-01) (2, 4.02044260633675598626e-01) (3, 4.20671516788689636712e-01) (4, 4.35375237596718811517e-01) (5, -6.93801405346872179791e-01) (6, -1.26284115128405671769e+00) (7, -7.96404945171357958600e-01) (8, -1.70514653229035306747e-01) (0, -8.07470733935292561689e-01) (1, -3.97432870409727447003e-04) (2, -6.61247785158374234982e-02) (3, -4.45115966274523770091e-03) (4, -1.24450791902086993490e-01) (5, 7.24612052671178119567e-01) (6, 9.17894622794855896686e-01) (7, 8.18135234646065967468e-01) (8, -1.88581569666740556102e-01) (0, 1.22839429216575438120e-01) (1, 3.02572346928145219369e-01) (2, 3.64918950649525342111e-01) (3, 4.34936057480599103098e-01) (4, 2.63546477707649995370e-01) (5, 3.79508335148374920109e+00) (6, 3.60326312004043458614e+00) (7, 3.84529414778034572819e+00) (8, 5.95739521279028294565e-01) (9, -8.19497571265450641675e-02) (10, 6.63165576480762131162e-01) (11, 7.24772736154929764218e-01) (12, 6.99764437698260910459e-01) (13, 4.17904564254739818718e-01) (14, 4.30922360234716472771e-01) (15, 5.06336786859491350121e-01) (16, -1.48351909824585292963e-01) (17, 7.11427218936816818662e-01) (18, 3.73441747193459183674e-01) (19, 2.50552957310368917820e-01) 
