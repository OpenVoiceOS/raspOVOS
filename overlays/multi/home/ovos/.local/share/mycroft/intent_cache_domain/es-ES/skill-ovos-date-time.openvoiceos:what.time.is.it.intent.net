FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.55832520703405674745e+00) (1, 1.02726984522850028902e+00) (2, 9.87944697361297308191e-01) (3, 9.23144315700835993432e-01) (4, 9.03486189763850977563e-01) (5, 6.43502589588030904366e+00) (6, -1.62121275391419694678e+00) (7, 4.32499366503693138952e+00) (8, 4.39250065638697595460e+00) (9, 1.92108723196061816907e+01) (10, -1.26216657397318265943e+00) (0, -2.22864668741709542887e-01) (1, -6.69641155665737786151e-01) (2, -6.73386137848717369891e-01) (3, -7.43466760879379795490e-01) (4, -5.95105048185211815692e-01) (5, -7.02615671938028008014e+00) (6, 2.07278751537209926514e-01) (7, -3.24219581385836441711e+00) (8, -4.44910692119677797507e+00) (9, -1.33210103995816506739e+01) (10, -1.15287294353295724503e-01) (0, 2.29684318278563281979e+00) (1, 6.35604800954741699925e-01) (2, 6.73682583794278144751e-01) (3, 6.91068327352684752540e-01) (4, 6.36620233133715851537e-01) (5, -7.82862955912488556187e-01) (6, 1.94944498577126756889e-02) (7, -4.17609482389921637946e+00) (8, -1.68424301570589651789e+00) (9, -7.28953229075839592710e-01) (10, 1.56243059018447733033e-01) (0, -1.26295885366320348453e+00) (1, -7.30047475462776707111e-01) (2, -5.95904972320419945575e-01) (3, -7.21578385597092197834e-01) (4, -6.98291946118694828449e-01) (5, -7.04345779454078346760e+00) (6, 1.48683867726944995979e+00) (7, -4.75450857460614084715e+00) (8, -4.35192488994082449238e+00) (9, -1.34195367283837594385e+01) (10, 3.62758127947779673850e-01) (0, 7.64486045197610764035e-01) (1, 4.76030217700993296681e-01) (2, 4.61848808669840571461e-01) (3, 5.96642801755463580982e-01) (4, 5.82547003620659809009e-01) (5, 7.04558149219779128458e+00) (6, -9.11888478568199878360e-01) (7, 4.81409904276150157898e+00) (8, 4.72856418168472547592e+00) (9, 1.90303790914686885571e+01) (10, -6.35057251937070632586e-01) (0, 9.34955436178320109519e-01) (1, -1.18257171932525419200e-02) (2, -7.59392857078380195679e-02) (3, 3.17035101827316603829e-02) (4, -1.18854562676617633854e-03) (5, -9.38593555023303993678e-01) (6, -9.86487556208696936277e-02) (7, -5.01474139142804101188e-02) (8, 1.08402618192201316560e-01) (9, -2.07227781711443670432e+00) (10, -9.10847842445247773968e-02) (0, -4.15924021856966308341e-01) (1, -6.91479846571579764847e-02) (2, -1.38221862885822388556e-01) (3, -1.74681487653125799842e-01) (4, -2.41607624266018006232e-01) (5, 2.43103888427176695330e+00) (6, 5.26323220740594455158e-01) (7, 2.02677855204002499434e-01) (8, 4.60103534466263897063e-01) (9, 1.55711464662418723748e+01) (10, 6.06143700560658249543e-01) (0, -1.71673819348103356974e-01) (1, -6.50537762707096733905e-01) (2, -6.37603510087353386737e-01) (3, -6.92327469503504322468e-01) (4, -6.95430468684059666096e-01) (5, -7.11582376023497076289e+00) (6, -5.54727056643505855860e-02) (7, -1.44302291680582039923e+00) (8, -3.70851987178404529644e+00) (9, -1.33885480425970353480e+01) (10, -9.39957970596138059349e-02) (0, 2.33379270185363507650e+00) (1, 5.68552368361877391578e-01) (2, 6.02620367933438982888e-01) (3, 5.29211138416456172706e-01) (4, 6.44950998057054025736e-01) (5, -5.28479006864925882070e-01) (6, -2.28158213770716822300e-01) (7, -3.30934306173476544544e+00) (8, -1.62075566537562476555e+00) (9, -8.87858396241434366658e-01) (10, -1.60871703732400117559e-01) (0, 8.51821595710630319331e-01) (1, -1.69802357459619468472e-01) (2, -1.53749601001098579189e-01) (3, -1.79913667047574943325e-01) (4, -1.16736461425378787449e-01) (5, -6.73185712074449771336e+00) (6, -1.53295942084935510330e+00) (7, -9.22187191296391234330e-02) (8, -1.00899743155593624166e+00) (9, -1.07102045444459097467e+01) (10, -1.19303169350041426977e-01) (11, 3.83929710924323319698e-01) (12, -1.06395634573801092793e-01) (13, -5.69410704397841582747e-01) (14, -1.06212901634080938984e-01) (15, 3.53805285036261796261e-01) (16, -3.36618033962146234739e-01) (17, 6.42667493926387334291e-01) (18, -8.30321858943539325981e-02) (19, -5.55851571583434234114e-01) (20, -3.61293643159180388746e-01) (21, 4.29155935544745237298e-01) 
