FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.26199025539352738257e+00) (1, -7.33563167032118268462e-02) (2, -7.84498688753958173248e-02) (3, 4.63943245831613254593e-02) (4, -1.43063527521009661858e-02) (5, 1.19005315545940604238e+00) (6, 3.58679541505430229953e-02) (7, -9.64497324599409111556e+00) (8, 9.38548026715562214162e-03) (9, 1.05884155911553340390e-01) (0, 3.29891083259108375270e-01) (1, 6.99150560039999979800e-01) (2, 6.96797428268912333316e-01) (3, 7.64272955793860453433e-01) (4, 6.85856585938456553286e-01) (5, 1.36338456976872801629e-01) (6, 2.72802929000611593668e-01) (7, -5.05593764532434786219e+00) (8, 6.95331906516078013247e-01) (9, 7.39080899608239860754e-01) (0, 3.31524272213979398494e-02) (1, -2.10015857604352901289e-01) (2, -1.11427089211551630377e-01) (3, -1.54943568644134471723e-01) (4, -5.34348990889472463817e-02) (5, 3.06195938956516255924e-01) (6, -9.99401141406450754801e-02) (7, 3.35809288290436658286e+00) (8, -9.71959311963472849527e-02) (9, 5.86199189261528280648e-02) (0, -5.53539389255028213555e-01) (1, 3.42919880165868995459e-01) (2, 3.74234104170614478857e-01) (3, 3.76793348803335426123e-01) (4, 2.81552912308984992773e-01) (5, -2.50757423788460276359e-01) (6, 2.03651909259665531149e-01) (7, 1.14697564608030262434e+01) (8, 2.66157376947976531678e-01) (9, 3.08752133009909612849e-01) (0, 7.98704807411237671655e-02) (1, -8.53159185620231130809e-02) (2, -1.57428635296432445356e-01) (3, -1.76564065751640270063e-01) (4, -9.24701448651236990184e-02) (5, 1.57914871346729268620e-01) (6, 2.72084470389928195777e-02) (7, 3.44964940962489041709e+00) (8, -4.55265355571178031990e-02) (9, -2.56678064628509117195e-02) (0, 3.86090283710482318202e-01) (1, 7.35030440229895609683e-01) (2, 6.93525662261965769595e-01) (3, 6.50994306046488779849e-01) (4, 6.32417941082242252016e-01) (5, 1.77221603203278899041e-01) (6, 2.87755409793610805735e-01) (7, -5.01680959139096582788e+00) (8, 5.82953815896037341737e-01) (9, 6.51160464835271568518e-01) (0, -6.71471470477562393242e-01) (1, 3.74531158819013831884e-01) (2, 2.11574086561018170904e-01) (3, 2.28025795533472241949e-01) (4, 3.60043773069196937353e-01) (5, -2.01077596843393935355e-01) (6, 2.35727791217673232627e-01) (7, 1.13518004930190983259e+01) (8, 2.44445587876416570161e-01) (9, 3.23755054233550054743e-01) (0, -7.23766156914215530449e-01) (1, 2.04516956224256696295e-01) (2, 3.40477907671743629248e-01) (3, 2.87680195286089179785e-01) (4, 2.80283974125200507910e-01) (5, -2.02585035562666548881e-01) (6, 2.24085341527412690299e-01) (7, 1.13623643247954788649e+01) (8, 2.72752750101663055116e-01) (9, 3.07228876708029730036e-01) (0, -6.00598135473709549004e-01) (1, 2.21090474738889875006e-01) (2, 3.20539826168829200537e-01) (3, 2.38044244810157956671e-01) (4, 3.00657601668649909765e-01) (5, -1.21393279731424968970e-01) (6, 2.36965254165989153146e-01) (7, 1.14640394812993946516e+01) (8, 2.61576730194665374452e-01) (9, 3.20857851264952642634e-01) (0, 2.32002067149334884055e-01) (1, 7.05189464230063456363e-01) (2, 7.33962414402487772769e-01) (3, 6.06931661803248645448e-01) (4, 7.41934535641196268863e-01) (5, 7.31850350813226357971e-01) (6, 9.64250906001495766695e-01) (7, -5.03839217994439447779e+00) (8, 7.37043393392088908023e-01) (9, 5.91415726792916984778e-01) (10, -2.56586209903147066669e-01) (11, -2.03413085197349213784e-01) (12, 5.93572867650511981630e-01) (13, 3.90798071040922401220e-01) (14, 6.34939876932624103212e-01) (15, -2.59377383743663425530e-01) (16, 2.99856172516161201269e-01) (17, 3.60524752750211952002e-01) (18, 3.47311431183630225927e-01) (19, -1.70804263209243384347e-01) (20, 3.26180586232954261572e-01) 
