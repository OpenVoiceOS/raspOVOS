FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.56865978280880669082e+00) (1, 5.93695708639156105590e-01) (2, 5.78497418291103127075e-01) (3, 5.40306762880813251648e-01) (4, 5.72296940810214760376e-01) (5, 2.90327279468677046381e+00) (6, -2.45617245257071029063e-02) (7, 6.24376929062758190270e+00) (8, -3.92375122304960122221e+00) (9, 9.35730724456243362352e-02) (10, -2.46598830938432045379e-01) (0, 5.08862577735176824234e+00) (1, 1.56588775084294223872e-01) (2, 1.97640911654509338069e-01) (3, 1.25040532068289661494e-01) (4, 2.57426434175051399578e-01) (5, 1.13164012058560900509e-01) (6, 8.35707197384393918327e-01) (7, -3.24359725841229096233e+00) (8, 1.16939657928583073954e+00) (9, 7.90754180121068128706e-01) (10, 1.47311470368730534908e+00) (0, 4.60679978080330565504e-01) (1, 1.25326926232521673743e-01) (2, 2.55572072874952482824e-02) (3, -4.53153826582978896953e-02) (4, -3.84453835969676607082e-03) (5, 1.08926441691571129766e+00) (6, 1.80273159646174907511e-01) (7, 3.72139112715002273735e-01) (8, -7.44822353443960749608e-01) (9, 3.71717639494964280367e-01) (10, 3.27147420253489029651e-01) (0, 3.16817253725710124002e+00) (1, 8.41812479745423836164e-01) (2, 1.01178314114717249339e+00) (3, 8.40041096757924599103e-01) (4, 8.54985232900655311994e-01) (5, 1.12791141554238483202e+00) (6, 1.49968330593689458397e+00) (7, 3.45165506827820323110e+00) (8, -3.88517536842910260475e+00) (9, 9.18391783077527001922e-01) (10, 2.80216611318025221600e-01) (0, 1.51673735345580795730e+00) (1, 6.13589310175906788025e-01) (2, 5.36745191640388141785e-01) (3, 6.04418256408702503357e-01) (4, 6.14560150630008350525e-01) (5, 2.86193801661632063471e+00) (6, -3.27029441416433822032e-02) (7, 6.29043801504593513840e+00) (8, -3.92614835049911459208e+00) (9, 4.55200075828359057573e-02) (10, -3.71113053369231393752e-01) (0, 1.61184694015526153166e-01) (1, 6.75893722568337990131e-02) (2, 1.21616496239487503761e-02) (3, 9.09751639707725295869e-03) (4, 5.90952633415047917653e-02) (5, 7.10155924796870396953e-01) (6, -2.90649638914239252102e-03) (7, 3.38422399679714103193e-01) (8, 1.48278375403569251390e-01) (9, 3.92010219622680344820e-01) (10, 3.40622719135019791370e-01) (0, 4.20488872701182181402e-01) (1, 4.74172885833711379999e-02) (2, -6.47536857738789922018e-03) (3, -7.86128435911208067743e-02) (4, 7.64357204853029215119e-02) (5, -2.82656489734666116487e-01) (6, -1.10529151248256879425e-02) (7, -1.12610363483312991839e+00) (8, 6.83298643917018555527e+00) (9, -3.33613127329912273478e-01) (10, 4.35655895550312199926e-01) (0, 1.27443968427042553238e+00) (1, 5.71110550095286328975e-01) (2, 7.01158802737440689512e-01) (3, 7.32669170726981011654e-01) (4, 5.76142083634581525509e-01) (5, -2.20632177564483011878e+00) (6, 3.49886137331873792178e-01) (7, -4.89008393162265020404e-01) (8, -5.65488210354286735537e+00) (9, -2.01327839652014270455e-02) (10, -5.43850420626544178715e-02) (0, 5.04450638948670171402e+00) (1, 3.26976593387265646040e-01) (2, 1.89772646677632911283e-01) (3, 2.23135344487567582883e-01) (4, 3.45517437708516672590e-01) (5, -4.18953080046930770308e-01) (6, 7.83667209871622416628e-01) (7, -3.06078621605110212656e+00) (8, -1.44728584953310424055e+00) (9, 8.14924636029925042457e-01) (10, 1.67057174978011135913e+00) (0, -4.19065308897996846582e+00) (1, -2.51912944073806710499e-01) (2, -2.66871087308059751209e-01) (3, -2.80432902331481936908e-01) (4, -2.88815863485466062244e-01) (5, 6.71402280719363697692e-02) (6, -9.50804934597037493260e-02) (7, 1.02053317889378949990e-01) (8, 4.63646642078727655445e+00) (9, -3.42295490197438712077e-01) (10, -1.17064531120349757387e-01) (11, 4.67874231070473989291e-01) (12, -3.51418995072858453277e-01) (13, 4.11005272783909525458e-01) (14, 2.35178716747244144492e-02) (15, 4.37641771763757070346e-01) (16, 3.19934826670164540463e-01) (17, 4.72226262818571329571e-01) (18, -2.57632181709103291745e-01) (19, -3.33104758744258211411e-01) (20, 9.14796373363700343617e-01) (21, 4.44816992609573524931e-01) 
