FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=28 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (28, 6, 5.00000000000000000000e-01) (28, 6, 5.00000000000000000000e-01) (28, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.76111502175096745759e+00) (1, 3.93286078397993321687e+00) (2, 1.99359875375600820169e-01) (3, 3.82970321898226018220e+00) (4, 4.98506338394642367629e-01) (5, -1.45520323553935360117e+00) (6, -2.37948336344390665165e-01) (7, -2.03901857774883066288e-01) (8, -1.43665166238204311533e+00) (9, -1.57699838692203830881e+00) (10, -1.63006781080619167490e+00) (11, -1.44450902977839779062e+00) (12, -1.55481550881520580454e+00) (13, -8.68779515710990324351e-01) (14, -8.82068237153212919566e-01) (15, -1.99829025577223595711e-01) (16, -3.72125592659629078618e-01) (17, -2.95134489070094319096e-01) (18, -1.02035708804331237687e+00) (19, -1.56282293062126931282e-01) (20, -2.73798112403071614018e-01) (21, -2.96879288386023731938e-01) (22, -3.64017494599736424199e-01) (23, -2.26348031889117451421e-01) (24, -2.97248978744662495366e-01) (25, -1.69870378221388862450e+00) (26, -6.26849098265960358312e-01) (27, -2.05292326434429101001e-01) (0, -3.78222104136709447175e+00) (1, 3.94924322490457768708e+00) (2, 1.76744353229375844583e-01) (3, 3.93081832651857610017e+00) (4, 4.68142078317165866164e-01) (5, -1.44693692067519497080e+00) (6, -3.09932239990859725864e-01) (7, -1.91984460395007855427e-01) (8, -1.46799737254039119883e+00) (9, -1.47332163194075893564e+00) (10, -1.52132738420621227426e+00) (11, -1.47050625124827694101e+00) (12, -1.61617723146334957285e+00) (13, -7.90735771742980375620e-01) (14, -7.54355868188063993784e-01) (15, -1.17885237942850884529e-01) (16, -2.63441060315287800542e-01) (17, -2.40349878202594013921e-01) (18, -9.85705599977592772376e-01) (19, -2.12388551245844658943e-01) (20, -3.16306297312892170659e-01) (21, -2.28545819054759236089e-01) (22, -3.57492793928302021733e-01) (23, -3.70926317404425831548e-01) (24, -3.06247015129245014897e-01) (25, -1.67267549182292030174e+00) (26, -6.36085389316871308019e-01) (27, -1.82186109050090722095e-01) (0, -3.95038796190981145173e+00) (1, 3.84945137773517842561e+00) (2, 1.41063332760902410135e-01) (3, 3.94154538933996434480e+00) (4, 3.84732672072411019393e-01) (5, -1.50523346701518367929e+00) (6, -1.98090077083736215702e-01) (7, -3.05758108090787628086e-01) (8, -1.51802761146680187387e+00) (9, -1.63346337566033672495e+00) (10, -1.62318362334624599619e+00) (11, -1.55188220033303569956e+00) (12, -1.47264222839728664560e+00) (13, -7.83851591733615293833e-01) (14, -8.61729049918572798106e-01) (15, -3.57119575249317255938e-02) (16, -3.78513135592854710332e-01) (17, -2.20010702143824787846e-01) (18, -1.02158854235611373795e+00) (19, -1.87760874735477534259e-02) (20, -2.41182495485461445561e-01) (21, -2.29777265916980000249e-01) (22, -8.99155990078071898353e-01) (23, -3.38310707937396260014e-01) (24, -9.18314398123840636146e-01) (25, -1.72864459599371955711e+00) (26, -5.48048058659627579381e-01) (27, -1.24082130416210120738e-01) (28, 3.93577413980726475984e+00) (29, 3.92825243596796269685e+00) (30, 3.88587581341032262117e+00) (31, -3.16601144512252408170e-02) 
