FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.84516333182814729064e+00) (1, -1.73495098392958446709e+00) (2, -2.49639482215601882231e+00) (3, 1.80710376716788978513e+00) (4, 2.38362948933329876766e+00) (5, 1.87946052988532197325e+00) (6, 2.13758269576184645189e+00) (7, 1.90628259485981432775e+00) (8, 2.06210492416658341952e+00) (9, -2.71668165434884611997e+00) (10, 1.94837058853549294213e+00) (11, 2.05147119317565618246e+00) (12, 2.52700884367607425673e+00) (13, 2.37454877385583218441e+00) (14, 1.85673917969229829161e+00) (15, 1.72815848804649085935e+00) (16, 2.59970687897485230877e+00) (17, 1.14861287576020365542e+00) (18, 1.92957987775567185729e+00) (19, 1.95869671692612778990e+00) (20, 5.94473056593529847191e+00) (21, 2.66933868164870857775e-01) (22, 1.02503817915129280536e+00) (23, 1.96189471191189257482e+00) (0, -7.25415768440018204899e-01) (1, 1.16488850001071408968e+00) (2, 1.37895873424003156948e+00) (3, 2.36716189986006381174e-02) (4, -1.98942290180367065133e+00) (5, -1.13211211602944694654e+00) (6, -1.08248870542566866249e+00) (7, -6.04812125082264673281e-01) (8, -1.79524430162317560900e+00) (9, 1.36784464661943894193e+00) (10, -1.27079378585022029213e+00) (11, -1.91451411969072626817e+00) (12, -1.82460090047724055040e+00) (13, -1.27739689208814555244e+00) (14, -1.27399147191997541562e+00) (15, -6.81164475753468723340e-01) (16, -9.42049928314764417614e-01) (17, -4.41353727034614673475e-01) (18, -6.40356652609159082701e-01) (19, -6.32100150159646601011e-01) (20, -1.33880032417056871186e-01) (21, -3.49340806444190243862e-01) (22, -7.18151852929076683907e-01) (23, -6.36750476773033868838e-01) (0, -1.39666675942998597115e+00) (1, 2.06158351147238771972e+00) (2, 2.63431222840088796744e+00) (3, -4.24921957726909382824e-01) (4, -6.41533510852942745473e-01) (5, -1.32172179930887012667e+00) (6, -7.02407089095509418186e-01) (7, -5.85777460113670378483e-01) (8, -1.21120204633052530596e+00) (9, 2.77122685503199583934e+00) (10, -9.02822374548495787394e-01) (11, -1.15547542875583353350e+00) (12, -1.06814828371579806365e+00) (13, -1.18636826379728410608e+00) (14, -1.26803038233003406710e+00) (15, -5.89023084144096431558e-01) (16, -6.50575696438822737022e-01) (17, -1.02040204367234510485e+00) (18, -7.85152137667065375126e-01) (19, -9.12273899108296149052e-01) (20, -1.00047495899197835811e+00) (21, -1.22172622076196613072e+00) (22, -6.36123836497063610551e-01) (23, -2.02308086373263007474e+00) (24, -1.09265945329661473551e+00) (25, 3.28439581376434563964e+00) (26, 2.11094292148419384603e+01) (27, -6.53968252689548279477e-01) 
