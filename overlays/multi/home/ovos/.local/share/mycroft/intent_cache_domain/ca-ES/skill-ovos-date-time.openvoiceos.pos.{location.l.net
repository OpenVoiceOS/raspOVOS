FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=24 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (24, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.41649766611279570583e+01) (1, -1.77522306602912738338e-01) (2, 6.79424160949961475353e+00) (3, 6.36361029900435748452e-01) (4, 1.42294545678133221855e+00) (5, -6.34177202542586648804e+00) (6, 1.40787480206617932055e+00) (7, -7.40356829323188359027e-01) (8, 6.51685052011077847745e-01) (9, -8.13104071065957473285e-02) (10, 4.89632249006633213373e-01) (11, -3.83830659533010709605e-01) (12, 1.43685869347338868174e+00) (13, 1.17735597364181749924e+01) (14, 1.55268459181564040250e+01) (15, 1.44025608113657543896e+00) (16, 5.22629309266687336333e+00) (17, 1.55547449164424378409e+01) (18, -5.19167167965220666126e-01) (19, 1.44035228673076765027e+00) (20, -4.82172456306055785547e+00) (21, 1.43814292325054182697e+00) (22, 1.50000000000000000000e+03) (23, -5.05682349037109846179e-01) (0, 1.12781040466895472463e+01) (1, -6.75153361196183299242e-01) (2, 1.18489750502132284993e+00) (3, -9.08669506043065511314e-01) (4, 2.43183110041106098631e-01) (5, 1.28958252280434559900e+00) (6, 5.46605747206634018376e-01) (7, 2.45448423880559474242e+00) (8, 1.08890207637716063260e+00) (9, 7.80095436407433173720e-01) (10, -1.34417049796680926343e-01) (11, -1.74177122919566174097e+00) (12, 5.50823097994036614544e-01) (13, 4.98294016448554089038e+00) (14, 1.30885021582411953389e+00) (15, 5.52018920424175218997e-01) (16, 1.77084624947026014752e+01) (17, 1.34418441026510970815e+00) (18, -1.29923081243827853726e+00) (19, 5.50290434691113827803e-01) (20, 1.36026003789141003431e+00) (21, 5.51323322715295716101e-01) (22, 1.50000000000000000000e+03) (23, -2.86567135731206024118e+00) (0, -1.73213622807818410365e+01) (1, 4.00370792852922097182e-01) (2, -1.51030505905296297264e+00) (3, -3.18990425541518751729e+00) (4, -3.25629295536634666419e-02) (5, 2.53497130329076814093e+00) (6, 2.78568718037231377593e-01) (7, 1.07964503802791238485e+01) (8, 9.62108239556959010663e-01) (9, 7.04881165647755159043e-01) (10, -2.94773392975287595874e-01) (11, -5.57323094336236835034e-01) (12, 2.74143155187127451899e-01) (13, -2.26211794300501978228e+00) (14, 1.29451916737866401519e+00) (15, 2.75762664690331726902e-01) (16, 5.09458557067148731790e+00) (17, 1.36549626853231331758e+00) (18, -5.02724331769159427097e-01) (19, 2.72770943123257003649e-01) (20, 6.07577102657032908084e-01) (21, 2.74867085710997660630e-01) (22, 1.50000000000000000000e+03) (23, 2.84494864421774518171e-01) (24, 3.27019662651186848734e+01) (25, -6.24553900269791597566e+01) (26, 5.34426686339051855157e+01) (27, -1.25906127809029992903e+01) 
