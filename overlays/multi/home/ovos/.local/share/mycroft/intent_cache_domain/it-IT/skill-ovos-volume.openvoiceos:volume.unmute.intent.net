FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=9 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (9, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.01102629233947505227e-01) (1, 4.03550372815703828344e-01) (2, 4.42030133104896028051e-01) (3, 4.83946689761256543250e-01) (4, 4.02610683239078004370e-01) (5, -3.89942879561350652651e+00) (6, 8.28619862936931461661e-01) (7, -8.51735720669032581043e-01) (8, 1.24324819752610427059e+00) (0, -2.02517163945865696917e+00) (1, -4.56417566100204619151e-01) (2, -4.45593273202026574076e-01) (3, -4.11246960917556969584e-01) (4, -4.65741237560356291514e-01) (5, 3.24170599047598617659e+00) (6, 1.24718489166275078861e-01) (7, 1.70236621121330117257e-01) (8, -2.37427003300435174316e-01) (0, 3.13819261831930029771e+00) (1, 1.47259465891323104714e-01) (2, 6.80515538038826001133e-02) (3, 1.33487514692745223854e-01) (4, 1.14172711509666457985e-01) (5, 1.44248175819805712905e+00) (6, 2.67554627656834242977e-01) (7, 2.13341650222764966927e-01) (8, 1.72384971667619291136e-01) (0, 2.51841964228069237208e+00) (1, 4.59219227401170326797e-01) (2, 4.07486821381005781539e-01) (3, 4.58404148785028053847e-01) (4, 5.11944244471940645980e-01) (5, -6.23373346481330470326e-01) (6, 4.00263857817426627062e-01) (7, 6.32640726499955174944e-01) (8, -5.01569574992130062796e-02) (0, -2.14308054937553427166e+00) (1, -4.11931252041900841654e-01) (2, -4.80483202198589476328e-01) (3, -4.33529322901809899271e-01) (4, -4.59436578610981138926e-01) (5, 3.20410254885015266524e+00) (6, 5.82605790711988348607e-03) (7, 8.82383250393103807374e-02) (8, -1.14760174966103717376e-01) (0, 2.49531190497791222072e+00) (1, 3.07598478537595976245e-01) (2, 3.23996513527429808033e-01) (3, 3.65218169432676653674e-01) (4, 2.86536890458858717334e-01) (5, 4.48066170828921694902e-01) (6, 4.77006067842880243646e-01) (7, 6.85764088862339971087e-01) (8, 1.54118250524186262140e-01) (0, 5.90672625253369254494e+00) (1, 4.74412475833020430560e-01) (2, 5.81693013319096841052e-01) (3, 4.90420696446023096637e-01) (4, 6.26346592911801391956e-01) (5, -5.72196263771892343897e+00) (6, 7.55987359316695806122e-01) (7, -5.00910285080627071252e-01) (8, 2.46842785271816078652e-01) (0, 1.35186744369368727625e-01) (1, -1.35403304602487672970e-01) (2, -1.05893834735735034580e-01) (3, -8.77063714521962578541e-02) (4, -1.00817545558794130489e-01) (5, 1.18842811059624651193e+01) (6, -1.50200869282848259445e-01) (7, -6.69036730044375582693e-02) (8, -1.91488717256439816561e-01) (0, 2.42714959783470085597e+00) (1, 3.86133267870070906458e-01) (2, 3.28469082107665399928e-01) (3, 4.22305091610076399622e-01) (4, 3.14959614863517145533e-01) (5, 3.22877052592263458219e-01) (6, 4.28324644841414192697e-01) (7, 5.63695110016266709430e-01) (8, 6.38771226912390188701e-02) (0, 2.43603695584451607203e+00) (1, 3.96707243662870745471e-01) (2, 3.94622690421141009143e-01) (3, 3.51728118401563982776e-01) (4, 3.28468068879640806568e-01) (5, -1.01266284121800304030e-01) (6, 4.09958620943289497873e-01) (7, 6.96920543544690129778e-01) (8, 2.23100925078953543634e-01) (9, -3.02389144743927806847e-01) (10, 8.09919547716783538860e-01) (11, 9.20582682095630044916e-02) (12, 4.49316338345107091357e-01) (13, 8.10508197757323189947e-01) (14, 5.04136871198009872685e-01) (15, -4.11811766233466269860e-01) (16, -6.91871984953732754864e-02) (17, 4.38639025786709269017e-01) (18, 4.73048344894942296435e-01) (19, 2.62885379773273253345e-01) 
