FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.98472390395154296705e-01) (1, 3.14207902924761028896e-02) (2, 5.51563954727396152378e-02) (3, -1.93420716746106960415e-02) (4, -5.58127382023587900739e-02) (5, -4.61718315309149085479e-01) (6, 4.05133531367433963322e-01) (7, -1.62248797512962772416e+00) (8, -6.29979204671473724808e-01) (9, 4.88032536279449976474e-03) (0, -2.26048524706290610009e-01) (1, -1.05189116947494356452e-02) (2, -2.29823919288955486051e-02) (3, -1.74552943026288515105e-01) (4, -1.58230326538547044768e-01) (5, 8.62081012363758336647e-01) (6, 8.97009875753045915481e-02) (7, 8.98738666138907849046e-01) (8, 1.16168250427774322198e+00) (9, -3.34874645584326169345e-01) (0, 6.78492935285135101431e-01) (1, 4.33679743633136716152e-01) (2, 4.37278985009059872890e-01) (3, 4.35232511684761014248e-01) (4, 4.96139979884491044704e-01) (5, 1.96577390237960669683e-01) (6, 4.30965152145972141273e-01) (7, -2.71826395567156597899e-01) (8, -2.32628722539253346424e-01) (9, 1.84002854779187097201e-01) (0, 5.07271963834637906743e-01) (1, 1.80139242824738254889e-01) (2, 1.57575148311083546027e-01) (3, 1.63897442784731617316e-01) (4, 2.53730951961701145514e-01) (5, 2.68357544512686119198e-01) (6, 1.32222796461164104898e+00) (7, -3.72799159007992697568e+00) (8, 8.85829142032121041872e-01) (9, 3.79613907552382834343e-01) (0, 3.09641577615578000859e+00) (1, 3.91692396338024606539e-01) (2, 3.56477361257114877535e-01) (3, 3.30334734256306161715e-01) (4, 4.17058948512115945650e-01) (5, -1.21172872750513205276e+00) (6, -7.53293584141071392857e-01) (7, -1.52339223043130611579e+00) (8, -9.71391441693702395455e-01) (9, 7.73076643280874220565e-01) (0, -7.18556958577868665206e-02) (1, -1.26800953890464807028e-01) (2, -1.94967831627350478285e-02) (3, -4.16212524429779712198e-02) (4, -3.87058849588852518786e-02) (5, 1.12835805421888557554e+00) (6, 6.19315117345227816870e-01) (7, -6.68247586385588387969e+00) (8, 1.27846577120492010948e+00) (9, -9.96888220639665159628e-03) (0, -3.33602193017574377709e-01) (1, -5.86662470147670603304e-02) (2, -3.93963782832683420687e-02) (3, -1.59799634550577468461e-01) (4, -2.07454408590561217851e-01) (5, 9.70099346527817374408e-01) (6, 4.97597101042341893873e-02) (7, 2.93417213238280294441e-01) (8, 1.13855770003111711475e+00) (9, -3.98758052335548174305e-01) (0, -2.69106389057805817089e-01) (1, -8.87541877381645416545e-02) (2, -4.76246210090957439176e-02) (3, -1.07466514622434256010e-01) (4, -8.69960742347084259318e-02) (5, 8.71670645150579570526e-01) (6, 3.22294832834345845729e-02) (7, 8.81046010813971935960e-01) (8, 1.07052625488551012012e+00) (9, -2.37633284613666673213e-01) (0, 9.42999759644662094438e-01) (1, 4.34312494187377717836e-01) (2, 5.87860332517646466677e-01) (3, 4.82052216022037183230e-01) (4, 5.34943492798827913148e-01) (5, 8.07028846234055352582e-01) (6, 2.06454197322668964176e+00) (7, -2.03170811617348112676e+00) (8, 5.32274423214010528049e-01) (9, 2.01780141397025325478e-01) (0, -2.95942648519845807886e-01) (1, -3.57217966363490915804e-02) (2, -6.38591377780498015149e-02) (3, -1.98130982999569243974e-01) (4, -1.87226380293136901445e-01) (5, 9.76170011284984706634e-01) (6, 3.93617841312956379118e-02) (7, 4.18939782060187337898e-01) (8, 1.28870368228232412555e+00) (9, -4.81484769330787432118e-01) (10, -1.41755812643559242492e-01) (11, 4.38228569998251327178e-01) (12, 4.91328502136925915345e-01) (13, -4.37656613448249437459e-02) (14, -4.92469925388372753439e-01) (15, -5.12933952676119297998e-01) (16, 3.89908128905958772936e-01) (17, 4.05433770176396035545e-01) (18, 5.21825375098447175048e-01) (19, 4.42997947600199115659e-01) (20, 2.87682248842677457112e-01) 
