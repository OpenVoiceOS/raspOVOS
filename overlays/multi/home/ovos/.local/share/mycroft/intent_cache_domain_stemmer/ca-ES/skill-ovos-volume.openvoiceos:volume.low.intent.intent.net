FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.27441827537593765918e-01) (1, -7.53773991521225067425e-02) (2, -1.61095006441675209219e-01) (3, -1.30351113205753349478e-01) (4, -1.93314584022365593130e-01) (5, 5.08204151038062143519e-02) (6, 2.08749364712622975659e+00) (7, 4.05515904143849859054e-01) (8, 1.95483213294013663530e-01) (9, 4.53669378828583033658e-02) (10, -7.16101748849949371056e-02) (0, 2.13653758875022647956e+00) (1, 2.39696183364385778658e-01) (2, 1.20455012779230374864e-01) (3, 1.16844692389959578516e-01) (4, 1.66891628067487890474e-01) (5, 3.65867375179587728251e-01) (6, 2.59688092248095658832e+00) (7, -4.68157277449685604864e-01) (8, -3.07557336466778352690e-01) (9, -5.69304291235560255835e-01) (10, 2.69199803636360146530e-01) (0, 5.00816913186392764779e-01) (1, 1.68136839931927878355e-01) (2, 1.08934556311093472258e-01) (3, 1.06056844061337612883e-01) (4, 2.54364800816498926039e-01) (5, 1.37328543278911252568e-01) (6, 9.61866564396991030605e+00) (7, 6.04308457933435461129e-01) (8, 2.14922392751241503328e-01) (9, 1.26133478609531612946e-01) (10, 8.73529644012394634878e-02) (0, 3.05756150502861157037e+00) (1, 1.47267678508216537381e-01) (2, 1.00932614633495038037e-01) (3, 7.21637213022057605327e-02) (4, 9.18311790913883818632e-02) (5, 2.64152352383837496497e-01) (6, 3.58446752397856061023e+00) (7, -3.50179323002416331700e-01) (8, -2.17870138066280943923e-01) (9, -5.22312942968958915380e-01) (10, 2.61203955044006175257e-01) (0, 2.06409182556797476948e+00) (1, 2.22926696508559785137e-01) (2, 1.31431443362865135738e-01) (3, 2.11940711110267243633e-01) (4, 2.52040317028197846660e-01) (5, 4.02515481703838551297e-01) (6, -1.89722290067262400193e+00) (7, 3.12645876664482347262e-01) (8, 1.12793244843752948903e+00) (9, 1.10374581546206140814e+00) (10, 3.02095868641541642763e-01) (0, 2.41155529424828642959e+01) (1, 4.43302754910176455283e-01) (2, 5.42253334672635367575e-01) (3, 6.27864052207654288473e-01) (4, 4.79603417815154364767e-01) (5, -7.99632666249448220697e+00) (6, -5.66480939533204608249e-02) (7, -1.88667880475051386036e+00) (8, 2.19413812725656603986e-01) (9, -2.41667625454241863370e-01) (10, 2.04347511887665866936e+00) (0, 3.34075997996245721566e+00) (1, 1.39570463899347879666e-01) (2, 8.52877688443399867291e-02) (3, 2.16024022999975778836e-01) (4, 9.13276751374937495465e-02) (5, 2.84919603611170579871e-01) (6, -1.85773914819475027826e+00) (7, 9.32309270189339844848e-02) (8, 5.48057642759729679582e-01) (9, 4.46933985369132869003e-01) (10, 2.15900627891233098943e-01) (0, -9.47331747467993867673e-01) (1, -6.93484584894766692420e-02) (2, -1.21597703835069154144e-01) (3, -9.87509380188574537041e-02) (4, -3.95250807610144222481e-02) (5, 1.28214341991759084478e-03) (6, 2.07268226542857503247e+00) (7, 1.51685023783067751690e-01) (8, 6.52611128206825354126e-03) (9, 6.09195410755879671050e-02) (10, -4.24999325218867740617e-02) (0, -8.45072026828810551891e-01) (1, -5.29658536520590389474e-02) (2, -2.37613807526221125499e-02) (3, -5.98359744158377115930e-02) (4, -1.56984962811767020385e-01) (5, -4.94146115592169893338e-02) (6, 1.98982713993188475854e+00) (7, 6.44057537591527506926e-03) (8, 1.26994014635113228184e-01) (9, 9.00307769250450057319e-02) (10, -1.69800381237573572157e-01) (0, 1.54622836054046519649e+01) (1, 6.38173748049330247234e-01) (2, 6.06882740053724778484e-01) (3, 6.25592600795816911052e-01) (4, 5.89000206682276261638e-01) (5, -7.33958650996482298012e+00) (6, 5.10033227145421763638e-01) (7, 1.84751748032387863585e-01) (8, 6.86258829058272401547e-01) (9, 4.97095511726193262092e-01) (10, 7.28844505165670564217e-01) (11, 6.54324040351519475855e-01) (12, 4.32418283993188989900e-01) (13, -2.63423040493608526247e-02) (14, 3.45632729950819284070e-01) (15, 3.63611751126860893724e-01) (16, -5.46949418930388620019e-01) (17, 4.36102360113602482983e-01) (18, 7.14933828054079900660e-01) (19, 4.39979947922601699606e-01) (20, -1.56864216198088129994e-01) (21, 3.08241601464624537243e-01) 
