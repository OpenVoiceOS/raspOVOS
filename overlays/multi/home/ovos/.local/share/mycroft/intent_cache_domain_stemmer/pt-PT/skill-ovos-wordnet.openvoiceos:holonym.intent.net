FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.08958207689928654460e+00) (1, 9.89336158081800670638e-02) (2, 1.42497004096201113077e-01) (3, 2.12432832543543170800e-01) (4, 9.02288640782148571029e-02) (5, 2.35923807106909327880e-01) (6, 9.42251274815135431151e-02) (7, 5.23101528343892008266e-01) (8, 8.13128055749916178740e+00) (9, 2.14534160810052443313e-01) (10, -2.26184060714732604325e+00) (11, 1.05043756181271930039e-01) (0, 2.37482358196331316824e-02) (1, 7.68007313215531423056e-02) (2, 1.06045467158535869356e-01) (3, 1.07921687265614421602e-01) (4, 1.95741107070244793609e-02) (5, 3.47732328734965456807e-01) (6, 1.81805120954276255851e-01) (7, 6.17225850405850665070e-04) (8, -6.64446436393849104718e+00) (9, 2.77455871283826593920e-01) (10, 2.10843750797487636817e+01) (11, 2.24890025856400471715e-01) (0, -1.17221336989480096058e+00) (1, -7.28064397103638655251e-02) (2, -2.21651829195722932520e-01) (3, -1.75027325165972108545e-01) (4, -1.50947585118517274561e-01) (5, 1.20238505091659661494e-01) (6, -2.03489669717965282469e-01) (7, -1.05928909309774874070e-01) (8, 1.56445896106796156211e+00) (9, -1.17405641267214422285e-01) (10, 1.89757388377880298336e+00) (11, -5.55638648859442474404e-01) (0, 3.17075286356277227795e-02) (1, 1.55914672611759147491e-01) (2, 5.75760015831450269741e-02) (3, 1.16012283562229048806e-01) (4, 6.75819003568152026906e-02) (5, 2.66129992228416600852e-01) (6, 1.04039137688624938605e-01) (7, 1.54773885323445433565e-02) (8, -7.05127392230575189558e+00) (9, 1.69536408489311091197e-01) (10, 2.10861832015491863501e+01) (11, 2.48841796870378745288e-01) (0, -1.55880353958614992216e+00) (1, 5.96818470873130335619e-01) (2, 5.31783805705798640062e-01) (3, 6.97085001982940211107e-01) (4, 6.54979565657866968920e-01) (5, -8.22057787963597491609e-02) (6, -1.37792855774284905834e+00) (7, 5.91493554933801957141e-01) (8, -2.31894211177820519509e+00) (9, -3.08087495357003027241e-01) (10, 5.11670117187642237155e+00) (11, -4.98777357131590215467e-01) (0, 2.41951797715537902933e-01) (1, 1.62281234060164925026e-01) (2, 6.57597074850763269049e-02) (3, 1.46614898239013163872e-01) (4, 1.41765926276084391899e-01) (5, 1.35717591047877006449e-01) (6, 5.21482921042500588427e-02) (7, 3.42068474912496423013e-01) (8, 6.58168631966089989760e+00) (9, 2.28156578962982692360e-01) (10, -9.14709741170749573991e-02) (11, 4.14841581149615334922e-02) (0, -1.50232261045397774701e-01) (1, 2.31980072185469787804e-03) (2, 1.57678674029559567904e-01) (3, 5.82829667799181910803e-02) (4, 2.90758973531432089732e-02) (5, 7.54213168431344255227e-02) (6, 1.14829210098047668209e-01) (7, -2.86585043317428428411e-02) (8, -5.54531748662529011540e+00) (9, 3.72759155193841673626e-02) (10, 5.89018942020000713100e-01) (11, 1.34127314695268895495e-01) (0, -6.71087163509587747434e-01) (1, -1.44040132250108310341e-01) (2, -2.55871253396787123879e-01) (3, -1.04666019167222526520e-01) (4, -1.44746223773278781533e-01) (5, 2.55638973036738381683e-01) (6, -1.29691951775798480773e-01) (7, -3.41995732639002680830e-01) (8, 3.11511201729374131997e-01) (9, -2.17590488388431757549e-01) (10, -4.24612974906212681248e+00) (11, -4.29068845515775121324e-01) (0, -8.68136678044919285480e-02) (1, 1.39621577180005035368e-01) (2, 1.05177997565842645811e-01) (3, 7.75915598040590459572e-02) (4, 8.52177841132650548683e-02) (5, 4.83099490681112075929e-01) (6, 2.30106127751751571298e-01) (7, 1.36562620196795270200e-01) (8, -7.65409768843107496394e+00) (9, 4.98358065531186167352e-01) (10, 2.12010189023558481836e+01) (11, 2.00061428583586525809e-01) (0, 8.35792303537270409031e-01) (1, 1.44165388378850539697e-01) (2, 8.97053322527328611535e-02) (3, 1.82673401269666413338e-01) (4, 1.08122631046525571885e-01) (5, 1.98157591982057817992e-01) (6, 3.39616198579795192103e-01) (7, 4.09987085063834633125e-01) (8, 8.96564828814810788060e+00) (9, 1.55800915203877954340e-01) (10, -2.34127396544497523578e+00) (11, 1.58779419221984741117e-01) (12, 4.39176995562464200784e-01) (13, 3.42244990584548769430e-01) (14, 7.83922227644695879256e-01) (15, 3.95830064603616416097e-01) (16, -1.49715269006501588978e-01) (17, 2.63224786317638403954e-01) (18, -8.02515835346462313993e-01) (19, 5.50624531406390671506e-01) (20, 2.17088641354213268686e-01) (21, 2.74625294939312536435e-01) (22, 2.02271608719279322175e-01) 
