FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.38488462442626136806e+00) (1, 6.45693635568716645112e-02) (2, 2.29065103457071761461e-02) (3, 1.49239314906368464309e-01) (4, 1.75802795402775019484e-01) (5, -7.07366237859951008105e-02) (6, 1.73698334572482071536e-01) (7, -1.06735858730348853740e+00) (8, 1.01085558062414967995e-01) (9, 1.61206471846217572197e-02) (10, 9.06696812569558613371e-02) (0, 4.32436779407308158341e+00) (1, 2.84913207015334402072e-01) (2, 3.74626065215407644260e-01) (3, 2.84894502332745824802e-01) (4, 3.55225379189788137424e-01) (5, 1.65150589414069765004e-01) (6, 3.36836782583625149456e-01) (7, -4.08630922650932859597e+00) (8, 7.10137187143058123961e-02) (9, 3.70358682908252689892e-01) (10, 1.46365320533057813313e-01) (0, 5.60769503144723557853e+00) (1, 1.42916351235745220372e+00) (2, 1.28003369695780544468e+00) (3, 1.26411201483843593785e+00) (4, 1.39739952660439259446e+00) (5, 2.06547655673071517413e+00) (6, 1.95008951144263207311e+01) (7, -3.42032500835598618494e+00) (8, 1.56366765708581056948e+00) (9, 6.37826356023431961795e-01) (10, 3.96369665408418503372e-01) (0, 1.00595344390664838130e+01) (1, 7.42624194580205759797e-02) (2, 1.76721287633765627989e-01) (3, 1.65227083231795718321e-01) (4, 2.13701052333701541075e-01) (5, -1.39145830258815683678e+00) (6, 2.65501347483979688313e-01) (7, -1.77386705598512306459e+00) (8, -4.94514578072500821104e-01) (9, 1.48643347105996359581e-01) (10, 5.92827236452928452159e-01) (0, -1.03365830068098274452e+00) (1, 1.11988976160574946195e-01) (2, 1.06064408580351834943e-01) (3, 1.12681611935187372953e-01) (4, 2.59919758239279055645e-02) (5, 1.84253413300783985829e-01) (6, -2.80683863043659054259e-01) (7, 2.05461844185423514464e-01) (8, 4.83543661621045964272e-03) (9, -2.14103606381976147022e-01) (10, 1.68657230550824543958e-01) (0, 4.31897132719029475112e+00) (1, 1.13622094927867692271e-01) (2, 5.78074934469068255072e-02) (3, 1.00961353121837418834e-01) (4, 4.07889219508969988470e-02) (5, 3.13420212052315239060e-02) (6, 9.15226841438107341364e-02) (7, -1.42406859971098653794e+00) (8, 6.92546542947282683933e-02) (9, 1.92571620443270419276e-01) (10, 3.08745881982775860486e-01) (0, 4.57188769913478765261e+00) (1, 3.49230269089642442193e-01) (2, 3.25120309487286485162e-01) (3, 3.73652631536427415337e-01) (4, 3.75489572182598985162e-01) (5, 1.23765923257052126161e+01) (6, 4.85434268188865203353e-01) (7, -5.82374647247864896116e+00) (8, 5.25499559548659789243e+00) (9, 1.13504582491921815479e-01) (10, -4.49030970055759370840e-01) (0, 1.04763405085265528527e+01) (1, 7.76706217598267412150e-01) (2, 6.50372310351677751505e-01) (3, 7.73250966142960405314e-01) (4, 6.25319882106133317912e-01) (5, 3.88478725933563495687e+00) (6, 4.10477120831728647943e+00) (7, -3.00857187548142679390e+00) (8, 1.43325717584148493167e+00) (9, 2.43561646774279827454e-01) (10, 4.07185643458650436965e-01) (0, 4.29338385040034342666e+00) (1, 4.07942764541297658853e-02) (2, 2.96272717496543491755e-02) (3, 6.43577508708625539713e-02) (4, 9.64490629812866095971e-02) (5, -1.01071788520479183271e-01) (6, 2.08406247516069842440e-01) (7, -7.48536876331271083806e-01) (8, 1.08813955908636891823e-01) (9, 4.15309803505946664726e-02) (10, 1.76552459997199151509e-01) (0, 1.06557015521422848714e+00) (1, 2.25409406050516708531e-01) (2, 2.38982739671541766224e-01) (3, 1.70565391703917129673e-01) (4, 3.36203540488554442067e-01) (5, 3.24476756510181721382e-02) (6, 5.57038780411830303230e-01) (7, -8.68981708984778222771e+00) (8, 3.46155673614979897401e-01) (9, 5.67316376755611639915e-01) (10, 4.14469634373383424841e-02) (11, -1.34227954762544093859e-01) (12, -5.17451590976058306559e-01) (13, 3.18132408236166674964e-01) (14, -2.78616087489718500247e-01) (15, 3.86646989115698891393e-01) (16, -1.32930021262652409142e-01) (17, 7.34293830836226235625e-01) (18, 3.89069929991862073493e-01) (19, -1.09061201503170460136e-01) (20, -7.10652886898647806468e-01) (21, 1.67088903693724838417e-01) 
