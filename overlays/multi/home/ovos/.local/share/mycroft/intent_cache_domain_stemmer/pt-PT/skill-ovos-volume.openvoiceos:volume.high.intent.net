FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.75731442510639013221e+01) (1, 2.48770211772585181365e-01) (2, 3.50258705155515936980e-01) (3, 3.93011053042078284392e-01) (4, 2.93891643123293300199e-01) (5, -6.40910535161949912464e+00) (6, -2.30024946678454411675e-01) (7, 1.07431739618540245118e+00) (8, -1.27954167533563700765e+00) (9, 4.68218291946642883872e-01) (10, 9.85406636113676737132e-01) (0, 2.03176152000148846355e+01) (1, 8.42169038911465883679e-01) (2, 9.01906982024316072888e-01) (3, 9.45211067755822420544e-01) (4, 7.55606040318612448559e-01) (5, 8.25233541353881427938e+00) (6, 6.79543502596354320744e-01) (7, 9.00761197140172598097e+00) (8, 4.55676042441664996829e+00) (9, 1.44163142231915397673e+00) (10, -7.68201188476108076664e-01) (0, 2.00146937244651503818e+01) (1, 3.20405696572763631913e-01) (2, 3.25705670805675695512e-01) (3, 3.72346197309000204179e-01) (4, 4.37626612426740835282e-01) (5, -3.97808288674007037855e+00) (6, -8.20876321637197148284e-01) (7, -6.51661927375275729091e-01) (8, -1.39591655051825114242e+00) (9, 4.96972218853233560498e-01) (10, 8.57593244726214121165e-01) (0, -3.23063509913631241588e+00) (1, -8.64429865258865559596e-02) (2, -1.08571583427780185560e-01) (3, -6.84825275319748127956e-02) (4, -8.30727163928680623073e-02) (5, 1.00413268684161982591e+00) (6, 2.67313754222827770768e-01) (7, -1.20736924437107276398e-01) (8, 6.52898624337186928024e-01) (9, 8.41999074782296685893e-02) (10, -1.99917052856082910761e-01) (0, 1.06002133805015041901e+00) (1, 7.02931992642725350651e-02) (2, 3.57982143090612454223e-03) (3, -6.29818067623727669002e-03) (4, -2.88802869684850679888e-02) (5, 7.63437705147579359632e-01) (6, 2.14360337106921639005e+00) (7, -1.11606454081044361715e+01) (8, 2.30863052027424009438e+00) (9, 1.65765601819817476326e+00) (10, 7.48130545832662446903e-02) (0, -3.68628535838563753391e-01) (1, -2.12626718465296557503e-02) (2, -9.91410278264490546496e-02) (3, -9.42062400762049140246e-02) (4, -1.82548109490057647308e-01) (5, 4.21351464761608895948e-01) (6, 6.53982306185092177042e-02) (7, 1.54795059931729062086e+00) (8, 3.46945994349133202128e-01) (9, -1.54816776562115371307e-01) (10, -1.93037956598791943241e-01) (0, 7.64088641098658261086e+00) (1, 4.39236994971146099687e-01) (2, 4.13752522457947302659e-01) (3, 4.35420867194046545823e-01) (4, 4.09607570756783057053e-01) (5, 2.15605603094047948431e+00) (6, 3.03382458735059135080e+00) (7, -3.22119507160747753360e+00) (8, 2.79076742656373610885e+00) (9, 3.95625648118722972324e-01) (10, 2.71033935713902940368e-01) (0, 7.63353436041892763342e-01) (1, -1.06687079876948594237e-02) (2, 1.59744652011961862925e-01) (3, 1.30274655321211740855e-01) (4, -7.59595443907272720868e-03) (5, -1.67477622535576575746e-01) (6, -9.51899684339566898306e-02) (7, -1.52897613650057384582e-01) (8, -1.04085800419768004232e+00) (9, 1.34066344834284645327e-01) (10, 1.50764814607105890332e-01) (0, 1.10412226337649777008e+00) (1, 3.09441951211144074263e-02) (2, 8.03592247064758985475e-02) (3, -1.85239273015807628942e-02) (4, 1.59035619824712426418e-01) (5, 6.63968334007576155287e-01) (6, 2.25779640077092613737e+00) (7, -1.11351297561196371788e+01) (8, 1.81199582592549868210e+00) (9, 1.69184519982929559845e+00) (10, -4.53550650856943404765e-02) (0, 1.99964815997598357455e+01) (1, 6.33662189066550585181e-01) (2, 7.46553594887397253821e-01) (3, 7.39175419032714331458e-01) (4, 7.25474561274192186744e-01) (5, -6.57084918623425284778e+00) (6, -7.45360403250340919357e-01) (7, 1.03256899689496833838e-01) (8, -1.24645285118942195091e+00) (9, 3.57540538420892950455e-01) (10, 9.69664252216372202220e-01) (11, -2.98048075533642542467e-01) (12, 6.31867590823585012494e-01) (13, -1.96032040035302418390e-01) (14, 4.31452543091501716788e-01) (15, -4.01207881154026446691e-01) (16, 2.38115867429900651686e-01) (17, 4.12502520383705162388e-01) (18, 2.49056397834140144654e-02) (19, -3.14173022390808576176e-01) (20, -1.70222528492982166926e-01) (21, 4.27362468037232767770e-01) 
