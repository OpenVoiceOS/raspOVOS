FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 9.61826481212274542187e-01) (1, 3.07054760690991079830e-01) (2, 2.39533210929695844493e-01) (3, 3.64157276984516775631e-01) (4, 3.83416297670666372799e-01) (5, 1.76080157506248169419e+00) (6, -3.83949801143534985570e+00) (7, 1.00890248401954241153e+00) (8, 1.63218455674645102071e+00) (9, 1.01061208921935836713e+01) (10, 2.96104724105729799621e-01) (0, -8.23168562959325722517e-01) (1, -1.55459223796336254431e-01) (2, -2.03033330400197137289e-01) (3, -9.19247851862593223782e-02) (4, -1.68999327827899087362e-01) (5, -1.91430781584447484711e+00) (6, 1.00030018352955671901e+01) (7, -7.40091833281038447012e-01) (8, -7.01322511660063319106e-01) (9, -2.36295574694644378022e-01) (10, -1.14999569921310898502e-01) (0, -2.52086300945262131723e-01) (1, 1.13593039140453724856e-01) (2, 1.66250390038242795709e-01) (3, 1.07499149665584950442e-01) (4, 1.30774018392315338755e-01) (5, 1.53319975616651849037e+01) (6, -4.15618848980953692340e-01) (7, 2.22103317940105959849e-01) (8, 1.64795315676276532546e-01) (9, -5.76640799310602220062e-02) (10, -6.89518304604257170620e-02) (0, 1.08328379748977798869e+00) (1, 2.91393760153351055742e-01) (2, 3.44657823005018459916e-01) (3, 2.52819992163477225144e-01) (4, 2.67103898831901831468e-01) (5, 1.48378495996910803045e-01) (6, -1.14327510584926228532e+00) (7, 1.04514496642939636040e+00) (8, 2.02991641877226136614e+00) (9, 1.64644785624196465790e+01) (10, 1.85347601413198226350e-01) (0, 9.94770068962470999097e-01) (1, 4.29435716968857572606e-01) (2, 2.97776581746422575048e-01) (3, 2.86988122415625379613e-01) (4, 3.73218135935150907567e-01) (5, 3.53329158080859695445e+00) (6, -3.69151072187060158569e+00) (7, 2.82038448133316990152e+01) (8, 5.95893401872533590158e-01) (9, 9.01844211839936527042e+00) (10, 3.20791345795124138718e-01) (0, 3.26052676543850339375e-01) (1, 4.39899702896715982803e-01) (2, 3.90550402333380453079e-01) (3, 4.52175599863173238724e-01) (4, 4.71355078150870188125e-01) (5, -3.50699836527657460294e-01) (6, -5.63286659730077055031e+00) (7, 3.08875160499086420796e-01) (8, 9.50598079311805954639e-01) (9, -9.63592763160187271154e-01) (10, -1.37391424086354074774e-01) (0, 2.38417666832738489591e-01) (1, 6.09762048006208590145e-01) (2, 6.79889319121988466854e-01) (3, 6.66681384325178316708e-01) (4, 6.16240357637556135373e-01) (5, -3.30020144164500858763e-02) (6, -7.53880368272255463324e+00) (7, 4.39432793695692214264e-01) (8, 1.27431510573099004979e+00) (9, -2.80204925845422447850e+00) (10, 1.88274438224299039968e-01) (0, 9.11402199704544058179e-01) (1, 4.71488742238521107986e-01) (2, 5.97703384316205399429e-01) (3, 5.20224290049313919937e-01) (4, 5.96372904336690323746e-01) (5, 1.77923274521811558557e+00) (6, -3.85770538452723199541e+00) (7, 1.20067913228734779452e+00) (8, 1.74369779870936492117e+00) (9, 9.07794561409257205753e+00) (10, 3.91992108653906656812e-01) (0, 7.99599980262092646655e+00) (1, 6.68924671048104046989e-01) (2, 6.74539577597557782340e-01) (3, 6.03466671341835736442e-01) (4, 6.78937260443150281120e-01) (5, -3.15376807678989035111e+00) (6, -3.20827497226586366708e+00) (7, 1.83255816267730731184e+00) (8, 3.46278313044849905822e+00) (9, -8.37897526209895993077e+00) (10, 3.30587668751755980878e+00) (0, 4.78401156975767072321e-02) (1, -4.50388670019380918386e-02) (2, -2.28130772761576186558e-02) (3, 3.08622538991696823696e-02) (4, -1.29038023953842395652e-01) (5, -2.70144214064293120003e+00) (6, -2.54258498468381999302e+00) (7, -8.40375734434766652470e-01) (8, -4.63547288426192138910e-01) (9, -6.69463638720428494411e-02) (10, -9.42926353248280668673e-02) (11, 4.00123668041305891041e-01) (12, 7.86081366207795562140e-01) (13, 3.33423873496454858945e-01) (14, 1.14014032211689611551e-01) (15, 3.15714794890900818380e-01) (16, -1.44911596568957190545e-01) (17, -3.99069969226672760509e-01) (18, 3.07254943745156494650e-01) (19, -2.11736992371087590081e-01) (20, 2.69077650809084988059e-02) (21, 1.43906107165773400336e-01) 
