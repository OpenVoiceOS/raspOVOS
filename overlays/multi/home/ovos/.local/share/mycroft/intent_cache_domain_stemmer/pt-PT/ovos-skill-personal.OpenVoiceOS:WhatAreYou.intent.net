FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.29429596998387097528e+01) (1, 6.06617936135967553146e-02) (2, -1.95645606873789575098e-02) (3, 1.36517488324805147393e-01) (4, 1.37526133024855501397e-01) (5, -1.75786582047569983622e+00) (6, 3.21250401680134434201e+00) (7, 7.72923774547171316129e-01) (8, 2.85113980585700477199e-01) (9, 1.49956999806898338967e+00) (10, 2.61132695489171909320e-02) (11, -2.39065095721875064960e-01) (0, -9.25702618456477210884e+00) (1, 5.20620176164692693987e-01) (2, 5.41566481409853528461e-01) (3, 6.22626734493559430561e-01) (4, 6.48227808593100141010e-01) (5, 3.44863980402871028730e+00) (6, -3.21208147216506167965e+00) (7, 1.88553652354348977305e+00) (8, 3.09351347313120550453e+00) (9, 1.67536546008910169903e+00) (10, 7.25943818733987278335e-01) (11, 8.06569157314086515598e-01) (0, -3.38248376868516553717e-01) (1, -1.68311105784117315265e-02) (2, -1.30624280985533365584e-02) (3, 5.93812881294549371747e-02) (4, 3.35949478927911257542e-02) (5, -3.69762821753910286837e-01) (6, 1.28177162538451705487e+00) (7, 8.61181812516739614294e-02) (8, 6.56217584345659799006e-01) (9, 9.47261443604209940617e-01) (10, 7.21532294814332259003e-02) (11, -4.04310810826056687972e-01) (0, -9.20443212634915397530e+00) (1, 5.44734446153993467910e-01) (2, 5.27700112954731070936e-01) (3, 4.92847597048635399641e-01) (4, 5.69524345741624693495e-01) (5, 3.42777895321770564863e+00) (6, -3.08349349677962303318e+00) (7, 2.87020043293352200564e+00) (8, 2.43840722523060060567e+00) (9, 1.52198135025755659777e-01) (10, 8.35187114820775233781e-01) (11, 7.78229294490600187473e-01) (0, -5.14669749151320843339e+00) (1, -3.49292921882313686655e-02) (2, -3.03102898460072441023e-02) (3, -1.91122470909777116520e-03) (4, -7.27677586537045367754e-02) (5, 1.42969361529294558544e+00) (6, 3.50599733246239886331e-01) (7, -1.52372512501547235919e-01) (8, 3.20886613390451783112e-02) (9, 4.67673853883315421287e-02) (10, 4.05483530984602269509e-01) (11, -1.28089901326714578067e-01) (0, -9.25549265391224906807e+00) (1, 5.84673648296183179340e-01) (2, 6.47079718826597760639e-01) (3, 5.34647615222519578815e-01) (4, 5.32164258478468599201e-01) (5, 3.39727744599505321332e+00) (6, -3.20459819842047854976e+00) (7, 1.87450280227531274058e+00) (8, 2.42464478097286439962e+00) (9, 1.80744985282881698296e+00) (10, 6.71059726722118443654e-01) (11, 7.39660609114093148264e-01) (0, -2.42900317184457126274e+00) (1, 5.57326099416577291912e-01) (2, 4.90439674398267022593e-01) (3, 5.95455779275261831707e-01) (4, 4.88283185800873986704e-01) (5, 3.48266317834778682538e+00) (6, -3.67578130693669358209e+00) (7, 3.36034505046004783324e+00) (8, 2.56553181131857632735e+00) (9, -1.09398224487861650545e+00) (10, 7.50812024710006853390e-01) (11, 8.94049172448634132948e-01) (0, 1.19916278022060431852e+01) (1, -1.77264437536614388735e-01) (2, -1.44704804281609533678e-01) (3, -8.12953044575624311774e-02) (4, -1.16471373001950248560e-01) (5, -5.69119065095426646117e-01) (6, -9.09983050626930412008e-01) (7, 1.17463423193121224708e-01) (8, -5.37330403356886199262e-01) (9, -6.87627161029243483270e-01) (10, -2.51355965361310051964e-01) (11, 6.39962485739258735151e-01) (0, 3.14800323587208996656e-01) (1, -1.41317007274277456341e-01) (2, -1.63511526913292654095e-01) (3, -2.88719657369925913892e-02) (4, -7.66847926684692121624e-02) (5, 2.16978162624835796413e-01) (6, 4.16101870878132384934e-01) (7, 3.64962341851368610168e-01) (8, 1.41940945993727951624e+00) (9, 3.16771984263879313737e-01) (10, 9.17002177662956663440e-01) (11, 3.02252975389553424357e-01) (0, -9.18818647808426902657e+00) (1, 5.46426843641982795674e-01) (2, 5.15907544432865128314e-01) (3, 5.65035853325114967305e-01) (4, 5.57409982918487312276e-01) (5, 3.41337447752877132245e+00) (6, -3.11682686466641589718e+00) (7, 2.75003167251463009890e+00) (8, 1.51738386824824678101e+00) (9, 1.88194744080765685723e+00) (10, 8.13270038909789994008e-01) (11, 8.04752944183135587863e-01) (12, 8.49189603984865870601e-01) (13, -6.79000836557745596211e-02) (14, 7.35931772336715361860e-01) (15, -7.55157691187261920218e-02) (16, 1.17188292488017475890e+00) (17, -5.16417545027136534741e-02) (18, -4.52495777826198292138e-02) (19, -6.06994094055754773720e-01) (20, 1.36918225028589080061e-01) (21, -4.48239070124029845288e-02) (22, 5.53369907304195995934e-01) 
