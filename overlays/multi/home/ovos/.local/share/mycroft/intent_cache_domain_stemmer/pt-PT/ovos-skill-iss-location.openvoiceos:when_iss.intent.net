FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=15 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (15, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.93776808089415997216e+00) (1, 5.10656153383911903809e-01) (2, 4.94677533927620705079e-01) (3, 6.04663250568569732302e-01) (4, 5.37457385632456707825e-01) (5, -4.84319897560576606566e+00) (6, 3.09879829317932675714e-01) (7, -2.30793887589894053392e-01) (8, 2.74159361475785012807e-01) (9, 1.90493638866909453800e-01) (10, 3.84811288212237201378e-01) (11, 1.27589973064594253138e+00) (12, 3.30779224741073507587e+00) (13, 4.38037715099786240103e+00) (14, 2.36703586200800675243e-01) (0, -1.10248782108519205458e+00) (1, -1.55180595702970269834e-01) (2, -3.07532444484079015012e-01) (3, -1.26023344583356594617e-01) (4, -1.58196337408864740048e-01) (5, 1.44725950230029543064e+00) (6, 8.23300075192618385778e-01) (7, 2.05450932597578139749e+00) (8, -2.63819836612219693617e-01) (9, -2.70315488347572907557e-01) (10, -1.66153304917003918906e-01) (11, -6.81196884792629742122e-02) (12, -7.21360056979550301470e-02) (13, 2.47568126548156408617e-01) (14, -2.40271976175364138095e-01) (0, 4.72335312088526193541e-01) (1, 1.82034371864997712720e-01) (2, 2.10948264670574037183e-01) (3, 1.94460092556678620923e-01) (4, 3.10646987033092347730e-01) (5, -3.31461356893637981713e+00) (6, -2.45272354892942079374e-01) (7, -1.32688893045969491524e+00) (8, 4.07804178156635777075e-01) (9, -3.22487267512005099102e-02) (10, -6.37000414389293917461e-02) (11, 3.60145476849119128282e-01) (12, -1.39432641646829752480e-01) (13, -5.03137577552386972002e-01) (14, 2.55593676600426727985e-02) (0, 5.04444691856897886595e-01) (1, 2.63759946894847718823e-01) (2, 2.04382753443919984448e-01) (3, 2.13784980100595323194e-01) (4, 2.51111461293899385083e-01) (5, -2.72313513881767432778e+00) (6, -7.53707049036361209637e-01) (7, -1.43640279052601882448e+00) (8, 2.75028241880915014228e-01) (9, -6.09596517522968950331e-02) (10, -7.44549703438916188336e-02) (11, 4.29626872172322649135e-01) (12, 4.77344776667694148387e-02) (13, -8.91170023430721047752e-01) (14, 8.71932823691338454442e-02) (0, 8.52580938870091398218e-02) (1, 3.12380374329324916882e-01) (2, 3.88341874735590175671e-01) (3, 3.29904005782839016003e-01) (4, 3.43944453554388240857e-01) (5, 1.32422761811668454612e+01) (6, -9.15413644872322684876e-01) (7, -1.50063993176688237341e+00) (8, 2.85845047795648884992e-02) (9, -2.89247120238781019186e-01) (10, -4.33704095400810174521e-01) (11, 1.07561766037397177342e+00) (12, 3.73188289947092277643e+00) (13, 4.12660673572263192455e+00) (14, 1.17410613080202716474e-01) (0, 2.24548216164320546540e+00) (1, 4.35435228719067479730e-01) (2, 4.49539449735236074090e-01) (3, 5.82050882949185055537e-01) (4, 4.86324191762757207513e-01) (5, 3.20156410254739576260e+00) (6, 3.92709906637774497362e-01) (7, 4.80103775486962647268e-01) (8, 9.36147663689768649853e-01) (9, 1.24776270782663378789e+00) (10, 1.29792269488884937090e+00) (11, 4.84824379442900244008e-01) (12, -1.52363636244192890423e+00) (13, -3.20301383364984104674e+00) (14, 7.00361127876627742594e-01) (0, -6.47980446009872479429e-01) (1, 1.06896054717552202451e-01) (2, 1.23457282509918369467e-02) (3, 3.39593186702842886326e-02) (4, 1.25229477610702671225e-02) (5, 1.98846896859346800035e+00) (6, 6.29043553996123550043e-01) (7, 7.98922079450571032133e-01) (8, -8.75464154116479265078e-02) (9, -1.39444519359536389658e-01) (10, -6.57175914432417546118e-02) (11, -4.16687377455853547037e-01) (12, -9.38699455540959043498e-02) (13, -6.22954498113024723871e-01) (14, -6.20421839587060319765e-02) (0, 2.56191684911902894939e+00) (1, 5.21592318397688381459e-01) (2, 4.83049790692257174918e-01) (3, 5.45980568361210338857e-01) (4, 4.96618475150989835409e-01) (5, -1.99642832691460547778e+00) (6, -1.09469936128915712459e+00) (7, -3.07154465222337802466e-01) (8, 3.13194118865215032077e-01) (9, 1.44032341326623680722e-01) (10, 1.52862471426873924862e-01) (11, 9.19065700466553558989e-01) (12, 4.55503214382623333734e+00) (13, 4.95659682783587740573e+00) (14, -9.33221971139320372046e-01) (0, 2.74387972850714256801e-01) (1, 3.40456650512453273816e-01) (2, 3.81828443067308620495e-01) (3, 3.77821729438539699597e-01) (4, 2.29809277611013690334e-01) (5, 1.31559280200655042137e+01) (6, -3.54092482462534829946e-01) (7, -1.66746155312527699621e+00) (8, 1.09417574759709368415e-01) (9, -3.73964908041000410055e-01) (10, -4.40338867224693231162e-01) (11, 1.18888327905587942723e+00) (12, 3.78658420912205917475e+00) (13, 4.07235676361760567943e+00) (14, 7.36752653920045991187e-02) (0, -6.81887345402477307310e-01) (1, 1.08979952308189409482e-01) (2, 9.59078937497253591893e-02) (3, 5.08308902111168081639e-02) (4, -1.32460437986736175725e-02) (5, 1.19852373257824460495e+01) (6, -4.47993521747121203891e-01) (7, -3.55785313661573232569e-03) (8, 1.20486590582342983913e-01) (9, -1.77259690468981240263e-01) (10, -1.15898021090693637003e-01) (11, -2.29409509065770289560e-01) (12, -6.66039498132053875423e-02) (13, -1.97093805830443058458e-01) (14, -6.72366393439141618593e-02) (15, 1.91219109223940864073e-01) (16, 2.31720250625259610588e-01) (17, -5.37429698453307236328e-01) (18, -7.90483423696416331872e-01) (19, 4.78072917862940705014e-01) (20, -1.57388941380723318408e-01) (21, 3.01745036329489901838e-01) (22, 2.13905106412032142149e-01) (23, 3.89851941569853699399e-01) (24, 1.58937298013798633534e-01) (25, 2.60227011150900633396e-01) 
