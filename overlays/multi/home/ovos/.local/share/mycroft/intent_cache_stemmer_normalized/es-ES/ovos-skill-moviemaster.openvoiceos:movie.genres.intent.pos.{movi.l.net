FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=16 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (16, 6, 5.00000000000000000000e-01) (16, 6, 5.00000000000000000000e-01) (16, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (4, 4, 5.00000000000000000000e-01) (0, 4, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.84172467795561844994e+00) (1, -2.17649416589666655497e+00) (2, -8.39500494083832649039e-01) (3, -1.76251436991717724823e+00) (4, -1.62306107194811866101e-01) (5, -1.03596980514789693828e+00) (6, -7.19568403713942150723e-01) (7, -2.22073405122668399159e+00) (8, -1.12252590968066856547e+00) (9, -8.55828417419703391111e-01) (10, 9.41330868638998174980e-01) (11, -4.30927130030252736326e-01) (12, -7.81139062026845687470e-01) (13, -2.62001683793578687975e-01) (14, 1.04814716214654146675e+00) (15, 2.10255823176816303288e+00) (0, -9.39767696218851478207e-01) (1, 7.59818554894430953084e-01) (2, 6.22168387524771049346e-02) (3, 1.49827009899997616316e+01) (4, 2.87136410045224332865e-01) (5, 2.59639603887546976946e-01) (6, 2.11748042110699030705e-01) (7, 8.45164843006382282553e-01) (8, 5.21264474384931730810e+00) (9, 1.78787260187991903226e-01) (10, 2.43445341835422629506e-01) (11, -7.70766858546716671086e-01) (12, 1.51533109494640227943e+00) (13, -5.55289734021020692234e-02) (14, -7.73368617888323228726e-01) (15, -8.31118405120733649838e-01) (0, 3.73014627677749688317e+00) (1, -2.16893210971285155253e+00) (2, -8.75559553286503700065e-01) (3, -1.67273881508138133611e+00) (4, -8.18461473898001029559e-02) (5, -9.56081789162407824634e-01) (6, -7.64271619074583630216e-01) (7, -2.20673643684298648182e+00) (8, -1.23314678831750512700e+00) (9, 3.34363585608331792542e-01) (10, 9.86684437729364538505e-01) (11, -3.99556646691419881101e-01) (12, -7.75833071450101607880e-01) (13, -3.73106663904701041368e-01) (14, 5.69437418360622671365e-01) (15, 2.11250983816102344548e+00) (16, -1.21651067572571900399e+01) (17, 1.35266627725504573476e+00) (18, -1.21931973087527421029e+01) (19, -1.47340165565373570900e+00) 
