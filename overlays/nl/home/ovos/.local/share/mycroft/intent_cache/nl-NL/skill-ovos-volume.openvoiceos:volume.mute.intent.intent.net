FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=10 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (10, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.62772195265430186240e+00) (1, 4.57858251361388468581e-01) (2, 4.13332352368373234786e-01) (3, 3.83715828834313710249e-01) (4, 3.45296824304599125899e-01) (5, 3.22763334811918500833e+00) (6, -1.74373529833874285622e+00) (7, 3.46901081607698458242e+01) (8, 1.13652099491999809544e+01) (9, 2.66714171989129666951e-01) (0, -5.50011404484543109383e-01) (1, -5.82872210252022571186e-02) (2, 1.71301187765860660206e-02) (3, -2.19440935361122982372e-02) (4, 1.97848947537207706104e-02) (5, 1.83731030548560242410e-01) (6, 1.53959337474423718639e+00) (7, 1.82425641892746015493e+00) (8, -1.17562472244686591627e-01) (9, -9.56977012309671304369e-02) (0, 2.82357160288861042119e-01) (1, -8.91172717236110439876e-02) (2, 5.35133128143718758696e-02) (3, -4.39439545296260655749e-02) (4, -5.57456741951534023860e-02) (5, 1.66213926025548963672e+00) (6, -9.06958441344900379022e+00) (7, -3.14614200543632094309e+01) (8, 1.17002169701356129039e+00) (9, -5.95422721023636039583e-02) (0, -1.21234138041624484039e+00) (1, -8.27914616860109392471e-02) (2, -3.28138089574533456383e-02) (3, -1.70851788560267059403e-01) (4, -2.76772594846445181560e-02) (5, 2.27756635902610055089e-01) (6, 1.13837846282440846579e+00) (7, 9.79928932210653691470e-01) (8, 1.19162712205221690831e-01) (9, -7.96688479676582739231e-02) (0, -2.86451985980270329435e+00) (1, -1.73254819268999993298e-01) (2, -1.79005355189427901863e-02) (3, -1.50698462183295189831e-01) (4, -2.68174499819859822602e-02) (5, 3.25956649954068311548e-01) (6, 8.78194577505438500609e-01) (7, 1.10748310643557923427e+00) (8, 3.64264213987966656294e-01) (9, -8.19878964617385547209e-02) (0, 4.16072372866791173607e+00) (1, 5.60509704674268527391e-01) (2, 5.96001692737127219957e-01) (3, 6.14724644149328036669e-01) (4, 4.51978684092546489914e-01) (5, 1.01722567448803324908e+01) (6, -2.68168576950533044112e+00) (7, 3.46327741921900766897e+01) (8, 7.47346784674424391426e+00) (9, -1.63933206039484646865e+00) (0, 3.09583559381886475048e-01) (1, -6.53522005819258400283e-02) (2, -1.09483613684075803407e-01) (3, -4.03593769811568178763e-02) (4, -3.68818259381232180227e-02) (5, 1.11907797308047629592e+00) (6, -9.05442793575926074823e+00) (7, -3.13912489291300360605e+01) (8, 1.19977462205189899791e+00) (9, 1.17706631452154097950e+00) (0, -1.69593852648751952650e+00) (1, -2.04148084471807017559e-02) (2, -1.57344905341683327649e-01) (3, -1.81888626570521294568e-01) (4, -1.54626590813218056653e-01) (5, 9.33641099018718834124e-02) (6, 9.99641553943735994281e-01) (7, 9.64489306407283142342e-01) (8, 2.20839604260657351720e-01) (9, -4.27759527161254426986e-02) (0, -3.48904978080646521743e-01) (1, 1.01663019881251676102e-01) (2, 1.18936266756089845803e-02) (3, -1.96511108422247407490e-02) (4, 9.26018472766908240512e-02) (5, 4.41703339751965351478e-01) (6, 1.85795534485701807625e+00) (7, 2.52700731288594360180e+00) (8, -4.08162106299520766051e-01) (9, 1.43646067847818970087e-01) (0, -5.51082251541674228434e-01) (1, -1.26720993029808860764e-02) (2, -4.39834548341965503315e-02) (3, -1.84002248751854793896e-02) (4, -1.14707618038628098023e-01) (5, 1.65044173474061084406e-01) (6, 1.53892718853074383922e+00) (7, 1.80206926046207471792e+00) (8, -2.26923104188495664002e-02) (9, -9.06468520614744088792e-02) (10, 4.42200086250009893885e-01) (11, 3.18691344351120342537e-01) (12, -1.61701167205645257585e-01) (13, 3.44071269990576300568e-01) (14, 3.87036021512457917293e-01) (15, 4.42981955226480927923e-01) (16, -1.18831861163038302043e-01) (17, 4.08386610161969254573e-01) (18, 3.97039365008185263228e-01) (19, 3.57302300926903459999e-01) (20, 3.08374208919606040968e-01) 
